[["Map",1,2,9,10,65,66,112,113,852,853],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.6","content-config-digest","d96ef7641e0762c2","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://snugug.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"monokai\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null,null,null,null,null],\"rehypePlugins\":[],\"remarkRehype\":{\"handlers\":{}},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","categories",["Map",11,12,26,27,39,40,52,53],"raphaël-js",{"id":11,"data":13,"filePath":16,"digest":17,"rendered":18},{"title":14,"description":15},"Raphaël JS",null,"src/content/categories/raphaël-js.md","87d76fe5ab75f6f1",{"html":19,"metadata":20},"",{"headings":21,"localImagePaths":22,"remoteImagePaths":23,"frontmatter":24,"imagePaths":25},[],[],[],{"title":14,"description":15},[],"responsive-web-design",{"id":26,"data":28,"filePath":30,"digest":31,"rendered":32},{"title":29,"description":15},"Responsive Web Design","src/content/categories/responsive-web-design.md","74775585d7b683c9",{"html":19,"metadata":33},{"headings":34,"localImagePaths":35,"remoteImagePaths":36,"frontmatter":37,"imagePaths":38},[],[],[],{"title":29,"description":15},[],"svg",{"id":39,"data":41,"filePath":43,"digest":44,"rendered":45},{"title":42,"description":15},"SVG","src/content/categories/svg.md","4082b21a5faf7506",{"html":19,"metadata":46},{"headings":47,"localImagePaths":48,"remoteImagePaths":49,"frontmatter":50,"imagePaths":51},[],[],[],{"title":42,"description":15},[],"web-development",{"id":52,"data":54,"filePath":56,"digest":57,"rendered":58},{"title":55,"description":15},"Web Development","src/content/categories/web-development.md","2e4a927f905ffd8b",{"html":19,"metadata":59},{"headings":60,"localImagePaths":61,"remoteImagePaths":62,"frontmatter":63,"imagePaths":64},[],[],[],{"title":55,"description":15},[],"pages",["Map",67,68,93,94],"me",{"id":67,"data":69,"body":72,"filePath":73,"digest":74,"rendered":75},{"title":70,"summary":71},"About Me","The professional biography and headshot of Sam Richard, aka Snugug.","![Headshot of Sam](/images/me/square.jpg){.headshot}\n\nHey there! I'm Sam! I work at [Google](https://www.google.com) as a Developer Advocate for Chrome OS!\n\nPrior to Google, I worked at [IBM](https://www.ibm.com/us-en/) as the UI Architect for Websites and Platform for [Watson](https://www.ibm.com/watson/), the Agile Team Experience Lead for the CIO, and the engineering lead for IBM's Digital Technical Engagement team. I got my start with the [New York State Senate](http://www.nysenate.gov) and have worked for the [World Economic Forum](http://www.weforum.org) and [NBCUniversal](http://www.nbcuniversal.com/) where a love of Open Source, Open Government, and generally an Open World were instilled and reinforced.\n\nI do quite a bit of public speaking and training. Most of my [presentations](/presentations) are available online, with some even having videos! If you see me out at a conference, come say hi! I also have contributed a lot of open source work, which you can get to from [my GitHub page](https://github.com/snugug).\n\nIf you wanna chat with me, the best way to is to ping me on Mastodon [@sam@snugug.com](https://mas.to/@snugug). If you like pictures of food, I'm [on Instagram](https://www.instagram.com/snugug/) too. If it's something about one of the projects I maintain, please file an issue instead of pinging me directly. I've also got a handy list of [links](/links) for all the ways to connect with me.\n\n## Conference Bios\n\n**The Personal**\n\n> Sam Richard, better known as Snugug throughout the Internet, is a developer with design tendencies and a love of building open source tools to help with both. Sam geeks out on content strategy, team process, and cultural transformation. His social media feed, though, is mostly food.\n>\n> Sam is currently working at Google to help companies build and deliver their web applications for Chrome and Chrome OS.\n\n**The Professional**\n\n> Sam Richard, better known as Snugug throughout the Internet, is a Developer Advocate for Chrome OS at Google. He has a background leading software architecture, development, design, and strategy for the web at Fortune 100 companies, and loves being able to share the knowledge he's gained doing so with anyone interested through teaching, speaking, and open source work. Outside of work, Sam is an avid amateur chef, foodie, and photographer, and often combines all three.\n\n## Licenses For My Site\n\nAll of the code and writing on this site falls under the [licenses outlined](https://github.com/Snugug/blog/blob/master/LICENSE.md) for the actual site itself! Everything is open sourced!\n\n## Disclaimer\n\nYou know, the standard _views and opinions are my own_ spiel. I speak for myself, not for any current, former, or future employers, or the communities I'm a member of, even if my words are echoed by others, or even myself in a official alter-ego.\n\nTo the best of my knowledge, all code and writing is original, derivative under or from an acceptable license, or appropriately credited.","src/content/pages/me.md","a73cdc0028982e29",{"html":76,"metadata":77},"\u003Cp>\u003Cimg src=\"/images/me/square.jpg\" alt=\"Headshot of Sam\" class=\"headshot\">\u003C/p>\n\u003Cp>Hey there! I’m Sam! I work at \u003Ca href=\"https://www.google.com\">Google\u003C/a> as a Developer Advocate for Chrome OS!\u003C/p>\n\u003Cp>Prior to Google, I worked at \u003Ca href=\"https://www.ibm.com/us-en/\">IBM\u003C/a> as the UI Architect for Websites and Platform for \u003Ca href=\"https://www.ibm.com/watson/\">Watson\u003C/a>, the Agile Team Experience Lead for the CIO, and the engineering lead for IBM’s Digital Technical Engagement team. I got my start with the \u003Ca href=\"http://www.nysenate.gov\">New York State Senate\u003C/a> and have worked for the \u003Ca href=\"http://www.weforum.org\">World Economic Forum\u003C/a> and \u003Ca href=\"http://www.nbcuniversal.com/\">NBCUniversal\u003C/a> where a love of Open Source, Open Government, and generally an Open World were instilled and reinforced.\u003C/p>\n\u003Cp>I do quite a bit of public speaking and training. Most of my \u003Ca href=\"/presentations\">presentations\u003C/a> are available online, with some even having videos! If you see me out at a conference, come say hi! I also have contributed a lot of open source work, which you can get to from \u003Ca href=\"https://github.com/snugug\">my GitHub page\u003C/a>.\u003C/p>\n\u003Cp>If you wanna chat with me, the best way to is to ping me on Mastodon \u003Ca href=\"https://mas.to/@snugug\">@sam@snugug.com\u003C/a>. If you like pictures of food, I’m \u003Ca href=\"https://www.instagram.com/snugug/\">on Instagram\u003C/a> too. If it’s something about one of the projects I maintain, please file an issue instead of pinging me directly. I’ve also got a handy list of \u003Ca href=\"/links\">links\u003C/a> for all the ways to connect with me.\u003C/p>\n\u003Ch2 id=\"conference-bios\">Conference Bios\u003C/h2>\n\u003Cp>\u003Cstrong>The Personal\u003C/strong>\u003C/p>\n\u003Cblockquote>\n\u003Cp>Sam Richard, better known as Snugug throughout the Internet, is a developer with design tendencies and a love of building open source tools to help with both. Sam geeks out on content strategy, team process, and cultural transformation. His social media feed, though, is mostly food.\u003C/p>\n\u003Cp>Sam is currently working at Google to help companies build and deliver their web applications for Chrome and Chrome OS.\u003C/p>\n\u003C/blockquote>\n\u003Cp>\u003Cstrong>The Professional\u003C/strong>\u003C/p>\n\u003Cblockquote>\n\u003Cp>Sam Richard, better known as Snugug throughout the Internet, is a Developer Advocate for Chrome OS at Google. He has a background leading software architecture, development, design, and strategy for the web at Fortune 100 companies, and loves being able to share the knowledge he’s gained doing so with anyone interested through teaching, speaking, and open source work. Outside of work, Sam is an avid amateur chef, foodie, and photographer, and often combines all three.\u003C/p>\n\u003C/blockquote>\n\u003Ch2 id=\"licenses-for-my-site\">Licenses For My Site\u003C/h2>\n\u003Cp>All of the code and writing on this site falls under the \u003Ca href=\"https://github.com/Snugug/blog/blob/master/LICENSE.md\">licenses outlined\u003C/a> for the actual site itself! Everything is open sourced!\u003C/p>\n\u003Ch2 id=\"disclaimer\">Disclaimer\u003C/h2>\n\u003Cp>You know, the standard \u003Cem>views and opinions are my own\u003C/em> spiel. I speak for myself, not for any current, former, or future employers, or the communities I’m a member of, even if my words are echoed by others, or even myself in a official alter-ego.\u003C/p>\n\u003Cp>To the best of my knowledge, all code and writing is original, derivative under or from an acceptable license, or appropriately credited.\u003C/p>",{"headings":78,"localImagePaths":89,"remoteImagePaths":90,"frontmatter":91,"imagePaths":92},[79,83,86],{"depth":80,"slug":81,"text":82},2,"conference-bios","Conference Bios",{"depth":80,"slug":84,"text":85},"licenses-for-my-site","Licenses For My Site",{"depth":80,"slug":87,"text":88},"disclaimer","Disclaimer",[],[],{"title":70,"summary":71},[],"presentations",{"id":93,"data":95,"body":98,"filePath":99,"digest":100,"rendered":101},{"title":96,"summary":97},"Presentations","Presentations Sam has given over the years","A simple list linking to the slides of presentations I've given. Only the most recent version of each presentation will be available. Newer talks will be first.\n\n- [Slides About Slides](https://snugug.github.io/slides-about-slides/)\n  - [EmpireJS](https://www.youtube.com/watch?v=g3UgJB2AWas) (video)\n- [Magic Tricks with Houdini](http://snugug.github.io/magic-tricks-with-houdini/)\n- [Building a Front-End Development Community at Work](https://snugug.github.io/building-fed/)\n- [Domo Arigato Mr. Roboto](http://snugug.github.io/mr-roboto/#/) (Cognitive Computing)\n  - [JSConf EU](https://www.youtube.com/watch?v=pKtG4dO-9Tw) (video)\n- [People First](http://snugug.github.io/people-first/)\n- [Yo Yo!](http://snugug.github.io/yo-yo/#/)\n- [Designing the Modern Web, Redux](http://snugug.github.io/modern-web-redux/#/)\n- [Content Strategy Deliverables](http://snugug.github.io/content-strategy-deliverables/#/)\n  - [DrupalCon Austin, June 2014](https://www.youtube.com/watch?v=jdMBc-pX84g) (video)\n- [Advanced Responsive Web Design (DrupalCon Austin)](http://fourkitchens.github.io/adv-rwd-with-sass/#/) (training)\n- [5 Outdated UX Patterns That Are Losing You Money!](http://snugug.github.io/Outdated-UX-Patterns/)\n- [Designing The Modern Web](http://snugug.github.io/designing-the-modern-web/#/) (training)\n- [Get Sassy](http://snugug.github.io/get-sassy/#/) (training)\n- [Advanced Responsive Design](http://snugug.github.io/rwd-sass-compass/#/) (training)\n- [Winning the Web with Twitter Bootstrap](http://snugug.github.io/winning-the-web/#/)\n- [Responsive Grids](http://snugug.github.io/responsive-grids/)\n- [Intro to the Command Line](http://snugug.github.io/Intro-Command-Line/)\n- [Responsive Design Challenges Roundtable](https://www.youtube.com/watch?v=U2VShQfHYb4) (video)\n- [Advertising in a Responsive World](https://www.youtube.com/watch?v=IVenIsCZpcc) (video)\n- [Style Prototyping](http://snugug.github.io/Style-Prototyping/)\n  - [NYC Camp, July 2013](http://drupaltv.org/video/style-prototyping) (video)\n  - [DrupalCon Prague, September 2013](https://www.youtube.com/watch?v=0C9BHQXa9zo) (video)\n- [Advanced RWD with Sass+Compass](http://snugug.github.io/advanced-rwd/) (training, NYC Camp 2013)\n- [Responsive Web Design with Sass+Compass](http://snugug.github.io/RWD-with-Sass-Compass/)\n  - [DrupalCon Munich, August 2012](http://snugug.com/musings/drupalcon-munich-presentation) (video)\n\n## Resources\n\nA list of resources I've created while giving presentations:\n\n- [Get Sassy Codebase](https://github.com/snugug/code-get-sassy) - In-training codebase for Get Sassy\n- [Advanced Responsive Design Codebase](https://github.com/snugug/code-rwd-sass-compass) - In-training codebase for Advanced Responsive Design\n- [Training Glossary](https://github.com/snugug/training-glossary/wiki) - Big glossary of terms and techniques used during my presentations and trainings.","src/content/pages/presentations.md","30ac906d37613b55",{"html":102,"metadata":103},"\u003Cp>A simple list linking to the slides of presentations I’ve given. Only the most recent version of each presentation will be available. Newer talks will be first.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://snugug.github.io/slides-about-slides/\">Slides About Slides\u003C/a>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.youtube.com/watch?v=g3UgJB2AWas\">EmpireJS\u003C/a> (video)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/magic-tricks-with-houdini/\">Magic Tricks with Houdini\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://snugug.github.io/building-fed/\">Building a Front-End Development Community at Work\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/mr-roboto/#/\">Domo Arigato Mr. Roboto\u003C/a> (Cognitive Computing)\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.youtube.com/watch?v=pKtG4dO-9Tw\">JSConf EU\u003C/a> (video)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/people-first/\">People First\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/yo-yo/#/\">Yo Yo!\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/modern-web-redux/#/\">Designing the Modern Web, Redux\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/content-strategy-deliverables/#/\">Content Strategy Deliverables\u003C/a>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.youtube.com/watch?v=jdMBc-pX84g\">DrupalCon Austin, June 2014\u003C/a> (video)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Ca href=\"http://fourkitchens.github.io/adv-rwd-with-sass/#/\">Advanced Responsive Web Design (DrupalCon Austin)\u003C/a> (training)\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/Outdated-UX-Patterns/\">5 Outdated UX Patterns That Are Losing You Money!\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/designing-the-modern-web/#/\">Designing The Modern Web\u003C/a> (training)\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/get-sassy/#/\">Get Sassy\u003C/a> (training)\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/rwd-sass-compass/#/\">Advanced Responsive Design\u003C/a> (training)\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/winning-the-web/#/\">Winning the Web with Twitter Bootstrap\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/responsive-grids/\">Responsive Grids\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/Intro-Command-Line/\">Intro to the Command Line\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.youtube.com/watch?v=U2VShQfHYb4\">Responsive Design Challenges Roundtable\u003C/a> (video)\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.youtube.com/watch?v=IVenIsCZpcc\">Advertising in a Responsive World\u003C/a> (video)\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/Style-Prototyping/\">Style Prototyping\u003C/a>\n\u003Cul>\n\u003Cli>\u003Ca href=\"http://drupaltv.org/video/style-prototyping\">NYC Camp, July 2013\u003C/a> (video)\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.youtube.com/watch?v=0C9BHQXa9zo\">DrupalCon Prague, September 2013\u003C/a> (video)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/advanced-rwd/\">Advanced RWD with Sass+Compass\u003C/a> (training, NYC Camp 2013)\u003C/li>\n\u003Cli>\u003Ca href=\"http://snugug.github.io/RWD-with-Sass-Compass/\">Responsive Web Design with Sass+Compass\u003C/a>\n\u003Cul>\n\u003Cli>\u003Ca href=\"http://snugug.com/musings/drupalcon-munich-presentation\">DrupalCon Munich, August 2012\u003C/a> (video)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"resources\">Resources\u003C/h2>\n\u003Cp>A list of resources I’ve created while giving presentations:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://github.com/snugug/code-get-sassy\">Get Sassy Codebase\u003C/a> - In-training codebase for Get Sassy\u003C/li>\n\u003Cli>\u003Ca href=\"https://github.com/snugug/code-rwd-sass-compass\">Advanced Responsive Design Codebase\u003C/a> - In-training codebase for Advanced Responsive Design\u003C/li>\n\u003Cli>\u003Ca href=\"https://github.com/snugug/training-glossary/wiki\">Training Glossary\u003C/a> - Big glossary of terms and techniques used during my presentations and trainings.\u003C/li>\n\u003C/ul>",{"headings":104,"localImagePaths":108,"remoteImagePaths":109,"frontmatter":110,"imagePaths":111},[105],{"depth":80,"slug":106,"text":107},"resources","Resources",[],[],{"title":96,"summary":97},[],"recipes",["Map",114,115,247,248,413,414,539,540,599,600,712,713,771,772],"brown-butter-sage-and-wild-mushroom-dressing",{"id":114,"data":116,"body":201,"filePath":202,"digest":203,"rendered":204},{"title":117,"published":118,"yield":119,"difficulty":120,"image":121,"instructions":122},"Brown Butter, Sage, and Wild Mushroom Dressing",["Date","2023-10-31T00:00:00.000Z"],"6-8 portions","medium","/src/images/recipes/brown-butter-sage-and-wild-mushroom-dressing.jpg",[123,139,170,185],{"time":124,"equipment":126,"ingredients":128,"procedure":137},{"active":125},"15 minutes",[127],"Saucepan",[129,132,135],{"name":130,"amount":131},"Mushroom stock","4 cups",{"name":133,"amount":134},"Dried shitake mushrooms","5",{"name":136,"amount":134},"Dried porcini mushrooms",[138],"Add mushroom stock and dried mushrooms into a saucepan and bring to a simmer for 15 minutes. Once done, remove from the heat and discard the dried mushrooms",{"time":140,"equipment":141,"ingredients":143,"procedure":164},{"active":125},[142],"Large skillet",[144,147,150,153,156,159,161],{"name":145,"amount":146},"Mixed wild mushrooms","700g",{"name":148,"amount":149},"Large yellow onion","1",{"name":151,"amount":152},"Thyme, finely shopped","2 tbsp",{"name":154,"amount":155},"Sage, finely chopped","3 tbsp",{"name":157,"amount":158},"Garlic","5 cloves",{"name":160,"amount":152},"Unsalted butter",{"name":162,"amount":163},"Kosher salt and freshly ground pepper","To taste",[165,166,167,168,169],"Preheat oven to 375 degrees","Heat a large skillet over medium-high heat, add butter, and sauté onions until they become translucent, about 4 minutes","Add garlic, thyme, and sage, and cook until fragrant, about 1 minute","Add mushrooms, salt and pepper, and cook until mushrooms have given up most of their water and are soft and caramelized","Add fortified mushroom stock and bring to a simmer",{"time":171,"equipment":173,"ingredients":175,"procedure":182},{"active":172},"5 minutes",[174],"Large bowl",[176,179],{"name":177,"amount":178},"Potato bread, cut into bite-sized cubes","570g",{"name":180,"amount":181},"Large eggs","2",[183,184],"Lightly beat both eggs","In a large bowl, combine mushrooms mixture, stuffing cubes, and eggs together and mix. The dressing should be very wet. Add more mushroom stock as needed",{"time":186,"equipment":189,"ingredients":192,"procedure":196},{"active":172,"inactive":187,"rest":188},"60 minutes","10 minutes",[190,191],"13x9x2 glass baking dish","Medium saucepan",[193],{"name":194,"amount":195},"Unsalted butter, plus more for greasing","4 tbsp",[197,198,199,200],"Grease the baking dish, then scrape the dressing mixture into the dish","Melt the 4tbsp butter in a medium saucepan over medium-high heat Cook, gently swirling pan constantly, until particles begin to turn golden brown and butter smells nutty, about 5 minutes. Remove from heat and continue swirling the pan until the butter is a rich brown, about 15 seconds longer. Pour evenly over the dressing mixture","Cover with aluminum foil and bake for 50-60 minutes until the top is golden brown, removing the foil after 20 minutes","Let cool for 10 minutes before serving","For the past five years, this has been my family's go-to Thanksgiving dressing recipe. It came to be thanks to two unexpected circumstances coming together at the same time. The first was meeting my partner; this was our first Thanksgiving together and she mostly eats vegetarian. That means our normally meat-filled dressing wasn't going to cut it. The second was my best friend being the definition of _extra_.\n\nSee, my friend was driving through Pennsylvania on his way to Thanksgiving at his parents, and in doing so, he was going to pass by mushroom farms. Did you know Pennsylvania grows [the majority of all mushrooms in the country](https://dced.pa.gov/paproudblog/did-you-know-pennsylvania-is-home-to-the-largest-grower-of-specialty-mushrooms/)? He called and asked if I wanted some mushrooms, I said yes, and he turned up with a 5lb box of mixed mushrooms, ranging from portobello to oysters to shiitakes to creminis, all for $16. Long story short: I had more mushrooms than I knew what to do with.\n\nFrom there, the rest of the recipe kinda fell together. I found potato bread stuffing cubes at my supermarket, and thought it'd be a nice addition. The slightly sweet, slightly earthy, super soft qualities of potato bread happen to make for amazing stuffing cubes. I didn't want to use chicken stock like I normally would, and like the potato bread cubes, I found mushroom stock at my supermarket, something I thought would give better flavor than just vegetable stock (fortifying with the dried mushrooms came the year after) I was (and still am) a little obsessed with brown butter, and knew that its nuttiness would go well with the mushrooms and goes with sage, so the butter and aromatics just fell into place.\n\nAs if you needed any more proof how much I love this dressing, the first Thanksgiving after I was [diagnosed with diabetes](/musings/a-beginners-guide-to-diabetes/) and was keeping myself on a very strict 30 grams of net carbs per day diet, I wrote this note in my low-carb Thanksgiving recipe guide:\n\n> While not technically low carb, the actual bread used is 16g net carbs per cup, and if you're going to splurge on carbs for any part of the meal, it may as well be the dressing.","src/content/recipes/brown-butter-sage-and-wild-mushroom-dressing.md","93d6a8585f8da239",{"html":205,"metadata":206},"\u003Cp>For the past five years, this has been my family’s go-to Thanksgiving dressing recipe. It came to be thanks to two unexpected circumstances coming together at the same time. The first was meeting my partner; this was our first Thanksgiving together and she mostly eats vegetarian. That means our normally meat-filled dressing wasn’t going to cut it. The second was my best friend being the definition of \u003Cem>extra\u003C/em>.\u003C/p>\n\u003Cp>See, my friend was driving through Pennsylvania on his way to Thanksgiving at his parents, and in doing so, he was going to pass by mushroom farms. Did you know Pennsylvania grows \u003Ca href=\"https://dced.pa.gov/paproudblog/did-you-know-pennsylvania-is-home-to-the-largest-grower-of-specialty-mushrooms/\">the majority of all mushrooms in the country\u003C/a>? He called and asked if I wanted some mushrooms, I said yes, and he turned up with a 5lb box of mixed mushrooms, ranging from portobello to oysters to shiitakes to creminis, all for $16. Long story short: I had more mushrooms than I knew what to do with.\u003C/p>\n\u003Cp>From there, the rest of the recipe kinda fell together. I found potato bread stuffing cubes at my supermarket, and thought it’d be a nice addition. The slightly sweet, slightly earthy, super soft qualities of potato bread happen to make for amazing stuffing cubes. I didn’t want to use chicken stock like I normally would, and like the potato bread cubes, I found mushroom stock at my supermarket, something I thought would give better flavor than just vegetable stock (fortifying with the dried mushrooms came the year after) I was (and still am) a little obsessed with brown butter, and knew that its nuttiness would go well with the mushrooms and goes with sage, so the butter and aromatics just fell into place.\u003C/p>\n\u003Cp>As if you needed any more proof how much I love this dressing, the first Thanksgiving after I was \u003Ca href=\"/musings/a-beginners-guide-to-diabetes/\">diagnosed with diabetes\u003C/a> and was keeping myself on a very strict 30 grams of net carbs per day diet, I wrote this note in my low-carb Thanksgiving recipe guide:\u003C/p>\n\u003Cblockquote>\n\u003Cp>While not technically low carb, the actual bread used is 16g net carbs per cup, and if you’re going to splurge on carbs for any part of the meal, it may as well be the dressing.\u003C/p>\n\u003C/blockquote>",{"headings":207,"localImagePaths":208,"remoteImagePaths":209,"frontmatter":210,"imagePaths":246},[],[],[],{"title":117,"published":211,"yield":119,"difficulty":120,"image":121,"instructions":212},"2023-10-31",[213,221,233,240],{"time":214,"equipment":215,"ingredients":216,"procedure":220},{"active":125},[127],[217,218,219],{"name":130,"amount":131},{"name":133,"amount":134},{"name":136,"amount":134},[138],{"time":222,"equipment":223,"ingredients":224,"procedure":232},{"active":125},[142],[225,226,227,228,229,230,231],{"name":145,"amount":146},{"name":148,"amount":149},{"name":151,"amount":152},{"name":154,"amount":155},{"name":157,"amount":158},{"name":160,"amount":152},{"name":162,"amount":163},[165,166,167,168,169],{"time":234,"equipment":235,"ingredients":236,"procedure":239},{"active":172},[174],[237,238],{"name":177,"amount":178},{"name":180,"amount":181},[183,184],{"time":241,"equipment":242,"ingredients":243,"procedure":245},{"active":172,"inactive":187,"rest":188},[190,191],[244],{"name":194,"amount":195},[197,198,199,200],[],"fragrant-sticky-rice-yuzu-chicken",{"id":247,"data":249,"body":362,"filePath":363,"digest":364,"rendered":365},{"title":250,"published":251,"yield":252,"difficulty":253,"image":254,"instructions":255},"Fragrant Sticky Rice with Yuzu Chicken",["Date","2019-12-07T00:00:00.000Z"],"2 servings","easy","/src/images/recipes/fragrant-sticky-rice-yuzu-chicken.jpg",[256,297,330],{"time":257,"ingredients":259,"procedure":289},{"active":172,"rest":258},"2-24 hours",[260,263,266,269,272,274,277,280,283,286],{"name":261,"amount":262},"Yuzu juice","5 tsp, about 5 fresh fruit",{"name":264,"amount":265},"Mirin","5 tbsp",{"name":267,"amount":268},"Olive oil","1 tbsp",{"name":270,"amount":271},"Lemongrass","1 stick",{"name":157,"amount":273},"4 cloves",{"name":275,"amount":276},"Galangal or ginger","1 inch",{"name":278,"amount":279},"Scallion whites","6-8",{"name":281,"amount":282},"Boneless, skinless chicken breast or thighs","1 lb",{"name":284,"amount":285},"Kosher salt","2 tsp",{"name":287,"amount":288},"Freshly ground black pepper","1 tsp",[290,291,292,293,294,295,296],"Place yuzu juice, mirin, olive oil, salt, and pepper in a quart container or similar.","Remove the outer layer from the lemongrass, exposing its core, remove both ends, divide into equal-sized pieces, crush, and add to the liquid.","Remove the outer layer from the galangal, cut into rounds, and add to the liquid.","Crush the garlic and scallion whites and add to the liquid.","Place a cap on the liquid and shake vigorously to combine all ingredients and lightly emulsify.","Cut the chicken into bite-sized cubes and add to the liquid, making sure all cubes are submerged.","Cover the container and refrigerate at least 2 hours, up to 24 hours.",{"time":298,"equipment":300,"ingredients":304,"procedure":323},{"active":188,"inactive":299},"20 minutes",[301,302,303],"High-power blender","Fine mesh sieve","Pressure cooker",[305,308,311,313,314,317,320],{"name":306,"amount":307},"Sticky rice","1 cup",{"name":309,"amount":310},"Water","As needed",{"name":275,"amount":312},"1/2 inch",{"name":270,"amount":271},{"name":315,"amount":316},"Coconut water","2/3 cup, plus more as needed",{"name":318,"amount":319},"Kafir lime leaf","4 leaves",{"name":321,"amount":322},"Sugar (optional)","1/2 tbsp",[324,325,326,327,328,329],"Add coconut water, sugar, and lime leaves to hopper of a high-powered blender.","Remove the outer layer from the lemongrass, exposing its core, remove both ends, divide into equal-sized pieces, and add to the blender.","Remove the outer layer from the galangal, cut in half, and add to the blender.","Blend on high until no solids remain and and mixture is evenly combined.","Filter liquid through fine mesh sieve, reserving the liquid and discarding the solids.","Fill pressure cooker to its minimum fill line with water, place a stainless steel steaming rack or similar stand into the water ensuring its top sits above the water line, add rice and liquid into a flat-bottomed stainless steel bowl, ensuring the liquid covers the rice (if not, add more coconut water), and pressure cook on high (12psi) for 12 minutes. Let the pressure come down naturally when cooking is complete. ",{"time":331,"ingredients":332,"procedure":349},{"active":125},[333,335,337,339,340,342,344,347],{"name":334,"amount":195},"Vegetable oil",{"name":336,"amount":282},"Leafy Chinese greens, like snow pea leaves or Chinese broccoli",{"name":157,"amount":338},"6 cloves",{"name":264,"amount":268},{"name":341,"amount":268},"Cornstartch",{"name":309,"amount":343},"1 cup plus 2 tbsp",{"name":345,"amount":346},"Scallion greens","6-8 scallions",{"name":348,"amount":288},"Toasted sesame oil",[350,351,352,353,354,355,356,357,358,359,360,361],"Preheat pan or wok over high heat","Rinse leafy greens and trim away any thick stems.","Finely slice garlic into very thin slivers.","Cut the scallion greens on a bias into thin slices.","Add 2 tbsp of vegetable oil to hot pan, add garlic and cook until fragrant and lightly golden brown, add the leafy greens, and cook down until greens are bright green and tender. They should shrink significantly in size. Remove from pan, set aside, and cover.","Add remaining 2 tbsp of vegetable oil to pan and heat.","Invert the chicken container into a bowl, remove the crushed aromatics, and add them to the hot oil. Cook until fragrant, then remove.","Pour chicken and marinade into hot pan with now fragrant oil and cook until chicken no longer appears raw.","Combine cornstarch and water together to form a slurry.","Add 3/4 of the scallions plus the water, mirin, and slurry to the pan, stir to combine evenly, and then cook down until most of the liquid has boiled off and the sauce has thickened.","Add the toasted sesame oil, toss to combine, then remove from heat.","Plate the chicken with the sauce over the sticky rice and garnish with remaining scallions.","When I first came up with this recipe for fragrant sticky rice, it was such a revelation in our house that it's become a practical staple on our table. Cooking it in a pressure cooker means that it doesn't need to be presoaked and can be done on a weeknight. But rice alone does not a dish make. After experimenting with a few different vegetable and topping options, I finally settled on leafy Chinese veggies and this diced yuzu marinated chicken; the combination of everything is truly hard to beat. With the marinade coming together quickly the night before, this is a tasty and easy weeknight dish.","src/content/recipes/fragrant-sticky-rice-yuzu-chicken.md","6e36880632a52b3c",{"html":366,"metadata":367},"\u003Cp>When I first came up with this recipe for fragrant sticky rice, it was such a revelation in our house that it’s become a practical staple on our table. Cooking it in a pressure cooker means that it doesn’t need to be presoaked and can be done on a weeknight. But rice alone does not a dish make. After experimenting with a few different vegetable and topping options, I finally settled on leafy Chinese veggies and this diced yuzu marinated chicken; the combination of everything is truly hard to beat. With the marinade coming together quickly the night before, this is a tasty and easy weeknight dish.\u003C/p>",{"headings":368,"localImagePaths":369,"remoteImagePaths":370,"frontmatter":371,"imagePaths":412},[],[],[],{"title":250,"published":372,"yield":252,"difficulty":253,"image":254,"instructions":373},"2019-12-07",[374,388,400],{"time":375,"ingredients":376,"procedure":387},{"active":172,"rest":258},[377,378,379,380,381,382,383,384,385,386],{"name":261,"amount":262},{"name":264,"amount":265},{"name":267,"amount":268},{"name":270,"amount":271},{"name":157,"amount":273},{"name":275,"amount":276},{"name":278,"amount":279},{"name":281,"amount":282},{"name":284,"amount":285},{"name":287,"amount":288},[290,291,292,293,294,295,296],{"time":389,"equipment":390,"ingredients":391,"procedure":399},{"active":188,"inactive":299},[301,302,303],[392,393,394,395,396,397,398],{"name":306,"amount":307},{"name":309,"amount":310},{"name":275,"amount":312},{"name":270,"amount":271},{"name":315,"amount":316},{"name":318,"amount":319},{"name":321,"amount":322},[324,325,326,327,328,329],{"time":401,"ingredients":402,"procedure":411},{"active":125},[403,404,405,406,407,408,409,410],{"name":334,"amount":195},{"name":336,"amount":282},{"name":157,"amount":338},{"name":264,"amount":268},{"name":341,"amount":268},{"name":309,"amount":343},{"name":345,"amount":346},{"name":348,"amount":288},[350,351,352,353,354,355,356,357,358,359,360,361],[],"lobster-mac-and-cheese",{"id":413,"data":415,"body":490,"filePath":491,"digest":492,"rendered":493},{"title":416,"published":417,"yield":418,"difficulty":253,"image":419,"instructions":420},"Lobster Mac & Cheese",["Date","2019-10-30T00:00:00.000Z"],"4 servings","/src/images/recipes/lobster-mac-and-cheese.jpg",[421,434,443,469,482],{"time":422,"ingredients":424,"procedure":429},{"active":172,"inactive":423},"20-25 minutes",[425,427,428],{"name":426,"amount":181},"1.5-2lb live main lobster",{"name":309,"amount":310},{"name":284,"amount":310},[430,431,432,433],"Place live lobster in freezer while water comes to boil, about 10-15 minutes","Fill a large pot with water and salt until the water \"tastes like the sea\" and bring to a boil","Place the lobster head-first into boiling water and boil for 7-8 minutes for 1½lb lobsters, 8-10 minutes for 2lb lobsters. Slightly under-cooking the lobster here is okay as we'll be baking it later.","Harvest the meat from the claws, knuckles, and tails of the lobsters, and cut into equal bite-sized pieces. Set aside.",{"time":435,"ingredients":437,"procedure":441},{"active":172,"inactive":436},"10-15 minutes",[438],{"name":439,"amount":440},"Dried radiatore or cascatelli pasta","8oz",[442],"In the same pot and water you boiled the lobsters, cook the pasta according to the manufacturer's directions. When done, reserve about 2 cups of pasta water, drain the pasta, and set aside.",{"time":444,"ingredients":445,"procedure":462},{"active":188},[446,448,450,452,454,457,459,460],{"name":447,"amount":307},"Whole milk",{"name":449,"amount":152},"Cornsartch",{"name":451,"amount":268},"Whole-grain dijon mustard",{"name":453,"amount":131},"Gruyère cheese, shredded",{"name":455,"amount":456},"Mild cheddar, shredded","2 cups",{"name":458,"amount":268},"Fresh tarragon, finely chopped",{"name":284,"amount":310},{"name":461,"amount":310},"Fresh ground black pepper",[463,464,465,466,467,468],"Preheat oven to 350°F.","In a large bowl, mix together the cheese and the cornstartch until cheese is evenly coated.","In a medium nonstick saucepan over medium heat, add the milk and tarragon and bring to a boil, stirring often, and then reduce to a simmer.","Stir in the mustard and salt and pepper to taste.","Stir in the cheese until it melts and is smooth.","Take off the heat, fold in the pasta and the lobster",{"time":470,"equipment":473,"ingredients":475,"procedure":479},{"active":471,"inactive":472},"5 miutes","15-20 minutes",[474],"Oven-safe ramekins or porcelain bakers",[476,478],{"name":477,"amount":307},"Seasoned breadcrumbs",{"name":160,"amount":152},[480,481],"Melt the butter and combine with the breadcrumbs.","Portion the pasta into four oven-safe dishes, top with breadcrumbs, and bake until golden brown on top, 15-20 minutes",{"time":483,"ingredients":485,"procedure":488},{"active":484},"1 min",[486],{"name":487,"amount":152},"Chives, finely chopped",[489],"Top with chives and serve.","Now technically this is radiatore and cheese, but you wouldn’t have known what I meant if I said that! Radiatore have a great shape for holding on to the cheese sauce, and the lobster adds nice sweet pops throughout the dish. If you can’t find radiatore, campanelle, fusilli, and even shells can do in a pinch. Just avoid elbow macaroni. You want a pasta that will hold on to the cheese sauce you’re making! If you want to just use the macaroni and cheese recipe, I’d remove the tarragon and keep the rest the same. You can also make macaroni and cheese cupcakes by dividing the recipe into a buttered and floured cupcake tray.","src/content/recipes/lobster-mac-and-cheese.md","a9335a87578a7159",{"html":494,"metadata":495},"\u003Cp>Now technically this is radiatore and cheese, but you wouldn’t have known what I meant if I said that! Radiatore have a great shape for holding on to the cheese sauce, and the lobster adds nice sweet pops throughout the dish. If you can’t find radiatore, campanelle, fusilli, and even shells can do in a pinch. Just avoid elbow macaroni. You want a pasta that will hold on to the cheese sauce you’re making! If you want to just use the macaroni and cheese recipe, I’d remove the tarragon and keep the rest the same. You can also make macaroni and cheese cupcakes by dividing the recipe into a buttered and floured cupcake tray.\u003C/p>",{"headings":496,"localImagePaths":497,"remoteImagePaths":498,"frontmatter":499,"imagePaths":538},[],[],[],{"title":416,"published":500,"yield":418,"difficulty":253,"image":419,"instructions":501},"2019-10-30",[502,509,514,526,533],{"time":503,"ingredients":504,"procedure":508},{"active":172,"inactive":423},[505,506,507],{"name":426,"amount":181},{"name":309,"amount":310},{"name":284,"amount":310},[430,431,432,433],{"time":510,"ingredients":511,"procedure":513},{"active":172,"inactive":436},[512],{"name":439,"amount":440},[442],{"time":515,"ingredients":516,"procedure":525},{"active":188},[517,518,519,520,521,522,523,524],{"name":447,"amount":307},{"name":449,"amount":152},{"name":451,"amount":268},{"name":453,"amount":131},{"name":455,"amount":456},{"name":458,"amount":268},{"name":284,"amount":310},{"name":461,"amount":310},[463,464,465,466,467,468],{"time":527,"equipment":528,"ingredients":529,"procedure":532},{"active":471,"inactive":472},[474],[530,531],{"name":477,"amount":307},{"name":160,"amount":152},[480,481],{"time":534,"ingredients":535,"procedure":537},{"active":484},[536],{"name":487,"amount":152},[489],[],"slow-scrambled-egg-toast",{"id":539,"data":541,"body":572,"filePath":573,"digest":574,"rendered":575},{"title":542,"published":543,"yield":252,"difficulty":120,"image":544,"instructions":545},"Slow Scrambled Egg Toast",["Date","2019-09-14T00:00:00.000Z"],"/src/images/recipes/slow-scrambled-egg-toast.jpg",[546,559],{"time":547,"ingredients":549,"procedure":555},{"active":548},"30 minutes",[550,552,553],{"name":180,"amount":551},"6",{"name":160,"amount":268},{"name":284,"amount":554},"1 pinch",[556,557,558],"Preheat nonstick skillet over low heat, adding the butter and allowing it to melt, but not foam.","Crack the eggs into a bowl, add the salt, and whisk together until whites and yolks are well combined.","Add the eggs to the skillet and, with a silicone or rubber spatula, stir constantly until all of the liquid has evaporated. You'll be left with very small egg curds that glisten and appear gooey. This should take about 20 minutes. You'll know you're close when the eggs no longer slide back when you move them around in the skillet.",{"time":560,"ingredients":562,"procedure":570},{"active":561,"inactive":172},"2 minutes",[563,566,569],{"name":564,"amount":565},"Thick-cut brioche or sourdough loaf","2 slices",{"name":567,"amount":568},"Thinly sliced scallion greens","1/4 cup",{"name":461,"amount":310},[571],"Toast the bread, then add 1/2 of the eggs on top (they should be gooey and stay in placed when added, even spreadable), and top with scallion greens and black pepper, to taste.","This one is Annie's favorite breakfast, super slow scrambled eggs on toast. The key to this recipe is patience. You need to keep the eggs moving over low heat, slowly driving all of the water out until what you're left with is almost jam-like in consistency. Because you'll be tempted to pump up the heat, and because they need constant attention, I think they're an intermediate difficulty dish. Trust me when I say that your patience is well rewarded! These eggs come out gooey and buttery, and may just be the best you've ever eaten.","src/content/recipes/slow-scrambled-egg-toast.md","22707aaf9474db08",{"html":576,"metadata":577},"\u003Cp>This one is Annie’s favorite breakfast, super slow scrambled eggs on toast. The key to this recipe is patience. You need to keep the eggs moving over low heat, slowly driving all of the water out until what you’re left with is almost jam-like in consistency. Because you’ll be tempted to pump up the heat, and because they need constant attention, I think they’re an intermediate difficulty dish. Trust me when I say that your patience is well rewarded! These eggs come out gooey and buttery, and may just be the best you’ve ever eaten.\u003C/p>",{"headings":578,"localImagePaths":579,"remoteImagePaths":580,"frontmatter":581,"imagePaths":598},[],[],[],{"title":542,"published":582,"yield":252,"difficulty":120,"image":544,"instructions":583},"2019-09-14",[584,591],{"time":585,"ingredients":586,"procedure":590},{"active":548},[587,588,589],{"name":180,"amount":551},{"name":160,"amount":268},{"name":284,"amount":554},[556,557,558],{"time":592,"ingredients":593,"procedure":597},{"active":561,"inactive":172},[594,595,596],{"name":564,"amount":565},{"name":567,"amount":568},{"name":461,"amount":310},[571],[],"split-pea-soup",{"id":599,"data":601,"body":669,"filePath":670,"digest":671,"rendered":672},{"title":602,"published":603,"yield":604,"difficulty":253,"image":605,"instructions":606},"Split Pea Soup",["Date","2020-02-01T00:00:00.000Z"],"8 servings","/src/images/recipes/split-pea-soup.jpg",[607,632,645],{"time":608,"equipment":609,"ingredients":610,"procedure":624},{"active":188,"inactive":172},[303],[611,613,616,617,619,620,622],{"name":612,"amount":181},"Medium leek",{"name":614,"amount":615},"Medium yellow onion","1, about .5 lb",{"name":157,"amount":158},{"name":267,"amount":618}," 2 tbsp",{"name":284,"amount":310},{"name":621,"amount":310},"Fresh ground cracked pepper",{"name":623,"amount":285},"Chipotle or tomato paste",[625,626,627,628,629,630,631],"Over medium-high heat, or high heat in an electric pressure cooker, heat the olive oil.","Slice the leeks, up to the dark green leaves, in to 2mm slices.","Cut the onion in half, remove the paper skin, and slice into 2mm slices.","Mince the garlic.","Add the onion and leeks to the heated olive oil and sweat down with salt and pepper, to taste, until onions are translucent and the leeks are wilted, about 5 minutes.","Add in the mixed garlic and sweat until fragrant.","Add in the chipotle paste and mix together until fragrant.",{"time":633,"ingredients":634,"procedure":641},{"active":188},[635,638],{"name":636,"amount":637},"Yukon gold potato","1 medium, about .5 lb",{"name":639,"amount":640},"Carrot","1 large, about .5 lb",[642,643,644],"Slice the carrot into 4mm thick rounds.","Slice the potato into 4mm thick flats, and then into approximately 1/2\" by 1/2\" squares.","Add the potatoes and carrot to the pot and cook until they've begun to soften, about 5 minutes.",{"time":646,"equipment":647,"ingredients":650,"procedure":664},{"active":172,"inactive":299},[648,649],"Cheese cloth","Butcher twine",[651,654,656,658,660,662,663],{"name":652,"amount":653},"Mushroom broth","6 cups",{"name":655,"amount":551},"Thyme sprig",{"name":657,"amount":181},"Bay leaf",{"name":659,"amount":134},"Dried mushrooms",{"name":661,"amount":282},"Dried split green peas",{"name":284,"amount":310},{"name":621,"amount":310},[665,666,667,668],"Add dried mushrooms, bay leaves, and thyme sprigs into a cheese cloth and form into a pouch, tied together with butcher twine, forming a _bouquet garni_.","Place the bouquet garni, mushroom broth, split green peas, salt, and pepper into the pot.","Cook at 9 PSI for 15 minutes then release pressure.","Remove the bouquet garni, stir soup together, season with salt and pepper, and serve","Another vegan soup recipe to add to my collection! The challenge with making split pea soup vegetarian is that a major source of flavor comes from ham bones or ham hocks, which impart smokey, meaty, umami notes into the soup. Split pea soup really needs these flavors, so to get the meaty and umami notes, I've made this with mushroom broth instead of the usual water. For the smokey notes, I've utilized one of my new favorite ingredients, chipotle paste, which adds the smokey flavor without a hint on spicy in the final product. Once the ham is replaced, the soup is, surprisingly vegan!","src/content/recipes/split-pea-soup.md","7cb7957e6d4839ef",{"html":673,"metadata":674},"\u003Cp>Another vegan soup recipe to add to my collection! The challenge with making split pea soup vegetarian is that a major source of flavor comes from ham bones or ham hocks, which impart smokey, meaty, umami notes into the soup. Split pea soup really needs these flavors, so to get the meaty and umami notes, I’ve made this with mushroom broth instead of the usual water. For the smokey notes, I’ve utilized one of my new favorite ingredients, chipotle paste, which adds the smokey flavor without a hint on spicy in the final product. Once the ham is replaced, the soup is, surprisingly vegan!\u003C/p>",{"headings":675,"localImagePaths":676,"remoteImagePaths":677,"frontmatter":678,"imagePaths":711},[],[],[],{"title":602,"published":679,"yield":604,"difficulty":253,"image":605,"instructions":680},"2020-02-01",[681,693,699],{"time":682,"equipment":683,"ingredients":684,"procedure":692},{"active":188,"inactive":172},[303],[685,686,687,688,689,690,691],{"name":612,"amount":181},{"name":614,"amount":615},{"name":157,"amount":158},{"name":267,"amount":618},{"name":284,"amount":310},{"name":621,"amount":310},{"name":623,"amount":285},[625,626,627,628,629,630,631],{"time":694,"ingredients":695,"procedure":698},{"active":188},[696,697],{"name":636,"amount":637},{"name":639,"amount":640},[642,643,644],{"time":700,"equipment":701,"ingredients":702,"procedure":710},{"active":172,"inactive":299},[648,649],[703,704,705,706,707,708,709],{"name":652,"amount":653},{"name":655,"amount":551},{"name":657,"amount":181},{"name":659,"amount":134},{"name":661,"amount":282},{"name":284,"amount":310},{"name":621,"amount":310},[665,666,667,668],[],"tamago-style-egg-sandwiches",{"id":712,"data":714,"body":748,"filePath":749,"digest":750,"rendered":751},{"title":715,"published":716,"yield":717,"difficulty":253,"image":718,"instructions":719},"Tamago-Style Egg Sandwiches",["Date","2023-01-14T00:00:00.000Z"],"4 Sandwiches","/src/images/recipes/tamago-style-egg-sandwiches.jpg",[720],{"time":721,"equipment":722,"ingredients":726,"procedure":738},{"active":172,"inactive":548,"rest":188},[723,724,725],"9\"x9\" metal cake pan","Non-stick spray","Rimmed baking sheet (optional)",[727,729,732,735,736],{"name":180,"amount":728},"10",{"name":730,"amount":731},"Dashi","2/3 cup",{"name":733,"amount":734},"Soy sauce","3.5 tsp",{"name":264,"amount":734},{"name":737,"amount":554},"Salt",[739,740,741,742,743,744,745,746,747],"Preheat oven to 300 degrees, or 275 with convection","Grease the bottom and sides of the cake pan with the non-stick spray","Crack the eggs into a large bowl, add the remaining ingredients and whisk to combine until homogenous. It should be well combined but not frothy; you don't want to whisk air into the eggs.","Pour the egg mixture into the cake pan","If using convection, bake. If not, put the cake pan onto the sheet pan and add about a cup and a half of water to the sheet pan. This will help regulate temperature swings in the oven.","Bake for 30-40 minutes, testing that a toothpick comes out clean from the center","Let eggs cool in the pan for 10 minutes, then invert the pan onto a cutting board to release the eggs.","Cut into 4 equal sized pieces","Use one slice per sandwich to build your sandwich how you'd like!","These infinitely customizable, meal-prep friendly sandwiches, inspired by America's Test Kitchen's [Kimchi Egg Sandwichs](https://www.youtube.com/watch?v=e_TWsKjlNkE), take inspiration from tamago sushi, a savory, slightly sweet rolled egg omelette. Tamago sushi is one of my favorites, and I find the additional flavors pair really well with savory breakfast flavors like cheese and breakfast meats.\n\nFor the dashi, I make a batch of Serious Eat's [Basic Japanese Dashi](https://www.seriouseats.com/basic-japanese-dashi-recipe). Don't worry about having extra, this recipe comes together so fast that I find myself going through the dashi pretty quickly as I keep making more eggs. If you still find yourself with too much, make some miso soup! As described in the America's Test Kitchen video, the liquid added to the eggs will help to tenderize them. The dashi is light in flavor so doesn't detract from the overall \"egginess\" of the eggs but does lend a subtle savoriness to them. The mirin, a Japanese cooking wine, adds slight sweetness, and the soy sauce adds another hit of savoriness and some saltiness. Together, they provide a great set of undertones to the eggs, elevating them without diluting the egg-forward flavor that the original recipe strives for.\n\nThe eggs are great fresh out of the oven, and but the real magic of this recipe is how well they keep in the fridge. Once cooled and cut, you can place these in the fridge in an airtight container and they'll stay for a few days. Reheating is super easy; pop one in the microwave for 60 seconds! To construct sandwiches, because the eggs are super tender, I recommend a soft roll, like brioche or challah, that's been lightly toasted. Load it up with whatever your favorite condiments and breakfast sandwich toppings! Pictured I've got some chopped kimchi, some Canadian bacon, and a slice of melted low-moisture mozzarella. I also find a slice of cheddar cheese, optionally microwaved for about 15 seconds on top of the eggs to melt it, and a slice or two of Taylor ham or Canadian bacon, heated stove-top or likewise zapped for 60 seconds on a paper towel, are great accompaniments.\n\nTasty, filling breakfast sandwiches in less than 5 minutes every morning; what's not to love?","src/content/recipes/tamago-style-egg-sandwiches.md","f36dbfb73564a983",{"html":752,"metadata":753},"\u003Cp>These infinitely customizable, meal-prep friendly sandwiches, inspired by America’s Test Kitchen’s \u003Ca href=\"https://www.youtube.com/watch?v=e_TWsKjlNkE\">Kimchi Egg Sandwichs\u003C/a>, take inspiration from tamago sushi, a savory, slightly sweet rolled egg omelette. Tamago sushi is one of my favorites, and I find the additional flavors pair really well with savory breakfast flavors like cheese and breakfast meats.\u003C/p>\n\u003Cp>For the dashi, I make a batch of Serious Eat’s \u003Ca href=\"https://www.seriouseats.com/basic-japanese-dashi-recipe\">Basic Japanese Dashi\u003C/a>. Don’t worry about having extra, this recipe comes together so fast that I find myself going through the dashi pretty quickly as I keep making more eggs. If you still find yourself with too much, make some miso soup! As described in the America’s Test Kitchen video, the liquid added to the eggs will help to tenderize them. The dashi is light in flavor so doesn’t detract from the overall “egginess” of the eggs but does lend a subtle savoriness to them. The mirin, a Japanese cooking wine, adds slight sweetness, and the soy sauce adds another hit of savoriness and some saltiness. Together, they provide a great set of undertones to the eggs, elevating them without diluting the egg-forward flavor that the original recipe strives for.\u003C/p>\n\u003Cp>The eggs are great fresh out of the oven, and but the real magic of this recipe is how well they keep in the fridge. Once cooled and cut, you can place these in the fridge in an airtight container and they’ll stay for a few days. Reheating is super easy; pop one in the microwave for 60 seconds! To construct sandwiches, because the eggs are super tender, I recommend a soft roll, like brioche or challah, that’s been lightly toasted. Load it up with whatever your favorite condiments and breakfast sandwich toppings! Pictured I’ve got some chopped kimchi, some Canadian bacon, and a slice of melted low-moisture mozzarella. I also find a slice of cheddar cheese, optionally microwaved for about 15 seconds on top of the eggs to melt it, and a slice or two of Taylor ham or Canadian bacon, heated stove-top or likewise zapped for 60 seconds on a paper towel, are great accompaniments.\u003C/p>\n\u003Cp>Tasty, filling breakfast sandwiches in less than 5 minutes every morning; what’s not to love?\u003C/p>",{"headings":754,"localImagePaths":755,"remoteImagePaths":756,"frontmatter":757,"imagePaths":770},[],[],[],{"title":715,"published":758,"yield":717,"difficulty":253,"image":718,"instructions":759},"2023-01-14",[760],{"time":761,"equipment":762,"ingredients":763,"procedure":769},{"active":172,"inactive":548,"rest":188},[723,724,725],[764,765,766,767,768],{"name":180,"amount":728},{"name":730,"amount":731},{"name":733,"amount":734},{"name":264,"amount":734},{"name":737,"amount":554},[739,740,741,742,743,744,745,746,747],[],"vegan-peanut-butter-chocolate-chunk-cookies",{"id":771,"data":773,"body":820,"filePath":821,"digest":822,"rendered":823},{"title":774,"published":775,"yield":776,"difficulty":253,"image":777,"instructions":778},"Vegan Peanut Butter Chocolate Chunk Cookies",["Date","2020-01-20T00:00:00.000Z"],"18 cookies","/src/images/recipes/vegan-peanut-butter-chocolate-chunk-cookies.jpg",[779,794],{"time":780,"equipment":781,"ingredients":783,"procedure":792},{"active":172},[782],"Stand mixer (optional)",[784,786,788,790],{"name":785,"amount":307},"Smooth peanut butter",{"name":787,"amount":307},"Dark brown sugar",{"name":789,"amount":181},"Ripe bananas, mashed",{"name":791,"amount":288},"Vanilla extract",[463,793],"Cream together peanut butter, brown sugar, banana, and vanilla. If using a stand mixer, do so with the paddle attachment on medium-low speed.",{"time":795,"equipment":797,"ingredients":799,"procedure":812},{"active":172,"inactive":796},"7 minutes",[798],"#40 ice cream scoop (optional)",[800,803,805,807,810],{"name":801,"amount":802},"All purpose flour","3/4 cup",{"name":804,"amount":288},"Baking soda",{"name":806,"amount":288},"Ground cinnamon",{"name":808,"amount":809},"100% dark chocolate","4 oz",{"name":284,"amount":811},"1/4 tsp",[813,814,815,816,817,818,819],"Combine flour, baking soda, kosher salt, and ground cinnamon in a separate bowl so everything is evenly distributed.","Add the flour mixture into the peanut butter mixture and mix to fully combine.","Roughly chop the chocolate and mix into the dough. The dough is going to be the consistency of damp sand, but should hold its shape when compressed.","Using a #40 Ice Cream Scoop, or about 1.5 tbsp, make balls of dough, and compress so they stay together.","Using a fork, press the balls of dough into disks, creating a crossed pattern in the dough.","Bake for 7 minutes.","Remove from baking sheet onto wire rack and let cool completely before eating.","I've been exploring more vegetarian and vegan cooking recently, and making cookies for my team, where one is vegan, gave me a perfect opportunity to figure out a tasty vegan cookie recipe! I never grew up on peanut butter cookies, but after doing some research they seemed like the best recipe to start with! After looking at a few recipes, I came up with this recipe, and I think it's pretty tasty! Annie does too, so I think they're a win. Don't be surprised if they're dry, though, these are peanut butter cookies after all!\n\nSome notes on the recipe: bananas are there to add moisture and provide a nice fruity flavor to the cookies. To ensure the cookies are vegan, make sure the dark chocolate is 100% dark. You could probably substitute maple syrup for the brown sugar and almond flour for the all-purpose flour to make these Paleo friendly, too (the vanilla is up to you there), but I haven't tried it. If you do, let me know!","src/content/recipes/vegan-peanut-butter-chocolate-chunk-cookies.md","a8319532d5accc2d",{"html":824,"metadata":825},"\u003Cp>I’ve been exploring more vegetarian and vegan cooking recently, and making cookies for my team, where one is vegan, gave me a perfect opportunity to figure out a tasty vegan cookie recipe! I never grew up on peanut butter cookies, but after doing some research they seemed like the best recipe to start with! After looking at a few recipes, I came up with this recipe, and I think it’s pretty tasty! Annie does too, so I think they’re a win. Don’t be surprised if they’re dry, though, these are peanut butter cookies after all!\u003C/p>\n\u003Cp>Some notes on the recipe: bananas are there to add moisture and provide a nice fruity flavor to the cookies. To ensure the cookies are vegan, make sure the dark chocolate is 100% dark. You could probably substitute maple syrup for the brown sugar and almond flour for the all-purpose flour to make these Paleo friendly, too (the vanilla is up to you there), but I haven’t tried it. If you do, let me know!\u003C/p>",{"headings":826,"localImagePaths":827,"remoteImagePaths":828,"frontmatter":829,"imagePaths":851},[],[],[],{"title":774,"published":830,"yield":776,"difficulty":253,"image":777,"instructions":831},"2020-01-20",[832,841],{"time":833,"equipment":834,"ingredients":835,"procedure":840},{"active":172},[782],[836,837,838,839],{"name":785,"amount":307},{"name":787,"amount":307},{"name":789,"amount":181},{"name":791,"amount":288},[463,793],{"time":842,"equipment":843,"ingredients":844,"procedure":850},{"active":172,"inactive":796},[798],[845,846,847,848,849],{"name":801,"amount":802},{"name":804,"amount":288},{"name":806,"amount":288},{"name":808,"amount":809},{"name":284,"amount":811},[813,814,815,816,817,818,819],[],"posts",["Map",854,855,872,873,921,922,942,943,969,970,1020,1021,1047,1048,1065,1066,1089,1090,1107,1108,1128,1129,1152,1153,1170,1171,1207,1208,1236,1237,1266,1267,1284,1285,1305,1306,1323,1324,1344,1345,1377,1378,1395,1396,1422,1423,1442,1443,1460,1461,1488,1489,1515,1516,1548,1549,1571,1572,1589,1590,1616,1617,1643,1644,1661,1662,1679,1680,1697,1698,1715,1716,1733,1734,1774,1775,1792,1793,1826,1827,1853,1854,1878,1879,1907,1908,1925,1926,1982,1983,2001,2002,2020,2021],"a-recipe-for-documentation",{"id":854,"data":856,"body":860,"filePath":861,"digest":862,"rendered":863},{"title":857,"published":858,"summary":859},"A Recipe for Documentation",["Date","2017-05-01T00:00:00.000Z"],"Technical documentation should be more like recipes in a cookbook.","Imagine opening up a cookbook to a recipe, _Introduction to Chocolate Cake_, and reading the following description:\n\n> Chocolate cake is a delicious desert that, besides being beautiful to look at, has a host of health benefits that will help you live a happier, more full life. And that's not just us boasting! Chocolate cake is chock full of vitamins, minerals, antioxidants, and more, each of which we can provide hard statistics to show you the importance of.\n\nThat sounds great! It sounds like if I want to learn how to make a chocolate cake, this is the recipe to start with! Why would I want to _start_ by making a desert in any other way? Well, under that it says this:\n\n> This recipe will be very in-depth, but we will assume you are already an accomplished baker. If you're not an accomplished baker, maybe consider buying a chocolate cake from the store. You won't have the control over the recipe, like you came here to learn, but, hey, chocolate cake.\n\nWoah! I thought this was an _introduction_ to chocolate cake! I came here to learn how to make chocolate cake! Why am I expected to be an accomplished baker _before_ I learn how to make chocolate cake?\n\nThat question, _why am I expected to be an accomplished baker_, I think often gets overlooked when writing technical documentation.\n\nThis week, I started playing with a big, well-known JavaScript framework. Specifically, because I'm a health (performance) nut, I was trying to figuring out how to do Server Side Rendering (SSR) with it. I know from having looked in to this before with other tools that building applications this way was _different_ than only client rendering. Even though we call them universal applications, the reality isn't quite that. About 1/2 way through this week, the documentation abruptly changed. It went from a simple set of documentation that I could get running in a handful of lines of code and then expand on, to documentation that assumes a lot of upfront knowledge and doesn't start running until the end. Well, I say that, but I only assume that. I got to the step that effectively started \"we assume you already know how to do this\" and stopped to write this post instead of learning a different tool to continue this introduction tutorial.\n\nThis is an issue of [complexity](https://www.infoq.com/presentations/Simple-Made-Easy) in our current development ecosystem. Our tools are tightly coupled (complected, if you will) with others. This leads to needing to know a whole complex stack in order to print out `\u003Cdiv>Hello World, you're on page {{ url }}\u003C/div>`. Complexity, in and of itself, isn't necessarily bad. Assuming that something as complex as our current ecosystem is as _easy_ for the audience as it is for those writing the documentation makes for _bad documentation_. In fact, it's a mostly wrong assumption to make. Documentation like tutorials, by and large, are not for individuals who have conquered the complexity presented to them. They are for individuals who are learning these concepts for the first time. The more we write documentation presuming existing expertise, the less useful we make these tutorials for the audience that's most likely to use them.\n\nThat's not to say there isn't a time and a place for advanced or expert tutorials that assume a level of expertise. Anything that does, though, shouldn't be billed as an introduction. In fact, it likely should go out of its way to inform users, in very clear, upfront language, before describing what someone will learn, that this is going to require skills they may not have. If that's the case, links to learning material should be given, up front, so users can self-pace and not get stuck midway through, lost for where to go next.\n\nReturning to our chocolate cake, how can we write better documentation and tutorials? Well, if you know me, you know the answer: food! Specifically, taking a page out of our cookbooks! I recently got the cookbook [Modernist Cuisine at Home](http://modernistcuisine.com/books/modernist-cuisine-at-home/), and opening it up was a revelation. Besides the gorgeous photography, they've managed to make the highly scientific and technical [molecular gastronomy](https://en.wikipedia.org/wiki/Molecular_gastronomy) cooking techniques approachable to those new to it! The key to how they do this is two-fold: how they structure the book, and how they structure their recipes. Peep the [Modernist Cuisine at Home Brochure](https://www.scribd.com/document/111133321/Modernist-Cuisine-at-Home-Brochure) to see how they not only describe what may be needed up-front in the book, but show readers how to use equipment they already have, and explains in-depth the new tools they're introducing. Diving in to the recipe section itself, and we see a model we can follow for our documentation and tutorials. Let's break it down.\n\nAt the very top of their recipes, they set expectations; how much will this make, how long will it take, how to store, how difficult is it, what special requirements are needed, what can this be paired with. Before even looking at the description, I have an idea of what I'm going to need in order to accomplish this recipe. The special requirements section all reference tools they talk about earlier in the book. The description is next, explaining what they like about the recipe and _why_ certain tools are used. Finally, there's the recipe itself. Each step is broken out with exact needs of each ingredient. If a step has multiple ingredients (unfortunately not pictured there), all of those ingredients are listed on the left. If a set of ingredients has multiple steps, they're all listed on the right before the next set of ingredients. Steps that describe something a user may not be immediately familiar with include pictures to help guide them. This, then, should be our gold-standard in writing documentation.\n\nTranslating this in to our world of technical documentation, we should start by setting expectations clearly up-front. How difficult is this going to be? How long is this going to take? What versions of everything are being used? What knowledge do I need to have before coming in, and where can I learn precisely what I need to know? Next, a description of the actual documentation, and why these tools and techniques are being recommended. Finally, our steps; what are all of the things we're going to need up-front for the following set of steps. Then the next set. Then the next set. All while avoiding [words that assume existing expertise](https://css-tricks.com/words-avoid-educational-writing/).\n\nWriting documentation's hard. Automated output never really gives enough for someone to learn from, so we need write long-form text. When we do so, we often, intentionally or not, assume users have the same grasp on the technology being used that we do. By doing this, we wind up writing documentation that's inaccessible to a large group of people who would like to use it. So let's improve that. Let's learn from cookbooks and start thinking about documentation as descriptions of kitchen equipment or cooking techniques, tutorials as recipes. I think that by doing so, we can write documentation as tasty as chocolate cake!","src/content/posts/a-recipe-for-documentation.md","9ccbe2c79fa6cb99",{"html":864,"metadata":865},"\u003Cp>Imagine opening up a cookbook to a recipe, \u003Cem>Introduction to Chocolate Cake\u003C/em>, and reading the following description:\u003C/p>\n\u003Cblockquote>\n\u003Cp>Chocolate cake is a delicious desert that, besides being beautiful to look at, has a host of health benefits that will help you live a happier, more full life. And that’s not just us boasting! Chocolate cake is chock full of vitamins, minerals, antioxidants, and more, each of which we can provide hard statistics to show you the importance of.\u003C/p>\n\u003C/blockquote>\n\u003Cp>That sounds great! It sounds like if I want to learn how to make a chocolate cake, this is the recipe to start with! Why would I want to \u003Cem>start\u003C/em> by making a desert in any other way? Well, under that it says this:\u003C/p>\n\u003Cblockquote>\n\u003Cp>This recipe will be very in-depth, but we will assume you are already an accomplished baker. If you’re not an accomplished baker, maybe consider buying a chocolate cake from the store. You won’t have the control over the recipe, like you came here to learn, but, hey, chocolate cake.\u003C/p>\n\u003C/blockquote>\n\u003Cp>Woah! I thought this was an \u003Cem>introduction\u003C/em> to chocolate cake! I came here to learn how to make chocolate cake! Why am I expected to be an accomplished baker \u003Cem>before\u003C/em> I learn how to make chocolate cake?\u003C/p>\n\u003Cp>That question, \u003Cem>why am I expected to be an accomplished baker\u003C/em>, I think often gets overlooked when writing technical documentation.\u003C/p>\n\u003Cp>This week, I started playing with a big, well-known JavaScript framework. Specifically, because I’m a health (performance) nut, I was trying to figuring out how to do Server Side Rendering (SSR) with it. I know from having looked in to this before with other tools that building applications this way was \u003Cem>different\u003C/em> than only client rendering. Even though we call them universal applications, the reality isn’t quite that. About 1/2 way through this week, the documentation abruptly changed. It went from a simple set of documentation that I could get running in a handful of lines of code and then expand on, to documentation that assumes a lot of upfront knowledge and doesn’t start running until the end. Well, I say that, but I only assume that. I got to the step that effectively started “we assume you already know how to do this” and stopped to write this post instead of learning a different tool to continue this introduction tutorial.\u003C/p>\n\u003Cp>This is an issue of \u003Ca href=\"https://www.infoq.com/presentations/Simple-Made-Easy\">complexity\u003C/a> in our current development ecosystem. Our tools are tightly coupled (complected, if you will) with others. This leads to needing to know a whole complex stack in order to print out \u003Ccode>&#x3C;div>Hello World, you're on page {{ url }}&#x3C;/div>\u003C/code>. Complexity, in and of itself, isn’t necessarily bad. Assuming that something as complex as our current ecosystem is as \u003Cem>easy\u003C/em> for the audience as it is for those writing the documentation makes for \u003Cem>bad documentation\u003C/em>. In fact, it’s a mostly wrong assumption to make. Documentation like tutorials, by and large, are not for individuals who have conquered the complexity presented to them. They are for individuals who are learning these concepts for the first time. The more we write documentation presuming existing expertise, the less useful we make these tutorials for the audience that’s most likely to use them.\u003C/p>\n\u003Cp>That’s not to say there isn’t a time and a place for advanced or expert tutorials that assume a level of expertise. Anything that does, though, shouldn’t be billed as an introduction. In fact, it likely should go out of its way to inform users, in very clear, upfront language, before describing what someone will learn, that this is going to require skills they may not have. If that’s the case, links to learning material should be given, up front, so users can self-pace and not get stuck midway through, lost for where to go next.\u003C/p>\n\u003Cp>Returning to our chocolate cake, how can we write better documentation and tutorials? Well, if you know me, you know the answer: food! Specifically, taking a page out of our cookbooks! I recently got the cookbook \u003Ca href=\"http://modernistcuisine.com/books/modernist-cuisine-at-home/\">Modernist Cuisine at Home\u003C/a>, and opening it up was a revelation. Besides the gorgeous photography, they’ve managed to make the highly scientific and technical \u003Ca href=\"https://en.wikipedia.org/wiki/Molecular_gastronomy\">molecular gastronomy\u003C/a> cooking techniques approachable to those new to it! The key to how they do this is two-fold: how they structure the book, and how they structure their recipes. Peep the \u003Ca href=\"https://www.scribd.com/document/111133321/Modernist-Cuisine-at-Home-Brochure\">Modernist Cuisine at Home Brochure\u003C/a> to see how they not only describe what may be needed up-front in the book, but show readers how to use equipment they already have, and explains in-depth the new tools they’re introducing. Diving in to the recipe section itself, and we see a model we can follow for our documentation and tutorials. Let’s break it down.\u003C/p>\n\u003Cp>At the very top of their recipes, they set expectations; how much will this make, how long will it take, how to store, how difficult is it, what special requirements are needed, what can this be paired with. Before even looking at the description, I have an idea of what I’m going to need in order to accomplish this recipe. The special requirements section all reference tools they talk about earlier in the book. The description is next, explaining what they like about the recipe and \u003Cem>why\u003C/em> certain tools are used. Finally, there’s the recipe itself. Each step is broken out with exact needs of each ingredient. If a step has multiple ingredients (unfortunately not pictured there), all of those ingredients are listed on the left. If a set of ingredients has multiple steps, they’re all listed on the right before the next set of ingredients. Steps that describe something a user may not be immediately familiar with include pictures to help guide them. This, then, should be our gold-standard in writing documentation.\u003C/p>\n\u003Cp>Translating this in to our world of technical documentation, we should start by setting expectations clearly up-front. How difficult is this going to be? How long is this going to take? What versions of everything are being used? What knowledge do I need to have before coming in, and where can I learn precisely what I need to know? Next, a description of the actual documentation, and why these tools and techniques are being recommended. Finally, our steps; what are all of the things we’re going to need up-front for the following set of steps. Then the next set. Then the next set. All while avoiding \u003Ca href=\"https://css-tricks.com/words-avoid-educational-writing/\">words that assume existing expertise\u003C/a>.\u003C/p>\n\u003Cp>Writing documentation’s hard. Automated output never really gives enough for someone to learn from, so we need write long-form text. When we do so, we often, intentionally or not, assume users have the same grasp on the technology being used that we do. By doing this, we wind up writing documentation that’s inaccessible to a large group of people who would like to use it. So let’s improve that. Let’s learn from cookbooks and start thinking about documentation as descriptions of kitchen equipment or cooking techniques, tutorials as recipes. I think that by doing so, we can write documentation as tasty as chocolate cake!\u003C/p>",{"headings":866,"localImagePaths":867,"remoteImagePaths":868,"frontmatter":869,"imagePaths":871},[],[],[],{"title":857,"published":870,"summary":859},"2017-05-01",[],"a-beginners-guide-to-diabetes",{"id":872,"data":874,"body":878,"filePath":879,"digest":880,"rendered":881},{"title":875,"published":876,"summary":877},"A Beginner's Guide to Diabetes",["Date","2022-10-26T00:00:00.000Z"],"My personal story about what I've learned over the past year since getting diagnosed with diabetes.",":::message{.error}\n_**I am not a doctor**. This is my personal story about what I've learned over the past year and what I've done under my doctor's supervision. Please talk to your doctor before changing how you manage your health._\n\n_Content warning, medical stuff_\n:::\n\nMy story starts Labor Day weekend 2021. My partner and I were on vacation in Lake George, NY. It was our first vacation since the pandemic began. We rented a little house all to ourselves on the lake. It was a lovely trip. On our drive home, we picked up an early dinner. When we got home, instead of eating it, I fell asleep for the rest of the day. I didn't think anything of it, I thought I was just tired.\n\nFor the next six weeks, every once in a while, I would have a day where I was just too tired to do anything, and would sleep the whole day. I lost 30lb without changing my diet. I also drank a lot of water. Around 3 liters a day. Besides that, though, I generally felt really good. Whenever I would have a tired spell, I would take a COVID test, and nothing, so I made a doctor's appointment. I saw the doctor, explained what was going on, had blood drawn, and that was that. That was October 12, 2021.\n\nThe next day, I got a frantic (for a doctor) call. I was asked if I was sure if I had fasted before my blood tests. I assured them I had. I was told I needed to come back in as soon as possible. I made an appointment for the next day, Thursday, October 14th, 2021.\n\nIf you read the title of the article, you know what my diagnosis was. I was told I was diabetic. Really, really diabetic. My heart absolutely sank. I've been overweight my entire life. Up until that point, the only things I really knew about diabetes were it was sugar related, it was stigmatized as being a \"fat person disease\" that could cause you to loose a foot and lead to death. I knew there were needles involved. And of course, [Wilford Brimley's \"diabetus\"](https://www.youtube.com/watch?v=6rm9BZ1osiM). I've been terrified of this diagnosis since high school. But just how bad was my diagnosis? Well, a here's the first of many \"medical things I've learned over the past year\":\n\n- Diabetes is all about insulin, the main hormone in our bodies that regulate how what we eat becomes energy for our body. It's a big deal. There are two main kinds of diabetics, Type 1 diabetics, who do not produce insulin (or, as a friend describes, a Type 1.5 diabetic who no longer can due to some other circumstances), and Type 2 diabetics who do produce insulin, but it either isn't enough, or their body is resistant to the insulin they do produce.\n- There are a number of tests to determine if someone is diabetic and what kind, but from what I've been able to understand, there are two main ones: a C-peptide test to determine if the body makes insulin, and a Hemoglobin A1c test to measure the average blood sugar levels over the past 3 months, measured as a percentage. If your body produces insulin, your A1c is the indicator of if you're considered diabetic.\n- A1c is broken down into three ranges, \u003C5.7 is considered normal or non-diabetic, 5.7-6.4 is considered at risk of becoming diabetic or pre-diabetic, and >=6.5 is considered diabetic. The A1c range for diabetes is usually given from 6-12. The scale stops as 12.\n\nMy A1c was 11.3. Probably gallows humor in hindsight, but I remember telling my partner the doctors were probably surprised I felt fine and was able to walk around with an A1c that high. The only good news? I made insulin, so I was Type 2 diabetic, not Type 1.\n\nThe endocrinologist who diagnosed me saw me for about 20 minutes.\n\nFirst up was denial. I don't eat much sugar! I basically don't drink! I rarely have soda! I don't even really do desserts! What I didn't know was all carbohydrates turn into sugar when digested, so the bagels and apples I was eating were just as bad. I needed to drastically change how I ate and move to a super low-carb diet. To help me navigate this, I was given a piece of paper with about 24 items on it, 12 each of low-carb and high-carb foods, printed from some rando's website.\n\nI was told I couldn't walk around barefoot anymore. The nerve endings in the soles of my feet may just stop working and I may wind up scorching the bottom of my feet like some horror story they knew of some guy at a pool. In fact, I could loose my feet entirely. In fact, go make a podiatrist appointment. Here's a referral. This is where anger set in. I hate shoes. I've given talks on international stages barefoot. Needing to be shoed at all times was unthinkable for me.\n\nI also needed to go make an optometrists appointment. Turns out the extra sugar in my blood could build up in my eyes and cause me to go blind.\n\nFinally,I got my meds and my monitor. My endo showed me briefly how to use my blood glucose monitor, the finger prick thing. I was prescribed two medications: Metformin, a drug to help my body better use the insulin it makes, and Jardiance, a drug that blocks extra glucose from being reabsorbed by the kidneys. And that was it! That is how I was told I have a life-altering chronic illness and the instructions I was given to manage it.\n\nI got home, took the rest of the day off, and picked up my meds. I don't remember what I had for dinner that night, but I do remember being upset that all I had wanted all week was a cheesesteak, and now I didn't know if I could ever have one again.\n\nThe next morning, I started my new routine. I took my blood glucose level, often shortened to blood sugar. It took me pricking my finger 3 time to get a working sample. I wasn't taught how to fill the strips, or how to prick my finger to make it hurt less. I screamed in frustration, a bloody finger, and no idea how to get it to work, until it did. It was 264 mg/dL. 269 mg/dL is the estimated average for an A1c of 11. I took my meds.\n\nThat day, I tried to eat a low-carb diet. The pamphlet I was given wasn't super helpful. I don't really remember eating much.\n\nSaturday was fine. Sunday morning, I went to the farmer's market, and when I came home, I felt like crap. I went to sleep for the rest of the day.. Monday, I still felt like crap. I took my blood sugar throughout the day and it was between 144-146 each time; high, but not dangerously so. I stayed in bed all day. I had water, and tried to have some Gatorade, a desperate attempt to have something in my system, not knowing if it was OK or not for me to drink. Tuesday, was the same. I had a telemedicine check-in with my endo. They weren't able to diagnose anything, and recommended I go to the ER.\n\nSo, it turns out I had diabetic ketoacidosis. I was moved to the intensive care unit. I had my finger pricked every few hours and was given regular insulin injections. I didn't really eat. I was in the ICU for 3 days. On the 3rd day, my partner later told me, she could tell I was feeling better because I had started complaining about the comfort (or lack there of) of the bed. I was finally moved from the ICU down to the general care area.\n\nIt took me being hospitalized for a life-threatening complication for me to get any real information about how I could manage my diabetes. I was on day 10 of being diagnosed. I had spent more time having the wonderful hospital staff manage it than I had. By the time Saturday had come around, I was feeling back to my old self and got to really dig into my diagnosis with the specialists who came to visit me:\n\n- A nutrition team came in and gave me a small book's worth of information on how to manage my diabetes. They talked with me about different kinds of food and how they affect my blood sugar and gave me a ton of resources. They also set me up with a nutritionist to follow-up with after I left the hospital.\n- I met with a new endocrinologist (endo, for short). She was fabulous. I asked her tons of questions. I learned what insulin resistance means and she confirmed my diagnosis (Type 2). She gave me guidelines for how many carbs I should eat and she even talked me through how she calculated that number. She described the different kinds of insulin, and when each is needed (before that, I didn't know there were different kinds!). At my request, she drew diagrams for me, wrote out formulas for me, and explained in detail basically every question I had about what was happening and why it was happening, from a biological perspective. Finally, she kicked me off Jardiance, having decided that that's probably what caused my DKA and said she wouldn't have started me on two drugs at once to manage my condition.\n\nI was all set to leave, I had seen everyone, but then I had a showdown with who became my hospital arch-nemesis: the general practitioner who had to sign off on my release. I had gone through all of my required stuff to be released, but when I asked if I was going to be released that day, they said \"no\", I needed sign-off from the endo who I had met with. I got it, could I be released? Still no. They were concerned that I may have a blood clot in my legs from lying down for a few days, so I needed to go get an ultrasound. That was a multi-hour round-trip. Ok, could I go then? Still no! When you're in the hospital for DKA, you leave the hospital on insulin. A wonderful nurse came in and taught me how to inject myself with the insulin I'd be getting when I left. This was in the morning. Now, in the late afternoon, I was told I needed me to prove I could give myself my insulin shot. No problem, I thought, until the nurse brought it in for me. I had be taught how to use a home-use, pre-filled auto-injector. They wanted me to use an old-school needle drawing from a vial, which I hadn't been taught. I told them I absolutely couldn't do that, I hadn't been taught that. The GP didn't care. I was ready to refuse their service and request an new GP when I was told the endo had confidence I would do it at home, and the nurse came and gave me my shot. I was finally released around 6pm Saturday, the 23rd. For those curious, the hospital food wasn't bad.\n\nStarting that Sunday, for the next two weeks. I stabbed my leg with an insulin shot every morning. Much like my first morning trying to get a blood sugar reading, I cried and yelled and cursed my situation every morning. I hated it. I didn't want this to be my life. I was deep into the depression stage. My diagnosing endo wanted me to come back in. I refused, and transferred my care to the new hospital endo. Fortunately, I had a 2-week checkup with my endo from the hospital. She saw I was keeping my blood sugar under control, and my final test results from the hospital, and she took me off the insulin and back onto Metformin. With Thanksgiving coming up, she also gave me one last bit of encouraging news: it was OK if my blood sugar got a little high, as long as it didn't stay high. I could splurge a little for Thanksgiving, as long as it came back in check. And if it didn't? I had the insulin to get it back in check. That single piece of advice has been the most helpful to me in living with my diabetes.\n\n## New diet, who dis?\n\nAfter being released from the hospital, my endo set a new diet for me: no more than than 60 grams of carbs per day. For reference, the USDA guide recommendation is about 250 grams. For reference, 1 slice of sandwich bread is about 15 grams. Everything I knew about healthy eating? Turned on its head. Veggies? Carbs. Fruit? Lots of carbs! Chicharrones? Just fat and protein! I can have as much of those as I want! Hot sauce? Basically nothing; throw that shit on everything!\n\nFor the first time in my life, I had food I was afraid of. I broke down at dinner one night because I had to choose between eating peppers and onions or a tortilla with my fajitas. But I think my love of food actually, and tendency towards savory over sweet, really helped me through here. My first meeting with my nutritionist, I was given a ton of information breaking down lists and lists of ingredients and categorizing them by how much impact they had on my blood sugar. Fortunately, I didn't need to do other, presumably common, things like cut soda and sweets out of my diet or learn how to cook for myself; I really just had to find bread alternatives. And make sure I had room for onions. I couldn't cut onions out of my diet. I started putting together recipes in my head; desperation bred innovation here. I wound up making buffalo mac and cheese with cauliflower rice, which became a real comfort food for me. I've made breakfast for myself every morning since being diagnosed and have perfected the hotel buffet style omelette and put together an excellent avocado toast hack. We found a food delivery service that had carb counts on everything so I could plan my week's food out. But then, my partner being the lovely person she is, got me an anniversary present that required me to rethink how I dealt with food.\n\nBefore I was diagnosed, knowing that I missed Austin, my partner had ordered me a bunch of sausage, jalapeño, and cheese kolaches. I was so excited to have them! But, they arrived after my return from the hospital. I was crestfallen, neither being able to enjoy a food nor a thoughtful present, all at once. I had been using MyFitnessPal to track my carbs, and I found it lacking. I hated the interface. I hated needing to pay for it to set my goals. I hated that even after paying for it it pushed upsells. And more than anything, I hated that it had a bunch of random user-generated food in there that wasn't reliable (Where did they get these numbers? What's 1 carrot compared to my carrot?). I needed something better.\n\n## Tracking my health\n\nWhen I started seriously tracking what I ate, I quickly started obsessing over nutrition labels. I noticed something important; all nutrition labels (in the US anyway) give serving size in either grams (weight) or milliliters (volume). Figuring out how many carbs I ate was a matter of measuring and multiplication! My best friend, a chemistry PhD, recommended I buy a scientific balance for my kitchen (aka a super fancy scale). I got one. This is really where my frustration with MyFitnessPal really manifested itself. I had precise measurements for what I was eating, and I couldn't properly track it! I started looking for a better way. I found the [USDA FoodCentral API](https://fdc.nal.usda.gov/api-guide.html). I had an idea. I was going to make my own app.\n\nStarting with the API, I made a simple web app (using Svelte, Vite, Firebase functions, and Firestore, for those interested). Everything in FoodCentral is measured by weight or milliliters, and baselined against either 100 grams or 100 milliliters, letting me accurately scale the nutrition of any food I put in. It was great! With a meal entry system in place, I could start fixing some of the other problems I had with MyFitnessPal. The first thing I cared about, tracking my blood sugar and food together in a timeline view, so I could see how what I ate affected my blood sugar. My nutritionist wanted me to take notes about how I was feeling throughout the day, so I added that. I was told I needed to loose weight, so I added weight tracking. I was told my excess water drinking was a clear sign of diabetes, so I added water consumption. After using it for a few weeks, I found that sometimes, I really just wanted to enter carb, protein, fat, and calorie estimates instead of looking up food. I added that! I now had a way to comprehensively track my health. I did what came naturally to me: take what I've learned and turn it into a scalable system. It gave me a safety net, something for me to unload my stress onto; I built something to help me process the trauma I was gone through. I built something to carry the burden of maintaining my health.\n\n## Cheat days on a health-critical diet?\n\nThanksgiving was my first big test. Besides breakfasts, I hadn't really cooked since being diagnosed, and Thanksgiving's usually a carb-heavy meal. I went to my parent's house, brought my scale, planned out my meal using my app, and weighed everything to the tenth of a gram. I made gravy using modernist techniques (xanthan gum and gelatin) instead of flour. I used monkfruit sweetener instead of sugar in my cranberry sauce. I made way too salty cauliflower puree. My family played along, and I really appreciated it. We did make Pillsbury biscuits and my potato bread, brown butter, sage, and mushroom dressing. It's something my partner likes too much, and I wasn't prepared to find a replacement for. I went into the day knowing it was going to be tough, but kept my endo's reminder in the back of my head; it's OK if my blood sugar got a little high, as long as it didn't stay high. My insulin shot was ready if I needed it. I had a plate of food, a little of everything, and the next morning, my blood sugar was OK. I trusted my doctor, and it got me through Thanksgiving. It was my first real challenge to my diet, and I came through the other side fine.\n\nThe next big challenge came in the middle of December. My partner had a business trip that required us to be in my old neighborhood in NYC. All of my favorite restaurants were there, and I didn't have my scale. I had a bagel for the first time from Russ & Daughters. I fought through anxiety and fear to order noodles from Momofuku Noodle Bar for dinner. I came out the other end OK again. I was doing well.\n\nI had a follow-up appointment with my endo in mid-January. I had been keeping really precise track of what I had been eating and my blood sugar. I felt good going into it. My A1c came back. 5.4. **_5.4_**. In 4 months, through diet alone, I had managed to bring my A1c down almost 6 points! Not only was I no longer in the diabetic range, I wasn't even in the pre-diabetic range! I was in a normal range! I had also lost weight! When I was admitted to the hospital, I weighed about 250lb. I now weighed 224lb. I was feeling great. My endo was impressed. She thought, going into the appointment, that she'd need to increase my Metformin dosage but, given where I was, she kept it the same. The system I had put in place was working.\n\n## Dealing with diet anxiety\n\nFor most of the prior 4 months, I had been sticking really strictly to the low range of my diet, trying to only have around 30 grams of carbs per day, total. I had been doing so well that I started to relax that, letting myself balloon it all the way up to a whopping 60 grams a day! I even added some fruit back into my diet! Salt on watermelon? A+. I had lost so much weight by this point I needed to go buy new pants because neither my pants nor my belts worked! It felt good! Then, disaster struck.\n\nRemember how I said, for the first time in my life, I had foods I was afraid of? Well, throughout these first few months, once a week, sometimes more, sometimes less, when my partner and I were trying to decide on dinner, I'd have an anxiety attack about not being able to eat anything at a restaurant we were looking at. I was like Neo in The Matrix; where he saw code everywhere, I saw carbs. This was probably made worse both because I know how to cook (so know where carbs get hidden) and know that restaurant cooking is usually punched up with what amounts to bonus carbs. I had mostly gotten this under control, I thought, until early February. I had ordered one of my comfort delivery foods from a local restaurant, shawarma over salad, for dinner, but when it arrived, something had gotten crossed in the order, and instead of salad, I had only rice. It broke me. All of my anxiety about food and my diet flooded over me, and I stopped eating dinner. Not that night. At all. I rearranged my eating schedule to have a late lunch every day. I divided my daily calories between the two meals. To this day, thinking about having dinner on weeknights bubbles up feelings of dread. It's something I'm still working on. All that's to say, I needed a break.\n\nAt the end of February, my partner planned a little weekend trip to Philadelphia for us. We needed to get out of the house, and away from our routine. I used it as an opportunity to try and overcome some of my anxiety around food; I decided to not track what I ate while I was there. We wound up having a great weekend. I finally got the cheesesteak I had been craving since October! We got some big soft pretzels and had some great Chinese noodles and dumplings. We ate indoors for the first (and really only since) time since the start of the pandemic. Per my doctor's recommendation, I took an extra Metformin pill at night. My blood sugar kept in range.\n\nIn March, my partner came through again. We had been craving the ability to go back to the movies, and she found a local drive-in movie theater. I had had a number of successful trips going out of my diet comfort zone, I decided to treat myself, and see what happened. I had a bag of buttered popcorn and Sno-Caps. It was delicious. I had really missed popcorn. The next morning, my blood sugar was fine again.\n\nBy April, thanks to these successful attempts at pushing up my carb limit, I decided to go wild and allow myself up to 90 grams of carbs per day! I could now have a full sandwich, on regular bread, for lunch, and not go over my carb limit! It felt freeing.\n\n## In a groove\n\nBy this time, I had expanded my app. I had added exercise tracking. I had deeply investigated choosing and tracking macros, the ratio of carbs, fat, and protein that make up your daily caloric intake, and added a whole system to manage and update it as your weight changes, including being able to set minimums as well as maximums. I had built in A1c estimation. I had built graphs to show weight and blood sugar trends. I added body fat percentage and BMI tracking. I put in the ability to generate reports! I had as close to a fully-connected view of food, blood sugar, weight, and exercise as I could have hoped for at that point. And the system worked.\n\nOn May 10, 2022, I had my second check-in with my endo. I now weighed 196lb. My app had estimated my A1c to be 5.4. It was 5.1. Only taking my blood sugar more would have made it more accurate. I had started wearing a smart watch again to track my resting heart rate. It had gone from around 120 beats per minute in October to around 70. I felt fantastic. My endo told me she talks about me to her other patients as proof that diet can control your diabetes. She _reduced_ my Metformin dosage, even suggesting that if I didn't want to, I could stop taking it! She didn't think she needed to see me again until November. I still needed to exercise more. Fair.\n\nBy this time, I had my eye set on a weight loss goal: 180lb. Before I started drastically losing weight in September of 2021, I weighed about 285lb. Loosing over 100lb felt like a good, and now reachable, goal for me. By the end of June, [I had lost 100lb](https://twitter.com/Snugug/status/1539962798129774592?s=20&t=9A1s_HytEmnHjx17HD660w). We went to a destination wedding mid-July and I overate a little. [I hit my goal mid-August](https://twitter.com/Snugug/status/1558591617078071296?s=20&t=9A1s_HytEmnHjx17HD660w). I've updated my macro goals from lose weight to maintain it.\n\nThis week, I finished the final feature I've wanted to build into my app for a long time: routines. Set up checks for logging anything in the app on a reoccurring basis, optionally within a time range, and get a gold star if you complete it. I built it to give me a visual indicator of whether I took my medicine each day. And that bring me to today, writing this for y'all.\n\n## What I've learned\n\nThroughout this process, I've learned a lot about diet, food, and health from talking to friends, specialists, and strangers about this journey. Hopefully some of this is helpful to you.\n\n### Diabetic friendly eating\n\nI was explicitly told by my endo that I couldn't eat less than 30 grams of carbs per day because that may push me into ketosis and she didn't want to risk that, with me having been hospitalized for DKA once already. But, keto diet branded foods? They're amazing. As with everything, you need to read the nutrition label and see what a serving actually is, and if the food really is low-carb or just marketing nonsense, but I find that most stuff in the supermarket labeled keto is a great alternative to other versions. I found I particularly liked the Sola brand of bread products, especially their golden wheat bread and hamburger buns. Be wary of \"healthy\" breads like Dave's Killer Bread or Ezekiel bread, while whole grains and especially nuts in bread may be considered \"healthier\", they also tend to bump up the carb count, so if you're going to eat them, make sure you've got your serving size down right. Believe it or not, good old fashioned nothing in it white Wonder bread is not bad; a single serving is 2 slices and less than 30 carbs! Some potato breads I also found were tasty and lower carb than others around. When looking for a crunchy snack, again turning to Keto goodies worked here, specifically chicharrones. I kind of fell in love with Pork King Good's Pink Salt & Vinegar chicharrones for a while. In general, though, I've found that between having a scale and a goal number of carbs for a snack or meal, I'm mostly able to eat what I'd like.\n\nI've also found that natural alternative sugars, like monk fruit, erythritol, allulose, are all excellent substitutes for sweetness in most applications. Even if I wasn't diabetic, I'd probably continue using these in recipes and applications where I mostly just needed sweetness, like pickled onions (I make so many of these), whipped cream, candied nuts, and the like. They aren't 1:1 replacements in recipes where sugar's ingredient function is more than really sweetness, so you'll need to experiment to get those right. I've found Lakanto a great source for monk fruit sweetener, and King Author makes a Keto baking sugar blend (as well as Keto flour) that have both proven at least mildly successful for me.\n\nA common thing, when looking at many \"Keto\" foods, is the advertisement of \"net carbs\". Talking with my endo and nutritionist about this, here's what I've learned: the standard net carb formula is total carbs minus fiber and sugar alcohol (what things like monk fruit, erythritol, and allulose are considered). How much food affects your blood sugar is called their [glycemic index](https://www.mayoclinic.org/healthy-lifestyle/nutrition-and-healthy-eating/in-depth/glycemic-index-diet), or GI. Sugar alcohols generally have a GI at or near 0, so they can be removed when \"counting carbs\". Fiber passes through your body undigested, so it, too, has a GI at or near 0. Both have said counting net carbs instead of total carbs works for some people, and doesn't work for others. For me, between when I was hospitalized and my first meeting with my endo after that, I was counting total carbs. I now count net carbs.\n\n### Tracking blood sugar\n\nFirst and foremost, unless your doctor tells you to, I wouldn't recommend tracking your blood sugar \"for fun\". For the most accurate reading, you're suppose to draw blood for a reading at least 4x a day. It's painful, it can be messy, and it requires a lot of equipment. That said, I did find it really interesting learning about how your body processes food. From my conversations, after you start eat, your body starts to produce insulin to turn your food into energy. About 2 hours after you've eaten, your blood sugar will be at its peak from your food. About 4 hours after you've eaten, it should have returned to normal. When you sleep, your blood sugar rests, too, and needs to \"wake up\" again. When taking my blood sugar, I've been told to always take it before meals, to get an accurate reading of my baseline. I also found that my blood sugar is constantly a little high in the morning, a combination of it still waking up and it being the tail end of my 24 hour medicine cycle (I take an extended release form of Metformin). Given how well I've managed my condition, I was given the OK by my doctor to cut back taking my blood sugar to morning and evening, and then eventually just morning, with the understanding that if it stayed high I'd need to up my dosage or come back in with some insulin. I've got two kinds sitting in my fridge: Lantus, long-acting insulin usually taken once per day, and Humalog, rapid-acting insulin taken to help reduce blood sugar spikes from eating.\n\nFor those who can't reduce how many times they take their blood sugar, there's a whole range of devices called continuous glucose monitors, or CGMs. They're devices that attach to your body, usually the under arm or stomach, with a little needle sitting just under your skin to read your glucose levels. Some of these are amazingly accurate; a friend of mine who requires an insulin pump has one accurate enough that it's allowed to control said pump. He's described it as a game-changer for him. That's not an introductory CGM, though. I tried the Libre Freestyle 2, a little white button that sat on the back of my arm. In theory it was great! I only needed to prick my finger when I calibrated it, and then it'd work in the background for two weeks. Whenever I needed a reading, I could tab my reader to it and I had it! It didn't work for me in practice, though. I found the readings were constantly on the low end of their accuracy guarantee (around 80% accurate) and resulted in a lot of false alarms for low blood sugar. It constantly came detached. I had one where blood came up through it. One of mine in December was inaccurate to their standards, so I was sent another one, the next one I used fell off in less than a week, then the next one I put on failed to work after the day's worth of calibration. 3 monitors in 2 weeks, none of which were super accurate? It wasn't convenient for me anymore, so I went back to my regular reader, with my updated schedule, after discussing it with my endo. So basically, your mileage may vary with them, but they're worth trying.\n\nOne last thing, if you're taking your blood sugar by pricking your finger, here are two protips I learned from the ICU nurses: prick your finger on the _side_ of your finger instead of the pad of your finger (it'll hurt less), and ratchet down the force just enough for it to draw blood and no more (no need for extra pain, and you really only need a drop of blood).\n\n### Losing weight\n\nIf you came here from my Twitter, you probably weren't expecting over 6k words on diabetes for how I lost weight, but the truth of the matter is, the only reason I lost this weight is I had a _very strong_ motivating factor to do so. I've tried to lose weight since literally high school, and the fact that I now weigh less than I did then is a testament to that motivation. Not to sound dramatic, but being overweight basically became an existential threat. That was my motivation. For the first few months, I didn't even really care how many calories I was eating, it was all about carbs, but the funny thing about being hospitalized and not eating for a few days is it reset my hunger levels. For the first few months, I probably ate between 1100 and 1500 calories a day through a combination of not being hungry, not being able to mindlessly eat carbs, and not wanting to just eat meat when my carb limit was expended. I found in that time that I wound up eating, by grams, roughly the same amount of fat and protein, so when I started to actively care about macros and losing weight, I used that as my baseline instead of trying to fit into a specific diet. With my current weight and weight maintenance goals, I look to eat about 1900 calories a day, with about 100 grams of carbs, 119 grams of fat, or about 70% of my remaining calories, and 115 grams of protein, or about 30% of my remaining calories. But finding the right ratio for you is personal and based on a number of factors. There are only two constants I've seen in this journey: energy in needs to be less than energy used, and sustainable weight loss is a long-term game, not a short-term one. I don't stress if my weight goes up or down a few pounds day-to-day, or if I have a cheat day, or week. The long-term trends, and the strategy for safely losing weight (less in than used, but don't go hungry) is what's important.\n\n### Diabetic health care\n\nFinally, I've had the opportunity to reflect on the health care I received when I was diagnosed, and have been able to talk to others, some of whom were recently diagnosed, some diagnosed a long time ago, and I've seen one common thread emerge: no one seems to get good advice. Everyone I've talked to had more or less the same story I had; they were given a blood glucose monitor, told to eat fewer carbs, told to get some follow-ups, then shoved out. It doesn't seem to matter what your health insurance is or where in the country you are, everyone really seems to be more-or-less left to figure it out, and cope with it, on their own. The first website I went to look for help was the American Diabetic Association. Most of the content on their website wasn't more helpful than what I had been given. Their diabetes food hub immediately served me a wall of Splenda sponsored recipes, which caused me to immediately check out. Even with the great team I've got now, I had to piece a number of things together myself. If I were to guess, it's probably a combination of nuance is hard, an information dump on top of the diagnosis would be overwhelming, prioritizing getting it under control, and time is short. I'm really thankful I had a friend to reach out to who had gone through this already who was able to reassure me that things got easier, and that I was able to do that for someone else, too, but we shouldn't rely on an ad-hoc network for these things. This is such a prevalent disease I'd have assumed support networks and reliable information would be easy to come by, but it's really not. Anything beyond surface-level advice is glaringly absent, or devoid of much other than opinion. My hope with sharing my story is that someone will read this and take from it what I got from my friend, and hopefully find something useful to help them on their journey, too.\n\n---\n\nThanks for reading. Love y'all!","src/content/posts/a-beginners-guide-to-diabetes.md","9d95e541d779b5d4",{"html":882,"metadata":883},"\u003Cdiv class=\"error message\" data-type=\"error\">\u003Cp>\u003Cem>\u003Cstrong>I am not a doctor\u003C/strong>. This is my personal story about what I’ve learned over the past year and what I’ve done under my doctor’s supervision. Please talk to your doctor before changing how you manage your health.\u003C/em>\u003C/p>\u003Cp>\u003Cem>Content warning, medical stuff\u003C/em>\u003C/p>\u003C/div>\n\u003Cp>My story starts Labor Day weekend 2021. My partner and I were on vacation in Lake George, NY. It was our first vacation since the pandemic began. We rented a little house all to ourselves on the lake. It was a lovely trip. On our drive home, we picked up an early dinner. When we got home, instead of eating it, I fell asleep for the rest of the day. I didn’t think anything of it, I thought I was just tired.\u003C/p>\n\u003Cp>For the next six weeks, every once in a while, I would have a day where I was just too tired to do anything, and would sleep the whole day. I lost 30lb without changing my diet. I also drank a lot of water. Around 3 liters a day. Besides that, though, I generally felt really good. Whenever I would have a tired spell, I would take a COVID test, and nothing, so I made a doctor’s appointment. I saw the doctor, explained what was going on, had blood drawn, and that was that. That was October 12, 2021.\u003C/p>\n\u003Cp>The next day, I got a frantic (for a doctor) call. I was asked if I was sure if I had fasted before my blood tests. I assured them I had. I was told I needed to come back in as soon as possible. I made an appointment for the next day, Thursday, October 14th, 2021.\u003C/p>\n\u003Cp>If you read the title of the article, you know what my diagnosis was. I was told I was diabetic. Really, really diabetic. My heart absolutely sank. I’ve been overweight my entire life. Up until that point, the only things I really knew about diabetes were it was sugar related, it was stigmatized as being a “fat person disease” that could cause you to loose a foot and lead to death. I knew there were needles involved. And of course, \u003Ca href=\"https://www.youtube.com/watch?v=6rm9BZ1osiM\">Wilford Brimley’s “diabetus”\u003C/a>. I’ve been terrified of this diagnosis since high school. But just how bad was my diagnosis? Well, a here’s the first of many “medical things I’ve learned over the past year”:\u003C/p>\n\u003Cul>\n\u003Cli>Diabetes is all about insulin, the main hormone in our bodies that regulate how what we eat becomes energy for our body. It’s a big deal. There are two main kinds of diabetics, Type 1 diabetics, who do not produce insulin (or, as a friend describes, a Type 1.5 diabetic who no longer can due to some other circumstances), and Type 2 diabetics who do produce insulin, but it either isn’t enough, or their body is resistant to the insulin they do produce.\u003C/li>\n\u003Cli>There are a number of tests to determine if someone is diabetic and what kind, but from what I’ve been able to understand, there are two main ones: a C-peptide test to determine if the body makes insulin, and a Hemoglobin A1c test to measure the average blood sugar levels over the past 3 months, measured as a percentage. If your body produces insulin, your A1c is the indicator of if you’re considered diabetic.\u003C/li>\n\u003Cli>A1c is broken down into three ranges, &#x3C;5.7 is considered normal or non-diabetic, 5.7-6.4 is considered at risk of becoming diabetic or pre-diabetic, and >=6.5 is considered diabetic. The A1c range for diabetes is usually given from 6-12. The scale stops as 12.\u003C/li>\n\u003C/ul>\n\u003Cp>My A1c was 11.3. Probably gallows humor in hindsight, but I remember telling my partner the doctors were probably surprised I felt fine and was able to walk around with an A1c that high. The only good news? I made insulin, so I was Type 2 diabetic, not Type 1.\u003C/p>\n\u003Cp>The endocrinologist who diagnosed me saw me for about 20 minutes.\u003C/p>\n\u003Cp>First up was denial. I don’t eat much sugar! I basically don’t drink! I rarely have soda! I don’t even really do desserts! What I didn’t know was all carbohydrates turn into sugar when digested, so the bagels and apples I was eating were just as bad. I needed to drastically change how I ate and move to a super low-carb diet. To help me navigate this, I was given a piece of paper with about 24 items on it, 12 each of low-carb and high-carb foods, printed from some rando’s website.\u003C/p>\n\u003Cp>I was told I couldn’t walk around barefoot anymore. The nerve endings in the soles of my feet may just stop working and I may wind up scorching the bottom of my feet like some horror story they knew of some guy at a pool. In fact, I could loose my feet entirely. In fact, go make a podiatrist appointment. Here’s a referral. This is where anger set in. I hate shoes. I’ve given talks on international stages barefoot. Needing to be shoed at all times was unthinkable for me.\u003C/p>\n\u003Cp>I also needed to go make an optometrists appointment. Turns out the extra sugar in my blood could build up in my eyes and cause me to go blind.\u003C/p>\n\u003Cp>Finally,I got my meds and my monitor. My endo showed me briefly how to use my blood glucose monitor, the finger prick thing. I was prescribed two medications: Metformin, a drug to help my body better use the insulin it makes, and Jardiance, a drug that blocks extra glucose from being reabsorbed by the kidneys. And that was it! That is how I was told I have a life-altering chronic illness and the instructions I was given to manage it.\u003C/p>\n\u003Cp>I got home, took the rest of the day off, and picked up my meds. I don’t remember what I had for dinner that night, but I do remember being upset that all I had wanted all week was a cheesesteak, and now I didn’t know if I could ever have one again.\u003C/p>\n\u003Cp>The next morning, I started my new routine. I took my blood glucose level, often shortened to blood sugar. It took me pricking my finger 3 time to get a working sample. I wasn’t taught how to fill the strips, or how to prick my finger to make it hurt less. I screamed in frustration, a bloody finger, and no idea how to get it to work, until it did. It was 264 mg/dL. 269 mg/dL is the estimated average for an A1c of 11. I took my meds.\u003C/p>\n\u003Cp>That day, I tried to eat a low-carb diet. The pamphlet I was given wasn’t super helpful. I don’t really remember eating much.\u003C/p>\n\u003Cp>Saturday was fine. Sunday morning, I went to the farmer’s market, and when I came home, I felt like crap. I went to sleep for the rest of the day.. Monday, I still felt like crap. I took my blood sugar throughout the day and it was between 144-146 each time; high, but not dangerously so. I stayed in bed all day. I had water, and tried to have some Gatorade, a desperate attempt to have something in my system, not knowing if it was OK or not for me to drink. Tuesday, was the same. I had a telemedicine check-in with my endo. They weren’t able to diagnose anything, and recommended I go to the ER.\u003C/p>\n\u003Cp>So, it turns out I had diabetic ketoacidosis. I was moved to the intensive care unit. I had my finger pricked every few hours and was given regular insulin injections. I didn’t really eat. I was in the ICU for 3 days. On the 3rd day, my partner later told me, she could tell I was feeling better because I had started complaining about the comfort (or lack there of) of the bed. I was finally moved from the ICU down to the general care area.\u003C/p>\n\u003Cp>It took me being hospitalized for a life-threatening complication for me to get any real information about how I could manage my diabetes. I was on day 10 of being diagnosed. I had spent more time having the wonderful hospital staff manage it than I had. By the time Saturday had come around, I was feeling back to my old self and got to really dig into my diagnosis with the specialists who came to visit me:\u003C/p>\n\u003Cul>\n\u003Cli>A nutrition team came in and gave me a small book’s worth of information on how to manage my diabetes. They talked with me about different kinds of food and how they affect my blood sugar and gave me a ton of resources. They also set me up with a nutritionist to follow-up with after I left the hospital.\u003C/li>\n\u003Cli>I met with a new endocrinologist (endo, for short). She was fabulous. I asked her tons of questions. I learned what insulin resistance means and she confirmed my diagnosis (Type 2). She gave me guidelines for how many carbs I should eat and she even talked me through how she calculated that number. She described the different kinds of insulin, and when each is needed (before that, I didn’t know there were different kinds!). At my request, she drew diagrams for me, wrote out formulas for me, and explained in detail basically every question I had about what was happening and why it was happening, from a biological perspective. Finally, she kicked me off Jardiance, having decided that that’s probably what caused my DKA and said she wouldn’t have started me on two drugs at once to manage my condition.\u003C/li>\n\u003C/ul>\n\u003Cp>I was all set to leave, I had seen everyone, but then I had a showdown with who became my hospital arch-nemesis: the general practitioner who had to sign off on my release. I had gone through all of my required stuff to be released, but when I asked if I was going to be released that day, they said “no”, I needed sign-off from the endo who I had met with. I got it, could I be released? Still no. They were concerned that I may have a blood clot in my legs from lying down for a few days, so I needed to go get an ultrasound. That was a multi-hour round-trip. Ok, could I go then? Still no! When you’re in the hospital for DKA, you leave the hospital on insulin. A wonderful nurse came in and taught me how to inject myself with the insulin I’d be getting when I left. This was in the morning. Now, in the late afternoon, I was told I needed me to prove I could give myself my insulin shot. No problem, I thought, until the nurse brought it in for me. I had be taught how to use a home-use, pre-filled auto-injector. They wanted me to use an old-school needle drawing from a vial, which I hadn’t been taught. I told them I absolutely couldn’t do that, I hadn’t been taught that. The GP didn’t care. I was ready to refuse their service and request an new GP when I was told the endo had confidence I would do it at home, and the nurse came and gave me my shot. I was finally released around 6pm Saturday, the 23rd. For those curious, the hospital food wasn’t bad.\u003C/p>\n\u003Cp>Starting that Sunday, for the next two weeks. I stabbed my leg with an insulin shot every morning. Much like my first morning trying to get a blood sugar reading, I cried and yelled and cursed my situation every morning. I hated it. I didn’t want this to be my life. I was deep into the depression stage. My diagnosing endo wanted me to come back in. I refused, and transferred my care to the new hospital endo. Fortunately, I had a 2-week checkup with my endo from the hospital. She saw I was keeping my blood sugar under control, and my final test results from the hospital, and she took me off the insulin and back onto Metformin. With Thanksgiving coming up, she also gave me one last bit of encouraging news: it was OK if my blood sugar got a little high, as long as it didn’t stay high. I could splurge a little for Thanksgiving, as long as it came back in check. And if it didn’t? I had the insulin to get it back in check. That single piece of advice has been the most helpful to me in living with my diabetes.\u003C/p>\n\u003Ch2 id=\"new-diet-who-dis\">New diet, who dis?\u003C/h2>\n\u003Cp>After being released from the hospital, my endo set a new diet for me: no more than than 60 grams of carbs per day. For reference, the USDA guide recommendation is about 250 grams. For reference, 1 slice of sandwich bread is about 15 grams. Everything I knew about healthy eating? Turned on its head. Veggies? Carbs. Fruit? Lots of carbs! Chicharrones? Just fat and protein! I can have as much of those as I want! Hot sauce? Basically nothing; throw that shit on everything!\u003C/p>\n\u003Cp>For the first time in my life, I had food I was afraid of. I broke down at dinner one night because I had to choose between eating peppers and onions or a tortilla with my fajitas. But I think my love of food actually, and tendency towards savory over sweet, really helped me through here. My first meeting with my nutritionist, I was given a ton of information breaking down lists and lists of ingredients and categorizing them by how much impact they had on my blood sugar. Fortunately, I didn’t need to do other, presumably common, things like cut soda and sweets out of my diet or learn how to cook for myself; I really just had to find bread alternatives. And make sure I had room for onions. I couldn’t cut onions out of my diet. I started putting together recipes in my head; desperation bred innovation here. I wound up making buffalo mac and cheese with cauliflower rice, which became a real comfort food for me. I’ve made breakfast for myself every morning since being diagnosed and have perfected the hotel buffet style omelette and put together an excellent avocado toast hack. We found a food delivery service that had carb counts on everything so I could plan my week’s food out. But then, my partner being the lovely person she is, got me an anniversary present that required me to rethink how I dealt with food.\u003C/p>\n\u003Cp>Before I was diagnosed, knowing that I missed Austin, my partner had ordered me a bunch of sausage, jalapeño, and cheese kolaches. I was so excited to have them! But, they arrived after my return from the hospital. I was crestfallen, neither being able to enjoy a food nor a thoughtful present, all at once. I had been using MyFitnessPal to track my carbs, and I found it lacking. I hated the interface. I hated needing to pay for it to set my goals. I hated that even after paying for it it pushed upsells. And more than anything, I hated that it had a bunch of random user-generated food in there that wasn’t reliable (Where did they get these numbers? What’s 1 carrot compared to my carrot?). I needed something better.\u003C/p>\n\u003Ch2 id=\"tracking-my-health\">Tracking my health\u003C/h2>\n\u003Cp>When I started seriously tracking what I ate, I quickly started obsessing over nutrition labels. I noticed something important; all nutrition labels (in the US anyway) give serving size in either grams (weight) or milliliters (volume). Figuring out how many carbs I ate was a matter of measuring and multiplication! My best friend, a chemistry PhD, recommended I buy a scientific balance for my kitchen (aka a super fancy scale). I got one. This is really where my frustration with MyFitnessPal really manifested itself. I had precise measurements for what I was eating, and I couldn’t properly track it! I started looking for a better way. I found the \u003Ca href=\"https://fdc.nal.usda.gov/api-guide.html\">USDA FoodCentral API\u003C/a>. I had an idea. I was going to make my own app.\u003C/p>\n\u003Cp>Starting with the API, I made a simple web app (using Svelte, Vite, Firebase functions, and Firestore, for those interested). Everything in FoodCentral is measured by weight or milliliters, and baselined against either 100 grams or 100 milliliters, letting me accurately scale the nutrition of any food I put in. It was great! With a meal entry system in place, I could start fixing some of the other problems I had with MyFitnessPal. The first thing I cared about, tracking my blood sugar and food together in a timeline view, so I could see how what I ate affected my blood sugar. My nutritionist wanted me to take notes about how I was feeling throughout the day, so I added that. I was told I needed to loose weight, so I added weight tracking. I was told my excess water drinking was a clear sign of diabetes, so I added water consumption. After using it for a few weeks, I found that sometimes, I really just wanted to enter carb, protein, fat, and calorie estimates instead of looking up food. I added that! I now had a way to comprehensively track my health. I did what came naturally to me: take what I’ve learned and turn it into a scalable system. It gave me a safety net, something for me to unload my stress onto; I built something to help me process the trauma I was gone through. I built something to carry the burden of maintaining my health.\u003C/p>\n\u003Ch2 id=\"cheat-days-on-a-health-critical-diet\">Cheat days on a health-critical diet?\u003C/h2>\n\u003Cp>Thanksgiving was my first big test. Besides breakfasts, I hadn’t really cooked since being diagnosed, and Thanksgiving’s usually a carb-heavy meal. I went to my parent’s house, brought my scale, planned out my meal using my app, and weighed everything to the tenth of a gram. I made gravy using modernist techniques (xanthan gum and gelatin) instead of flour. I used monkfruit sweetener instead of sugar in my cranberry sauce. I made way too salty cauliflower puree. My family played along, and I really appreciated it. We did make Pillsbury biscuits and my potato bread, brown butter, sage, and mushroom dressing. It’s something my partner likes too much, and I wasn’t prepared to find a replacement for. I went into the day knowing it was going to be tough, but kept my endo’s reminder in the back of my head; it’s OK if my blood sugar got a little high, as long as it didn’t stay high. My insulin shot was ready if I needed it. I had a plate of food, a little of everything, and the next morning, my blood sugar was OK. I trusted my doctor, and it got me through Thanksgiving. It was my first real challenge to my diet, and I came through the other side fine.\u003C/p>\n\u003Cp>The next big challenge came in the middle of December. My partner had a business trip that required us to be in my old neighborhood in NYC. All of my favorite restaurants were there, and I didn’t have my scale. I had a bagel for the first time from Russ &#x26; Daughters. I fought through anxiety and fear to order noodles from Momofuku Noodle Bar for dinner. I came out the other end OK again. I was doing well.\u003C/p>\n\u003Cp>I had a follow-up appointment with my endo in mid-January. I had been keeping really precise track of what I had been eating and my blood sugar. I felt good going into it. My A1c came back. 5.4. \u003Cstrong>\u003Cem>5.4\u003C/em>\u003C/strong>. In 4 months, through diet alone, I had managed to bring my A1c down almost 6 points! Not only was I no longer in the diabetic range, I wasn’t even in the pre-diabetic range! I was in a normal range! I had also lost weight! When I was admitted to the hospital, I weighed about 250lb. I now weighed 224lb. I was feeling great. My endo was impressed. She thought, going into the appointment, that she’d need to increase my Metformin dosage but, given where I was, she kept it the same. The system I had put in place was working.\u003C/p>\n\u003Ch2 id=\"dealing-with-diet-anxiety\">Dealing with diet anxiety\u003C/h2>\n\u003Cp>For most of the prior 4 months, I had been sticking really strictly to the low range of my diet, trying to only have around 30 grams of carbs per day, total. I had been doing so well that I started to relax that, letting myself balloon it all the way up to a whopping 60 grams a day! I even added some fruit back into my diet! Salt on watermelon? A+. I had lost so much weight by this point I needed to go buy new pants because neither my pants nor my belts worked! It felt good! Then, disaster struck.\u003C/p>\n\u003Cp>Remember how I said, for the first time in my life, I had foods I was afraid of? Well, throughout these first few months, once a week, sometimes more, sometimes less, when my partner and I were trying to decide on dinner, I’d have an anxiety attack about not being able to eat anything at a restaurant we were looking at. I was like Neo in The Matrix; where he saw code everywhere, I saw carbs. This was probably made worse both because I know how to cook (so know where carbs get hidden) and know that restaurant cooking is usually punched up with what amounts to bonus carbs. I had mostly gotten this under control, I thought, until early February. I had ordered one of my comfort delivery foods from a local restaurant, shawarma over salad, for dinner, but when it arrived, something had gotten crossed in the order, and instead of salad, I had only rice. It broke me. All of my anxiety about food and my diet flooded over me, and I stopped eating dinner. Not that night. At all. I rearranged my eating schedule to have a late lunch every day. I divided my daily calories between the two meals. To this day, thinking about having dinner on weeknights bubbles up feelings of dread. It’s something I’m still working on. All that’s to say, I needed a break.\u003C/p>\n\u003Cp>At the end of February, my partner planned a little weekend trip to Philadelphia for us. We needed to get out of the house, and away from our routine. I used it as an opportunity to try and overcome some of my anxiety around food; I decided to not track what I ate while I was there. We wound up having a great weekend. I finally got the cheesesteak I had been craving since October! We got some big soft pretzels and had some great Chinese noodles and dumplings. We ate indoors for the first (and really only since) time since the start of the pandemic. Per my doctor’s recommendation, I took an extra Metformin pill at night. My blood sugar kept in range.\u003C/p>\n\u003Cp>In March, my partner came through again. We had been craving the ability to go back to the movies, and she found a local drive-in movie theater. I had had a number of successful trips going out of my diet comfort zone, I decided to treat myself, and see what happened. I had a bag of buttered popcorn and Sno-Caps. It was delicious. I had really missed popcorn. The next morning, my blood sugar was fine again.\u003C/p>\n\u003Cp>By April, thanks to these successful attempts at pushing up my carb limit, I decided to go wild and allow myself up to 90 grams of carbs per day! I could now have a full sandwich, on regular bread, for lunch, and not go over my carb limit! It felt freeing.\u003C/p>\n\u003Ch2 id=\"in-a-groove\">In a groove\u003C/h2>\n\u003Cp>By this time, I had expanded my app. I had added exercise tracking. I had deeply investigated choosing and tracking macros, the ratio of carbs, fat, and protein that make up your daily caloric intake, and added a whole system to manage and update it as your weight changes, including being able to set minimums as well as maximums. I had built in A1c estimation. I had built graphs to show weight and blood sugar trends. I added body fat percentage and BMI tracking. I put in the ability to generate reports! I had as close to a fully-connected view of food, blood sugar, weight, and exercise as I could have hoped for at that point. And the system worked.\u003C/p>\n\u003Cp>On May 10, 2022, I had my second check-in with my endo. I now weighed 196lb. My app had estimated my A1c to be 5.4. It was 5.1. Only taking my blood sugar more would have made it more accurate. I had started wearing a smart watch again to track my resting heart rate. It had gone from around 120 beats per minute in October to around 70. I felt fantastic. My endo told me she talks about me to her other patients as proof that diet can control your diabetes. She \u003Cem>reduced\u003C/em> my Metformin dosage, even suggesting that if I didn’t want to, I could stop taking it! She didn’t think she needed to see me again until November. I still needed to exercise more. Fair.\u003C/p>\n\u003Cp>By this time, I had my eye set on a weight loss goal: 180lb. Before I started drastically losing weight in September of 2021, I weighed about 285lb. Loosing over 100lb felt like a good, and now reachable, goal for me. By the end of June, \u003Ca href=\"https://twitter.com/Snugug/status/1539962798129774592?s=20&#x26;t=9A1s_HytEmnHjx17HD660w\">I had lost 100lb\u003C/a>. We went to a destination wedding mid-July and I overate a little. \u003Ca href=\"https://twitter.com/Snugug/status/1558591617078071296?s=20&#x26;t=9A1s_HytEmnHjx17HD660w\">I hit my goal mid-August\u003C/a>. I’ve updated my macro goals from lose weight to maintain it.\u003C/p>\n\u003Cp>This week, I finished the final feature I’ve wanted to build into my app for a long time: routines. Set up checks for logging anything in the app on a reoccurring basis, optionally within a time range, and get a gold star if you complete it. I built it to give me a visual indicator of whether I took my medicine each day. And that bring me to today, writing this for y’all.\u003C/p>\n\u003Ch2 id=\"what-ive-learned\">What I’ve learned\u003C/h2>\n\u003Cp>Throughout this process, I’ve learned a lot about diet, food, and health from talking to friends, specialists, and strangers about this journey. Hopefully some of this is helpful to you.\u003C/p>\n\u003Ch3 id=\"diabetic-friendly-eating\">Diabetic friendly eating\u003C/h3>\n\u003Cp>I was explicitly told by my endo that I couldn’t eat less than 30 grams of carbs per day because that may push me into ketosis and she didn’t want to risk that, with me having been hospitalized for DKA once already. But, keto diet branded foods? They’re amazing. As with everything, you need to read the nutrition label and see what a serving actually is, and if the food really is low-carb or just marketing nonsense, but I find that most stuff in the supermarket labeled keto is a great alternative to other versions. I found I particularly liked the Sola brand of bread products, especially their golden wheat bread and hamburger buns. Be wary of “healthy” breads like Dave’s Killer Bread or Ezekiel bread, while whole grains and especially nuts in bread may be considered “healthier”, they also tend to bump up the carb count, so if you’re going to eat them, make sure you’ve got your serving size down right. Believe it or not, good old fashioned nothing in it white Wonder bread is not bad; a single serving is 2 slices and less than 30 carbs! Some potato breads I also found were tasty and lower carb than others around. When looking for a crunchy snack, again turning to Keto goodies worked here, specifically chicharrones. I kind of fell in love with Pork King Good’s Pink Salt &#x26; Vinegar chicharrones for a while. In general, though, I’ve found that between having a scale and a goal number of carbs for a snack or meal, I’m mostly able to eat what I’d like.\u003C/p>\n\u003Cp>I’ve also found that natural alternative sugars, like monk fruit, erythritol, allulose, are all excellent substitutes for sweetness in most applications. Even if I wasn’t diabetic, I’d probably continue using these in recipes and applications where I mostly just needed sweetness, like pickled onions (I make so many of these), whipped cream, candied nuts, and the like. They aren’t 1\u003C/p>\u003Cdiv>\u003C/div> replacements in recipes where sugar’s ingredient function is more than really sweetness, so you’ll need to experiment to get those right. I’ve found Lakanto a great source for monk fruit sweetener, and King Author makes a Keto baking sugar blend (as well as Keto flour) that have both proven at least mildly successful for me.\u003Cp>\u003C/p>\n\u003Cp>A common thing, when looking at many “Keto” foods, is the advertisement of “net carbs”. Talking with my endo and nutritionist about this, here’s what I’ve learned: the standard net carb formula is total carbs minus fiber and sugar alcohol (what things like monk fruit, erythritol, and allulose are considered). How much food affects your blood sugar is called their \u003Ca href=\"https://www.mayoclinic.org/healthy-lifestyle/nutrition-and-healthy-eating/in-depth/glycemic-index-diet\">glycemic index\u003C/a>, or GI. Sugar alcohols generally have a GI at or near 0, so they can be removed when “counting carbs”. Fiber passes through your body undigested, so it, too, has a GI at or near 0. Both have said counting net carbs instead of total carbs works for some people, and doesn’t work for others. For me, between when I was hospitalized and my first meeting with my endo after that, I was counting total carbs. I now count net carbs.\u003C/p>\n\u003Ch3 id=\"tracking-blood-sugar\">Tracking blood sugar\u003C/h3>\n\u003Cp>First and foremost, unless your doctor tells you to, I wouldn’t recommend tracking your blood sugar “for fun”. For the most accurate reading, you’re suppose to draw blood for a reading at least 4x a day. It’s painful, it can be messy, and it requires a lot of equipment. That said, I did find it really interesting learning about how your body processes food. From my conversations, after you start eat, your body starts to produce insulin to turn your food into energy. About 2 hours after you’ve eaten, your blood sugar will be at its peak from your food. About 4 hours after you’ve eaten, it should have returned to normal. When you sleep, your blood sugar rests, too, and needs to “wake up” again. When taking my blood sugar, I’ve been told to always take it before meals, to get an accurate reading of my baseline. I also found that my blood sugar is constantly a little high in the morning, a combination of it still waking up and it being the tail end of my 24 hour medicine cycle (I take an extended release form of Metformin). Given how well I’ve managed my condition, I was given the OK by my doctor to cut back taking my blood sugar to morning and evening, and then eventually just morning, with the understanding that if it stayed high I’d need to up my dosage or come back in with some insulin. I’ve got two kinds sitting in my fridge: Lantus, long-acting insulin usually taken once per day, and Humalog, rapid-acting insulin taken to help reduce blood sugar spikes from eating.\u003C/p>\n\u003Cp>For those who can’t reduce how many times they take their blood sugar, there’s a whole range of devices called continuous glucose monitors, or CGMs. They’re devices that attach to your body, usually the under arm or stomach, with a little needle sitting just under your skin to read your glucose levels. Some of these are amazingly accurate; a friend of mine who requires an insulin pump has one accurate enough that it’s allowed to control said pump. He’s described it as a game-changer for him. That’s not an introductory CGM, though. I tried the Libre Freestyle 2, a little white button that sat on the back of my arm. In theory it was great! I only needed to prick my finger when I calibrated it, and then it’d work in the background for two weeks. Whenever I needed a reading, I could tab my reader to it and I had it! It didn’t work for me in practice, though. I found the readings were constantly on the low end of their accuracy guarantee (around 80% accurate) and resulted in a lot of false alarms for low blood sugar. It constantly came detached. I had one where blood came up through it. One of mine in December was inaccurate to their standards, so I was sent another one, the next one I used fell off in less than a week, then the next one I put on failed to work after the day’s worth of calibration. 3 monitors in 2 weeks, none of which were super accurate? It wasn’t convenient for me anymore, so I went back to my regular reader, with my updated schedule, after discussing it with my endo. So basically, your mileage may vary with them, but they’re worth trying.\u003C/p>\n\u003Cp>One last thing, if you’re taking your blood sugar by pricking your finger, here are two protips I learned from the ICU nurses: prick your finger on the \u003Cem>side\u003C/em> of your finger instead of the pad of your finger (it’ll hurt less), and ratchet down the force just enough for it to draw blood and no more (no need for extra pain, and you really only need a drop of blood).\u003C/p>\n\u003Ch3 id=\"losing-weight\">Losing weight\u003C/h3>\n\u003Cp>If you came here from my Twitter, you probably weren’t expecting over 6k words on diabetes for how I lost weight, but the truth of the matter is, the only reason I lost this weight is I had a \u003Cem>very strong\u003C/em> motivating factor to do so. I’ve tried to lose weight since literally high school, and the fact that I now weigh less than I did then is a testament to that motivation. Not to sound dramatic, but being overweight basically became an existential threat. That was my motivation. For the first few months, I didn’t even really care how many calories I was eating, it was all about carbs, but the funny thing about being hospitalized and not eating for a few days is it reset my hunger levels. For the first few months, I probably ate between 1100 and 1500 calories a day through a combination of not being hungry, not being able to mindlessly eat carbs, and not wanting to just eat meat when my carb limit was expended. I found in that time that I wound up eating, by grams, roughly the same amount of fat and protein, so when I started to actively care about macros and losing weight, I used that as my baseline instead of trying to fit into a specific diet. With my current weight and weight maintenance goals, I look to eat about 1900 calories a day, with about 100 grams of carbs, 119 grams of fat, or about 70% of my remaining calories, and 115 grams of protein, or about 30% of my remaining calories. But finding the right ratio for you is personal and based on a number of factors. There are only two constants I’ve seen in this journey: energy in needs to be less than energy used, and sustainable weight loss is a long-term game, not a short-term one. I don’t stress if my weight goes up or down a few pounds day-to-day, or if I have a cheat day, or week. The long-term trends, and the strategy for safely losing weight (less in than used, but don’t go hungry) is what’s important.\u003C/p>\n\u003Ch3 id=\"diabetic-health-care\">Diabetic health care\u003C/h3>\n\u003Cp>Finally, I’ve had the opportunity to reflect on the health care I received when I was diagnosed, and have been able to talk to others, some of whom were recently diagnosed, some diagnosed a long time ago, and I’ve seen one common thread emerge: no one seems to get good advice. Everyone I’ve talked to had more or less the same story I had; they were given a blood glucose monitor, told to eat fewer carbs, told to get some follow-ups, then shoved out. It doesn’t seem to matter what your health insurance is or where in the country you are, everyone really seems to be more-or-less left to figure it out, and cope with it, on their own. The first website I went to look for help was the American Diabetic Association. Most of the content on their website wasn’t more helpful than what I had been given. Their diabetes food hub immediately served me a wall of Splenda sponsored recipes, which caused me to immediately check out. Even with the great team I’ve got now, I had to piece a number of things together myself. If I were to guess, it’s probably a combination of nuance is hard, an information dump on top of the diagnosis would be overwhelming, prioritizing getting it under control, and time is short. I’m really thankful I had a friend to reach out to who had gone through this already who was able to reassure me that things got easier, and that I was able to do that for someone else, too, but we shouldn’t rely on an ad-hoc network for these things. This is such a prevalent disease I’d have assumed support networks and reliable information would be easy to come by, but it’s really not. Anything beyond surface-level advice is glaringly absent, or devoid of much other than opinion. My hope with sharing my story is that someone will read this and take from it what I got from my friend, and hopefully find something useful to help them on their journey, too.\u003C/p>\n\u003Chr>\n\u003Cp>Thanks for reading. Love y’all!\u003C/p>",{"headings":884,"localImagePaths":916,"remoteImagePaths":917,"frontmatter":918,"imagePaths":920},[885,888,891,894,897,900,903,907,910,913],{"depth":80,"slug":886,"text":887},"new-diet-who-dis","New diet, who dis?",{"depth":80,"slug":889,"text":890},"tracking-my-health","Tracking my health",{"depth":80,"slug":892,"text":893},"cheat-days-on-a-health-critical-diet","Cheat days on a health-critical diet?",{"depth":80,"slug":895,"text":896},"dealing-with-diet-anxiety","Dealing with diet anxiety",{"depth":80,"slug":898,"text":899},"in-a-groove","In a groove",{"depth":80,"slug":901,"text":902},"what-ive-learned","What I’ve learned",{"depth":904,"slug":905,"text":906},3,"diabetic-friendly-eating","Diabetic friendly eating",{"depth":904,"slug":908,"text":909},"tracking-blood-sugar","Tracking blood sugar",{"depth":904,"slug":911,"text":912},"losing-weight","Losing weight",{"depth":904,"slug":914,"text":915},"diabetic-health-care","Diabetic health care",[],[],{"title":875,"published":919,"summary":877},"2022-10-26",[],"adaptable-components-with-css-style-queries",{"id":921,"data":923,"body":927,"filePath":928,"digest":929,"rendered":930},{"title":924,"published":925,"summary":926},"Adaptable Components with CSS Style Queries",["Date","2023-04-04T00:00:00.000Z"],"Use CSS Style Queries to let components adapt to more scenarios than just container size or screen width.","I'm in the process of refactoring [ChromeOS.dev](https://chromeos.dev) and using the opportunity to clean up our components and the styling that controls them. The site is designed to be maximally flexible; we don't use standard breakpoints, content areas are sized based on characters to maintain optimal line length, we've implemented flexible typography, and more. Think [intrinsic design](https://aneventapart.com/news/post/designing-intrinsic-layouts-aea-video) as coined by [Jen Simmons](https://front-end.social/@jensimmons). So when I sat down to refactor, [container queries](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Container_Queries) were the obvious choice for maintaining the responsive ideal of our site. I got through one component before I ran into an issue.\n\nOn our site, we've got a table of contents component (ToC). In theory, it's a pretty simple component: a list of certain headers on the page that, in one view, is collapsible with a background and in another, expanded without one. You can see examples on a [blog post](https://chromeos.dev/en/posts/grow-your-ideas-in-2023-dev-guidance-and-inspiration-for-delighting-chromeos-users) (_Grow your ideas in 2023: Dev guidance and inspiration for delighting ChromeOS users_) and a [reference page](https://chromeos.dev/en/web/desktop-progressive-web-apps) (_Desktop Progressive Web Apps_). My first thought was that this was a \"reverse container query\" moment, where the \"small view\" is for large viewports and the \"large view\" is for small viewports, except that's not quite true. That's not quite true, in practice.\n\nOur blog post layout and reference page layout are slightly different. One expands to two columns, one to three, and the columns are slightly different sizes. This ultimately means that, if I were to adapt just on component width or screen size, which we have to do today, the ToC winds up breaking in one or the other layout. This isn't ideal.\n\nPreviously, the way I'd get around this would be by duplicating CSS; having something, usually a class, I can query off of (like [Modernizr](https://modernizr.com/) style feature detection),attach the media query to that, then duplicate my CSS for each instance. Then, I had a brainstorm.\n\n## Custom view queries with CSS Style Queries\n\n[CSS Style Queries](https://developer.chrome.com/blog/style-queries/) are the cousin to container queries; instead of querying a container's size, they query a specific property/value pair. Right now, they're [only implemented in Chromium browsers](https://caniuse.com/css-container-queries-style) and only for [CSS Custom Properties](https://developer.mozilla.org/en-US/docs/Web/CSS/--*), but that's all you need! With style queries, you can write a layout using normal media queries and set the view you want for a component, like this:\n\n```scss\n.layout {\n  --toc-view: 'inline';\n}\n\n@media (min-width: 789px) {\n  .layout {\n    --toc-view: 'block';\n  }\n}\n```\n\nAnd then in your component, you can respond to it like this:\n\n```scss\n.toc {\n  color: red;\n}\n\n// Only apply this styling with the ToC is displayed \"inline\"\n@container style(--toc-view: 'inline') {\n  .toc {\n    color: blue;\n  }\n}\n\n// Only apply this styling with the ToC is displayed \"block\"\n@container style(--toc-view: 'block') {\n  .toc {\n    color: green;\n  }\n}\n```\n\nVoila! You've made a custom view query! You can do this on a per-component basis, like you see here, or, as I'm doing in our refactor, do it for higher-level layout parts (`--extras-inline` and `--subnav-inline`, either `0` or `1`). Now you can have components not only adapt to their size, but where they're used in a given layout!\n\nJust about anywhere where I had a similar pattern of duplicating CSS code based on a media query and \"pivot\" class can be replaced with this. The next component I'll be tackling with this is our main navigation. There, we set different breakpoints to go from an inline to an offscreen menu based on language. It's the same pattern I had with the ToC: media queries plus a \"pivot\" selector, and duplicated CSS. Now, I'll still have those, but they'll just change a custom property to signal that the menu should be rearranged! Much easier to maintain.\n\nYou can (and should) stack this pattern with other best-practice responsive patterns, like treating this as progressive enhancement, and starting small, and being flexible with the final display; this should be used as a way to expand your design options, not as a way to swim against the [ebb and flow of the web](https://alistapart.com/article/dao/).\n\n---\n\nWith this new pattern in my back pocket, I've now got three ways to change how a component looks: based on the viewport, based on its inherent size, and based on where it lives on the site, all without JavaScript, all without duplicating CSS, and all maintained in a component-first way. I'm already excited to use it, and hope you'll find uses for it in your work, too.","src/content/posts/adaptable-components-with-css-style-queries.md","33bf5e5e1d7fd9f0",{"html":931,"metadata":932},"\u003Cp>I’m in the process of refactoring \u003Ca href=\"https://chromeos.dev\">ChromeOS.dev\u003C/a> and using the opportunity to clean up our components and the styling that controls them. The site is designed to be maximally flexible; we don’t use standard breakpoints, content areas are sized based on characters to maintain optimal line length, we’ve implemented flexible typography, and more. Think \u003Ca href=\"https://aneventapart.com/news/post/designing-intrinsic-layouts-aea-video\">intrinsic design\u003C/a> as coined by \u003Ca href=\"https://front-end.social/@jensimmons\">Jen Simmons\u003C/a>. So when I sat down to refactor, \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Container_Queries\">container queries\u003C/a> were the obvious choice for maintaining the responsive ideal of our site. I got through one component before I ran into an issue.\u003C/p>\n\u003Cp>On our site, we’ve got a table of contents component (ToC). In theory, it’s a pretty simple component: a list of certain headers on the page that, in one view, is collapsible with a background and in another, expanded without one. You can see examples on a \u003Ca href=\"https://chromeos.dev/en/posts/grow-your-ideas-in-2023-dev-guidance-and-inspiration-for-delighting-chromeos-users\">blog post\u003C/a> (\u003Cem>Grow your ideas in 2023: Dev guidance and inspiration for delighting ChromeOS users\u003C/em>) and a \u003Ca href=\"https://chromeos.dev/en/web/desktop-progressive-web-apps\">reference page\u003C/a> (\u003Cem>Desktop Progressive Web Apps\u003C/em>). My first thought was that this was a “reverse container query” moment, where the “small view” is for large viewports and the “large view” is for small viewports, except that’s not quite true. That’s not quite true, in practice.\u003C/p>\n\u003Cp>Our blog post layout and reference page layout are slightly different. One expands to two columns, one to three, and the columns are slightly different sizes. This ultimately means that, if I were to adapt just on component width or screen size, which we have to do today, the ToC winds up breaking in one or the other layout. This isn’t ideal.\u003C/p>\n\u003Cp>Previously, the way I’d get around this would be by duplicating CSS; having something, usually a class, I can query off of (like \u003Ca href=\"https://modernizr.com/\">Modernizr\u003C/a> style feature detection),attach the media query to that, then duplicate my CSS for each instance. Then, I had a brainstorm.\u003C/p>\n\u003Ch2 id=\"custom-view-queries-with-css-style-queries\">Custom view queries with CSS Style Queries\u003C/h2>\n\u003Cp>\u003Ca href=\"https://developer.chrome.com/blog/style-queries/\">CSS Style Queries\u003C/a> are the cousin to container queries; instead of querying a container’s size, they query a specific property/value pair. Right now, they’re \u003Ca href=\"https://caniuse.com/css-container-queries-style\">only implemented in Chromium browsers\u003C/a> and only for \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/--*\">CSS Custom Properties\u003C/a>, but that’s all you need! With style queries, you can write a layout using normal media queries and set the view you want for a component, like this:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.layout\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  --toc-view: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'inline'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">789\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .layout\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    --toc-view: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'block'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>And then in your component, you can respond to it like this:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.toc\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Only apply this styling with the ToC is displayed \"inline\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">@container style(--toc-view: 'inline') {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .toc\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">blue\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Only apply this styling with the ToC is displayed \"block\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">@container style(--toc-view: 'block') {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .toc\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Voila! You’ve made a custom view query! You can do this on a per-component basis, like you see here, or, as I’m doing in our refactor, do it for higher-level layout parts (\u003Ccode>--extras-inline\u003C/code> and \u003Ccode>--subnav-inline\u003C/code>, either \u003Ccode>0\u003C/code> or \u003Ccode>1\u003C/code>). Now you can have components not only adapt to their size, but where they’re used in a given layout!\u003C/p>\n\u003Cp>Just about anywhere where I had a similar pattern of duplicating CSS code based on a media query and “pivot” class can be replaced with this. The next component I’ll be tackling with this is our main navigation. There, we set different breakpoints to go from an inline to an offscreen menu based on language. It’s the same pattern I had with the ToC: media queries plus a “pivot” selector, and duplicated CSS. Now, I’ll still have those, but they’ll just change a custom property to signal that the menu should be rearranged! Much easier to maintain.\u003C/p>\n\u003Cp>You can (and should) stack this pattern with other best-practice responsive patterns, like treating this as progressive enhancement, and starting small, and being flexible with the final display; this should be used as a way to expand your design options, not as a way to swim against the \u003Ca href=\"https://alistapart.com/article/dao/\">ebb and flow of the web\u003C/a>.\u003C/p>\n\u003Chr>\n\u003Cp>With this new pattern in my back pocket, I’ve now got three ways to change how a component looks: based on the viewport, based on its inherent size, and based on where it lives on the site, all without JavaScript, all without duplicating CSS, and all maintained in a component-first way. I’m already excited to use it, and hope you’ll find uses for it in your work, too.\u003C/p>",{"headings":933,"localImagePaths":937,"remoteImagePaths":938,"frontmatter":939,"imagePaths":941},[934],{"depth":80,"slug":935,"text":936},"custom-view-queries-with-css-style-queries","Custom view queries with CSS Style Queries",[],[],{"title":924,"published":940,"summary":926},"2023-04-04",[],"amusing-analytics-december",{"id":942,"data":944,"body":948,"filePath":949,"digest":950,"rendered":951},{"title":945,"published":946,"summary":947},"Amusing Analytics for December",["Date","2013-01-12T00:00:00.000Z"],"Just decided to take a look at my analytics for the month of December, and I thought they were amusing, so I've decided to share.","Just decided to take a look at my analytics for the month of December 2012, and I thought they were amusing, so I've decided to share. I use Google Analytics, as a frame of reference. In the month of December, I had 1,408 visitors to my site. They averaged 1.54 pages per visit and 1:32 on site. 70.38% of them were new.\n\n## Location\n\nMy site was visited by users in 74 Countries/Territories with at least one page view from every continent on the planet (Antartica notwithstanding). The most active continent was Europe, with 620 visits. The least active was Africa, with just 5. There were 18 visits from a _(not set)_ continent. The most active sub continent regions were North America followed by West, North, East, than South Europe. The least active sub continent region was the Caribbean, followed by East, South, and North Africa.\n\nThe 15 most active countries were, in descending order:\n\n1. United States\n2. United Kingdom\n3. Germany\n4. India\n5. Russia\n6. Netherlands\n7. Canada\n8. Belgium\n9. Australia\n10. France\n11. Ukraine\n12. Greece\n13. Italy\n14. Switzerland\n15. Israel\n\nThe 15 least active countries with at least one visit were, in ascending order:\n\n1. Uruguay\n2. Uganda\n3. Paraguay\n4. Maldives\n5. Myanmar [Burma]\n6. Montenegro\n7. Moldova\n8. Lebanon\n9. Iceland\n10. Ecuador\n11. Dominican Republic\n12. Bulgaria\n13. Argentina\n14. United Arab Emirates\n15. South Africa\n\nThe 15 most active cities were, in descending order:\n\n1. New York\n2. London\n3. Saratov\n4. Gent\n5. Dnipropetrovs'k\n6. Sydney\n7. Khania\n8. Ramat Gan\n9. Amsterdam\n10. Zurich\n11. Moscow\n12. Ardmore\n13. League City\n14. Paris\n15. Bangalore\n\nThe 4th most active city was (not set), so it was omitted.\n\n## Technology\n\nAs someone who argues for cross-browser compatibility and a mobile-first approach to all things web, Technology I find particularly interesting. Overall, I have 24 distinct Browser/Operating System pairings, with 87 different browser versions. Most of the different Browser/OS pairings come from Mobile. For purposes of the following statistics, when it says Safari (in-app), it's referring to opening a website in an application on an iOS device that is neither the default Safari app, nor one of the major secondary iOS browsers (Chrome, Opera Mini, etc…).\n\nThe Top 15 most active browsers/OS pairs were, in descending order:\n\n1. Chrome/Mac\n2. Chrome/Windows\n3. Safari/Mac\n4. Safari (in-app)/iOS\n5. Firefox/Windows\n6. Chrome/Linux\n7. Firefox/Mac\n8. Safari/iOS\n9. Firefox/Linux\n10. IE/Windows\n11. Chrome/Android\n12. Chrome/iOS\n13. Android Browser/Android\n14. Opera/Windows\n15. Mozilla Compatible Agent/Mac\n\nI get more combined Android traffic than I get IE traffic. My two most popular versions of IE are 8 and 9, both tied, with 10 a distant 3rd and 6 and 7 with one a piece.\n\nOne thing I've found is, I really need to figure out a nice wide layout for my site.I've got 60 distinct screen resolution, the largest being 6400x4000 (that's larger than the 4k beasts coming out, and it wasn't a bounce; they stuck around for a while!) and the smallest being 228x240. If we do the maths, that's a 6172x3760 area that my site should cover and cover well. That's just silly!\n\nTop 15 screen resolutions are, frankly, bordering on ginormous. They are, in descending order:\n\n1. 1920x1080\n2. 1440x900\n3. 2560x1440\n4. 1366x768\n5. 1680x1050\n6. 1280x800\n7. 1920x1200\n8. 230x480\n9. 768x1024\n10. 1280x1024\n11. 320x568\n12. 1600x900\n13. 1024x768\n14. 2560x1600\n15. 1600x1200\n\n## Mobile\n\nGoogle Analytics' Mobile data includes what they define as tablets and down as mobile traffic and everything else as not mobile traffic. While not entirely satisfied with those definitions, we'll run with it for the sake of this post.\n\nOver the month of December, a little over 20% of all of my site's traffic was from mobile devices. While both mobile and not mobile both have approximately the same number of pages per visit, mobile users stayed on the site a full minute less than non mobile, but also had 15.22% more new visits with only 7.51% more bounces.\n\nWhat everyone really wants to know about Mobile, though, is what devices people are browsing from. While I truly despise UA sniffing, and I'm assuming that's what GA is doing, I'm going to give it to you! So, the top 10 mobile devices to come to my site in December are, in descending order:\n\n1. Apple iPhone (includes all versions)\n2. Apple iPad (includes all versions, including mini)\n3. Google Nexus 7\n4. Samsung Galaxy Nexus\n5. Apple iPod\n6. HTC Vision\n7. Motorola MZ604 Xoom\n8. Samsung GT-I9300 Galaxy S3\n9. Samsung SGH-I897 Galaxy S Captivate\n10. SonyEricsson LT18i Xperia Arc\n\nNumber 5 was _(not set)_ so, again, I left it out of the rankings. Some interesting secondary characteristics from these devices. While the iPhone and iPad collectively blow Android out of the water with number of visits (iPads total 76 visits at number 2, Google Nexus 7 totals 8 visits at number 3), it's actually the Android users that spend more time on the site. The four devices that, on average, spent the most amount of time on my site are all Android devices with the top device averaging 6:14 on site compared to the iPhone's 0:56 and iPads's 0:29.\n\n---\n\nOk, I think that about wraps it up! If there's anything you're particularly interested in knowing that I haven't covered, let me know and if I can I'll let you know!","src/content/posts/amusing-analytics-december.md","50908aabaf07de71",{"html":952,"metadata":953},"\u003Cp>Just decided to take a look at my analytics for the month of December 2012, and I thought they were amusing, so I’ve decided to share. I use Google Analytics, as a frame of reference. In the month of December, I had 1,408 visitors to my site. They averaged 1.54 pages per visit and 1\u003C/p>\u003Cdiv>\u003C/div> on site. 70.38% of them were new.\u003Cp>\u003C/p>\n\u003Ch2 id=\"location\">Location\u003C/h2>\n\u003Cp>My site was visited by users in 74 Countries/Territories with at least one page view from every continent on the planet (Antartica notwithstanding). The most active continent was Europe, with 620 visits. The least active was Africa, with just 5. There were 18 visits from a \u003Cem>(not set)\u003C/em> continent. The most active sub continent regions were North America followed by West, North, East, than South Europe. The least active sub continent region was the Caribbean, followed by East, South, and North Africa.\u003C/p>\n\u003Cp>The 15 most active countries were, in descending order:\u003C/p>\n\u003Col>\n\u003Cli>United States\u003C/li>\n\u003Cli>United Kingdom\u003C/li>\n\u003Cli>Germany\u003C/li>\n\u003Cli>India\u003C/li>\n\u003Cli>Russia\u003C/li>\n\u003Cli>Netherlands\u003C/li>\n\u003Cli>Canada\u003C/li>\n\u003Cli>Belgium\u003C/li>\n\u003Cli>Australia\u003C/li>\n\u003Cli>France\u003C/li>\n\u003Cli>Ukraine\u003C/li>\n\u003Cli>Greece\u003C/li>\n\u003Cli>Italy\u003C/li>\n\u003Cli>Switzerland\u003C/li>\n\u003Cli>Israel\u003C/li>\n\u003C/ol>\n\u003Cp>The 15 least active countries with at least one visit were, in ascending order:\u003C/p>\n\u003Col>\n\u003Cli>Uruguay\u003C/li>\n\u003Cli>Uganda\u003C/li>\n\u003Cli>Paraguay\u003C/li>\n\u003Cli>Maldives\u003C/li>\n\u003Cli>Myanmar [Burma]\u003C/li>\n\u003Cli>Montenegro\u003C/li>\n\u003Cli>Moldova\u003C/li>\n\u003Cli>Lebanon\u003C/li>\n\u003Cli>Iceland\u003C/li>\n\u003Cli>Ecuador\u003C/li>\n\u003Cli>Dominican Republic\u003C/li>\n\u003Cli>Bulgaria\u003C/li>\n\u003Cli>Argentina\u003C/li>\n\u003Cli>United Arab Emirates\u003C/li>\n\u003Cli>South Africa\u003C/li>\n\u003C/ol>\n\u003Cp>The 15 most active cities were, in descending order:\u003C/p>\n\u003Col>\n\u003Cli>New York\u003C/li>\n\u003Cli>London\u003C/li>\n\u003Cli>Saratov\u003C/li>\n\u003Cli>Gent\u003C/li>\n\u003Cli>Dnipropetrovs’k\u003C/li>\n\u003Cli>Sydney\u003C/li>\n\u003Cli>Khania\u003C/li>\n\u003Cli>Ramat Gan\u003C/li>\n\u003Cli>Amsterdam\u003C/li>\n\u003Cli>Zurich\u003C/li>\n\u003Cli>Moscow\u003C/li>\n\u003Cli>Ardmore\u003C/li>\n\u003Cli>League City\u003C/li>\n\u003Cli>Paris\u003C/li>\n\u003Cli>Bangalore\u003C/li>\n\u003C/ol>\n\u003Cp>The 4th most active city was (not set), so it was omitted.\u003C/p>\n\u003Ch2 id=\"technology\">Technology\u003C/h2>\n\u003Cp>As someone who argues for cross-browser compatibility and a mobile-first approach to all things web, Technology I find particularly interesting. Overall, I have 24 distinct Browser/Operating System pairings, with 87 different browser versions. Most of the different Browser/OS pairings come from Mobile. For purposes of the following statistics, when it says Safari (in-app), it’s referring to opening a website in an application on an iOS device that is neither the default Safari app, nor one of the major secondary iOS browsers (Chrome, Opera Mini, etc…).\u003C/p>\n\u003Cp>The Top 15 most active browsers/OS pairs were, in descending order:\u003C/p>\n\u003Col>\n\u003Cli>Chrome/Mac\u003C/li>\n\u003Cli>Chrome/Windows\u003C/li>\n\u003Cli>Safari/Mac\u003C/li>\n\u003Cli>Safari (in-app)/iOS\u003C/li>\n\u003Cli>Firefox/Windows\u003C/li>\n\u003Cli>Chrome/Linux\u003C/li>\n\u003Cli>Firefox/Mac\u003C/li>\n\u003Cli>Safari/iOS\u003C/li>\n\u003Cli>Firefox/Linux\u003C/li>\n\u003Cli>IE/Windows\u003C/li>\n\u003Cli>Chrome/Android\u003C/li>\n\u003Cli>Chrome/iOS\u003C/li>\n\u003Cli>Android Browser/Android\u003C/li>\n\u003Cli>Opera/Windows\u003C/li>\n\u003Cli>Mozilla Compatible Agent/Mac\u003C/li>\n\u003C/ol>\n\u003Cp>I get more combined Android traffic than I get IE traffic. My two most popular versions of IE are 8 and 9, both tied, with 10 a distant 3rd and 6 and 7 with one a piece.\u003C/p>\n\u003Cp>One thing I’ve found is, I really need to figure out a nice wide layout for my site.I’ve got 60 distinct screen resolution, the largest being 6400x4000 (that’s larger than the 4k beasts coming out, and it wasn’t a bounce; they stuck around for a while!) and the smallest being 228x240. If we do the maths, that’s a 6172x3760 area that my site should cover and cover well. That’s just silly!\u003C/p>\n\u003Cp>Top 15 screen resolutions are, frankly, bordering on ginormous. They are, in descending order:\u003C/p>\n\u003Col>\n\u003Cli>1920x1080\u003C/li>\n\u003Cli>1440x900\u003C/li>\n\u003Cli>2560x1440\u003C/li>\n\u003Cli>1366x768\u003C/li>\n\u003Cli>1680x1050\u003C/li>\n\u003Cli>1280x800\u003C/li>\n\u003Cli>1920x1200\u003C/li>\n\u003Cli>230x480\u003C/li>\n\u003Cli>768x1024\u003C/li>\n\u003Cli>1280x1024\u003C/li>\n\u003Cli>320x568\u003C/li>\n\u003Cli>1600x900\u003C/li>\n\u003Cli>1024x768\u003C/li>\n\u003Cli>2560x1600\u003C/li>\n\u003Cli>1600x1200\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"mobile\">Mobile\u003C/h2>\n\u003Cp>Google Analytics’ Mobile data includes what they define as tablets and down as mobile traffic and everything else as not mobile traffic. While not entirely satisfied with those definitions, we’ll run with it for the sake of this post.\u003C/p>\n\u003Cp>Over the month of December, a little over 20% of all of my site’s traffic was from mobile devices. While both mobile and not mobile both have approximately the same number of pages per visit, mobile users stayed on the site a full minute less than non mobile, but also had 15.22% more new visits with only 7.51% more bounces.\u003C/p>\n\u003Cp>What everyone really wants to know about Mobile, though, is what devices people are browsing from. While I truly despise UA sniffing, and I’m assuming that’s what GA is doing, I’m going to give it to you! So, the top 10 mobile devices to come to my site in December are, in descending order:\u003C/p>\n\u003Col>\n\u003Cli>Apple iPhone (includes all versions)\u003C/li>\n\u003Cli>Apple iPad (includes all versions, including mini)\u003C/li>\n\u003Cli>Google Nexus 7\u003C/li>\n\u003Cli>Samsung Galaxy Nexus\u003C/li>\n\u003Cli>Apple iPod\u003C/li>\n\u003Cli>HTC Vision\u003C/li>\n\u003Cli>Motorola MZ604 Xoom\u003C/li>\n\u003Cli>Samsung GT-I9300 Galaxy S3\u003C/li>\n\u003Cli>Samsung SGH-I897 Galaxy S Captivate\u003C/li>\n\u003Cli>SonyEricsson LT18i Xperia Arc\u003C/li>\n\u003C/ol>\n\u003Cp>Number 5 was \u003Cem>(not set)\u003C/em> so, again, I left it out of the rankings. Some interesting secondary characteristics from these devices. While the iPhone and iPad collectively blow Android out of the water with number of visits (iPads total 76 visits at number 2, Google Nexus 7 totals 8 visits at number 3), it’s actually the Android users that spend more time on the site. The four devices that, on average, spent the most amount of time on my site are all Android devices with the top device averaging 6\u003C/p>\u003Cdiv>\u003C/div> on site compared to the iPhone’s 0\u003Cdiv>\u003C/div> and iPads’s 0\u003Cdiv>\u003C/div>.\u003Cp>\u003C/p>\n\u003Chr>\n\u003Cp>Ok, I think that about wraps it up! If there’s anything you’re particularly interested in knowing that I haven’t covered, let me know and if I can I’ll let you know!\u003C/p>",{"headings":954,"localImagePaths":964,"remoteImagePaths":965,"frontmatter":966,"imagePaths":968},[955,958,961],{"depth":80,"slug":956,"text":957},"location","Location",{"depth":80,"slug":959,"text":960},"technology","Technology",{"depth":80,"slug":962,"text":963},"mobile","Mobile",[],[],{"title":945,"published":967,"summary":947},"2013-01-12",[],"armadillo",{"id":969,"data":971,"body":975,"filePath":976,"digest":977,"rendered":978},{"title":972,"published":973,"summary":974},"Armadillo",["Date","2016-12-31T00:00:00.000Z"],"Armadillo 3.0 is out! It's faster, easier to maintain, and comes with service workers! Let's learn what Armadillo is!","A couple weeks ago, I wrote about how I was [testing Gulp tasks](https://snugug.com/musings/unit-testing-gulp-tasks/) for an in-progress rebuild of [Armadillo](https://github.com/snugug/gulp-armadillo), my static site generator (that actually powers this site!). [Last time I did this](https://snugug.com/musings/yo-dawg-i-heard-you-like-redesigns/), I promised a full write-up on Armadillo, which I swear I wrote (in fact was _just_ looking for it) but looks like I never did. So, consider this that writeup!\n\n## What is Armadillo\n\n``````bash\n               ,.-----__\n            ,:::://///,:::-.\n          /:''/////// ``:::`;/|/     .--------------.\n         /'   ||||||     :://'`\\     | Hello, again |\n        .' ,   ||||||     `/(  e \\   /--------------'\n  -===~__-'\\__X_`````\\_____/~`-._ `.\n              ~~        ~~       `~-'\n``````\n\nI've got a mantra when it comes to building open-source projects: **pick a name, make the ASCII art, start coding**. Armadillo here's proof.\n\nArmadillo [started back in May 2013](https://github.com/Snugug/generator-armadillo/commit/928636eeaf074a39acfe62391838684e6baef3bb) as a [Yeoman](http://yeoman.io/) generator for scaffolding out a Grunt-based static site generator. It was one of my earliest Node projects.\n\nToday, Armadillo is still a static site generator, but it's evolved to be a set of composable [Gulp](http://gulpjs.com/) plugins and tasks that can be configured and used as-is, or can be brought in to another Gulp project as the basis for doing static site generation. Because it's Gulp, Armadillo can be extended with any and all of the goodies available to the Gulp ecosystem.\n\n## What Does Armadillo Do?\n\nArmadillo, when using the [default config](https://github.com/Snugug/gulp-armadillo/blob/master/config/default.js), takes static files, compiles those that it needs to, and spits out a static site.\n\n### Static Assets\n\nStatic assets, like videos (`videos`), audio (`audio`), fonts (`fonts`), and documents (`docs`), all get copied directly to a folder of the same name.\n\n### Images\n\nImages get run through [image optimization](https://www.npmjs.com/package/gulp-imagemin) and get placed in the `images` folder.\n\n### Sass\n\nSass gets watched from the `sass` directory, linted using [Sass Lint](https://github.com/sasstools/sass-lint), and compiled using [Node Sass](https://www.npmjs.com/package/node-sass) with [Eyeglass](https://github.com/sass-eyeglass/eyeglass) to allow for Sass NPM modules to be used!\n\n### JavaScript\n\nJavaScript compiling is a big space right now, with the heaviest hitter being Webpack. That would seem to make it the obvious choice for inclusion, but I've found Webpack to be too slow for my liking, and don't like that it wants to _be_ the ecosystem. I'm still very much a fan o Gulp, and I know that for many of my users, Webpack presents a very big learning curve. That said, I felt strongly that some form of JavaScript compiling was needed for Armadillo 3, and so it comes with [Rollup](http://rollupjs.org/).\n\nI like Rollup as I find its learning curve to be fairly minimal, it has a sizable community in and of itself, is quite fast, and can be integrated in to a Gulp based workflow in a way I was satisfied with without needing to own the whole ecosystem. I've bundled it with the Node Module and CommonJS loaders to be able to import modules from NPM, and I pass the bundle through [Babel](https://babeljs.io/) once it's compiled, but mostly to gain the ability to use [Babili](https://github.com/babel/babili/) as an ES2015+ aware minifier (I've been running in to too many issues with Uglify and ES2015, so had to make a switch). User-written JavaScript gets linted using [ESLint](http://eslint.org/).\n\n### Markup\n\nArmadillo supports two different ways of producing markup: either by writing HTML, or by writing [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/) (my preferred Markdown syntax). Both support [front matter](https://jekyllrb.com/docs/frontmatter/) for defining variables to be passed in to the actual page render.\n\nMarkdown previously was rendered with Marked, which I love, but found hard to extend as I wanted to, and feels very much like it's in maintenance mode. For Armadillo 3, I've switched to [Remarkable](https://www.npmjs.com/package/remarkable) which is very fast and has support for a plugin system, which I put to use to extend it a little. The documentation is lacking, but it's working well so far. One of the extensions I've written is to have the rendered syntax highlighting be done through [Prism](http://prismjs.com/), with proper `pre` and `code` wrapping, reducing the need to have to run it in browser.\n\nTemplating for markup rendering is done through [Nunjucks](https://mozilla.github.io/nunjucks/). Nunjucks has been my go-to templating engine of choice since Swig was discontinued, and I explored switching to Twig for Armadillo 3, but ultimately decided that Nunjucks still reigns supreme in the token-based Node templating languages for my needs, so it's here.\n\nFull documentation of markup rendering extensions can be found in the [Armadillo Additions](https://github.com/Snugug/gulp-armadillo/wiki/Armadillo-Additions) section of Armadillo's documentation.\n\n### Server\n\nArmadillo uses [Browsersync](https://www.browsersync.io/) to run its development server, allowing for automatic code injection, navigation and scroll sync, and testing on actual devices, all out of the box. This means more accurate cross-browser cross-device development that only requires an open URL.\n\n## What A Fast Armadillo\n\nOne of my goals for Armadillo, starting with the previous version, is to automate much of the work that goes in to making a _super fast site_. In Armadillo 2, that meant including [Critical](https://github.com/addyosmani/critical) to automatically extract and inline above-the-fold CSS and load the remaining CSS asynchronously. This goes a very long way to producing a fast [First Meaningful Paint](https://developers.google.com/web/tools/lighthouse/audits/first-meaningful-paint) and [Time to Interactive](https://developers.google.com/web/tools/lighthouse/audits/time-to-interactive), two key metrics for looking at Load in [RAIL Performance Measurement](https://developers.google.com/web/fundamentals/performance/rail).\n\nIn Armadillo 3, though, this has been supplemented to make sites even faster. [Service Workers](https://developers.google.com/web/fundamentals/getting-started/primers/service-workers) are a low-level browser cache API can be leveraged by developers to precisely control a browser's cache. One of the amazing uses for this is the ability to cache the actual content and markup of a page, allowing content to be available offline! With a static site generator producing, well, mostly static sites, this is a _perfect_ way to turn performance up to 11. Armadillo will now use [sw-precache](https://github.com/GoogleChrome/sw-precache) to automatically generate a service worker to cache all of its static files, and inject in to the top of the rendered JavaScript file the code needed to actually register and use the service worker! With these two things combined, it becomes a 0-touch process to implement some of the most advanced performance tuning techniques available! Faster sites for everyone!\n\n## The Future\n\nI currently use Armadillo for two things right now: this here blog, and creating web-based presentations. The later has become quite an interesting use-case for me, and I'd like to see if I can make Armadillo easier to use for when I'm doing so. That may mean extending the newly-updated [Armadillo Yeoman Generator](https://github.com/Snugug/generator-armadillo/) (which needs some testing and semantic release love) or something else; not quite sure.\n\nSince \"finishing\" Armadillo 3.0 3 days ago, I've already released 6 point releases with new functionality (yay automated semantic release!), but now my [issue queue is empty](https://github.com/Snugug/gulp-armadillo/issues) so I'd love to hear ideas as to how to improve my little Webadillo (right? yah? sure.). Moving documentation from the wiki to an actual site is likely the first step after working out a better way to deploy to GitHub Pages than the current shell script I've got. For now, though, I'm very happy with the current state of the codebase, so get out there, use it, and leave me some feedback!\n\n## Yo Armadillo!\n\nTo get started with Armadillo, the easiest thing to do is use the Yeoman generator. Be sure that Node 6+ is being used, and run the following from the command line:\n\n**Install Yeoman and the Armadillo generator globally**\n\n```bash\nnpm i yo generator-armadillo -g\n```\n\n**Run the Armadillo generator**\n\n```bash\nyo armadillo\n```\n\nFollow the on-screen instructions. Once the project is scaffolded out, move in to that folder in the command line, and run the following:\n\n**Start Armadillo**\n\n```bash\nnpm start\n```\n\nThis will kick off the build to get Armadillo up and running!\n\n---\n\n```bash\n:-.\n::`;/|/     .---------------.\n:://'`\\     | Happy Coding! |\n `/(  e \\   /---------------'\n__/~`-._ `.\n~       `~-'\n```","src/content/posts/armadillo.md","ff870b1c109070a2",{"html":979,"metadata":980},"\u003Cp>A couple weeks ago, I wrote about how I was \u003Ca href=\"https://snugug.com/musings/unit-testing-gulp-tasks/\">testing Gulp tasks\u003C/a> for an in-progress rebuild of \u003Ca href=\"https://github.com/snugug/gulp-armadillo\">Armadillo\u003C/a>, my static site generator (that actually powers this site!). \u003Ca href=\"https://snugug.com/musings/yo-dawg-i-heard-you-like-redesigns/\">Last time I did this\u003C/a>, I promised a full write-up on Armadillo, which I swear I wrote (in fact was \u003Cem>just\u003C/em> looking for it) but looks like I never did. So, consider this that writeup!\u003C/p>\n\u003Ch2 id=\"what-is-armadillo\">What is Armadillo\u003C/h2>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">               ,.-----__\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">            ,:::://///,:::-.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">          /:\u003C/span>\u003Cspan style=\"color:#A6E22E\">''\u003C/span>\u003Cspan style=\"color:#A6E22E\">///////\u003C/span>\u003Cspan style=\"color:#E6DB74\"> ``\u003C/span>\u003Cspan style=\"color:#66D9EF\">:::\u003C/span>\u003Cspan style=\"color:#E6DB74\">`;\u003C/span>\u003Cspan style=\"color:#A6E22E\">/\u003C/span>\u003Cspan style=\"color:#F92672\">|\u003C/span>\u003Cspan style=\"color:#A6E22E\">/\u003C/span>\u003Cspan style=\"color:#E6DB74\">     .--------------.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">         /'   ||||||     :://'\u003C/span>\u003Cspan style=\"color:#E6DB74\">`\u003C/span>\u003Cspan style=\"color:#A6E22E\">\\\u003C/span>\u003Cspan style=\"color:#F92672\">     |\u003C/span>\u003Cspan style=\"color:#A6E22E\"> Hello,\u003C/span>\u003Cspan style=\"color:#E6DB74\"> again\u003C/span>\u003Cspan style=\"color:#F92672\"> |\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF\">        .\u003C/span>\u003Cspan style=\"color:#A6E22E\">' ,   ||||||     `/(  e \\   /--------------'\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  -\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">==~__-'\\__X_`````\\_____/~`-._ `.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">              ~~        ~~       `~-'\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>I’ve got a mantra when it comes to building open-source projects: \u003Cstrong>pick a name, make the ASCII art, start coding\u003C/strong>. Armadillo here’s proof.\u003C/p>\n\u003Cp>Armadillo \u003Ca href=\"https://github.com/Snugug/generator-armadillo/commit/928636eeaf074a39acfe62391838684e6baef3bb\">started back in May 2013\u003C/a> as a \u003Ca href=\"http://yeoman.io/\">Yeoman\u003C/a> generator for scaffolding out a Grunt-based static site generator. It was one of my earliest Node projects.\u003C/p>\n\u003Cp>Today, Armadillo is still a static site generator, but it’s evolved to be a set of composable \u003Ca href=\"http://gulpjs.com/\">Gulp\u003C/a> plugins and tasks that can be configured and used as-is, or can be brought in to another Gulp project as the basis for doing static site generation. Because it’s Gulp, Armadillo can be extended with any and all of the goodies available to the Gulp ecosystem.\u003C/p>\n\u003Ch2 id=\"what-does-armadillo-do\">What Does Armadillo Do?\u003C/h2>\n\u003Cp>Armadillo, when using the \u003Ca href=\"https://github.com/Snugug/gulp-armadillo/blob/master/config/default.js\">default config\u003C/a>, takes static files, compiles those that it needs to, and spits out a static site.\u003C/p>\n\u003Ch3 id=\"static-assets\">Static Assets\u003C/h3>\n\u003Cp>Static assets, like videos (\u003Ccode>videos\u003C/code>), audio (\u003Ccode>audio\u003C/code>), fonts (\u003Ccode>fonts\u003C/code>), and documents (\u003Ccode>docs\u003C/code>), all get copied directly to a folder of the same name.\u003C/p>\n\u003Ch3 id=\"images\">Images\u003C/h3>\n\u003Cp>Images get run through \u003Ca href=\"https://www.npmjs.com/package/gulp-imagemin\">image optimization\u003C/a> and get placed in the \u003Ccode>images\u003C/code> folder.\u003C/p>\n\u003Ch3 id=\"sass\">Sass\u003C/h3>\n\u003Cp>Sass gets watched from the \u003Ccode>sass\u003C/code> directory, linted using \u003Ca href=\"https://github.com/sasstools/sass-lint\">Sass Lint\u003C/a>, and compiled using \u003Ca href=\"https://www.npmjs.com/package/node-sass\">Node Sass\u003C/a> with \u003Ca href=\"https://github.com/sass-eyeglass/eyeglass\">Eyeglass\u003C/a> to allow for Sass NPM modules to be used!\u003C/p>\n\u003Ch3 id=\"javascript\">JavaScript\u003C/h3>\n\u003Cp>JavaScript compiling is a big space right now, with the heaviest hitter being Webpack. That would seem to make it the obvious choice for inclusion, but I’ve found Webpack to be too slow for my liking, and don’t like that it wants to \u003Cem>be\u003C/em> the ecosystem. I’m still very much a fan o Gulp, and I know that for many of my users, Webpack presents a very big learning curve. That said, I felt strongly that some form of JavaScript compiling was needed for Armadillo 3, and so it comes with \u003Ca href=\"http://rollupjs.org/\">Rollup\u003C/a>.\u003C/p>\n\u003Cp>I like Rollup as I find its learning curve to be fairly minimal, it has a sizable community in and of itself, is quite fast, and can be integrated in to a Gulp based workflow in a way I was satisfied with without needing to own the whole ecosystem. I’ve bundled it with the Node Module and CommonJS loaders to be able to import modules from NPM, and I pass the bundle through \u003Ca href=\"https://babeljs.io/\">Babel\u003C/a> once it’s compiled, but mostly to gain the ability to use \u003Ca href=\"https://github.com/babel/babili/\">Babili\u003C/a> as an ES2015+ aware minifier (I’ve been running in to too many issues with Uglify and ES2015, so had to make a switch). User-written JavaScript gets linted using \u003Ca href=\"http://eslint.org/\">ESLint\u003C/a>.\u003C/p>\n\u003Ch3 id=\"markup\">Markup\u003C/h3>\n\u003Cp>Armadillo supports two different ways of producing markup: either by writing HTML, or by writing \u003Ca href=\"https://guides.github.com/features/mastering-markdown/\">GitHub Flavored Markdown\u003C/a> (my preferred Markdown syntax). Both support \u003Ca href=\"https://jekyllrb.com/docs/frontmatter/\">front matter\u003C/a> for defining variables to be passed in to the actual page render.\u003C/p>\n\u003Cp>Markdown previously was rendered with Marked, which I love, but found hard to extend as I wanted to, and feels very much like it’s in maintenance mode. For Armadillo 3, I’ve switched to \u003Ca href=\"https://www.npmjs.com/package/remarkable\">Remarkable\u003C/a> which is very fast and has support for a plugin system, which I put to use to extend it a little. The documentation is lacking, but it’s working well so far. One of the extensions I’ve written is to have the rendered syntax highlighting be done through \u003Ca href=\"http://prismjs.com/\">Prism\u003C/a>, with proper \u003Ccode>pre\u003C/code> and \u003Ccode>code\u003C/code> wrapping, reducing the need to have to run it in browser.\u003C/p>\n\u003Cp>Templating for markup rendering is done through \u003Ca href=\"https://mozilla.github.io/nunjucks/\">Nunjucks\u003C/a>. Nunjucks has been my go-to templating engine of choice since Swig was discontinued, and I explored switching to Twig for Armadillo 3, but ultimately decided that Nunjucks still reigns supreme in the token-based Node templating languages for my needs, so it’s here.\u003C/p>\n\u003Cp>Full documentation of markup rendering extensions can be found in the \u003Ca href=\"https://github.com/Snugug/gulp-armadillo/wiki/Armadillo-Additions\">Armadillo Additions\u003C/a> section of Armadillo’s documentation.\u003C/p>\n\u003Ch3 id=\"server\">Server\u003C/h3>\n\u003Cp>Armadillo uses \u003Ca href=\"https://www.browsersync.io/\">Browsersync\u003C/a> to run its development server, allowing for automatic code injection, navigation and scroll sync, and testing on actual devices, all out of the box. This means more accurate cross-browser cross-device development that only requires an open URL.\u003C/p>\n\u003Ch2 id=\"what-a-fast-armadillo\">What A Fast Armadillo\u003C/h2>\n\u003Cp>One of my goals for Armadillo, starting with the previous version, is to automate much of the work that goes in to making a \u003Cem>super fast site\u003C/em>. In Armadillo 2, that meant including \u003Ca href=\"https://github.com/addyosmani/critical\">Critical\u003C/a> to automatically extract and inline above-the-fold CSS and load the remaining CSS asynchronously. This goes a very long way to producing a fast \u003Ca href=\"https://developers.google.com/web/tools/lighthouse/audits/first-meaningful-paint\">First Meaningful Paint\u003C/a> and \u003Ca href=\"https://developers.google.com/web/tools/lighthouse/audits/time-to-interactive\">Time to Interactive\u003C/a>, two key metrics for looking at Load in \u003Ca href=\"https://developers.google.com/web/fundamentals/performance/rail\">RAIL Performance Measurement\u003C/a>.\u003C/p>\n\u003Cp>In Armadillo 3, though, this has been supplemented to make sites even faster. \u003Ca href=\"https://developers.google.com/web/fundamentals/getting-started/primers/service-workers\">Service Workers\u003C/a> are a low-level browser cache API can be leveraged by developers to precisely control a browser’s cache. One of the amazing uses for this is the ability to cache the actual content and markup of a page, allowing content to be available offline! With a static site generator producing, well, mostly static sites, this is a \u003Cem>perfect\u003C/em> way to turn performance up to 11. Armadillo will now use \u003Ca href=\"https://github.com/GoogleChrome/sw-precache\">sw-precache\u003C/a> to automatically generate a service worker to cache all of its static files, and inject in to the top of the rendered JavaScript file the code needed to actually register and use the service worker! With these two things combined, it becomes a 0-touch process to implement some of the most advanced performance tuning techniques available! Faster sites for everyone!\u003C/p>\n\u003Ch2 id=\"the-future\">The Future\u003C/h2>\n\u003Cp>I currently use Armadillo for two things right now: this here blog, and creating web-based presentations. The later has become quite an interesting use-case for me, and I’d like to see if I can make Armadillo easier to use for when I’m doing so. That may mean extending the newly-updated \u003Ca href=\"https://github.com/Snugug/generator-armadillo/\">Armadillo Yeoman Generator\u003C/a> (which needs some testing and semantic release love) or something else; not quite sure.\u003C/p>\n\u003Cp>Since “finishing” Armadillo 3.0 3 days ago, I’ve already released 6 point releases with new functionality (yay automated semantic release!), but now my \u003Ca href=\"https://github.com/Snugug/gulp-armadillo/issues\">issue queue is empty\u003C/a> so I’d love to hear ideas as to how to improve my little Webadillo (right? yah? sure.). Moving documentation from the wiki to an actual site is likely the first step after working out a better way to deploy to GitHub Pages than the current shell script I’ve got. For now, though, I’m very happy with the current state of the codebase, so get out there, use it, and leave me some feedback!\u003C/p>\n\u003Ch2 id=\"yo-armadillo\">Yo Armadillo!\u003C/h2>\n\u003Cp>To get started with Armadillo, the easiest thing to do is use the Yeoman generator. Be sure that Node 6+ is being used, and run the following from the command line:\u003C/p>\n\u003Cp>\u003Cstrong>Install Yeoman and the Armadillo generator globally\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">npm\u003C/span>\u003Cspan style=\"color:#E6DB74\"> i\u003C/span>\u003Cspan style=\"color:#E6DB74\"> yo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> generator-armadillo\u003C/span>\u003Cspan style=\"color:#AE81FF\"> -g\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>\u003Cstrong>Run the Armadillo generator\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">yo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> armadillo\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Follow the on-screen instructions. Once the project is scaffolded out, move in to that folder in the command line, and run the following:\u003C/p>\n\u003Cp>\u003Cstrong>Start Armadillo\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">npm\u003C/span>\u003Cspan style=\"color:#E6DB74\"> start\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This will kick off the build to get Armadillo up and running!\u003C/p>\n\u003Chr>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">:-.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF\">::\u003C/span>\u003Cspan style=\"color:#E6DB74\">`;\u003C/span>\u003Cspan style=\"color:#A6E22E\">/\u003C/span>\u003Cspan style=\"color:#F92672\">|\u003C/span>\u003Cspan style=\"color:#A6E22E\">/\u003C/span>\u003Cspan style=\"color:#E6DB74\">     .---------------.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF\">:\u003C/span>\u003Cspan style=\"color:#E6DB74\">://\u003C/span>\u003Cspan style=\"color:#A6E22E\">'`\\     | Happy Coding! |\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\"> `/(  e \\   /---------------'\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">__/~\u003C/span>\u003Cspan style=\"color:#E6DB74\">`\u003C/span>\u003Cspan style=\"color:#A6E22E\">-._\u003C/span>\u003Cspan style=\"color:#E6DB74\"> `\u003C/span>\u003Cspan style=\"color:#66D9EF\">.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">~\u003C/span>\u003Cspan style=\"color:#E6DB74\">       `\u003C/span>\u003Cspan style=\"color:#A6E22E\">~-\u003C/span>\u003Cspan style=\"color:#A6E22E\">'\u003C/span>\u003C/span>\u003C/code>\u003C/pre>",{"headings":981,"localImagePaths":1015,"remoteImagePaths":1016,"frontmatter":1017,"imagePaths":1019},[982,985,988,991,994,997,1000,1003,1006,1009,1012],{"depth":80,"slug":983,"text":984},"what-is-armadillo","What is Armadillo",{"depth":80,"slug":986,"text":987},"what-does-armadillo-do","What Does Armadillo Do?",{"depth":904,"slug":989,"text":990},"static-assets","Static Assets",{"depth":904,"slug":992,"text":993},"images","Images",{"depth":904,"slug":995,"text":996},"sass","Sass",{"depth":904,"slug":998,"text":999},"javascript","JavaScript",{"depth":904,"slug":1001,"text":1002},"markup","Markup",{"depth":904,"slug":1004,"text":1005},"server","Server",{"depth":80,"slug":1007,"text":1008},"what-a-fast-armadillo","What A Fast Armadillo",{"depth":80,"slug":1010,"text":1011},"the-future","The Future",{"depth":80,"slug":1013,"text":1014},"yo-armadillo","Yo Armadillo!",[],[],{"title":972,"published":1018,"summary":974},"2016-12-31",[],"aurora-30-magic-birds-and-boars",{"id":1020,"data":1022,"body":1026,"filePath":1027,"digest":1028,"rendered":1029},{"title":1023,"published":1024,"summary":1025},"Aurora 3.0 - Magic Birds and Boars",["Date","2013-05-04T00:00:00.000Z"],"I'm excited to announce the official release of Aurora 3.0! Ian and I have been worked hard to build out a base theme that truly is designed around the best tools and techniques available for front end development today.","I'm excited to announce the official release of Aurora 3.0! Ian and I have been worked hard to build out a base theme that truly is designed around the best tools and techniques available for front end development today. In the process, we've built better Drupal tools and walked the bleeding edge of Node.js, all to suss out the absolute best tools for the various jobs that we do most often.\n\n## Updates to Aurora Base Theme\n\nThere are three large changes made to the Aurora Base Theme itself. The two most prominent ones are the removal of the two sidebar regions from the standard `page.tpl.php` because, let's be honest, sidebars are a lie, and the removal of the standard system information from `page.tpl.php` (site name, logo, tabs, messages, etc…). Instead we encourage you to create your layouts through CSS and a grid system for when you need it and to use [Blockify](http://drupal.org/project/blockify) (or a similar module) to get those blocks you'd like back.\n\nThe other big thing we've done to the base theme itself is the removal of many of the advanced theme settings in favor of [Magic module](/musings/do-you-believe-magic) integration. This way we have a standard way of using these advanced features across multiple themes with modules only needing to support the Magic syntaxes. We think this is a big win for the Drupal community, and we will be actively maintaining that module as well.\n\n## Updates to the Aurora Gem\n\nAlong with some standard tweaks, we've got some exciting new updates to the Aurora gem! We've streamlined the available subtheme selections to include what use to be the Singularity install as the basic install, the Corona install, and a new SMACSS based subtheme called Polaris. We've also included Gemfiles in all of the new base themes to keep your dependencies in check.\n\nWe've also included some advanced integration with the awesome Bower and Grunt tools. Both tools can be installed optionally into your new base themes or even in to your old base themes.\n\nThe Bower integration is just enough to get your started, a `components.json` file for components and a `.bowerrc` file for controlling them.\n\nOur Grunt integration, on the other hand, is super cool, bleeding edge, and generally awesome. Instead of using Compass to compile your Sass directly, we've included `grunt build` and `grunt watch` tasks. The `grunt watch` task will compile your Sass for you with far fewer resources needed by the native Compass compiler (and will run everything through Bundler!), JSHint your JavaScript for you, and will even set up a LiveReload server for you so you don't have to buy any apps or or deal with any complicated setup! The `grunt build` task will also compile your Sass for you into production mode and optimize your images for you!\n\n## Updates to the Aurora Docs\n\nWhile our old PDF manual was very neat, it was a pain to keep up to date and, therefore, was out of date. We've updated our docs, put them up on GitHub, and now anyone can view them or edit them from anywhere. [Go check them out!](http://snugug.github.io/Aurora/)","src/content/posts/aurora-30-magic-birds-and-boars.md","d6c1f7c4c8dbd78e",{"html":1030,"metadata":1031},"\u003Cp>I’m excited to announce the official release of Aurora 3.0! Ian and I have been worked hard to build out a base theme that truly is designed around the best tools and techniques available for front end development today. In the process, we’ve built better Drupal tools and walked the bleeding edge of Node.js, all to suss out the absolute best tools for the various jobs that we do most often.\u003C/p>\n\u003Ch2 id=\"updates-to-aurora-base-theme\">Updates to Aurora Base Theme\u003C/h2>\n\u003Cp>There are three large changes made to the Aurora Base Theme itself. The two most prominent ones are the removal of the two sidebar regions from the standard \u003Ccode>page.tpl.php\u003C/code> because, let’s be honest, sidebars are a lie, and the removal of the standard system information from \u003Ccode>page.tpl.php\u003C/code> (site name, logo, tabs, messages, etc…). Instead we encourage you to create your layouts through CSS and a grid system for when you need it and to use \u003Ca href=\"http://drupal.org/project/blockify\">Blockify\u003C/a> (or a similar module) to get those blocks you’d like back.\u003C/p>\n\u003Cp>The other big thing we’ve done to the base theme itself is the removal of many of the advanced theme settings in favor of \u003Ca href=\"/musings/do-you-believe-magic\">Magic module\u003C/a> integration. This way we have a standard way of using these advanced features across multiple themes with modules only needing to support the Magic syntaxes. We think this is a big win for the Drupal community, and we will be actively maintaining that module as well.\u003C/p>\n\u003Ch2 id=\"updates-to-the-aurora-gem\">Updates to the Aurora Gem\u003C/h2>\n\u003Cp>Along with some standard tweaks, we’ve got some exciting new updates to the Aurora gem! We’ve streamlined the available subtheme selections to include what use to be the Singularity install as the basic install, the Corona install, and a new SMACSS based subtheme called Polaris. We’ve also included Gemfiles in all of the new base themes to keep your dependencies in check.\u003C/p>\n\u003Cp>We’ve also included some advanced integration with the awesome Bower and Grunt tools. Both tools can be installed optionally into your new base themes or even in to your old base themes.\u003C/p>\n\u003Cp>The Bower integration is just enough to get your started, a \u003Ccode>components.json\u003C/code> file for components and a \u003Ccode>.bowerrc\u003C/code> file for controlling them.\u003C/p>\n\u003Cp>Our Grunt integration, on the other hand, is super cool, bleeding edge, and generally awesome. Instead of using Compass to compile your Sass directly, we’ve included \u003Ccode>grunt build\u003C/code> and \u003Ccode>grunt watch\u003C/code> tasks. The \u003Ccode>grunt watch\u003C/code> task will compile your Sass for you with far fewer resources needed by the native Compass compiler (and will run everything through Bundler!), JSHint your JavaScript for you, and will even set up a LiveReload server for you so you don’t have to buy any apps or or deal with any complicated setup! The \u003Ccode>grunt build\u003C/code> task will also compile your Sass for you into production mode and optimize your images for you!\u003C/p>\n\u003Ch2 id=\"updates-to-the-aurora-docs\">Updates to the Aurora Docs\u003C/h2>\n\u003Cp>While our old PDF manual was very neat, it was a pain to keep up to date and, therefore, was out of date. We’ve updated our docs, put them up on GitHub, and now anyone can view them or edit them from anywhere. \u003Ca href=\"http://snugug.github.io/Aurora/\">Go check them out!\u003C/a>\u003C/p>",{"headings":1032,"localImagePaths":1042,"remoteImagePaths":1043,"frontmatter":1044,"imagePaths":1046},[1033,1036,1039],{"depth":80,"slug":1034,"text":1035},"updates-to-aurora-base-theme","Updates to Aurora Base Theme",{"depth":80,"slug":1037,"text":1038},"updates-to-the-aurora-gem","Updates to the Aurora Gem",{"depth":80,"slug":1040,"text":1041},"updates-to-the-aurora-docs","Updates to the Aurora Docs",[],[],{"title":1023,"published":1045,"summary":1025},"2013-05-04",[],"austin",{"id":1047,"data":1049,"body":1053,"filePath":1054,"digest":1055,"rendered":1056},{"title":1050,"published":1051,"summary":1052},"Austin",["Date","2017-01-31T00:00:00.000Z"],"I've moved to Austin and taken a new role at IBM","I couldn't have asked for a better day.\n\nIt had just snowed, like really snowed, the first real snow of the winter, the evening before, and was still snowing when I met up with [Morgan](https://twitter.com/NegaMorgan) and [Suzi](https://twitter.com/meat_cookies) at the [Whitney](http://whitney.org/) around 3. Morgan use to be our manager back when we worked at NBC 3+ years ago, we affectionately call her \"Boss Lady For Life\", and when we get together, we eat our way through whatever town we're in. Today, New York was once again on the menu.\n\nWe had a 2 hour lunch at [Untitled](http://www.untitledatthewhitney.com/), then roamed around the museum for a few hours. They had a portrait exhibit that we were there for. Somewhere between the second and third floor we were exploring, around a larger-than-life statue of a person made out of wax, as a candle, currently burning and melting, we decided that we were having too much fun and needed to get dinner together. It was a Saturday night, but somehow we managed a 10:00 reservation at [Barbuto](http://www.barbutonyc.com/index.php), a place Suzi had been trying to get us to go to forever. Morgan had an appointment she had to keep, so Suzi and I went over to Union Square and saw Rogue One in 4DX. The movie let out and we managed to get a ride through the snow and arrive _just_ in time for our reservation; another 2 hour affair. We finished after midnight, literally closing down Barbuto (our table was the only one not put away for the night when we left).\n\nThat was January 7th, my last night as a New York City resident.\n\nThe following morning, my parents came in to the city, we went to [Russ & Daughters Cafe](http://www.russanddaughterscafe.com/) for breakfast, then they dropped me off at the airport for my one-way flight down to Austin.\n\nRight now, I'm in the midst of my 4th week living down here; it still almost feels like a business trip, not a move. But I've got an apartment and I'm car shopping, so it's going to start feeling more permanent real fast, real soon.\n\nChances are if you're reading this, and we've met in person, your image of me is probably intertwined with New York. Every single person who I've told over the past few months that I'm moving has said as much, and no one could see me leaving New York. Honestly, neither could I. It took almost 3 months of internal deliberation to make that decision. I've got a lot of friends here in Austin, both at IBM and outside of it, and I've probably spent about 4 months over the past 2.5 years here, so the decision was relatively easier than it otherwise could have been. It's probably also why it still feels like a business trip.\n\nSo, why did I move? Starting with people is easy. For the past 18ish months, one of my mentors, [Damon](https://twitter.com/DamonDeaner), and I have been traveling together running [Hackademy](https://snugug.com/musings/what-is-ibm-hackademy/). Over the summer he was promoted to the Head of Global Design Talent for [IBM Design](https://twitter.com/IBMDesign), so I wouldn't get to continue working with him. He's in Austin every other week, though, so moving here would allow me to stay connected with him in-person. Another one of my mentors, [Bill](https://twitter.com/BillHiggins), is the Distinguished Engineer in charge of product direction for the organization I moved in to, so I would get to start working with him in an official capacity instead of a secondary one, which excited me. I also personally knew most of the team down here in Austin, having actually previously worked on the same team as one, so I knew I wasn't going to be moving in to a truly unknown dynamic here.\n\nAs important as the people, though, is the work. I was brought down to help lead the Agile Team Experience for IBM's CIO organization. The same thinking (and many of the same people) who have helped radically transform the way IBM works over the past few years and I've worked with to help bring in and evangelize Slack, GitHub, ZenHub, Travis CI, and others over the past two years are now setting their sites on improving how teams work. For me, this is the exact kind of problem that really interests me: a problem about people, where the underlying model isn't yet fully understood or the required technology fully developed, at a giant scale. This moves me from a strictly architectural role to include product design and leadership, and that's really exciting.\n\nWhile New York is home and leaving it was hard, I now get to call Austin home too. If you're in the area, for a conference, for fun, or cause, ya know, you live here too, reach out! I've still got all the good food recommendations in Austin like I did in New York, and I'm sure we can put together a BBQ and Taco tour.","src/content/posts/austin.md","f9edd543ded105ff",{"html":1057,"metadata":1058},"\u003Cp>I couldn’t have asked for a better day.\u003C/p>\n\u003Cp>It had just snowed, like really snowed, the first real snow of the winter, the evening before, and was still snowing when I met up with \u003Ca href=\"https://twitter.com/NegaMorgan\">Morgan\u003C/a> and \u003Ca href=\"https://twitter.com/meat_cookies\">Suzi\u003C/a> at the \u003Ca href=\"http://whitney.org/\">Whitney\u003C/a> around 3. Morgan use to be our manager back when we worked at NBC 3+ years ago, we affectionately call her “Boss Lady For Life”, and when we get together, we eat our way through whatever town we’re in. Today, New York was once again on the menu.\u003C/p>\n\u003Cp>We had a 2 hour lunch at \u003Ca href=\"http://www.untitledatthewhitney.com/\">Untitled\u003C/a>, then roamed around the museum for a few hours. They had a portrait exhibit that we were there for. Somewhere between the second and third floor we were exploring, around a larger-than-life statue of a person made out of wax, as a candle, currently burning and melting, we decided that we were having too much fun and needed to get dinner together. It was a Saturday night, but somehow we managed a 10\u003C/p>\u003Cdiv>\u003C/div> reservation at \u003Ca href=\"http://www.barbutonyc.com/index.php\">Barbuto\u003C/a>, a place Suzi had been trying to get us to go to forever. Morgan had an appointment she had to keep, so Suzi and I went over to Union Square and saw Rogue One in 4DX. The movie let out and we managed to get a ride through the snow and arrive \u003Cem>just\u003C/em> in time for our reservation; another 2 hour affair. We finished after midnight, literally closing down Barbuto (our table was the only one not put away for the night when we left).\u003Cp>\u003C/p>\n\u003Cp>That was January 7th, my last night as a New York City resident.\u003C/p>\n\u003Cp>The following morning, my parents came in to the city, we went to \u003Ca href=\"http://www.russanddaughterscafe.com/\">Russ &#x26; Daughters Cafe\u003C/a> for breakfast, then they dropped me off at the airport for my one-way flight down to Austin.\u003C/p>\n\u003Cp>Right now, I’m in the midst of my 4th week living down here; it still almost feels like a business trip, not a move. But I’ve got an apartment and I’m car shopping, so it’s going to start feeling more permanent real fast, real soon.\u003C/p>\n\u003Cp>Chances are if you’re reading this, and we’ve met in person, your image of me is probably intertwined with New York. Every single person who I’ve told over the past few months that I’m moving has said as much, and no one could see me leaving New York. Honestly, neither could I. It took almost 3 months of internal deliberation to make that decision. I’ve got a lot of friends here in Austin, both at IBM and outside of it, and I’ve probably spent about 4 months over the past 2.5 years here, so the decision was relatively easier than it otherwise could have been. It’s probably also why it still feels like a business trip.\u003C/p>\n\u003Cp>So, why did I move? Starting with people is easy. For the past 18ish months, one of my mentors, \u003Ca href=\"https://twitter.com/DamonDeaner\">Damon\u003C/a>, and I have been traveling together running \u003Ca href=\"https://snugug.com/musings/what-is-ibm-hackademy/\">Hackademy\u003C/a>. Over the summer he was promoted to the Head of Global Design Talent for \u003Ca href=\"https://twitter.com/IBMDesign\">IBM Design\u003C/a>, so I wouldn’t get to continue working with him. He’s in Austin every other week, though, so moving here would allow me to stay connected with him in-person. Another one of my mentors, \u003Ca href=\"https://twitter.com/BillHiggins\">Bill\u003C/a>, is the Distinguished Engineer in charge of product direction for the organization I moved in to, so I would get to start working with him in an official capacity instead of a secondary one, which excited me. I also personally knew most of the team down here in Austin, having actually previously worked on the same team as one, so I knew I wasn’t going to be moving in to a truly unknown dynamic here.\u003C/p>\n\u003Cp>As important as the people, though, is the work. I was brought down to help lead the Agile Team Experience for IBM’s CIO organization. The same thinking (and many of the same people) who have helped radically transform the way IBM works over the past few years and I’ve worked with to help bring in and evangelize Slack, GitHub, ZenHub, Travis CI, and others over the past two years are now setting their sites on improving how teams work. For me, this is the exact kind of problem that really interests me: a problem about people, where the underlying model isn’t yet fully understood or the required technology fully developed, at a giant scale. This moves me from a strictly architectural role to include product design and leadership, and that’s really exciting.\u003C/p>\n\u003Cp>While New York is home and leaving it was hard, I now get to call Austin home too. If you’re in the area, for a conference, for fun, or cause, ya know, you live here too, reach out! I’ve still got all the good food recommendations in Austin like I did in New York, and I’m sure we can put together a BBQ and Taco tour.\u003C/p>",{"headings":1059,"localImagePaths":1060,"remoteImagePaths":1061,"frontmatter":1062,"imagePaths":1064},[],[],[],{"title":1050,"published":1063,"summary":1052},"2017-01-31",[],"book-recommendations",{"id":1065,"data":1067,"body":1071,"filePath":1072,"digest":1073,"rendered":1074},{"title":1068,"published":1069,"summary":1070},"Book Recommendations",["Date","2020-03-17T00:00:00.000Z"],"Books that I've read and plan on reading, and that I recommend you read too.","Every year, I'm lucky enough to be able to go on a family vacation and, while there, I like to binge on books. I just got back from this vacation, and while there I read **The Phoenix Project**; it's a novel that helped to introduce DevOps to a wide audience. I've had it for a while and never read it because I was already a DevOps practitioner by the time it was recommended to me, but it helped clarify and expand my understanding about DevOps and its importance from a historical, managerial, and business perspective. I highly recommend it! There's also a sequel, **The Unicorn Project**, which takes place over the same timeframe as The Phoenix Project, but told from the Dev side instead of the Ops side. I started that this morning; if you're interested in reading along with me.\n\nI thought I'd also share a list of books I've previously read that have helped shape how I think about things like leadership, organizations, and personal development.\n\n## Recommendations\n\nMany of these books have been recommended to me by [Bill Higgins](https://twitter.com/billhiggins) or my wonderful wife Anne Biggs. If you've got a book recommendation, shoot me a tweet.\n\nThe Field Guide to Understanding Human Error: Third Edition\n\n: Recommended to me by [John Allspaw](https://twitter.com/allspaw), one of the foundational thinkers on DevOps and resilience engineering. Book postulates there's an \"old\" way to think about errors and a \"new\" way to think about them, and why the \"new\" way is better for understanding systems and actions and working to fix problems. A foundational way of thinking for Resilience Engineering and has personally changed how I approach problems.\n\nStructure of Scientific Revolutions\n: This book is where the term _paradigm shift_ was coined. It's a philosopher of science's take on the history of science, which in and of itself is fascinating, but the big take away is understanding what drives change, or paradigm shifts.\n\nLeading Change\n: From a Harvard Business Review article to a full book, this talks about the steps needed to make organizational change stick at scale. The first few steps align with the paradigm shifts talked about in Structure of Scientific Revolutions\n\nDiffusion of Innovations\n: This is a harder, longer read, and I haven't actually read the entire thing, but the pieces I have have been real eye-opening. It's a whole set of research followed by analysis of that research describing how new ideas, especially new technology, takes root. The theory presented is great grounding for everything from getting ideas to land to introducing products to market .\n\nGood Strategy/Bad Strategy: The Difference and Why It Matters\n: If you've ever felt there was something missing in strategy presentations you see, this will explain why to you. It first talks about bad strategy and what people confuse with strategy, and then talks about the kernel of good strategy; the minimum needed to make an effective strategy, with lots of examples throughout.\n\nHow To Be A Star At Work\n: Based on research of star performers at Bell Labs, this book provides immense practical activities you can do to improve how perform at work, with the edition I have including specific insights for women and members of minority groups.\n\nThe Mythical Man-Month\n: A deeply fascinating look at some of the pioneers of software engineering at IBM, this book is where Brooks' Law, \"adding developers to a late project will only make it more late\", comes from. Great insights into software engineering as a whole that still rings true today.\n\nMake It Stick\n: The cognitive science of learning, especially retrieval practice. I've adopted things I've learned in this book to talks and workshops I've run with great results.\n\nThe Five Dysfunctions of a Team\n: A parable-style guide on the five things needed to lead a cohesive team.\n\n## Queue\n\nMy current reading queue includes the following, in no particular order:\n\nThe Goal/Beyond the Goal\n: A novelization, much like The Phoenix Project (in fact, mentioned several times in that book), and its follow-up retrospective, that brought the concepts of _lean manufacturing_ to a wide audience in the same way that TPP did for DevOps.\n\nStrategy: A History\n: A massive tome discussing the history of strategic thinking.\n\nHow to Talk So Kids Will Listen & Listen So Kids Will Talk\n: A book recommended to me on gentle communication.\n\nThinking Fast and Slow\n: A book about the science of how we think; intuition vs logic.\n\nRuined by Design\n: The craft of design, how designers ruined the world, and the responsibility designers have to help fix it.\n\nYou Look Like a Thing and I Love You\n: A lighthearted but comprehensive introduction to Artificial Intelligence.\n\nBecause Internet\n: A linguist's exploration of what shapes human language, how we communicate, and the language of the internet.\n\nCreativity Inc\n: The story of Pixar and how to lead in order to create great things.\n\nInvisible Women\n: How bias, especially towards women, is baked into the data and systems that power the world.\n\nHumble Leadership\n: How to build and lead effective team cultures.\n\nMeasure What Matters\n: It's a book about OKRs.","src/content/posts/book-recommendations.md","d97c44f8d28e9a58",{"html":1075,"metadata":1076},"\u003Cp>Every year, I’m lucky enough to be able to go on a family vacation and, while there, I like to binge on books. I just got back from this vacation, and while there I read \u003Cstrong>The Phoenix Project\u003C/strong>; it’s a novel that helped to introduce DevOps to a wide audience. I’ve had it for a while and never read it because I was already a DevOps practitioner by the time it was recommended to me, but it helped clarify and expand my understanding about DevOps and its importance from a historical, managerial, and business perspective. I highly recommend it! There’s also a sequel, \u003Cstrong>The Unicorn Project\u003C/strong>, which takes place over the same timeframe as The Phoenix Project, but told from the Dev side instead of the Ops side. I started that this morning; if you’re interested in reading along with me.\u003C/p>\n\u003Cp>I thought I’d also share a list of books I’ve previously read that have helped shape how I think about things like leadership, organizations, and personal development.\u003C/p>\n\u003Ch2 id=\"recommendations\">Recommendations\u003C/h2>\n\u003Cp>Many of these books have been recommended to me by \u003Ca href=\"https://twitter.com/billhiggins\">Bill Higgins\u003C/a> or my wonderful wife Anne Biggs. If you’ve got a book recommendation, shoot me a tweet.\u003C/p>\n\u003Cdl>\n\u003Cdt>The Field Guide to Understanding Human Error: Third Edition\u003C/dt>\n\u003Cdd>\n\u003Cp>Recommended to me by \u003Ca href=\"https://twitter.com/allspaw\">John Allspaw\u003C/a>, one of the foundational thinkers on DevOps and resilience engineering. Book postulates there’s an “old” way to think about errors and a “new” way to think about them, and why the “new” way is better for understanding systems and actions and working to fix problems. A foundational way of thinking for Resilience Engineering and has personally changed how I approach problems.\u003C/p>\n\u003C/dd>\n\u003Cdt>Structure of Scientific Revolutions\u003C/dt>\n\u003Cdd>This book is where the term \u003Cem>paradigm shift\u003C/em> was coined. It’s a philosopher of science’s take on the history of science, which in and of itself is fascinating, but the big take away is understanding what drives change, or paradigm shifts.\n\u003C/dd>\n\u003Cdt>Leading Change\u003C/dt>\n\u003Cdd>From a Harvard Business Review article to a full book, this talks about the steps needed to make organizational change stick at scale. The first few steps align with the paradigm shifts talked about in Structure of Scientific Revolutions\n\u003C/dd>\n\u003Cdt>Diffusion of Innovations\u003C/dt>\n\u003Cdd>This is a harder, longer read, and I haven’t actually read the entire thing, but the pieces I have have been real eye-opening. It’s a whole set of research followed by analysis of that research describing how new ideas, especially new technology, takes root. The theory presented is great grounding for everything from getting ideas to land to introducing products to market .\n\u003C/dd>\n\u003Cdt>Good Strategy/Bad Strategy: The Difference and Why It Matters\u003C/dt>\n\u003Cdd>If you’ve ever felt there was something missing in strategy presentations you see, this will explain why to you. It first talks about bad strategy and what people confuse with strategy, and then talks about the kernel of good strategy; the minimum needed to make an effective strategy, with lots of examples throughout.\n\u003C/dd>\n\u003Cdt>How To Be A Star At Work\u003C/dt>\n\u003Cdd>Based on research of star performers at Bell Labs, this book provides immense practical activities you can do to improve how perform at work, with the edition I have including specific insights for women and members of minority groups.\n\u003C/dd>\n\u003Cdt>The Mythical Man-Month\u003C/dt>\n\u003Cdd>A deeply fascinating look at some of the pioneers of software engineering at IBM, this book is where Brooks’ Law, “adding developers to a late project will only make it more late”, comes from. Great insights into software engineering as a whole that still rings true today.\n\u003C/dd>\n\u003Cdt>Make It Stick\u003C/dt>\n\u003Cdd>The cognitive science of learning, especially retrieval practice. I’ve adopted things I’ve learned in this book to talks and workshops I’ve run with great results.\n\u003C/dd>\n\u003Cdt>The Five Dysfunctions of a Team\u003C/dt>\n\u003Cdd>A parable-style guide on the five things needed to lead a cohesive team.\n\u003C/dd>\n\u003C/dl>\n\u003Ch2 id=\"queue\">Queue\u003C/h2>\n\u003Cp>My current reading queue includes the following, in no particular order:\u003C/p>\n\u003Cdl>\n\u003Cdt>The Goal/Beyond the Goal\u003C/dt>\n\u003Cdd>A novelization, much like The Phoenix Project (in fact, mentioned several times in that book), and its follow-up retrospective, that brought the concepts of \u003Cem>lean manufacturing\u003C/em> to a wide audience in the same way that TPP did for DevOps.\n\u003C/dd>\n\u003Cdt>Strategy: A History\u003C/dt>\n\u003Cdd>A massive tome discussing the history of strategic thinking.\n\u003C/dd>\n\u003Cdt>How to Talk So Kids Will Listen &#x26; Listen So Kids Will Talk\u003C/dt>\n\u003Cdd>A book recommended to me on gentle communication.\n\u003C/dd>\n\u003Cdt>Thinking Fast and Slow\u003C/dt>\n\u003Cdd>A book about the science of how we think; intuition vs logic.\n\u003C/dd>\n\u003Cdt>Ruined by Design\u003C/dt>\n\u003Cdd>The craft of design, how designers ruined the world, and the responsibility designers have to help fix it.\n\u003C/dd>\n\u003Cdt>You Look Like a Thing and I Love You\u003C/dt>\n\u003Cdd>A lighthearted but comprehensive introduction to Artificial Intelligence.\n\u003C/dd>\n\u003Cdt>Because Internet\u003C/dt>\n\u003Cdd>A linguist’s exploration of what shapes human language, how we communicate, and the language of the internet.\n\u003C/dd>\n\u003Cdt>Creativity Inc\u003C/dt>\n\u003Cdd>The story of Pixar and how to lead in order to create great things.\n\u003C/dd>\n\u003Cdt>Invisible Women\u003C/dt>\n\u003Cdd>How bias, especially towards women, is baked into the data and systems that power the world.\n\u003C/dd>\n\u003Cdt>Humble Leadership\u003C/dt>\n\u003Cdd>How to build and lead effective team cultures.\n\u003C/dd>\n\u003Cdt>Measure What Matters\u003C/dt>\n\u003Cdd>It’s a book about OKRs.\n\u003C/dd>\n\u003C/dl>",{"headings":1077,"localImagePaths":1084,"remoteImagePaths":1085,"frontmatter":1086,"imagePaths":1088},[1078,1081],{"depth":80,"slug":1079,"text":1080},"recommendations","Recommendations",{"depth":80,"slug":1082,"text":1083},"queue","Queue",[],[],{"title":1068,"published":1087,"summary":1070},"2020-03-17",[],"art-directed-images-with-css-container-queries",{"id":1089,"data":1091,"body":1095,"filePath":1096,"digest":1097,"rendered":1098},{"title":1092,"published":1093,"summary":1094},"Art Directed Images with CSS Container Queries",["Date","2023-01-06T00:00:00.000Z"],"How to art direct images with container queries, no JavaScript required.","I've just started a refactor of some code for ChromeOS.dev and I'm starting with a tricky component that I'm looking to refactor into using [container queries](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Container_Queries). This component has a `\u003Cpicture>` element in it that uses media queries for art direction. Works great now, but part of this refactor is going from 3 separate components that all basically do the same thing to one single, container query based one, so that media query needs to go. So I started digging in.\n\nI found Sara Soueidan's wonderful [Component-level art direction with CSS Container Queries](https://www.sarasoueidan.com/blog/component-level-art-direction-with-container-queries-and-picture/) post which mentions this, but sadly doesn't have an answer other than bumping the images to CSS. Ten I came across the [`srcset` and `sizes` interaction with container queries](https://github.com/w3c/csswg-drafts/issues/5889) issue from Una in the CSS Working Group drafts. Reading through that article, it got me thinking, and I think I've got a workable, if lightly bad for above-the-fold performance solution that requires 0 JavaScript.\n\nThanks to wonderful work by Tim Kadlec, we've known since 2012 that [`display: none` images still get downloaded by browsers](https://timkadlec.com/2012/04/media-query-asset-downloading-results/). This is because browsers try and eagerly download images before styling and layout has occurred to improve loading performance. But, something we didn't have then, but we do have now, is built-in support for lazy loading via `loading=\"lazy\"` attribute on images.\n\nI put together a [quick CodePen proof of concept](https://codepen.io/Snugug/pen/VwBmqQQ) based on comments in the CSSWG issue and, sure enough,in Chrome anyway, a lazy loaded image won't download if display is `none`. And just like that, a solution emerged.\n\nNow, the reason this isn't great for performance is it will delay image loading, so [largest contentful paint](https://web.dev/lcp/) may suffer, so `\u003Cpicture>` elements are probably better most of the time. That said, if you need container based image art direction, here's how you do it:\n\n1. Add `loading=\"lazy\"` to lazy load the desired images, one image per \"art direction\"\n2. `display: none` the images that need to be art directed\n3. Use container queries to undo `display: none` (with `block` for instance).\n\nThat's it! No JavaScript,only a couple of straightforward lines of CSS. Here's the example from the CodePen:\n\n```scss\n// Hide the image tags\nimg {\n  display: none;\n}\n\n// Set the container to track inline size\n.container {\n  container-type: inline-size;\n  width: 100%;\n}\n\n// Make the first image block initially, then none at the desired width\n.pic-1 {\n  display: block;\n\n  @container (min-width: 700px) {\n    display: none;\n  }\n}\n\n// Make the second image block at the desired width\n.pic-2 {\n  @container (min-width: 700px) {\n    display: initial;\n  }\n}\n```\n\nSomething to consider if you're looking to give this a go in production:\n\n- Small examples will probably seem to work fine, but do test if you're using this a lot\n- After talking this out with Una, she recommends adding a placeholder in to help prevent layout shift. You can probably accomplish something similar using a trick similar to what Sara mentions in her post; wrap your images in a parent with an [`aspect-ratio`](https://developer.mozilla.org/en-US/docs/Web/CSS/aspect-ratio) that can change based on what image is being pulled in (so more container queries)\n\nThat's it! Go have fun with it!","src/content/posts/art-directed-images-with-css-container-queries.md","c1c3e2e66e9e7f46",{"html":1099,"metadata":1100},"\u003Cp>I’ve just started a refactor of some code for ChromeOS.dev and I’m starting with a tricky component that I’m looking to refactor into using \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Container_Queries\">container queries\u003C/a>. This component has a \u003Ccode>&#x3C;picture>\u003C/code> element in it that uses media queries for art direction. Works great now, but part of this refactor is going from 3 separate components that all basically do the same thing to one single, container query based one, so that media query needs to go. So I started digging in.\u003C/p>\n\u003Cp>I found Sara Soueidan’s wonderful \u003Ca href=\"https://www.sarasoueidan.com/blog/component-level-art-direction-with-container-queries-and-picture/\">Component-level art direction with CSS Container Queries\u003C/a> post which mentions this, but sadly doesn’t have an answer other than bumping the images to CSS. Ten I came across the \u003Ca href=\"https://github.com/w3c/csswg-drafts/issues/5889\">\u003Ccode>srcset\u003C/code> and \u003Ccode>sizes\u003C/code> interaction with container queries\u003C/a> issue from Una in the CSS Working Group drafts. Reading through that article, it got me thinking, and I think I’ve got a workable, if lightly bad for above-the-fold performance solution that requires 0 JavaScript.\u003C/p>\n\u003Cp>Thanks to wonderful work by Tim Kadlec, we’ve known since 2012 that \u003Ca href=\"https://timkadlec.com/2012/04/media-query-asset-downloading-results/\">\u003Ccode>display: none\u003C/code> images still get downloaded by browsers\u003C/a>. This is because browsers try and eagerly download images before styling and layout has occurred to improve loading performance. But, something we didn’t have then, but we do have now, is built-in support for lazy loading via \u003Ccode>loading=\"lazy\"\u003C/code> attribute on images.\u003C/p>\n\u003Cp>I put together a \u003Ca href=\"https://codepen.io/Snugug/pen/VwBmqQQ\">quick CodePen proof of concept\u003C/a> based on comments in the CSSWG issue and, sure enough,in Chrome anyway, a lazy loaded image won’t download if display is \u003Ccode>none\u003C/code>. And just like that, a solution emerged.\u003C/p>\n\u003Cp>Now, the reason this isn’t great for performance is it will delay image loading, so \u003Ca href=\"https://web.dev/lcp/\">largest contentful paint\u003C/a> may suffer, so \u003Ccode>&#x3C;picture>\u003C/code> elements are probably better most of the time. That said, if you need container based image art direction, here’s how you do it:\u003C/p>\n\u003Col>\n\u003Cli>Add \u003Ccode>loading=\"lazy\"\u003C/code> to lazy load the desired images, one image per “art direction”\u003C/li>\n\u003Cli>\u003Ccode>display: none\u003C/code> the images that need to be art directed\u003C/li>\n\u003Cli>Use container queries to undo \u003Ccode>display: none\u003C/code> (with \u003Ccode>block\u003C/code> for instance).\u003C/li>\n\u003C/ol>\n\u003Cp>That’s it! No JavaScript,only a couple of straightforward lines of CSS. Here’s the example from the CodePen:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Hide the image tags\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">img\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  display\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">none\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Set the container to track inline size\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.container\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  container-type\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">inline-size\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">%\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Make the first image block initially, then none at the desired width\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.pic-1\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  display\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">block\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  @\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">container\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    display\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">none\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Make the second image block at the desired width\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.pic-2\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  @\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">container\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    display\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">initial\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Something to consider if you’re looking to give this a go in production:\u003C/p>\n\u003Cul>\n\u003Cli>Small examples will probably seem to work fine, but do test if you’re using this a lot\u003C/li>\n\u003Cli>After talking this out with Una, she recommends adding a placeholder in to help prevent layout shift. You can probably accomplish something similar using a trick similar to what Sara mentions in her post; wrap your images in a parent with an \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/aspect-ratio\">\u003Ccode>aspect-ratio\u003C/code>\u003C/a> that can change based on what image is being pulled in (so more container queries)\u003C/li>\n\u003C/ul>\n\u003Cp>That’s it! Go have fun with it!\u003C/p>",{"headings":1101,"localImagePaths":1102,"remoteImagePaths":1103,"frontmatter":1104,"imagePaths":1106},[],[],[],{"title":1092,"published":1105,"summary":1094},"2023-01-06",[],"bulletproof-combo-fixed-and-fluid-grids-css3-calc",{"id":1107,"data":1109,"body":1113,"filePath":1114,"digest":1115,"rendered":1116},{"title":1110,"published":1111,"summary":1112},"Bulletproof Combo Fixed and Fluid Grids with CSS3 Calc",["Date","2014-01-17T00:00:00.000Z"],"CSS3 Calc can be used to do all sorts of neat things, including creating some fantastic advanced responsive grids. Oh yah, and a new Singularity output style to support it.","You wanna see something cool?\n\n@[vimeo](https://vimeo.com/84435424) {data-aspect-ratio=500x89}\n\nDid you catch that? If not, take a good look at the red and green columns. Notice something different about them? How about something a bit more practical.\n\n@[vimeo](https://vimeo.com/84435488) {data-aspect-ratio=500x89}\n\nSee it there? Are you excited yet, because I know I am!\n\nYesterday morning I had a bit of a brainstorm. Working on a new project, I was asked by a designer who didn't have any responsive web design experience if he could have a fixed width sidebar and a fluid, flexible column to fill the rest of the space. I told him he'd need to wait until [flexbox](http://www.w3.org/TR/css3-flexbox/) in order to have it; he didn't understand what that meant. I though in the back of my mind \"well, maybe with [calc](http://www.w3.org/TR/css3-values/#calc) you could pull something off\", but I let that though go quickly because, well, it was stupid. Oh but how the unconscious works! I was awoken yesterday morning at 5am to my brain yelling at me \"SAM! YOU'VE ALREADY DONE ALL OF THE MATH! JUST PRINT IT OUT AS A STRING!\" To which, I replied \"Brain, shut up. It's too early to mess with calc for the first time.\" My brain didn't listen. After taking a quick trip to [Can I Use](http://caniuse.com/calc), I was amazed by the fact that, for the most part (and certainly for this project's support level), not only could I reliably use `calc`, but I could use it unprefixed! After reading that, my brain wouldn't let me go back to sleep.\n\nIn order to get the calculations right, I had to do a bit of math. I like math, but this was annoying math because the only way I'm able to check the results is by rendering everything in browser; no way to check my work as I went. With a bit of work, I came up with the following (somewhat) simple formula for determining the width of a single fluid item in a mixed fixed/fluid column pattern:\n\n```bash\n((100% - (sum of fixed widths + sum of gutter widths)) / (sum of fluid width)) * (fluid column width)\n```\n\nIt's fairly straight forward; take the whole width, subtract the fixed parts, divide into equal sized columns, multiply by column width. Sure, fair enough. But then, what happens if you want to span multiple fluid columns? Well you get a formula that looks something like this:\n\n```bash\n(((100% - (sum of fixed widths + sum of gutter widths)) / (sum of fluid width)) * (fluid column width) + (gutter width)) + (((100% - (sum of fixed widths + sum of column widths)) / (sum of fluid width)) * (fluid column width))\n```\n\nFair enough, math, it's complex. Did I mention yet that that's the _string_ that needs to get printed out? What about a mixture of fixed and fluid columns?\n\n```bash\n(((100% - (sum of fixed widths + sum of gutter widths)) / (sum of fluid width)) * (fluid column width) + (gutter width)) + (fixed width + gutter width) + (((100% - (sum of fixed widths + sum of column widths)) / (sum of fluid width)) * (fluid column width))\n```\n\nOkay, that's getting unwieldy. But it's not over! We want to be able to use [isolation](https://github.com/Team-Sass/Singularity/wiki/Output-Styles#isolation) output's source order independent ordering, so we need to calculate margins too! Simple enough, the width of each column preceding the one we're on plus a gutter a piece, but remember the formula for fluid width items! To give you an idea of what that'd look like (and it's calculated width), here's the margin property for the blue item in the first video (the initial `0.5em` is because we're using [split gutters](https://github.com/Team-Sass/Singularity/wiki/Creating-Grids#split-gutters)).\n\n```scss\n.third {\n  width: calc((((100% - (520px + 5em)) / (4))) * 2);\n  margin-left: calc(\n    0.5em + (320px + 1em) + (((100% - (520px + 5em)) / (4)) * 1 + 1em)\n  );\n}\n```\n\nYah, long story short, this is stupid and you shouldn't ever use this method; at least not without a CSS Preprocessor\n\n## Enter Sass\n\nI love [Singularity](https://github.com/Team-Sass/Singularity/) and I'm really proud of 1.2.0's output plugin system. Scott and I have always envisioned Singularity as a base API for working with grids, something that can be extended in ways unimaginable. So, I decided to write an Output Plugin for Singularity called `calc`. Because we're not ready to support it fully yet, it's living in [Singularity Extras](https://github.com/Team-Sass/Singularity-extras) now as of version 1.0.0.alpha.1. Using it is easy, just download (either add that version to your Gemfile, or [download the files directly to your project](https://github.com/Team-Sass/Singularity-extras/releases/tag/1.0.0.alpha.1)) and import `singularity-extras/outputs`. Then, you're ready to use!\n\n`calc` grids are some restrictions placed on them that `float` and `isolation` grids don't. First, they must be asymmetric grids, meaning you must define the width of each column. You can mix any units you want as long as they are compatible with `calc` (as of this writing, for instance, `rem` units aren't for some reason). If you want to define parts of the remaining fluid area, you do so with unit less numbers just like you would when normally using Singularity. The other change is that `calc` grids only work with fixed width gutters (gutters with defined units, including `%` if you so choose) as the alternative would be having the gutter widths being defined by the remaining fluid area, which is quite hard to grok and doesn't make much sense to me. Mix units all you want, `calc` will take care of it (at least in all of my tests). Otherwise, `calc` behaves more or less identical to `isolation`. To give you an idea of what this looks like, here's the grid definition for the first video:\n\n```scss\n@import 'breakpoint';\n@import 'singularitygs';\n@import 'singularity-extras/outputs';\n\n@include add-grid(320px 1 2 200px 1);\n@include add-gutter(1em);\n@include add-gutter-style('split');\n@include sgs-change('output', 'calc');\n```\n\nHere's the HTML and the Sass for the second video:\n\n```html\n\u003C!doctype html>\n\u003Chtml lang=\"en\">\n  \u003Chead>\n    \u003Cmeta charset=\"UTF-8\" />\n    \u003Ctitle>Test\u003C/title>\n    \u003Clink rel=\"stylesheet\" href=\"css/test.css\" />\n  \u003C/head>\n  \u003Cbody>\n    \u003Cdiv class=\"main\">\u003C/div>\n    \u003Cdiv class=\"primary-sidebar\">\u003C/div>\n    \u003Cdiv class=\"secondary-sidebar\">\u003C/div>\n  \u003C/body>\n\u003C/html>\n```\n\n```scss\n@import 'breakpoint';\n@import 'singularitygs';\n@import 'singularity-extras/generators/ratio';\n@import 'singularity-extras/generators/snap';\n@import 'singularity-extras/outputs';\n\n@include add-grid(400px 1 300px);\n@include add-gutter(1em);\n@include sgs-change('output', 'calc');\n\n.main {\n  background: red;\n  @include grid-span(1, 2);\n}\n\n.primary-sidebar {\n  background: green;\n  @include grid-span(1, 1);\n}\n\n.secondary-sidebar {\n  background: blue;\n  @include grid-span(1, 3);\n}\n\n* {\n  box-sizing: border-box;\n}\n\nbody {\n  margin: 0;\n  padding: 0;\n}\n\ndiv {\n  height: 100vh;\n  margin: 0;\n  padding: 0;\n}\n```\n\nI hope you enjoy doing some awesome and crazy things with this. Enjoy!","src/content/posts/bulletproof-combo-fixed-and-fluid-grids-css3-calc.md","007a37bc767e2ddc",{"html":1117,"metadata":1118},"\u003Cp>You wanna see something cool?\u003C/p>\n\u003Cp data-aspect-ratio=\"500x89\">@\u003Ca href=\"https://vimeo.com/84435424\">vimeo\u003C/a> \u003C/p>\n\u003Cp>Did you catch that? If not, take a good look at the red and green columns. Notice something different about them? How about something a bit more practical.\u003C/p>\n\u003Cp data-aspect-ratio=\"500x89\">@\u003Ca href=\"https://vimeo.com/84435488\">vimeo\u003C/a> \u003C/p>\n\u003Cp>See it there? Are you excited yet, because I know I am!\u003C/p>\n\u003Cp>Yesterday morning I had a bit of a brainstorm. Working on a new project, I was asked by a designer who didn’t have any responsive web design experience if he could have a fixed width sidebar and a fluid, flexible column to fill the rest of the space. I told him he’d need to wait until \u003Ca href=\"http://www.w3.org/TR/css3-flexbox/\">flexbox\u003C/a> in order to have it; he didn’t understand what that meant. I though in the back of my mind “well, maybe with \u003Ca href=\"http://www.w3.org/TR/css3-values/#calc\">calc\u003C/a> you could pull something off”, but I let that though go quickly because, well, it was stupid. Oh but how the unconscious works! I was awoken yesterday morning at 5am to my brain yelling at me “SAM! YOU’VE ALREADY DONE ALL OF THE MATH! JUST PRINT IT OUT AS A STRING!” To which, I replied “Brain, shut up. It’s too early to mess with calc for the first time.” My brain didn’t listen. After taking a quick trip to \u003Ca href=\"http://caniuse.com/calc\">Can I Use\u003C/a>, I was amazed by the fact that, for the most part (and certainly for this project’s support level), not only could I reliably use \u003Ccode>calc\u003C/code>, but I could use it unprefixed! After reading that, my brain wouldn’t let me go back to sleep.\u003C/p>\n\u003Cp>In order to get the calculations right, I had to do a bit of math. I like math, but this was annoying math because the only way I’m able to check the results is by rendering everything in browser; no way to check my work as I went. With a bit of work, I came up with the following (somewhat) simple formula for determining the width of a single fluid item in a mixed fixed/fluid column pattern:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">((\u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">%\u003C/span>\u003Cspan style=\"color:#F92672\"> -\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (sum of fixed widths \u003C/span>\u003Cspan style=\"color:#F92672\">+\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> sum of gutter widths)) / (\u003C/span>\u003Cspan style=\"color:#A6E22E\">sum\u003C/span>\u003Cspan style=\"color:#E6DB74\"> of\u003C/span>\u003Cspan style=\"color:#E6DB74\"> fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">*\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#A6E22E\">fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> column\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>It’s fairly straight forward; take the whole width, subtract the fixed parts, divide into equal sized columns, multiply by column width. Sure, fair enough. But then, what happens if you want to span multiple fluid columns? Well you get a formula that looks something like this:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">(((\u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">%\u003C/span>\u003Cspan style=\"color:#F92672\"> -\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (sum of fixed widths \u003C/span>\u003Cspan style=\"color:#F92672\">+\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> sum of gutter widths)) / (\u003C/span>\u003Cspan style=\"color:#A6E22E\">sum\u003C/span>\u003Cspan style=\"color:#E6DB74\"> of\u003C/span>\u003Cspan style=\"color:#E6DB74\"> fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">*\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#A6E22E\">fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> column\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) + (\u003C/span>\u003Cspan style=\"color:#A6E22E\">gutter\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) + (((\u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">%\u003C/span>\u003Cspan style=\"color:#F92672\"> -\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (sum of fixed widths \u003C/span>\u003Cspan style=\"color:#F92672\">+\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> sum of column widths)) / (\u003C/span>\u003Cspan style=\"color:#A6E22E\">sum\u003C/span>\u003Cspan style=\"color:#E6DB74\"> of\u003C/span>\u003Cspan style=\"color:#E6DB74\"> fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">*\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#A6E22E\">fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> column\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">))\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Fair enough, math, it’s complex. Did I mention yet that that’s the \u003Cem>string\u003C/em> that needs to get printed out? What about a mixture of fixed and fluid columns?\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">(((\u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">%\u003C/span>\u003Cspan style=\"color:#F92672\"> -\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (sum of fixed widths \u003C/span>\u003Cspan style=\"color:#F92672\">+\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> sum of gutter widths)) / (\u003C/span>\u003Cspan style=\"color:#A6E22E\">sum\u003C/span>\u003Cspan style=\"color:#E6DB74\"> of\u003C/span>\u003Cspan style=\"color:#E6DB74\"> fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">*\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#A6E22E\">fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> column\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) + (\u003C/span>\u003Cspan style=\"color:#A6E22E\">gutter\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) + (\u003C/span>\u003Cspan style=\"color:#A6E22E\">fixed\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#E6DB74\"> +\u003C/span>\u003Cspan style=\"color:#E6DB74\"> gutter\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) + (((\u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">%\u003C/span>\u003Cspan style=\"color:#F92672\"> -\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (sum of fixed widths \u003C/span>\u003Cspan style=\"color:#F92672\">+\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> sum of column widths)) / (\u003C/span>\u003Cspan style=\"color:#A6E22E\">sum\u003C/span>\u003Cspan style=\"color:#E6DB74\"> of\u003C/span>\u003Cspan style=\"color:#E6DB74\"> fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">*\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#A6E22E\">fluid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> column\u003C/span>\u003Cspan style=\"color:#E6DB74\"> width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">))\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Okay, that’s getting unwieldy. But it’s not over! We want to be able to use \u003Ca href=\"https://github.com/Team-Sass/Singularity/wiki/Output-Styles#isolation\">isolation\u003C/a> output’s source order independent ordering, so we need to calculate margins too! Simple enough, the width of each column preceding the one we’re on plus a gutter a piece, but remember the formula for fluid width items! To give you an idea of what that’d look like (and it’s calculated width), here’s the margin property for the blue item in the first video (the initial \u003Ccode>0.5em\u003C/code> is because we’re using \u003Ca href=\"https://github.com/Team-Sass/Singularity/wiki/Creating-Grids#split-gutters\">split gutters\u003C/a>).\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.third\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">calc\u003C/span>\u003Cspan style=\"color:#F8F8F2\">((((\u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">%\u003C/span>\u003Cspan style=\"color:#F92672\"> -\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#AE81FF\">520\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F92672\"> +\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 5\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#AE81FF\">4\u003C/span>\u003Cspan style=\"color:#F8F8F2\">))) \u003C/span>\u003Cspan style=\"color:#F92672\">*\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  margin-left\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">calc\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#AE81FF\">    0.5\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F92672\"> +\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#AE81FF\">320\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F92672\"> +\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) \u003C/span>\u003Cspan style=\"color:#F92672\">+\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (((\u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">%\u003C/span>\u003Cspan style=\"color:#F92672\"> -\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#AE81FF\">520\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F92672\"> +\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 5\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#AE81FF\">4\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">*\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#F92672\"> +\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  );\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Yah, long story short, this is stupid and you shouldn’t ever use this method; at least not without a CSS Preprocessor\u003C/p>\n\u003Ch2 id=\"enter-sass\">Enter Sass\u003C/h2>\n\u003Cp>I love \u003Ca href=\"https://github.com/Team-Sass/Singularity/\">Singularity\u003C/a> and I’m really proud of 1.2.0’s output plugin system. Scott and I have always envisioned Singularity as a base API for working with grids, something that can be extended in ways unimaginable. So, I decided to write an Output Plugin for Singularity called \u003Ccode>calc\u003C/code>. Because we’re not ready to support it fully yet, it’s living in \u003Ca href=\"https://github.com/Team-Sass/Singularity-extras\">Singularity Extras\u003C/a> now as of version 1.0.0.alpha.1. Using it is easy, just download (either add that version to your Gemfile, or \u003Ca href=\"https://github.com/Team-Sass/Singularity-extras/releases/tag/1.0.0.alpha.1\">download the files directly to your project\u003C/a>) and import \u003Ccode>singularity-extras/outputs\u003C/code>. Then, you’re ready to use!\u003C/p>\n\u003Cp>\u003Ccode>calc\u003C/code> grids are some restrictions placed on them that \u003Ccode>float\u003C/code> and \u003Ccode>isolation\u003C/code> grids don’t. First, they must be asymmetric grids, meaning you must define the width of each column. You can mix any units you want as long as they are compatible with \u003Ccode>calc\u003C/code> (as of this writing, for instance, \u003Ccode>rem\u003C/code> units aren’t for some reason). If you want to define parts of the remaining fluid area, you do so with unit less numbers just like you would when normally using Singularity. The other change is that \u003Ccode>calc\u003C/code> grids only work with fixed width gutters (gutters with defined units, including \u003Ccode>%\u003C/code> if you so choose) as the alternative would be having the gutter widths being defined by the remaining fluid area, which is quite hard to grok and doesn’t make much sense to me. Mix units all you want, \u003Ccode>calc\u003C/code> will take care of it (at least in all of my tests). Otherwise, \u003Ccode>calc\u003C/code> behaves more or less identical to \u003Ccode>isolation\u003C/code>. To give you an idea of what this looks like, here’s the grid definition for the first video:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'breakpoint'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'singularitygs'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'singularity-extras/outputs'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> add-grid\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#AE81FF\">320\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 200\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> add-gutter\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> add-gutter-style\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'split'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> sgs-change\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'output'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#E6DB74\">'calc'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Here’s the HTML and the Sass for the second video:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"html\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;!\u003C/span>\u003Cspan style=\"color:#F92672\">doctype\u003C/span>\u003Cspan style=\"color:#A6E22E\"> html\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">html\u003C/span>\u003Cspan style=\"color:#A6E22E\"> lang\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"en\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">head\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">meta\u003C/span>\u003Cspan style=\"color:#A6E22E\"> charset\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"UTF-8\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> />\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">title\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>Test&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">title\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">link\u003C/span>\u003Cspan style=\"color:#A6E22E\"> rel\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"stylesheet\"\u003C/span>\u003Cspan style=\"color:#A6E22E\"> href\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"css/test.css\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> />\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">head\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">body\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#A6E22E\"> class\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"main\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#A6E22E\"> class\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"primary-sidebar\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#A6E22E\"> class\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"secondary-sidebar\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">body\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">html\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'breakpoint'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'singularitygs'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'singularity-extras/generators/ratio'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'singularity-extras/generators/snap'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'singularity-extras/outputs'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> add-grid\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#AE81FF\">400\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 300\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> add-gutter\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> sgs-change\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'output'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#E6DB74\">'calc'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.main\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> grid-span\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#AE81FF\">2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.primary-sidebar\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> grid-span\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.secondary-sidebar\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">blue\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> grid-span\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#AE81FF\">3\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">*\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  box-sizing\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">border-box\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">body\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  margin\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">0\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  padding\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">0\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">vh\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  margin\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">0\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  padding\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">0\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>I hope you enjoy doing some awesome and crazy things with this. Enjoy!\u003C/p>",{"headings":1119,"localImagePaths":1123,"remoteImagePaths":1124,"frontmatter":1125,"imagePaths":1127},[1120],{"depth":80,"slug":1121,"text":1122},"enter-sass","Enter Sass",[],[],{"title":1110,"published":1126,"summary":1112},"2014-01-17",[],"comparing-privacy-focused-analytics-tools",{"id":1128,"data":1130,"body":1134,"filePath":1135,"digest":1136,"rendered":1137},{"title":1131,"published":1132,"summary":1133},"Comparing Privacy-Focused Analytics Tools",["Date","2023-01-25T00:00:00.000Z"],"A head-to-head-to-head comparison of Cloudflare Web Analytics, Plausible, and Fathom, three privacy-preserving analytics solutions, after running each on my site for a week.","For the past week or so, I've been experimenting with three (paid) privacy-preserving analytics solutions for my site: Cloudflare Web Analytics, Plausible, and Fathom. My needs are pretty simple: I just want a sense of how people are using my site. I don't need really need things like active users, flow through my site, or other tracking that would require uniquely identifying an individual as they go through my site. So, how do these three stack up? The tl;dr is I'm going to stick with Plausible. Here's why:\n\n## Cloudflare Web Analytics\n\nI really loved the idea of Cloudflare Web Analytics (CWA). My site is already proxied behind Cloudflare, so this felt like a no-brainer. I didn't even need to add anything to my site; it can track stuff from how it serves and adds a small bonus script for tracking a few additional items like Core Web Vitals and page load time (which I really like). Unfortunately, that's where what I like about CWA ends.\n\nCWA has the basics: referrers, paths, browsers, OS, and device type, but is missing bounce rate and time on page, and doesn't support custom events. You're also unfortunately, you're limited to top 15 items for each category (except country, for some reason). I like being able to exclude items (like a landing page) from overall analytics, but the missing key analytics and the limited depth make the overall experience not great. There are two other problems I have with CWA: confusion between CWA and Cloudflare Analytics, and the accuracy of CWA.\n\nCloudflare offers traffic analytics if you proxy through them. It's got a ton of great information, but it uses nearly the same interface as their web analytics, generally is in the same menu area, but is _really_ not the same thing. When first getting set up, I constantly got confused between the two, and navigating between them is equally confusing because they're in different sections of near-identically looking areas of the Cloudflare site. This is a UX thing that can be solved, but it's not yet!\n\nFinally, accuracy of CWA confuses me. Plausible and Fathom have the same number of total pageviews and near identical visitors (±2%), but CWA's pageviews are 34% higher than the other two, and visits are 110% higher. I have no idea why they're so much higher, but because it's the outlier of the three I lean towards the other two being more representative.\n\n## Fathom and Plausible\n\nBoth Fathom and Plausible are pretty comparable to each other; both do all of the analytics you expect (visitors, views, time on site, bounce rate, etc…). Both support custom events, can be proxied to be served from your domain, have support for UTM campaigns, countries, and you can dive into individual items to see more. So it really comes down to small bits to choose one over the other, and for me this is where Plausible pulls away.\n\nWhile both support sources and UTMs/campaigns, Plausible can (today) integrate with Google Search Console to see top search terms (although it doesn't look like search terms filter with other filters), which is great to have in one place. Plausible groups campaigns with sources, whereas Fathom keeps them separate. Overall, I like the Plausible interface better.\n\nNext is pages. Both show visitors, pageviews, time on page, and page entries (although the last is a little different between the two). The places where Plausible pulls away for me are it shows exit pages, bounce rate, and has a \"details\" view that gives a big table view of all data (it has this for each view, but here's the first place it really shines). The one weird thing, which I don't have an answer for, is that Fathom's time on page is about 70% more than Plausible's, but because it doesn't have a details view its hard to track down where the differences between pages are as I need to go into each page individually.\n\nLocations, the story is the same. Both show countries, but Plausible has regions and cities, too, plus a map view, which I particularly like. Once more with devices; both show device type and browser, but Plausible has a better breakdown (more options and describes the width they're using to bucket) and includes operating system, too.\n\nPlausible also includes the ability to do some advanced filtering, so like CWA, you can exclude your landing page, or any number of other other things it tracks. I also like the overall UI a little bit more (different sections have different accent colors, referrers have favicons, it responds a little better). Plausible also offers an NPM module to directly bundle their code (which is pretty tiny) with your site code, removing the need to proxy it for better tracking.\n\nThere are some interesting intangibles for both. Fathom has optional uptime monitoring included and an affiliate program if you're into that kinda thing. Plausible is open source (APGLv3) and donate some of their revenue to environmental causes and open source.\n\n---\n\nAfter running these three for a week, I'm going to stick with Plausible. The pricing is right (for me), the features are right, and it's giving me the insights I'm interested in to improve my site. My next steps are to experiment with adding events, and maybe set up a public view for the analytics once I've given it some time to settle in.","src/content/posts/comparing-privacy-focused-analytics-tools.md","80e44493fee1f806",{"html":1138,"metadata":1139},"\u003Cp>For the past week or so, I’ve been experimenting with three (paid) privacy-preserving analytics solutions for my site: Cloudflare Web Analytics, Plausible, and Fathom. My needs are pretty simple: I just want a sense of how people are using my site. I don’t need really need things like active users, flow through my site, or other tracking that would require uniquely identifying an individual as they go through my site. So, how do these three stack up? The tl;dr is I’m going to stick with Plausible. Here’s why:\u003C/p>\n\u003Ch2 id=\"cloudflare-web-analytics\">Cloudflare Web Analytics\u003C/h2>\n\u003Cp>I really loved the idea of Cloudflare Web Analytics (CWA). My site is already proxied behind Cloudflare, so this felt like a no-brainer. I didn’t even need to add anything to my site; it can track stuff from how it serves and adds a small bonus script for tracking a few additional items like Core Web Vitals and page load time (which I really like). Unfortunately, that’s where what I like about CWA ends.\u003C/p>\n\u003Cp>CWA has the basics: referrers, paths, browsers, OS, and device type, but is missing bounce rate and time on page, and doesn’t support custom events. You’re also unfortunately, you’re limited to top 15 items for each category (except country, for some reason). I like being able to exclude items (like a landing page) from overall analytics, but the missing key analytics and the limited depth make the overall experience not great. There are two other problems I have with CWA: confusion between CWA and Cloudflare Analytics, and the accuracy of CWA.\u003C/p>\n\u003Cp>Cloudflare offers traffic analytics if you proxy through them. It’s got a ton of great information, but it uses nearly the same interface as their web analytics, generally is in the same menu area, but is \u003Cem>really\u003C/em> not the same thing. When first getting set up, I constantly got confused between the two, and navigating between them is equally confusing because they’re in different sections of near-identically looking areas of the Cloudflare site. This is a UX thing that can be solved, but it’s not yet!\u003C/p>\n\u003Cp>Finally, accuracy of CWA confuses me. Plausible and Fathom have the same number of total pageviews and near identical visitors (±2%), but CWA’s pageviews are 34% higher than the other two, and visits are 110% higher. I have no idea why they’re so much higher, but because it’s the outlier of the three I lean towards the other two being more representative.\u003C/p>\n\u003Ch2 id=\"fathom-and-plausible\">Fathom and Plausible\u003C/h2>\n\u003Cp>Both Fathom and Plausible are pretty comparable to each other; both do all of the analytics you expect (visitors, views, time on site, bounce rate, etc…). Both support custom events, can be proxied to be served from your domain, have support for UTM campaigns, countries, and you can dive into individual items to see more. So it really comes down to small bits to choose one over the other, and for me this is where Plausible pulls away.\u003C/p>\n\u003Cp>While both support sources and UTMs/campaigns, Plausible can (today) integrate with Google Search Console to see top search terms (although it doesn’t look like search terms filter with other filters), which is great to have in one place. Plausible groups campaigns with sources, whereas Fathom keeps them separate. Overall, I like the Plausible interface better.\u003C/p>\n\u003Cp>Next is pages. Both show visitors, pageviews, time on page, and page entries (although the last is a little different between the two). The places where Plausible pulls away for me are it shows exit pages, bounce rate, and has a “details” view that gives a big table view of all data (it has this for each view, but here’s the first place it really shines). The one weird thing, which I don’t have an answer for, is that Fathom’s time on page is about 70% more than Plausible’s, but because it doesn’t have a details view its hard to track down where the differences between pages are as I need to go into each page individually.\u003C/p>\n\u003Cp>Locations, the story is the same. Both show countries, but Plausible has regions and cities, too, plus a map view, which I particularly like. Once more with devices; both show device type and browser, but Plausible has a better breakdown (more options and describes the width they’re using to bucket) and includes operating system, too.\u003C/p>\n\u003Cp>Plausible also includes the ability to do some advanced filtering, so like CWA, you can exclude your landing page, or any number of other other things it tracks. I also like the overall UI a little bit more (different sections have different accent colors, referrers have favicons, it responds a little better). Plausible also offers an NPM module to directly bundle their code (which is pretty tiny) with your site code, removing the need to proxy it for better tracking.\u003C/p>\n\u003Cp>There are some interesting intangibles for both. Fathom has optional uptime monitoring included and an affiliate program if you’re into that kinda thing. Plausible is open source (APGLv3) and donate some of their revenue to environmental causes and open source.\u003C/p>\n\u003Chr>\n\u003Cp>After running these three for a week, I’m going to stick with Plausible. The pricing is right (for me), the features are right, and it’s giving me the insights I’m interested in to improve my site. My next steps are to experiment with adding events, and maybe set up a public view for the analytics once I’ve given it some time to settle in.\u003C/p>",{"headings":1140,"localImagePaths":1147,"remoteImagePaths":1148,"frontmatter":1149,"imagePaths":1151},[1141,1144],{"depth":80,"slug":1142,"text":1143},"cloudflare-web-analytics","Cloudflare Web Analytics",{"depth":80,"slug":1145,"text":1146},"fathom-and-plausible","Fathom and Plausible",[],[],{"title":1131,"published":1150,"summary":1133},"2023-01-25",[],"cookbook",{"id":1152,"data":1154,"body":1158,"filePath":1159,"digest":1160,"rendered":1161},{"title":1155,"published":1156,"summary":1157},"Cookbook",["Date","2019-09-15T00:00:00.000Z"],"I've added a cookbook section to the site!","It's September and this is my first post of the year! I really need to get better at that. Anyway. This is a good one! Something that y'all have been asking for for a long time, and something I've finally gotten around to kinda sorta doing, is finally here on the site! MY RECIPES!\n\nThat's right! That food that I Instagram all the time, I'm finally going to start putting those recipes online! It's all under [/cookbook](/cookbook), which is going to have all of my recipe cards, which for now include some basic information for you to see if the recipe's right for you. The first recipe I wrote down, for my [slow scrambled egg toast](/cookbook/slow-scrambled-egg-toast), is mostly to design and test the format, but it's also a good exercise in egg cookery for y'all! Let's take a look at the recipe format.\n\nThe recipe format is ~~stolen from~~ inspired by one of my favorite cookbooks of all time, [Modernist Cuisine at Home](https://modernistcuisine.com/books/modernist-cuisine-at-home/). The whole thing is fantastic, from their food photography to the really interesting and useful techniques to the recipe format, which when I saw I immediately was blown away at how, well, _perfect_ it was. At the time, I thought that that's how all recipes should be formatted, so when it came time to write mine down, that's what I went with!\n\nNow, I'm no test kitchen, so these recipes are going to be only _roughly_ what I do with rough timings to match, so no scaling or alternative measurements unless I know them already, but the actual recipes should be easy enough to follow! Recipes are arranged in a table, with each row consisting of the ingredients and measurements you need, and the steps you're going to do with those ingredients. Because you're likely use to traditional recipe layouts, an easy \"conversion\" is to read the first two columns for what you're going to use, and the last for your instructions. This recipe layout I feel makes _mise en place_ easier and the overall recipe easier to follow.\n\nIn terms of the actual technical stuff that went in to making this, I've tried to keep it as accessible as possible, but I'm working with tables in tables. If you find it wonky, please let me know; I'd love help improving it! I've also discovered the [`object-fit`](https://developer.mozilla.org/en-US/docs/Web/CSS/object-fit) and [`object-position`](https://developer.mozilla.org/en-US/docs/Web/CSS/object-position) properties, which effectively let me take an actual `img` tag and treat it like a background image! It's a super nifty trick that I think will solve lots of accessibility paint points for me for things like card UIs in the future.\n\nI hope you enjoy me finally both updating my blog and adding recipes to it! Have fun cooking!","src/content/posts/cookbook.md","e1eb1ccad3bf2a5e",{"html":1162,"metadata":1163},"\u003Cp>It’s September and this is my first post of the year! I really need to get better at that. Anyway. This is a good one! Something that y’all have been asking for for a long time, and something I’ve finally gotten around to kinda sorta doing, is finally here on the site! MY RECIPES!\u003C/p>\n\u003Cp>That’s right! That food that I Instagram all the time, I’m finally going to start putting those recipes online! It’s all under \u003Ca href=\"/cookbook\">/cookbook\u003C/a>, which is going to have all of my recipe cards, which for now include some basic information for you to see if the recipe’s right for you. The first recipe I wrote down, for my \u003Ca href=\"/cookbook/slow-scrambled-egg-toast\">slow scrambled egg toast\u003C/a>, is mostly to design and test the format, but it’s also a good exercise in egg cookery for y’all! Let’s take a look at the recipe format.\u003C/p>\n\u003Cp>The recipe format is \u003Cdel>stolen from\u003C/del> inspired by one of my favorite cookbooks of all time, \u003Ca href=\"https://modernistcuisine.com/books/modernist-cuisine-at-home/\">Modernist Cuisine at Home\u003C/a>. The whole thing is fantastic, from their food photography to the really interesting and useful techniques to the recipe format, which when I saw I immediately was blown away at how, well, \u003Cem>perfect\u003C/em> it was. At the time, I thought that that’s how all recipes should be formatted, so when it came time to write mine down, that’s what I went with!\u003C/p>\n\u003Cp>Now, I’m no test kitchen, so these recipes are going to be only \u003Cem>roughly\u003C/em> what I do with rough timings to match, so no scaling or alternative measurements unless I know them already, but the actual recipes should be easy enough to follow! Recipes are arranged in a table, with each row consisting of the ingredients and measurements you need, and the steps you’re going to do with those ingredients. Because you’re likely use to traditional recipe layouts, an easy “conversion” is to read the first two columns for what you’re going to use, and the last for your instructions. This recipe layout I feel makes \u003Cem>mise en place\u003C/em> easier and the overall recipe easier to follow.\u003C/p>\n\u003Cp>In terms of the actual technical stuff that went in to making this, I’ve tried to keep it as accessible as possible, but I’m working with tables in tables. If you find it wonky, please let me know; I’d love help improving it! I’ve also discovered the \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/object-fit\">\u003Ccode>object-fit\u003C/code>\u003C/a> and \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/object-position\">\u003Ccode>object-position\u003C/code>\u003C/a> properties, which effectively let me take an actual \u003Ccode>img\u003C/code> tag and treat it like a background image! It’s a super nifty trick that I think will solve lots of accessibility paint points for me for things like card UIs in the future.\u003C/p>\n\u003Cp>I hope you enjoy me finally both updating my blog and adding recipes to it! Have fun cooking!\u003C/p>",{"headings":1164,"localImagePaths":1165,"remoteImagePaths":1166,"frontmatter":1167,"imagePaths":1169},[],[],[],{"title":1155,"published":1168,"summary":1157},"2019-09-15",[],"css-strategy",{"id":1170,"data":1172,"body":1177,"filePath":1178,"digest":1179,"rendered":1180},{"title":1173,"published":1174,"updated":1175,"summary":1176},"CSS Strategy",["Date","2013-07-28T00:00:00.000Z"],["Date","2014-01-17T00:00:00.000Z"],"My current thoughts on this subject have been codified in North",":::message{.warning}\nMy current thoughts on this subject have been codified in [North](https://github.com/snugug/north).\n:::\n\nPart of what I do at work is creating and maintaining our front-end standards, and this includes a CSS strategy. The first, and if you know any of my work most obvious, part of this strategy is the use of Sass for CSS Preprocessing. Sass adds so much for large scale maintainability that this is really a no-brainer. That's the how, but what about the what? What are we going to be writing with our CSS Preprocessor? What's our class naming strategy? This has been bugging me a lot. Right now, there are three prevailing thoughts on CSS strategy: [SMACSS](https://smacss.com/), [OOCSS](http://oocss.org/), and [BEM](http://bem.info/). I dislike all of them. I find that SMACSS is too loose of a convention (that at times contradicts its own advice) to work at scale with a large distributed team. OOCSS stores all of its styling knowledge in the HTML instead of the CSS where it belongs, and is also pretty loose in its naming conventions. BEM's conventions work against how CSS natively parses and frankly destroys the cascade, the one thing that CSS is excellent at. While I may not like SMACSS's `.pod .pod-body.is-active`, I absolutely despise BEM's `.slider__figure--is-active`. None of the current strategies really seem to cover architecture (the core pieces that make up your styling, think framework) and implementation (the details of a single site).\n\nIt's not all fire and brimstone, though. I like that both SMACSS and OOCSS emphasize thinking in reusable patterns and that BEM has a visual way of easily distinguishing between different conceptual pieces that go into styling. I'm also a fan of SMACSS's recommendation to use a style guide, although it really doesn't go into that much which disappoints me. That being said, pretty much all of these CSS strategies are built for writing vanilla CSS, none really utilize the power that CSS Preprocessors have to offer.\n\nAs it turns out, a bunch of my really smart friends, including [Dale Sande](https://twitter.com/anotheruiguy), [Scott Kellum](https://twitter.com/scottkellum), [Mason Wendell](https://twitter.com/codingdesigner), and [Rob Wierzbowski](https://twitter.com/robwierzbowski), have similar gripes about these existing strategies. We've decided to [work together](https://github.com/team-sass/sucks) to try and create a new CSS strategy that hopefully will solve the issues we have with those that currently exist. While it's in the _very_ early stages (we started working on this Friday, it will be a long journey), I firmly believe that we will get the best results if we can get some feedback on it while we work on it. I'm especially interested in where people have pain points with the existing strategies and, where possible, what their solutions are.\n\n## Current Thoughts\n\nI've spent the past couple of days thinking about what I like and what I dislike about these strategies, and what I'd like to see in a strategy. The following is what I'm looking to cover in this new strategy:\n\n- Variable, Mixin, and Extendable Classes\n- Style Guides\n  - Element Guides\n  - Component Guides\n- CSS Naming Conventions\n- Separation of architecture vs implementation\n\nI'd also like to stick to the following design philosophy:\n\n\u003Cblockquote cite=\"http://www.brainyquote.com/quotes/quotes/a/antoinedes121910.html#GeAxVqpIyzdqELch.99\">\u003Cp>A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away.\u003C/p>\u003Cb>Antoine de Saint-Exupery\u003C/b>\u003C/blockquote>\n\nI firmly believe that being as concise as possible when choosing significant properties should be a priority, as should designing for extensibility and reusability. To me, it's one of the places where BEM falls down the hardest; it's replaced selector specificity with selector naming specificity. To me, this is one of OOCSS's strengths; being able to create modules, submodules, and skins that are decoupled enough that they have proper semantic meaning standing alone.\n\nI've got some of the more high-level pieces figured out already I think. For me, the separation of architecture and implementation, and the creating of a reusable Style Guide have been fairly well encompassed in [Style Prototypes](https://github.com/Team-Sass/generator-style-prototype). I also think that we can leverage preprocessing for mixins and extendables for properties that get shared across multiple pieces. [Toolkit's Contributing Guide](https://github.com/Team-Sass/toolkit/blob/1.x.x/CONTRIBUTING.md) does a fairly good job at breaking down how that would work, with good examples being [Intrinsic Ratios](https://github.com/Team-Sass/toolkit/blob/1.x.x/compass/stylesheets/toolkit/_intrinsic-ratio.scss) and [Clearfix](https://github.com/Team-Sass/toolkit/blob/1.x.x/compass/stylesheets/toolkit/_clearfix.scss). These mixins are designed to be either extended or write properties directly and are written in such a way as to make implementation easy. Mixins and extendables like this would be part of the Style Guide.\n\nNaming conventions and strategy are the big thing that I'm still working through. I will fully admit, I haven't implemented what I'm about to propose yet, but rather is based on my experiences. I prefer semantic naming of classes, describing their purpose, to functional naming (maybe highlighted instead of border-red). This way, the same semantics can be used to produce varied results. Either way, it's all subject to change, but this is what I've got:\n\n### Bases\n\nThese are the variables, mixins, and extendables that power your Style/Component guides. They are core patterns that are shared by multiple components/objects/nuances.\n\n### Components\n\nThese are classes, without prefix, to be used as styling anchor points (and, of course, can include styling in and of themselves). Components will probably be equally used inside of Style/Component guides and in individual implementations. They are similar to blocks in BEM and modules in SMACSS and OOCSS.\n\n```scss\n.component {\n}\n```\n\n### Objects\n\nThese are classes, prefixed with an underscore, to be used to style individual pieces that could be used to make up a component. Objects will mostly be used in Style/Component guides, with individual changes happening inside of implementations, probably using a Component as an anchor for a change. They are similar to elements in BEM and sub-modules in SMACSS.\n\n```scss\n_object {\n}\n```\n\n### Nuances\n\nThese are classes, prefixed with a dash, to be used to alter the appearance of a component or object. They are similar to modifiers in BEM, themes/states in SMACSS, and skins in OOCSS.\n\n```scss\n.-nuance {\n}\n```\n\n### Grids and Layout\n\nWhen building grids and layouts, I prefer to use semantic grid frameworks like [Singularity](https://github.com/Team-Sass/Singularity/wiki) as well as asymmetric grids. These do not lend themselves well to grid classes, nor would I really want them to. I find grid classes make maintaining your layouts hard. I haven't quite figured out exactly where I would prefer to put them, but my initial feeling is that they are implementation specific and would be defined inside of an implementation. They would pivot off of components or objects, but not entirely sure yet.\n\nHere's a CodePen of [how this would all work](http://codepen.io/Snugug/pen/mfKvo) as proposed right now.\n\nAnyway, with all of this, feedback more than welcome.","src/content/posts/css-strategy.md","935f61b98cd621d1",{"html":1181,"metadata":1182},"\u003Cdiv class=\"warning message\" data-type=\"warning\">\u003Cp>My current thoughts on this subject have been codified in \u003Ca href=\"https://github.com/snugug/north\">North\u003C/a>.\u003C/p>\u003C/div>\n\u003Cp>Part of what I do at work is creating and maintaining our front-end standards, and this includes a CSS strategy. The first, and if you know any of my work most obvious, part of this strategy is the use of Sass for CSS Preprocessing. Sass adds so much for large scale maintainability that this is really a no-brainer. That’s the how, but what about the what? What are we going to be writing with our CSS Preprocessor? What’s our class naming strategy? This has been bugging me a lot. Right now, there are three prevailing thoughts on CSS strategy: \u003Ca href=\"https://smacss.com/\">SMACSS\u003C/a>, \u003Ca href=\"http://oocss.org/\">OOCSS\u003C/a>, and \u003Ca href=\"http://bem.info/\">BEM\u003C/a>. I dislike all of them. I find that SMACSS is too loose of a convention (that at times contradicts its own advice) to work at scale with a large distributed team. OOCSS stores all of its styling knowledge in the HTML instead of the CSS where it belongs, and is also pretty loose in its naming conventions. BEM’s conventions work against how CSS natively parses and frankly destroys the cascade, the one thing that CSS is excellent at. While I may not like SMACSS’s \u003Ccode>.pod .pod-body.is-active\u003C/code>, I absolutely despise BEM’s \u003Ccode>.slider__figure--is-active\u003C/code>. None of the current strategies really seem to cover architecture (the core pieces that make up your styling, think framework) and implementation (the details of a single site).\u003C/p>\n\u003Cp>It’s not all fire and brimstone, though. I like that both SMACSS and OOCSS emphasize thinking in reusable patterns and that BEM has a visual way of easily distinguishing between different conceptual pieces that go into styling. I’m also a fan of SMACSS’s recommendation to use a style guide, although it really doesn’t go into that much which disappoints me. That being said, pretty much all of these CSS strategies are built for writing vanilla CSS, none really utilize the power that CSS Preprocessors have to offer.\u003C/p>\n\u003Cp>As it turns out, a bunch of my really smart friends, including \u003Ca href=\"https://twitter.com/anotheruiguy\">Dale Sande\u003C/a>, \u003Ca href=\"https://twitter.com/scottkellum\">Scott Kellum\u003C/a>, \u003Ca href=\"https://twitter.com/codingdesigner\">Mason Wendell\u003C/a>, and \u003Ca href=\"https://twitter.com/robwierzbowski\">Rob Wierzbowski\u003C/a>, have similar gripes about these existing strategies. We’ve decided to \u003Ca href=\"https://github.com/team-sass/sucks\">work together\u003C/a> to try and create a new CSS strategy that hopefully will solve the issues we have with those that currently exist. While it’s in the \u003Cem>very\u003C/em> early stages (we started working on this Friday, it will be a long journey), I firmly believe that we will get the best results if we can get some feedback on it while we work on it. I’m especially interested in where people have pain points with the existing strategies and, where possible, what their solutions are.\u003C/p>\n\u003Ch2 id=\"current-thoughts\">Current Thoughts\u003C/h2>\n\u003Cp>I’ve spent the past couple of days thinking about what I like and what I dislike about these strategies, and what I’d like to see in a strategy. The following is what I’m looking to cover in this new strategy:\u003C/p>\n\u003Cul>\n\u003Cli>Variable, Mixin, and Extendable Classes\u003C/li>\n\u003Cli>Style Guides\n\u003Cul>\n\u003Cli>Element Guides\u003C/li>\n\u003Cli>Component Guides\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>CSS Naming Conventions\u003C/li>\n\u003Cli>Separation of architecture vs implementation\u003C/li>\n\u003C/ul>\n\u003Cp>I’d also like to stick to the following design philosophy:\u003C/p>\n\u003Cblockquote cite=\"http://www.brainyquote.com/quotes/quotes/a/antoinedes121910.html#GeAxVqpIyzdqELch.99\">\u003Cp>A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away.\u003C/p>\u003Cb>Antoine de Saint-Exupery\u003C/b>\u003C/blockquote>\n\u003Cp>I firmly believe that being as concise as possible when choosing significant properties should be a priority, as should designing for extensibility and reusability. To me, it’s one of the places where BEM falls down the hardest; it’s replaced selector specificity with selector naming specificity. To me, this is one of OOCSS’s strengths; being able to create modules, submodules, and skins that are decoupled enough that they have proper semantic meaning standing alone.\u003C/p>\n\u003Cp>I’ve got some of the more high-level pieces figured out already I think. For me, the separation of architecture and implementation, and the creating of a reusable Style Guide have been fairly well encompassed in \u003Ca href=\"https://github.com/Team-Sass/generator-style-prototype\">Style Prototypes\u003C/a>. I also think that we can leverage preprocessing for mixins and extendables for properties that get shared across multiple pieces. \u003Ca href=\"https://github.com/Team-Sass/toolkit/blob/1.x.x/CONTRIBUTING.md\">Toolkit’s Contributing Guide\u003C/a> does a fairly good job at breaking down how that would work, with good examples being \u003Ca href=\"https://github.com/Team-Sass/toolkit/blob/1.x.x/compass/stylesheets/toolkit/_intrinsic-ratio.scss\">Intrinsic Ratios\u003C/a> and \u003Ca href=\"https://github.com/Team-Sass/toolkit/blob/1.x.x/compass/stylesheets/toolkit/_clearfix.scss\">Clearfix\u003C/a>. These mixins are designed to be either extended or write properties directly and are written in such a way as to make implementation easy. Mixins and extendables like this would be part of the Style Guide.\u003C/p>\n\u003Cp>Naming conventions and strategy are the big thing that I’m still working through. I will fully admit, I haven’t implemented what I’m about to propose yet, but rather is based on my experiences. I prefer semantic naming of classes, describing their purpose, to functional naming (maybe highlighted instead of border-red). This way, the same semantics can be used to produce varied results. Either way, it’s all subject to change, but this is what I’ve got:\u003C/p>\n\u003Ch3 id=\"bases\">Bases\u003C/h3>\n\u003Cp>These are the variables, mixins, and extendables that power your Style/Component guides. They are core patterns that are shared by multiple components/objects/nuances.\u003C/p>\n\u003Ch3 id=\"components\">Components\u003C/h3>\n\u003Cp>These are classes, without prefix, to be used as styling anchor points (and, of course, can include styling in and of themselves). Components will probably be equally used inside of Style/Component guides and in individual implementations. They are similar to blocks in BEM and modules in SMACSS and OOCSS.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.component\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"objects\">Objects\u003C/h3>\n\u003Cp>These are classes, prefixed with an underscore, to be used to style individual pieces that could be used to make up a component. Objects will mostly be used in Style/Component guides, with individual changes happening inside of implementations, probably using a Component as an anchor for a change. They are similar to elements in BEM and sub-modules in SMACSS.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">_object {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"nuances\">Nuances\u003C/h3>\n\u003Cp>These are classes, prefixed with a dash, to be used to alter the appearance of a component or object. They are similar to modifiers in BEM, themes/states in SMACSS, and skins in OOCSS.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.-nuance\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"grids-and-layout\">Grids and Layout\u003C/h3>\n\u003Cp>When building grids and layouts, I prefer to use semantic grid frameworks like \u003Ca href=\"https://github.com/Team-Sass/Singularity/wiki\">Singularity\u003C/a> as well as asymmetric grids. These do not lend themselves well to grid classes, nor would I really want them to. I find grid classes make maintaining your layouts hard. I haven’t quite figured out exactly where I would prefer to put them, but my initial feeling is that they are implementation specific and would be defined inside of an implementation. They would pivot off of components or objects, but not entirely sure yet.\u003C/p>\n\u003Cp>Here’s a CodePen of \u003Ca href=\"http://codepen.io/Snugug/pen/mfKvo\">how this would all work\u003C/a> as proposed right now.\u003C/p>\n\u003Cp>Anyway, with all of this, feedback more than welcome.\u003C/p>",{"headings":1183,"localImagePaths":1202,"remoteImagePaths":1203,"frontmatter":1204,"imagePaths":1206},[1184,1187,1190,1193,1196,1199],{"depth":80,"slug":1185,"text":1186},"current-thoughts","Current Thoughts",{"depth":904,"slug":1188,"text":1189},"bases","Bases",{"depth":904,"slug":1191,"text":1192},"components","Components",{"depth":904,"slug":1194,"text":1195},"objects","Objects",{"depth":904,"slug":1197,"text":1198},"nuances","Nuances",{"depth":904,"slug":1200,"text":1201},"grids-and-layout","Grids and Layout",[],[],{"title":1173,"published":1205,"summary":1176,"updated":1126},"2013-07-28",[],"debugging-sass-source-maps",{"id":1207,"data":1209,"body":1214,"filePath":1215,"digest":1216,"rendered":1217},{"title":1210,"published":1211,"updated":1212,"summary":1213},"Debugging Sass with Source Maps",["Date","2013-02-28T00:00:00.000Z"],["Date","2013-07-06T00:00:00.000Z"],"One of the super exciting features in Sass 3.3, currently in development, is the introduction of native Source Maps as a successor to Sass Debug Info. Working Source Map reading for Sass in Google Chrome Canary means this is a real debugging option you can start looking at today.",":::message{.warning}\nAfter some user confusion about the difference between Source Maps and Debug Info, this article has been updated to more clearly focus on Source Maps. This update incorporates the previous update in which Paul Irish pointed out that the UI for individual properties have been added to Canary's Source Map implementation.\n:::\n\nOne of the super exciting features in Sass 3.3, currently in development, is the introduction of native [Source Maps](http://www.html5rocks.com/en/tutorials/developertools/sourcemaps/) in Sass. Source Maps are a generic mapping format written in JSON that can be utilized by any processed file to create relations between pre-processed files and post-processed files, for instance between pre-compressed JavaScript and the expanded development files or, as in our case, between compiled CSS and the development Sass files. If you've ever used [FireSass](https://addons.mozilla.org/en-us/firefox/addon/firesass-for-firebug/) or Sass's `--debug-info` flag, you can think of Source Maps as their successor.\n\n## Before We Start\n\nGoogle Chrome [Canary](https://www.google.com/intl/en/chrome/browser/canary.html) currently has support for Sass Source Maps built in, so I will be referencing their implementation of debugging for the purposes of this post. There are other tools that are able to do what Chrome does, but Chrome provides a good good baseline for comparison. To enable Source Maps in Chrome, go to [chrome://flags](chrome://flags) inside of your Canary browser and enable `Enable Developer Tools experiments.`. You'll need to restart your browser afterwards. Once enabled, open up your Web Inspector, open up settings (the gear in the lower-right corner), go to `Experiments`, check `Support for Sass`, and restart your browser to have the changes take effect.\n\n## Sass Source Maps\n\nSource Maps change the Sass debugging game. Now, in order to test Sass Source Maps, your'e going to need the prerelease version of Sass 3.3 which you can install by running `gem install sass --pre`. You're going to need at least **Sass 3.3.0.alpha.101** for Source Maps to work. If you're compiling using Sass, you can compile your files with Source Maps by doing something like `sass --watch --sourcemap style.scss:style.css`; as of this writing, adding `sass_options = {:sourcemap => true}` into Compass's config.rb unfortunately [does not work](https://github.com/chriseppstein/compass/issues/1189), but it hopefully will soon. With Source Maps enabled, in addition to your compiled file, you get a file in the same directory called `file.css.map` which looks something like this:\n\n```javascript\n{\n\"version\": \"3\",\n\"mappings\": \"AAOA,IAAK;EACH,MAAM,EAAE,IAAI;EACZ,KAAK,EAAE,IAAI;ECRX,gBAAgB,EAAE,IAAI;EDUtB,OAAO,EAAE,IAAI\",\n\"sources\": [\"../sass/test.scss\",\"../sass/_mixin.scss\"],\n\"file\": \"test.css\"\n}\n```\n\nLook! A pretty JSON file! It's fairly human-readable except for the actual mappings which are encoded to make their size smaller. It also shows us all of the sources that make up that file, providing us a good way to see what actually is going into our files.\n\nIf you go to Sources in Canary, you'll be in for a wonderful surprise: each partial that is used to generate your final CSS file gets displayed! That means you can easily see your whole development partial structure!\n\nOn top of all of that, the Source Map not only maps selectors to their source, it also maps _individual properties_ to their source! Simply `ctrl+click` (Windows) or `cmd-click` (Mac) to go straight to the line in the file a property comes from! As promised, Sass Source Maps allow you to dive in to a property that comes from mixins, jumping straight to the line in the file inside the mixin it comes from, as well as dive in to a property that comes from extendables, jumping straight to the line in the file inside the extendable it comes from and even working with placeholder extendables. If there was one disappointment, it's that, while the Source Maps will take you to a property that's built using a function and it will show you the function call, if the function is supplied by a partial, that partial isn't included in the Source Map tree and there's still no easy way to jump to the actual function definition. That being said, I'm not sure how I would effectively go about implementing that, so I can't be too upset about that.\n\nAnyway, all in all, this is absolutely amazing, and I'm super excited to have this available to us in Sass. Huge thanks to Alexander Pavlov for the patch to put this into Chrome and I believe who wrote the Source Map patch for Sass to begin with.\n\n## Sass Debug Info\n\nIf you have previously used FireSass or or Sass's `--debug-info`, you were using an ad-hoc hack to determine the source of selectors, but `--debug-info` _is not_ a true Source Map. The new Source Map feature above is the first real implementation of Source Maps in Sass. If you are unable to use Sass 3.3's Source Map feature, you can still debug Sass currently with Debug Info.\n\nCurrently available in the stable version of Sass, as of this writing it's Sass 3.2.6, is the `--debug-info` flag. With this flag enabled, Sass will print out a non-standard media query that tools can read and determine the source file from. If you're compiling using Sass, you can compile your files with the debug info by doing something like `sass --watch --debug-info style.scss:style.css`; if you're compiling using Compass, you can add `sass_options = {:debug_info => true}` to the bottom of your `config.rb` file. With Debug Info on, above each selector in your compiled CSS file, a non-standard media query will be printed that looks something like this:\n\n```scss\n/* Compressed (what you'll see) */\n/* @media -sass-debug-info{filename{font-family:file\\:\\/\\/\\/Users\\/Richard\\/Prototypes\\/sourcemap\\/sass\\/test\\.scss}line{font-family:\\000034}} */\n\n/* Expanded */\n@media -sass-debug-info {\n  filename {\n    font-family: file\\:\\/\\/\\/Users\\/Richard\\/Prototypes\\/sourcemap\\/sass\\/test\\.scss;\n  }\n  line {\n    font-family: \\000034;\n  }\n}\n```\n\nDebug Info, instead of producing a Source Map, will produce a non-standard media query `-sass-debug-info` with two fake selectors; `filename` and `line`. The `filename` selector has the absolute path to the file, whereas the `line` selector has the line number the selector comes from (although this is a bit of misdirection as the line is actually 4, not 34). Debug Info isn't as powerful as Source Maps, being unable to dig into individual properties or pulling in all of the partials you're using. Google Chrome stable supports Debug Info, enabled the same way you enable Source Maps in Chrome Canary. When enabled, Sass's Debug Info will replace your normal properties with Debug Info properties just like with Source Maps, although in Sources, you will only see the primary Sass file, not any of the partials.","src/content/posts/debugging-sass-source-maps.md","814359601f26f1bd",{"html":1218,"metadata":1219},"\u003Cdiv class=\"warning message\" data-type=\"warning\">\u003Cp>After some user confusion about the difference between Source Maps and Debug Info, this article has been updated to more clearly focus on Source Maps. This update incorporates the previous update in which Paul Irish pointed out that the UI for individual properties have been added to Canary’s Source Map implementation.\u003C/p>\u003C/div>\n\u003Cp>One of the super exciting features in Sass 3.3, currently in development, is the introduction of native \u003Ca href=\"http://www.html5rocks.com/en/tutorials/developertools/sourcemaps/\">Source Maps\u003C/a> in Sass. Source Maps are a generic mapping format written in JSON that can be utilized by any processed file to create relations between pre-processed files and post-processed files, for instance between pre-compressed JavaScript and the expanded development files or, as in our case, between compiled CSS and the development Sass files. If you’ve ever used \u003Ca href=\"https://addons.mozilla.org/en-us/firefox/addon/firesass-for-firebug/\">FireSass\u003C/a> or Sass’s \u003Ccode>--debug-info\u003C/code> flag, you can think of Source Maps as their successor.\u003C/p>\n\u003Ch2 id=\"before-we-start\">Before We Start\u003C/h2>\n\u003Cp>Google Chrome \u003Ca href=\"https://www.google.com/intl/en/chrome/browser/canary.html\">Canary\u003C/a> currently has support for Sass Source Maps built in, so I will be referencing their implementation of debugging for the purposes of this post. There are other tools that are able to do what Chrome does, but Chrome provides a good good baseline for comparison. To enable Source Maps in Chrome, go to \u003Ca href=\"chrome://flags\">chrome://flags\u003C/a> inside of your Canary browser and enable \u003Ccode>Enable Developer Tools experiments.\u003C/code>. You’ll need to restart your browser afterwards. Once enabled, open up your Web Inspector, open up settings (the gear in the lower-right corner), go to \u003Ccode>Experiments\u003C/code>, check \u003Ccode>Support for Sass\u003C/code>, and restart your browser to have the changes take effect.\u003C/p>\n\u003Ch2 id=\"sass-source-maps\">Sass Source Maps\u003C/h2>\n\u003Cp>Source Maps change the Sass debugging game. Now, in order to test Sass Source Maps, your’e going to need the prerelease version of Sass 3.3 which you can install by running \u003Ccode>gem install sass --pre\u003C/code>. You’re going to need at least \u003Cstrong>Sass 3.3.0.alpha.101\u003C/strong> for Source Maps to work. If you’re compiling using Sass, you can compile your files with Source Maps by doing something like \u003Ccode>sass --watch --sourcemap style.scss:style.css\u003C/code>; as of this writing, adding \u003Ccode>sass_options = {:sourcemap => true}\u003C/code> into Compass’s config.rb unfortunately \u003Ca href=\"https://github.com/chriseppstein/compass/issues/1189\">does not work\u003C/a>, but it hopefully will soon. With Source Maps enabled, in addition to your compiled file, you get a file in the same directory called \u003Ccode>file.css.map\u003C/code> which looks something like this:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"javascript\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">{\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">\"version\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#E6DB74\">\"3\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">\"mappings\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#E6DB74\">\"AAOA,IAAK;EACH,MAAM,EAAE,IAAI;EACZ,KAAK,EAAE,IAAI;ECRX,gBAAgB,EAAE,IAAI;EDUtB,OAAO,EAAE,IAAI\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">\"sources\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: [\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"../sass/test.scss\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"../sass/_mixin.scss\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">],\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">\"file\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#E6DB74\">\"test.css\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Look! A pretty JSON file! It’s fairly human-readable except for the actual mappings which are encoded to make their size smaller. It also shows us all of the sources that make up that file, providing us a good way to see what actually is going into our files.\u003C/p>\n\u003Cp>If you go to Sources in Canary, you’ll be in for a wonderful surprise: each partial that is used to generate your final CSS file gets displayed! That means you can easily see your whole development partial structure!\u003C/p>\n\u003Cp>On top of all of that, the Source Map not only maps selectors to their source, it also maps \u003Cem>individual properties\u003C/em> to their source! Simply \u003Ccode>ctrl+click\u003C/code> (Windows) or \u003Ccode>cmd-click\u003C/code> (Mac) to go straight to the line in the file a property comes from! As promised, Sass Source Maps allow you to dive in to a property that comes from mixins, jumping straight to the line in the file inside the mixin it comes from, as well as dive in to a property that comes from extendables, jumping straight to the line in the file inside the extendable it comes from and even working with placeholder extendables. If there was one disappointment, it’s that, while the Source Maps will take you to a property that’s built using a function and it will show you the function call, if the function is supplied by a partial, that partial isn’t included in the Source Map tree and there’s still no easy way to jump to the actual function definition. That being said, I’m not sure how I would effectively go about implementing that, so I can’t be too upset about that.\u003C/p>\n\u003Cp>Anyway, all in all, this is absolutely amazing, and I’m super excited to have this available to us in Sass. Huge thanks to Alexander Pavlov for the patch to put this into Chrome and I believe who wrote the Source Map patch for Sass to begin with.\u003C/p>\n\u003Ch2 id=\"sass-debug-info\">Sass Debug Info\u003C/h2>\n\u003Cp>If you have previously used FireSass or or Sass’s \u003Ccode>--debug-info\u003C/code>, you were using an ad-hoc hack to determine the source of selectors, but \u003Ccode>--debug-info\u003C/code> \u003Cem>is not\u003C/em> a true Source Map. The new Source Map feature above is the first real implementation of Source Maps in Sass. If you are unable to use Sass 3.3’s Source Map feature, you can still debug Sass currently with Debug Info.\u003C/p>\n\u003Cp>Currently available in the stable version of Sass, as of this writing it’s Sass 3.2.6, is the \u003Ccode>--debug-info\u003C/code> flag. With this flag enabled, Sass will print out a non-standard media query that tools can read and determine the source file from. If you’re compiling using Sass, you can compile your files with the debug info by doing something like \u003Ccode>sass --watch --debug-info style.scss:style.css\u003C/code>; if you’re compiling using Compass, you can add \u003Ccode>sass_options = {:debug_info => true}\u003C/code> to the bottom of your \u003Ccode>config.rb\u003C/code> file. With Debug Info on, above each selector in your compiled CSS file, a non-standard media query will be printed that looks something like this:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">/* Compressed (what you'll see) */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">/* @media -sass-debug-info{filename{font-family:file\\:\\/\\/\\/Users\\/Richard\\/Prototypes\\/sourcemap\\/sass\\/test\\.scss}line{font-family:\\000034}} */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">/* Expanded */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> -sass-debug-info {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  filename {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    font-family\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: file\\:\\\u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">\\\u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">\\\u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">Users\\\u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">Richard\\\u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">Prototypes\\\u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">sourcemap\\\u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">sass\\\u003C/span>\u003Cspan style=\"color:#F92672\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">test\\.scss;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  line\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    font-family\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \\\u003C/span>\u003Cspan style=\"color:#AE81FF\">000034\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Debug Info, instead of producing a Source Map, will produce a non-standard media query \u003Ccode>-sass-debug-info\u003C/code> with two fake selectors; \u003Ccode>filename\u003C/code> and \u003Ccode>line\u003C/code>. The \u003Ccode>filename\u003C/code> selector has the absolute path to the file, whereas the \u003Ccode>line\u003C/code> selector has the line number the selector comes from (although this is a bit of misdirection as the line is actually 4, not 34). Debug Info isn’t as powerful as Source Maps, being unable to dig into individual properties or pulling in all of the partials you’re using. Google Chrome stable supports Debug Info, enabled the same way you enable Source Maps in Chrome Canary. When enabled, Sass’s Debug Info will replace your normal properties with Debug Info properties just like with Source Maps, although in Sources, you will only see the primary Sass file, not any of the partials.\u003C/p>",{"headings":1220,"localImagePaths":1230,"remoteImagePaths":1231,"frontmatter":1232,"imagePaths":1235},[1221,1224,1227],{"depth":80,"slug":1222,"text":1223},"before-we-start","Before We Start",{"depth":80,"slug":1225,"text":1226},"sass-source-maps","Sass Source Maps",{"depth":80,"slug":1228,"text":1229},"sass-debug-info","Sass Debug Info",[],[],{"title":1210,"published":1233,"summary":1213,"updated":1234},"2013-02-28","2013-07-06",[],"developing-on-chrome-os",{"id":1236,"data":1238,"body":1242,"filePath":1243,"digest":1244,"rendered":1245},{"title":1239,"published":1240,"summary":1241},"Setting up a Chrome OS Development Environment",["Date","2018-10-31T00:00:00.000Z"],"After joining Google, I was given a Google Pixelbook as my main computer. This is my journey to get it set up for web development",":::message{.warning}\n_Disclaimer: I now work for Google, and while this post is about me setting up my work Google Pixelbook, these are my personal thoughts and not Google's._\n:::\n\nSo, like the introduction says, I just joined Google! My first order of business, clearly, was getting my new Pixelbook set up to do some webdev on it. Now, being most comfortable developing on a Mac, I immediately reached for the Terminal which... wasn't there. I thought I was stuck, knowing that I'm most comfortable developing when I'm zooming around in `zsh`, but then a coworker helped me get [Crostini](https://www.reddit.com/r/Crostini/) set up. This is the key to being a happy web developer (or probably most any developer) on Chrome OS.\n\nCrostini, also known as Linux on Chrome OS, will actually let you run a Linux container (or maybe virtual machine? Not entirely sure ) on your Chromebook. This means that, currently (Chrome OS 70), once you've gotten it installed, you'll get a Debian container and a terminal ready to go! Poking around the subreddit above it _appears_ that you can install other containers, but Debian works well for me.\n\nWith the Debian install, you don't get an actual Linux desktop, like you would with say a Virtual Box VM. Instead, you get something much more interesting; after getting set up, the Linux environment for all intents and purposes _feels_ like a fully integrated part of the OS! There's a `Linux files` folder in the Files app that puts stuff directly in to the container, and the native Chrome can access the container's `localhost` (or `penguin.linux.test`, if you're feeling cool). With my Linux container set up, the next for me was setting up a development environment that felt familiar to me coming from a Mac. For me, that first step was replacing the terminal that comes with Crostini with a new one, because I wanted to full control over customizing the look, feel, and shortcuts of my terminal.\n\n## Terminal Setup\n\nAfter a bunch of playing around for a good terminal replacement, I stumbled upon a [Reddit thread](https://www.reddit.com/r/Crostini/comments/8rgq26/multi_tabs_in_terminal/e29vjqr/) that help me install [Tilix](https://gnunn1.github.io/tilix-web/). I was looking for a good [iTerm 2](https://www.iterm2.com/) replacement, and this comes really close! The key bits from that thread, to get Tilix running, are as follows:\n\n```bash\n$ echo 'deb http://ftp.debian.org/debian stretch-backports main' | sudo tee /etc/apt/sources.list.d/stretch-backports.list\n$ sudo apt update\n$ sudo apt -y install tilix\n$ sudo ln -s /etc/profile.d/vte-2.91.sh /etc/profile.d/vte.sh\n```\n\nThis will add Stretch Backports as an `apt` source, update the `apt` source, and install Tilix. The last line symlinks `vte.sh` so Tilix can use it. The final thing you need to do is source that in your `.bashrc` or `.zshrc` file.\n\n```bash\nif [ $TILIX_ID ] || [ $VTE_VERSION ]; then\n    source /etc/profile.d/vte.sh\nfi\n```\n\nWith that set up, Tilix became launchable from the Chrome OS launcher and pinnable!\n\nNext, I wanted to use `zsh` instead of `bash`. I love [Oh My Zsh](https://github.com/robbyrussell/oh-my-zsh), which is an open source `zsh` configuration management framework, so I went to work installing that. Installation is a fairly straight forward, simply run `sudo apt-get install zsh wget` and we had `zsh`! We also install `wget` here because it doesn't come with our Linux container, and then use that to follow the standard _Oh My Zsh_ install instructions. I also recommend using the [z](https://github.com/robbyrussell/oh-my-zsh/tree/master/plugins/z), [shrink-path](https://github.com/robbyrussell/oh-my-zsh/tree/master/plugins/shrink-path), and [zsh-syntax-highlighting](https://github.com/zsh-users/zsh-syntax-highlighting) `zsh` plugins; they're real productivity and quality-of-life enhancements for my terminal.\n\nFinally, it's time to edit settings for Tilix! Open Tilix, click the top-left icon, and hit Preferences. From there, either edit the Default profile, or create a new one, go to the _Command_ tab, check `Run a custom command instead of my shell`, and under the command, type `zsh`. This will make Tilix run `zsh`! Then, go ahead and customize both the terminal and `zsh` to your liking!\n\nWhile you're in Tilix preferences, you should play around with the shortcuts they provide. I like app-like shortcuts, like `CTRL+C`/`CTRL+V` for copy/paste, so go ahead and change those yo our heart's content\n\nOne last bit that may come in handy; if you're using a `zsh` theme that makes use of [Powerline fonts](https://github.com/powerline/fonts) (like I do), you'll need do a little bit extra to get them installed. After downloading the fonts I wanted, I followed another [Reddit thread](https://www.reddit.com/r/Crostini/comments/9ih3nv/installing_fonts/) to install the fonts I need. The steps are:\n\n1. Create a folder named `.fonts` in the home (`~`) directory\n2. Copy the font files to install into that folder\n3. Run `fc-cache -fv` to verbosely force the cache to rebuild.\n\nOnce done, go back in to your profile under Tilix preferences and use the newly installed fonts!\n\n## Web Development Environment\n\nWith the terminal squared away, it's now time to set up a web dev environment! The first thing on my list was installing a better text editor. It turns out that [Visual Studio Code](https://code.visualstudio.com/) not only is available for Debian, but it runs _beautifully_ on our new setup! Download the `.deb` file from their site, save it to the Linux files folder, and then from your terminal, in the folder you downloaded the `.deb` file, run `sudo dpkg -i visual-studio-install-filename.deb`, replacing the last bit with the actual filename. That's it! You've got full VS Code now!\n\nThe final bit I really need is a Node environment. Instead of installing Node directly, I prefer using [NVM](https://github.com/creationix/nvm) (Node Version Manager) coupled with [AVN](https://github.com/wbyoung/avn) (Automatic Version Switching for Node). The installation instructions that are provided for both work wonders. The only caution I have here that you need to install NVM _and_ a version of Node _before_ installing AVN because AVN requires a Node install. With both installed, the bottom of my `~/.zshrc` file looks like this:\n\n```bash\n# Node Version Manager and ANV\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\"  # This loads nvm\n[ -s \"$NVM_DIR/bash_completion\" ] && \\. \"$NVM_DIR/bash_completion\"  # This loads nvm bash_completion\n[[ -s \"$HOME/.avn/bin/avn.sh\" ]] && source \"$HOME/.avn/bin/avn.sh\" # load avn\nexport PATH=\"/usr/local/bin:$PATH\"\n```\n\nI also enable the `node`, `npm`, and `nvm` plugins for `zsh`.\n\n## Migrating from a Mac\n\nIf you're coming from a Mac, one of the biggest pain points I found was the keyboard and trackpad are, by default, set up to mimic Windows. This can be resolved in settings, though! From the App Launcher, open Settings, then navigate (from the hamburger menu) to **Device**. Under **Touchpad**, you can set scrolling to `Australian`, or natural scrolling in the Mac world, and under **Keyboard**, swap the `Ctrl` and `Alt` keys. If you wind up constantly hitting the Google Assistant button in between the keyboard's `Ctrl` and `Alt` keys like I do, unfortunately that can't be remapped as of this writing, so the only way to stop that is by disabling Google Assistant entirely. I think that if and when that can be remapped, I'll probably re-enable Assistant and assign it to the `Ctrl` key, and have the assistant key be the new `Alt` (so `Alt` key === `Ctrl`, Assistant key === `Alt`, `Ctrl` key === Assistant, as opposed to Assistant key being disabled now, and `Ctrl` key === `Alt` currently). Finally, under **Displays**, you can change the Internal Display size. I set mine so it looks like `1500 x 1000` which is closest to my previous Mac's `1440 x 900` display. Change this to your liking.\n\nThe last thing that may be missing are some familiar and useful CLI commands; specifically, the `open` command, and `pbcopy`/`pbpaste`. They aren't natively available in Debian, so we'll need to roll our own.\n\nTo tackle `open`, in `~/.zshrc`, add the following function:\n\n```bash\nopen() {\n  setsid nohup xdg-open $1 > /dev/null 2> /dev/null\n}\n```\n\nThis will open whatever file or folder name is passed in, in the default application, in a new, effectively detached session, emulating how OSX's `open` command works.\n\nFor `pbcopy` and `pbpaste` (copying to and pasting from the clipboard), I followed [an article](https://www.ostechnix.com/how-to-use-pbcopy-and-pbpaste-commands-on-linux/) that had me install `xclip` (`sudo apt-get install xclip`) and then add the following aliases to my `~/.zshrc` file:\n\n```bash\nalias pbcopy='xclip -selection clipboard'\nalias pbpaste='xclip -selection clipboard -o'\n```\n\nThere's also a Linux port of Homebrew called [Linuxbrew](http://linuxbrew.sh/) which looks interesting, but I haven't investigated it yet.\n\n## Final Thoughts\n\nI consider myself somewhat of a power Mac user so getting my new Pixelbook set up to my liking is a _must_ in order for me to feel comfortable using it. There are still some gaps; I'd like to be able to change all of the global keyboard shortcuts (specifically, missing `CMD+Tab` to move through applications and `CMD+~` to move through application windows, the equivelant here would be `Ctrl` instead of `CMD`), and while the Pixelbook has great mouse-centric window snapping, I'm really missing keyboard shortcuts for window sizing and placement, like with [Divvy](http://mizage.com/divvy/) or [Spectacle](https://www.spectacleapp.com/). I'm also missing multitouch gestures, which I use extensively and extensively customize with [BetterTouchTool](https://folivora.ai/).\n\nThere's also another issue I've run in to though; the death by a thousand papercuts of tools you're likely use to or dependent on that don't have great web-based or Linux, like the Adobe suite, Sketch, [1Password](https://1password.com/), and other Mac and/or Windows-centric desktop apps. Some of these have Android alternatives that can be installed through the Play store on Chrome OS, but for many, you'll just need to go without for now.\n\nOn the other hand, [Progressive Web Apps](https://developers.google.com/web/progressive-web-apps/) are treated as _fabulous_ first-class citizens on Chrome OS, with you being able to install them and have them be treated, for all intents and purposes, as any other app. [Twitter's PWA](https://mobile.twitter.com), for example, works great installed. Because of how well these work, and the progress with which [WebAssembly](https://webassembly.org/) is coming along, I can see a future in which some of these desktop apps are able to be ported to the web and installed as a PWA, but I think that ma still be a bit far off for now.","src/content/posts/developing-on-chrome-os.md","192741e09d80d8dd",{"html":1246,"metadata":1247},"\u003Cdiv class=\"warning message\" data-type=\"warning\">\u003Cp>\u003Cem>Disclaimer: I now work for Google, and while this post is about me setting up my work Google Pixelbook, these are my personal thoughts and not Google’s.\u003C/em>\u003C/p>\u003C/div>\n\u003Cp>So, like the introduction says, I just joined Google! My first order of business, clearly, was getting my new Pixelbook set up to do some webdev on it. Now, being most comfortable developing on a Mac, I immediately reached for the Terminal which… wasn’t there. I thought I was stuck, knowing that I’m most comfortable developing when I’m zooming around in \u003Ccode>zsh\u003C/code>, but then a coworker helped me get \u003Ca href=\"https://www.reddit.com/r/Crostini/\">Crostini\u003C/a> set up. This is the key to being a happy web developer (or probably most any developer) on Chrome OS.\u003C/p>\n\u003Cp>Crostini, also known as Linux on Chrome OS, will actually let you run a Linux container (or maybe virtual machine? Not entirely sure ) on your Chromebook. This means that, currently (Chrome OS 70), once you’ve gotten it installed, you’ll get a Debian container and a terminal ready to go! Poking around the subreddit above it \u003Cem>appears\u003C/em> that you can install other containers, but Debian works well for me.\u003C/p>\n\u003Cp>With the Debian install, you don’t get an actual Linux desktop, like you would with say a Virtual Box VM. Instead, you get something much more interesting; after getting set up, the Linux environment for all intents and purposes \u003Cem>feels\u003C/em> like a fully integrated part of the OS! There’s a \u003Ccode>Linux files\u003C/code> folder in the Files app that puts stuff directly in to the container, and the native Chrome can access the container’s \u003Ccode>localhost\u003C/code> (or \u003Ccode>penguin.linux.test\u003C/code>, if you’re feeling cool). With my Linux container set up, the next for me was setting up a development environment that felt familiar to me coming from a Mac. For me, that first step was replacing the terminal that comes with Crostini with a new one, because I wanted to full control over customizing the look, feel, and shortcuts of my terminal.\u003C/p>\n\u003Ch2 id=\"terminal-setup\">Terminal Setup\u003C/h2>\n\u003Cp>After a bunch of playing around for a good terminal replacement, I stumbled upon a \u003Ca href=\"https://www.reddit.com/r/Crostini/comments/8rgq26/multi_tabs_in_terminal/e29vjqr/\">Reddit thread\u003C/a> that help me install \u003Ca href=\"https://gnunn1.github.io/tilix-web/\">Tilix\u003C/a>. I was looking for a good \u003Ca href=\"https://www.iterm2.com/\">iTerm 2\u003C/a> replacement, and this comes really close! The key bits from that thread, to get Tilix running, are as follows:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">$\u003C/span>\u003Cspan style=\"color:#E6DB74\"> echo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'deb http://ftp.debian.org/debian stretch-backports main'\u003C/span>\u003Cspan style=\"color:#F92672\"> |\u003C/span>\u003Cspan style=\"color:#A6E22E\"> sudo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> tee\u003C/span>\u003Cspan style=\"color:#E6DB74\"> /etc/apt/sources.list.d/stretch-backports.list\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">$\u003C/span>\u003Cspan style=\"color:#E6DB74\"> sudo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> apt\u003C/span>\u003Cspan style=\"color:#E6DB74\"> update\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">$\u003C/span>\u003Cspan style=\"color:#E6DB74\"> sudo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> apt\u003C/span>\u003Cspan style=\"color:#AE81FF\"> -y\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> tilix\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">$\u003C/span>\u003Cspan style=\"color:#E6DB74\"> sudo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> ln\u003C/span>\u003Cspan style=\"color:#AE81FF\"> -s\u003C/span>\u003Cspan style=\"color:#E6DB74\"> /etc/profile.d/vte-2.91.sh\u003C/span>\u003Cspan style=\"color:#E6DB74\"> /etc/profile.d/vte.sh\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This will add Stretch Backports as an \u003Ccode>apt\u003C/code> source, update the \u003Ccode>apt\u003C/code> source, and install Tilix. The last line symlinks \u003Ccode>vte.sh\u003C/code> so Tilix can use it. The final thing you need to do is source that in your \u003Ccode>.bashrc\u003C/code> or \u003Ccode>.zshrc\u003C/code> file.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> [ $TILIX_ID ] \u003C/span>\u003Cspan style=\"color:#F92672\">||\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> [ $VTE_VERSION ]; \u003C/span>\u003Cspan style=\"color:#F92672\">then\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF\">    source\u003C/span>\u003Cspan style=\"color:#E6DB74\"> /etc/profile.d/vte.sh\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">fi\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>With that set up, Tilix became launchable from the Chrome OS launcher and pinnable!\u003C/p>\n\u003Cp>Next, I wanted to use \u003Ccode>zsh\u003C/code> instead of \u003Ccode>bash\u003C/code>. I love \u003Ca href=\"https://github.com/robbyrussell/oh-my-zsh\">Oh My Zsh\u003C/a>, which is an open source \u003Ccode>zsh\u003C/code> configuration management framework, so I went to work installing that. Installation is a fairly straight forward, simply run \u003Ccode>sudo apt-get install zsh wget\u003C/code> and we had \u003Ccode>zsh\u003C/code>! We also install \u003Ccode>wget\u003C/code> here because it doesn’t come with our Linux container, and then use that to follow the standard \u003Cem>Oh My Zsh\u003C/em> install instructions. I also recommend using the \u003Ca href=\"https://github.com/robbyrussell/oh-my-zsh/tree/master/plugins/z\">z\u003C/a>, \u003Ca href=\"https://github.com/robbyrussell/oh-my-zsh/tree/master/plugins/shrink-path\">shrink-path\u003C/a>, and \u003Ca href=\"https://github.com/zsh-users/zsh-syntax-highlighting\">zsh-syntax-highlighting\u003C/a> \u003Ccode>zsh\u003C/code> plugins; they’re real productivity and quality-of-life enhancements for my terminal.\u003C/p>\n\u003Cp>Finally, it’s time to edit settings for Tilix! Open Tilix, click the top-left icon, and hit Preferences. From there, either edit the Default profile, or create a new one, go to the \u003Cem>Command\u003C/em> tab, check \u003Ccode>Run a custom command instead of my shell\u003C/code>, and under the command, type \u003Ccode>zsh\u003C/code>. This will make Tilix run \u003Ccode>zsh\u003C/code>! Then, go ahead and customize both the terminal and \u003Ccode>zsh\u003C/code> to your liking!\u003C/p>\n\u003Cp>While you’re in Tilix preferences, you should play around with the shortcuts they provide. I like app-like shortcuts, like \u003Ccode>CTRL+C\u003C/code>/\u003Ccode>CTRL+V\u003C/code> for copy/paste, so go ahead and change those yo our heart’s content\u003C/p>\n\u003Cp>One last bit that may come in handy; if you’re using a \u003Ccode>zsh\u003C/code> theme that makes use of \u003Ca href=\"https://github.com/powerline/fonts\">Powerline fonts\u003C/a> (like I do), you’ll need do a little bit extra to get them installed. After downloading the fonts I wanted, I followed another \u003Ca href=\"https://www.reddit.com/r/Crostini/comments/9ih3nv/installing_fonts/\">Reddit thread\u003C/a> to install the fonts I need. The steps are:\u003C/p>\n\u003Col>\n\u003Cli>Create a folder named \u003Ccode>.fonts\u003C/code> in the home (\u003Ccode>~\u003C/code>) directory\u003C/li>\n\u003Cli>Copy the font files to install into that folder\u003C/li>\n\u003Cli>Run \u003Ccode>fc-cache -fv\u003C/code> to verbosely force the cache to rebuild.\u003C/li>\n\u003C/ol>\n\u003Cp>Once done, go back in to your profile under Tilix preferences and use the newly installed fonts!\u003C/p>\n\u003Ch2 id=\"web-development-environment\">Web Development Environment\u003C/h2>\n\u003Cp>With the terminal squared away, it’s now time to set up a web dev environment! The first thing on my list was installing a better text editor. It turns out that \u003Ca href=\"https://code.visualstudio.com/\">Visual Studio Code\u003C/a> not only is available for Debian, but it runs \u003Cem>beautifully\u003C/em> on our new setup! Download the \u003Ccode>.deb\u003C/code> file from their site, save it to the Linux files folder, and then from your terminal, in the folder you downloaded the \u003Ccode>.deb\u003C/code> file, run \u003Ccode>sudo dpkg -i visual-studio-install-filename.deb\u003C/code>, replacing the last bit with the actual filename. That’s it! You’ve got full VS Code now!\u003C/p>\n\u003Cp>The final bit I really need is a Node environment. Instead of installing Node directly, I prefer using \u003Ca href=\"https://github.com/creationix/nvm\">NVM\u003C/a> (Node Version Manager) coupled with \u003Ca href=\"https://github.com/wbyoung/avn\">AVN\u003C/a> (Automatic Version Switching for Node). The installation instructions that are provided for both work wonders. The only caution I have here that you need to install NVM \u003Cem>and\u003C/em> a version of Node \u003Cem>before\u003C/em> installing AVN because AVN requires a Node install. With both installed, the bottom of my \u003Ccode>~/.zshrc\u003C/code> file looks like this:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\"># Node Version Manager and ANV\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">export\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> NVM_DIR\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$HOME\u003C/span>\u003Cspan style=\"color:#E6DB74\">/.nvm\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">[ \u003C/span>\u003Cspan style=\"color:#F92672\">-s\u003C/span>\u003Cspan style=\"color:#E6DB74\"> \"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$NVM_DIR\u003C/span>\u003Cspan style=\"color:#E6DB74\">/nvm.sh\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> ] &#x26;&#x26; \u003C/span>\u003Cspan style=\"color:#A6E22E\">\\.\u003C/span>\u003Cspan style=\"color:#E6DB74\"> \"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$NVM_DIR\u003C/span>\u003Cspan style=\"color:#E6DB74\">/nvm.sh\"\u003C/span>\u003Cspan style=\"color:#88846F\">  # This loads nvm\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">[ \u003C/span>\u003Cspan style=\"color:#F92672\">-s\u003C/span>\u003Cspan style=\"color:#E6DB74\"> \"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$NVM_DIR\u003C/span>\u003Cspan style=\"color:#E6DB74\">/bash_completion\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> ] &#x26;&#x26; \u003C/span>\u003Cspan style=\"color:#A6E22E\">\\.\u003C/span>\u003Cspan style=\"color:#E6DB74\"> \"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$NVM_DIR\u003C/span>\u003Cspan style=\"color:#E6DB74\">/bash_completion\"\u003C/span>\u003Cspan style=\"color:#88846F\">  # This loads nvm bash_completion\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">[[ \u003C/span>\u003Cspan style=\"color:#F92672\">-s\u003C/span>\u003Cspan style=\"color:#E6DB74\"> \"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$HOME\u003C/span>\u003Cspan style=\"color:#E6DB74\">/.avn/bin/avn.sh\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> ]] &#x26;&#x26; \u003C/span>\u003Cspan style=\"color:#66D9EF\">source\u003C/span>\u003Cspan style=\"color:#E6DB74\"> \"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$HOME\u003C/span>\u003Cspan style=\"color:#E6DB74\">/.avn/bin/avn.sh\"\u003C/span>\u003Cspan style=\"color:#88846F\"> # load avn\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">export\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> PATH\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"/usr/local/bin:\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$PATH\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>I also enable the \u003Ccode>node\u003C/code>, \u003Ccode>npm\u003C/code>, and \u003Ccode>nvm\u003C/code> plugins for \u003Ccode>zsh\u003C/code>.\u003C/p>\n\u003Ch2 id=\"migrating-from-a-mac\">Migrating from a Mac\u003C/h2>\n\u003Cp>If you’re coming from a Mac, one of the biggest pain points I found was the keyboard and trackpad are, by default, set up to mimic Windows. This can be resolved in settings, though! From the App Launcher, open Settings, then navigate (from the hamburger menu) to \u003Cstrong>Device\u003C/strong>. Under \u003Cstrong>Touchpad\u003C/strong>, you can set scrolling to \u003Ccode>Australian\u003C/code>, or natural scrolling in the Mac world, and under \u003Cstrong>Keyboard\u003C/strong>, swap the \u003Ccode>Ctrl\u003C/code> and \u003Ccode>Alt\u003C/code> keys. If you wind up constantly hitting the Google Assistant button in between the keyboard’s \u003Ccode>Ctrl\u003C/code> and \u003Ccode>Alt\u003C/code> keys like I do, unfortunately that can’t be remapped as of this writing, so the only way to stop that is by disabling Google Assistant entirely. I think that if and when that can be remapped, I’ll probably re-enable Assistant and assign it to the \u003Ccode>Ctrl\u003C/code> key, and have the assistant key be the new \u003Ccode>Alt\u003C/code> (so \u003Ccode>Alt\u003C/code> key === \u003Ccode>Ctrl\u003C/code>, Assistant key === \u003Ccode>Alt\u003C/code>, \u003Ccode>Ctrl\u003C/code> key === Assistant, as opposed to Assistant key being disabled now, and \u003Ccode>Ctrl\u003C/code> key === \u003Ccode>Alt\u003C/code> currently). Finally, under \u003Cstrong>Displays\u003C/strong>, you can change the Internal Display size. I set mine so it looks like \u003Ccode>1500 x 1000\u003C/code> which is closest to my previous Mac’s \u003Ccode>1440 x 900\u003C/code> display. Change this to your liking.\u003C/p>\n\u003Cp>The last thing that may be missing are some familiar and useful CLI commands; specifically, the \u003Ccode>open\u003C/code> command, and \u003Ccode>pbcopy\u003C/code>/\u003Ccode>pbpaste\u003C/code>. They aren’t natively available in Debian, so we’ll need to roll our own.\u003C/p>\n\u003Cp>To tackle \u003Ccode>open\u003C/code>, in \u003Ccode>~/.zshrc\u003C/code>, add the following function:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">open\u003C/span>\u003Cspan style=\"color:#F8F8F2\">() {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  setsid\u003C/span>\u003Cspan style=\"color:#E6DB74\"> nohup\u003C/span>\u003Cspan style=\"color:#E6DB74\"> xdg-open\u003C/span>\u003Cspan style=\"color:#FD971F;font-style:italic\"> $1\u003C/span>\u003Cspan style=\"color:#F92672\"> >\u003C/span>\u003Cspan style=\"color:#E6DB74\"> /dev/null\u003C/span>\u003Cspan style=\"color:#F92672\"> 2>\u003C/span>\u003Cspan style=\"color:#E6DB74\"> /dev/null\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This will open whatever file or folder name is passed in, in the default application, in a new, effectively detached session, emulating how OSX’s \u003Ccode>open\u003C/code> command works.\u003C/p>\n\u003Cp>For \u003Ccode>pbcopy\u003C/code> and \u003Ccode>pbpaste\u003C/code> (copying to and pasting from the clipboard), I followed \u003Ca href=\"https://www.ostechnix.com/how-to-use-pbcopy-and-pbpaste-commands-on-linux/\">an article\u003C/a> that had me install \u003Ccode>xclip\u003C/code> (\u003Ccode>sudo apt-get install xclip\u003C/code>) and then add the following aliases to my \u003Ccode>~/.zshrc\u003C/code> file:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">alias\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> pbcopy\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">'xclip -selection clipboard'\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">alias\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> pbpaste\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">'xclip -selection clipboard -o'\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>There’s also a Linux port of Homebrew called \u003Ca href=\"http://linuxbrew.sh/\">Linuxbrew\u003C/a> which looks interesting, but I haven’t investigated it yet.\u003C/p>\n\u003Ch2 id=\"final-thoughts\">Final Thoughts\u003C/h2>\n\u003Cp>I consider myself somewhat of a power Mac user so getting my new Pixelbook set up to my liking is a \u003Cem>must\u003C/em> in order for me to feel comfortable using it. There are still some gaps; I’d like to be able to change all of the global keyboard shortcuts (specifically, missing \u003Ccode>CMD+Tab\u003C/code> to move through applications and \u003Ccode>CMD+~\u003C/code> to move through application windows, the equivelant here would be \u003Ccode>Ctrl\u003C/code> instead of \u003Ccode>CMD\u003C/code>), and while the Pixelbook has great mouse-centric window snapping, I’m really missing keyboard shortcuts for window sizing and placement, like with \u003Ca href=\"http://mizage.com/divvy/\">Divvy\u003C/a> or \u003Ca href=\"https://www.spectacleapp.com/\">Spectacle\u003C/a>. I’m also missing multitouch gestures, which I use extensively and extensively customize with \u003Ca href=\"https://folivora.ai/\">BetterTouchTool\u003C/a>.\u003C/p>\n\u003Cp>There’s also another issue I’ve run in to though; the death by a thousand papercuts of tools you’re likely use to or dependent on that don’t have great web-based or Linux, like the Adobe suite, Sketch, \u003Ca href=\"https://1password.com/\">1Password\u003C/a>, and other Mac and/or Windows-centric desktop apps. Some of these have Android alternatives that can be installed through the Play store on Chrome OS, but for many, you’ll just need to go without for now.\u003C/p>\n\u003Cp>On the other hand, \u003Ca href=\"https://developers.google.com/web/progressive-web-apps/\">Progressive Web Apps\u003C/a> are treated as \u003Cem>fabulous\u003C/em> first-class citizens on Chrome OS, with you being able to install them and have them be treated, for all intents and purposes, as any other app. \u003Ca href=\"https://mobile.twitter.com\">Twitter’s PWA\u003C/a>, for example, works great installed. Because of how well these work, and the progress with which \u003Ca href=\"https://webassembly.org/\">WebAssembly\u003C/a> is coming along, I can see a future in which some of these desktop apps are able to be ported to the web and installed as a PWA, but I think that ma still be a bit far off for now.\u003C/p>",{"headings":1248,"localImagePaths":1261,"remoteImagePaths":1262,"frontmatter":1263,"imagePaths":1265},[1249,1252,1255,1258],{"depth":80,"slug":1250,"text":1251},"terminal-setup","Terminal Setup",{"depth":80,"slug":1253,"text":1254},"web-development-environment","Web Development Environment",{"depth":80,"slug":1256,"text":1257},"migrating-from-a-mac","Migrating from a Mac",{"depth":80,"slug":1259,"text":1260},"final-thoughts","Final Thoughts",[],[],{"title":1239,"published":1264,"summary":1241},"2018-10-31",[],"do-you-believe-magic",{"id":1266,"data":1268,"body":1272,"filePath":1273,"digest":1274,"rendered":1275},{"title":1269,"published":1270,"summary":1271},"Do You Believe in Magic?",["Date","2013-05-01T00:00:00.000Z"],"Today I'm excited to announce Magic, a first-of-its-kind module for Drupal designed to integrate advanced theme development settings into any theme.","Today I'm excited to announce [Magic](http://drupal.org/project/magic), a first-of-its-kind module for Drupal designed to integrate advanced theme development settings into _any_ theme. Born from a collaboration between Ian Carrico ([ChinggizKhan](http://drupal.org/user/1300542)), Sebastian Siemssen ([fubhy](http://drupal.org/user/761344)), and myself, Magic aims to standardize much of the repeated features between various base themes, especially with Sebastian's [Omega 4](http://drupal.org/project/omega) and Ian and my [Aurora](http://drupal.org/project/aurora) base themes, and make those features easy to implement for any theme.\n\nTaking inspiration from Aurora, Omega, Zen, and Omega Tools, Magic seamlessly integrates into the theme settings for each theme and provides a multitude of enhancements that are available on a per-theme basis. These enhancements include excluding CSS and JavaScript files individually or in bulk, enhanced CSS aggregation, backporting of Drupal 8 JavaScript handling to Drupal 7, moving of JavaScript files from the head to the footer, and development options including rebuilding of theme registry on page reload, indicators for viewport width in both `px` and `em` as well as HTML classes most commonly added by JavaScript tools like Modernizr, and a quick and easy way to export all of your theme settings to your theme's .info file for deployment.\n\nWe are looking to add more tricks to Magic's bag, so if there's any great feature you'd really like to be able to use, let us know and we'll look into it. For now though, I'm super excited about magic and I can't wait for everyone to start playing around with it. Magic 1.1 is out now, and the first release of Aurora to take full advantage of Magic is Aurora 3.x, so either download that and start to play, or use it with _any_ theme you've got now to add a little magic to it!\n\nGood luck have fun!\n\n---\n\nA big huge awesome **YOU ROCK** goes out to Ian for really spearheading the build of Magic. He's the man. Everyone say thank you. He's [@iamcarrico](https://twitter.com/iamcarrico) on Twitter. Seriously though, thank him for being awesome and rocking this out. This wouldn't exist without him putting in the time. Also go thank Sebastian, he's [@thefubhy](https://twitter.com/thefubhy) on Twitter. Lots of the code in Magic came from his work to beat Drupal into submission in Omega 4.","src/content/posts/do-you-believe-magic.md","8d24fac522e52c57",{"html":1276,"metadata":1277},"\u003Cp>Today I’m excited to announce \u003Ca href=\"http://drupal.org/project/magic\">Magic\u003C/a>, a first-of-its-kind module for Drupal designed to integrate advanced theme development settings into \u003Cem>any\u003C/em> theme. Born from a collaboration between Ian Carrico (\u003Ca href=\"http://drupal.org/user/1300542\">ChinggizKhan\u003C/a>), Sebastian Siemssen (\u003Ca href=\"http://drupal.org/user/761344\">fubhy\u003C/a>), and myself, Magic aims to standardize much of the repeated features between various base themes, especially with Sebastian’s \u003Ca href=\"http://drupal.org/project/omega\">Omega 4\u003C/a> and Ian and my \u003Ca href=\"http://drupal.org/project/aurora\">Aurora\u003C/a> base themes, and make those features easy to implement for any theme.\u003C/p>\n\u003Cp>Taking inspiration from Aurora, Omega, Zen, and Omega Tools, Magic seamlessly integrates into the theme settings for each theme and provides a multitude of enhancements that are available on a per-theme basis. These enhancements include excluding CSS and JavaScript files individually or in bulk, enhanced CSS aggregation, backporting of Drupal 8 JavaScript handling to Drupal 7, moving of JavaScript files from the head to the footer, and development options including rebuilding of theme registry on page reload, indicators for viewport width in both \u003Ccode>px\u003C/code> and \u003Ccode>em\u003C/code> as well as HTML classes most commonly added by JavaScript tools like Modernizr, and a quick and easy way to export all of your theme settings to your theme’s .info file for deployment.\u003C/p>\n\u003Cp>We are looking to add more tricks to Magic’s bag, so if there’s any great feature you’d really like to be able to use, let us know and we’ll look into it. For now though, I’m super excited about magic and I can’t wait for everyone to start playing around with it. Magic 1.1 is out now, and the first release of Aurora to take full advantage of Magic is Aurora 3.x, so either download that and start to play, or use it with \u003Cem>any\u003C/em> theme you’ve got now to add a little magic to it!\u003C/p>\n\u003Cp>Good luck have fun!\u003C/p>\n\u003Chr>\n\u003Cp>A big huge awesome \u003Cstrong>YOU ROCK\u003C/strong> goes out to Ian for really spearheading the build of Magic. He’s the man. Everyone say thank you. He’s \u003Ca href=\"https://twitter.com/iamcarrico\">@iamcarrico\u003C/a> on Twitter. Seriously though, thank him for being awesome and rocking this out. This wouldn’t exist without him putting in the time. Also go thank Sebastian, he’s \u003Ca href=\"https://twitter.com/thefubhy\">@thefubhy\u003C/a> on Twitter. Lots of the code in Magic came from his work to beat Drupal into submission in Omega 4.\u003C/p>",{"headings":1278,"localImagePaths":1279,"remoteImagePaths":1280,"frontmatter":1281,"imagePaths":1283},[],[],[],{"title":1269,"published":1282,"summary":1271},"2013-05-01",[],"drupalcon-munich-presentation",{"id":1284,"data":1286,"body":1290,"filePath":1291,"digest":1292,"rendered":1293},{"title":1287,"published":1288,"summary":1289},"DrupalCon Munich Presentation",["Date","2012-08-20T00:00:00.000Z"],"The slides and video from my DrupalCon Munich presentation along with some links.","Thanks to everyone who came out to see my session. The slides from my talk are available [here](http://snugug.com/documents/drupalcon-munich-presentation/session.pdf). Please remember to [rate my session](http://munich2012.drupal.org/node/add/session-evaluation/249?destination=node/249) and be sure to come to my [Birds of a Feather sessions](http://munich2012.drupal.org/program/schedule/bofs/2012-08-22) tomorrow. I'll be holding three of them in the same room right in a row, a sort of mini Sass+Compass training going from installation through the topics presented in my talk and anything anyone else wants to talk about. I will also be around during the sprints and am happy to hold \"Sass Office Hours\" of sorts to help people out.\n\n[Here is the video of my talk](https://www.youtube.com/watch?v=bYEKF5qFMfg)\n\nIf you'd like to get a hold of me to chat while at the conference, ping me on Twitter [@Snugug](http://twitter.com/snugug).\n\nAlso, I've got Sassy Drupal stickers! Find me to get yourself one!\n\n## Direct links to the Compass extensions talked about:\n\n- [Susy](http://susy.oddbird.net)\n- [Singularity](http://singularity.gs/)\n- [Breakpoint](http://github.com/canarymason/breakpoint)\n- [Respond-to](http://github.com/snugug/respond-to)\n- [Toolkit](http://github.com/snugug/toolkit)","src/content/posts/drupalcon-munich-presentation.md","298da3ae4cb6e503",{"html":1294,"metadata":1295},"\u003Cp>Thanks to everyone who came out to see my session. The slides from my talk are available \u003Ca href=\"http://snugug.com/documents/drupalcon-munich-presentation/session.pdf\">here\u003C/a>. Please remember to \u003Ca href=\"http://munich2012.drupal.org/node/add/session-evaluation/249?destination=node/249\">rate my session\u003C/a> and be sure to come to my \u003Ca href=\"http://munich2012.drupal.org/program/schedule/bofs/2012-08-22\">Birds of a Feather sessions\u003C/a> tomorrow. I’ll be holding three of them in the same room right in a row, a sort of mini Sass+Compass training going from installation through the topics presented in my talk and anything anyone else wants to talk about. I will also be around during the sprints and am happy to hold “Sass Office Hours” of sorts to help people out.\u003C/p>\n\u003Cp>\u003Ca href=\"https://www.youtube.com/watch?v=bYEKF5qFMfg\">Here is the video of my talk\u003C/a>\u003C/p>\n\u003Cp>If you’d like to get a hold of me to chat while at the conference, ping me on Twitter \u003Ca href=\"http://twitter.com/snugug\">@Snugug\u003C/a>.\u003C/p>\n\u003Cp>Also, I’ve got Sassy Drupal stickers! Find me to get yourself one!\u003C/p>\n\u003Ch2 id=\"direct-links-to-the-compass-extensions-talked-about\">Direct links to the Compass extensions talked about:\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Ca href=\"http://susy.oddbird.net\">Susy\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://singularity.gs/\">Singularity\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://github.com/canarymason/breakpoint\">Breakpoint\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://github.com/snugug/respond-to\">Respond-to\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"http://github.com/snugug/toolkit\">Toolkit\u003C/a>\u003C/li>\n\u003C/ul>",{"headings":1296,"localImagePaths":1300,"remoteImagePaths":1301,"frontmatter":1302,"imagePaths":1304},[1297],{"depth":80,"slug":1298,"text":1299},"direct-links-to-the-compass-extensions-talked-about","Direct links to the Compass extensions talked about:",[],[],{"title":1287,"published":1303,"summary":1289},"2012-08-20",[],"dude-wheres-my-modal",{"id":1305,"data":1307,"body":1311,"filePath":1312,"digest":1313,"rendered":1314},{"title":1308,"published":1309,"summary":1310},"Dude, Where's My Modal?",["Date","2015-05-03T00:00:00.000Z"],"Modals. Popups. Overlays. Dialog Boxes. No matter what you call them; ugh. I can't even. If I were being gracious, I'd say that nine times out of ten, modals are the lazy way out of solving a hard (or sometimes not so hard) design or development problem. We should stop doing that.","Modals. Popups. Overlays. Dialog Boxes. No matter what you call them; ugh. I can't even. If I were being gracious, [I'd say](https://twitter.com/Snugug/status/592716919880450050) that nine times out of ten, modals are the lazy way out of solving a hard (or sometimes not so hard) design or development problem. We should stop doing that.\n\nModals have lots of technical issues with them; they usually break the universally standard browser back/forward functionality, they're amazingly hard to make accessible and usable to keyboard users, they tend to be pretty heavy to implement, there are innumerable ways to close one and it's never implemented consistently across different modals and usually has no hinting as to what ways will work making it a guess and check system each time, having a fixed size and position that covers the full screen makes it frustratingly difficult to make responsive with any modicum of sanity or decent user experience. But, ya know, with a robust enough (and tiny enough) JavaScript library, we can probably get over most of these issues (good luck with that, though). The real problem with modals is the human brain. Modals are an anti-pattern at the level that we are able to process information.\n\nHave you ever entered a room and totally forgotten why you had gone in there in the first place? Of course you have; we all have. There's a name for that: **The Doorway Effect**\n\n![Dude, Where's My Car?](/images/dude-wheres-my-modal/dude.gif)\n\nThe Doorway Effect, more formally known as the [location-updating effect](http://www.freakonomics.com/media/Radvansky%20Krawietz%20%26%20Tamplin%202011%20%28QJEP%29%20%281%29.pdf) describes: \"the finding that when people pass through a doorway to move from one location to another, they forget more information than if they do not make such a shift.… Essentially, a shift at an event boundary introduces a need to update one's understanding of the ongoing events, and this updating process is effortful.\" In their work [_Walking through doorways causes forgetting: Further explorations_](http://www.freakonomics.com/media/Radvansky%20Krawietz%20%26%20Tamplin%202011%20%28QJEP%29%20%281%29.pdf), Gabriel A. Radvansky, Sabine A. Krawietz, and Andrea K. Tamplin of the Department of Psychology, University of Notre Dame explored whether the Doorway Effect was dependent on how the environments are experienced. Their conclusion is that no, be it physical objects in the real world or virtual objects on a small screen, the Doorway Effect was not dependent on how the way the environments are experienced.\n\nNow why is the Doorway Effect so bad? Well, results showed that people make more errors when they had moved and that their response times slowed down to probes when their conditions were shifted as compared to when they were not shifted. Their conclusion? Needing to mentally update the model of what is happening winds up compromising memory.\n\nIn the paper, the researchers discuss an _event horizon model of event cognition and memory_. The relevant parts to the Doorway Effect are: \"(a) Events can be segmented, and different event models are created with people processing one at a time\", \"(b) information in the current event that is being actively processed is foregrounded\", and \"(d) there is retrieval interference for competitive retrieval\".\n\nThe first, event segmentation, occurs when an event boundary is encountered, such as a person moving from one room to another, and a new event model may be created and stored in memory, making the event model for the prior event decline in availability.\n\nThe second, the event model that is currently active in working memory is foregrounded, makes it easier to retrieve information from that event. The current event model occupies working memory, and available processing capacity is directed to it.\n\nThe third, retrieval interference of competitive retrieval, makes a person choose one memory trace to verify that information. When people move an object from one location to another, it is now associated with two location - the location it started in and the location it ended up in. Thus, there may be two event models that contain the target information, which compete with one another at retrieval, producing interference and making retrieval slower and more error prone.\n\nNow, how does this relate to the dreaded modal? Well, let's take the most common use case for a modal: contextual actions/task/information/etc… Modals by design take over the whole screen, stripping context from our contextual needs (which kinda defeats the purpose in and of itself), but more damning, thanks to the Doorway Effect, will cause more errors and slower response times from our users than not doing so. Modals are a harsh enough switch that they wind up creating a new event model for our users, creating an event boundary, and triggering the Doorway Effect. When we close the modal? Another event switch, a new event model for our users, a new event boundary.\n\nHow about the other uses for modals besides contextual information? One modal for our login, one for our lightbox, one for this, that? All may be wrapped in the same modal wrapper, but all contain different inner layouts, different inner content models, different contexts. The research in _Walking through doorways_ shows that increasing the number of new areas a user enters substantially increases the number of errors users have, and each new creative use for a modal is a new area for our users.\n\nHere comes the grumpy, kneejerk reaction to all of this: \"Fine, then what should we use instead?\" Ya know what sucks? There isn't a single drop-in replacement for modals. They've become the _deus ex machina_ of user experience design. In order to replace such a seemingly omni-functional tool, we need to be creative. Being creative is hard, for both designers and developers, and we can be tempted not to do the hard work needed to solve our users' problems in the best possible way for a large number of reasons, including some that can be out of our control. But we should try.\n\nThe first, and most obvious thing to do, is determine if clarity of context can be improved by bringing users to another page. I find this solution is best for administrative tasks as users are entering a new mental model and the cost of event switching can be justified by this new context switch while also providing ample context for users to orient themselves. I also really like this solution for user login, especially if an entire site isn't secured (for security reasons, never let users send their passwords over non-encrypted connections). When using a new page, ensure that the URLs (and breadcrumbs, messaging, etc…, if you have them) provide users with some contextual reminders of the action they are going to perform to help ensure they don't loose their train of through. Consider this: in places where an entirely new context is loaded into a modal, that's probably a good place to create a new physical page for a user to navigate to.\n\nThe second, and one I've become a really big fan of, is what I'm going to call the contextual slide open (that's a terrible name, someone suggest a better one). I first saw this pattern used in the iOS view of [Google Image search](https://images.google.com/?gws_rd=ssl), and has since expanded to all versions of Google Image search. The basic idea is that, instead of a modal, make the relevant content appear in-line, on the same page, contextually connected directly to the triggering element in both UI and animation, while keeping that trigger in view, with deep links to animate-in the contextual area on load, that can be closed through an obvious close indicator, by toggling the selected item, or by simply ignoring and moving on with the page, all without covering anything else on the page. While this doesn't resolve all of the issues we encounter with the Doorway Effect, it helps to mitigate them all in a fairly elegant way as it isn't an entirely new area, allowing for faster recovery from the event boundary by only requiring a tweak in the current event model instead of needing to build an entirely new one and removing the possibility that information is stored across two event models.\n\n\u003Cvideo src=\"https://snugug.github.io/videos/google-images-modal-replacement.mp4\" controls loop>\n  \u003Cp>Download a video of the \u003Ca href=\"https://snugug.github.io/videos/google-images-modal-replacement.mp4\">Google Image Search modal replacement\u003C/a>\u003C/p>\n\u003C/video>\n\nWith this information in had, and a couple of new patterns to consider and grow from, we should grab our bootstraps and pull ourselves out of the modal murk. As designers and developers, we are creatives, and being creative is hard. Our answer, like always, should be to do the hard work to find the best solution for our users, not simply use the same 'ol stuff without sitting back to consider if it's actually doing what we think it is. Modals are the prototypical example of a pattern that gets used and abused without though. We should stop doing that.","src/content/posts/dude-wheres-my-modal.md","ba10a68be5a68811",{"html":1315,"metadata":1316},"\u003Cp>Modals. Popups. Overlays. Dialog Boxes. No matter what you call them; ugh. I can’t even. If I were being gracious, \u003Ca href=\"https://twitter.com/Snugug/status/592716919880450050\">I’d say\u003C/a> that nine times out of ten, modals are the lazy way out of solving a hard (or sometimes not so hard) design or development problem. We should stop doing that.\u003C/p>\n\u003Cp>Modals have lots of technical issues with them; they usually break the universally standard browser back/forward functionality, they’re amazingly hard to make accessible and usable to keyboard users, they tend to be pretty heavy to implement, there are innumerable ways to close one and it’s never implemented consistently across different modals and usually has no hinting as to what ways will work making it a guess and check system each time, having a fixed size and position that covers the full screen makes it frustratingly difficult to make responsive with any modicum of sanity or decent user experience. But, ya know, with a robust enough (and tiny enough) JavaScript library, we can probably get over most of these issues (good luck with that, though). The real problem with modals is the human brain. Modals are an anti-pattern at the level that we are able to process information.\u003C/p>\n\u003Cp>Have you ever entered a room and totally forgotten why you had gone in there in the first place? Of course you have; we all have. There’s a name for that: \u003Cstrong>The Doorway Effect\u003C/strong>\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/dude-wheres-my-modal/dude.gif\" alt=\"Dude, Where&#x27;s My Car?\">\u003C/p>\n\u003Cp>The Doorway Effect, more formally known as the \u003Ca href=\"http://www.freakonomics.com/media/Radvansky%20Krawietz%20%26%20Tamplin%202011%20%28QJEP%29%20%281%29.pdf\">location-updating effect\u003C/a> describes: “the finding that when people pass through a doorway to move from one location to another, they forget more information than if they do not make such a shift.… Essentially, a shift at an event boundary introduces a need to update one’s understanding of the ongoing events, and this updating process is effortful.” In their work \u003Ca href=\"http://www.freakonomics.com/media/Radvansky%20Krawietz%20%26%20Tamplin%202011%20%28QJEP%29%20%281%29.pdf\">\u003Cem>Walking through doorways causes forgetting: Further explorations\u003C/em>\u003C/a>, Gabriel A. Radvansky, Sabine A. Krawietz, and Andrea K. Tamplin of the Department of Psychology, University of Notre Dame explored whether the Doorway Effect was dependent on how the environments are experienced. Their conclusion is that no, be it physical objects in the real world or virtual objects on a small screen, the Doorway Effect was not dependent on how the way the environments are experienced.\u003C/p>\n\u003Cp>Now why is the Doorway Effect so bad? Well, results showed that people make more errors when they had moved and that their response times slowed down to probes when their conditions were shifted as compared to when they were not shifted. Their conclusion? Needing to mentally update the model of what is happening winds up compromising memory.\u003C/p>\n\u003Cp>In the paper, the researchers discuss an \u003Cem>event horizon model of event cognition and memory\u003C/em>. The relevant parts to the Doorway Effect are: “(a) Events can be segmented, and different event models are created with people processing one at a time”, “(b) information in the current event that is being actively processed is foregrounded”, and “(d) there is retrieval interference for competitive retrieval”.\u003C/p>\n\u003Cp>The first, event segmentation, occurs when an event boundary is encountered, such as a person moving from one room to another, and a new event model may be created and stored in memory, making the event model for the prior event decline in availability.\u003C/p>\n\u003Cp>The second, the event model that is currently active in working memory is foregrounded, makes it easier to retrieve information from that event. The current event model occupies working memory, and available processing capacity is directed to it.\u003C/p>\n\u003Cp>The third, retrieval interference of competitive retrieval, makes a person choose one memory trace to verify that information. When people move an object from one location to another, it is now associated with two location - the location it started in and the location it ended up in. Thus, there may be two event models that contain the target information, which compete with one another at retrieval, producing interference and making retrieval slower and more error prone.\u003C/p>\n\u003Cp>Now, how does this relate to the dreaded modal? Well, let’s take the most common use case for a modal: contextual actions/task/information/etc… Modals by design take over the whole screen, stripping context from our contextual needs (which kinda defeats the purpose in and of itself), but more damning, thanks to the Doorway Effect, will cause more errors and slower response times from our users than not doing so. Modals are a harsh enough switch that they wind up creating a new event model for our users, creating an event boundary, and triggering the Doorway Effect. When we close the modal? Another event switch, a new event model for our users, a new event boundary.\u003C/p>\n\u003Cp>How about the other uses for modals besides contextual information? One modal for our login, one for our lightbox, one for this, that? All may be wrapped in the same modal wrapper, but all contain different inner layouts, different inner content models, different contexts. The research in \u003Cem>Walking through doorways\u003C/em> shows that increasing the number of new areas a user enters substantially increases the number of errors users have, and each new creative use for a modal is a new area for our users.\u003C/p>\n\u003Cp>Here comes the grumpy, kneejerk reaction to all of this: “Fine, then what should we use instead?” Ya know what sucks? There isn’t a single drop-in replacement for modals. They’ve become the \u003Cem>deus ex machina\u003C/em> of user experience design. In order to replace such a seemingly omni-functional tool, we need to be creative. Being creative is hard, for both designers and developers, and we can be tempted not to do the hard work needed to solve our users’ problems in the best possible way for a large number of reasons, including some that can be out of our control. But we should try.\u003C/p>\n\u003Cp>The first, and most obvious thing to do, is determine if clarity of context can be improved by bringing users to another page. I find this solution is best for administrative tasks as users are entering a new mental model and the cost of event switching can be justified by this new context switch while also providing ample context for users to orient themselves. I also really like this solution for user login, especially if an entire site isn’t secured (for security reasons, never let users send their passwords over non-encrypted connections). When using a new page, ensure that the URLs (and breadcrumbs, messaging, etc…, if you have them) provide users with some contextual reminders of the action they are going to perform to help ensure they don’t loose their train of through. Consider this: in places where an entirely new context is loaded into a modal, that’s probably a good place to create a new physical page for a user to navigate to.\u003C/p>\n\u003Cp>The second, and one I’ve become a really big fan of, is what I’m going to call the contextual slide open (that’s a terrible name, someone suggest a better one). I first saw this pattern used in the iOS view of \u003Ca href=\"https://images.google.com/?gws_rd=ssl\">Google Image search\u003C/a>, and has since expanded to all versions of Google Image search. The basic idea is that, instead of a modal, make the relevant content appear in-line, on the same page, contextually connected directly to the triggering element in both UI and animation, while keeping that trigger in view, with deep links to animate-in the contextual area on load, that can be closed through an obvious close indicator, by toggling the selected item, or by simply ignoring and moving on with the page, all without covering anything else on the page. While this doesn’t resolve all of the issues we encounter with the Doorway Effect, it helps to mitigate them all in a fairly elegant way as it isn’t an entirely new area, allowing for faster recovery from the event boundary by only requiring a tweak in the current event model instead of needing to build an entirely new one and removing the possibility that information is stored across two event models.\u003C/p>\n\u003Cvideo src=\"https://snugug.github.io/videos/google-images-modal-replacement.mp4\" controls loop>\n  \u003Cp>Download a video of the \u003Ca href=\"https://snugug.github.io/videos/google-images-modal-replacement.mp4\">Google Image Search modal replacement\u003C/a>\u003C/p>\n\u003C/video>\n\u003Cp>With this information in had, and a couple of new patterns to consider and grow from, we should grab our bootstraps and pull ourselves out of the modal murk. As designers and developers, we are creatives, and being creative is hard. Our answer, like always, should be to do the hard work to find the best solution for our users, not simply use the same ‘ol stuff without sitting back to consider if it’s actually doing what we think it is. Modals are the prototypical example of a pattern that gets used and abused without though. We should stop doing that.\u003C/p>",{"headings":1317,"localImagePaths":1318,"remoteImagePaths":1319,"frontmatter":1320,"imagePaths":1322},[],[],[],{"title":1308,"published":1321,"summary":1310},"2015-05-03",[],"element-queries",{"id":1323,"data":1325,"body":1329,"filePath":1330,"digest":1331,"rendered":1332},{"title":1326,"published":1327,"summary":1328}," Element Queries",["Date","2013-11-11T00:00:00.000Z"],"When building responsive sites, especially style and component guide driven responsive sites, being able to query an item's width instead of the viewport is invaluable for re-usability. While we don't have them natively, we can emulate them with JavaScript.","When building responsive sites, especially style and component guide driven responsive sites, eventually the idea of \"why can't we just query our element instead of the viewport\" comes up. Sometimes the question is formed as \"working around the lack of element queries\", sometimes as \"media queries are a hack\", but no matter how it's phrased, the question always makes the assumption that getting native element queries is a foregone certainty and seem to miss the fundamental issue with element queries: they can't, really, be implemented natively.\n\nTab Atkins has a [great writeup on the issues of element queries](http://www.xanthir.com/b4PR0). There are circularity issues in both styling declaration (setting `width: 400px` at a `min-width: 450px` for instance) and in needing to get properties of elements based on the content placed inside of it (think `inline` elements, just about any `height` query). Add on top of this the need for your page to be rendered by the browser in order for the proper sizes to be calculated and then, potentially, rerendered again and, potentially, rerendered again, ad nauseam. In fact, the only real solution that Tab and Boris Zbarsky, a hacker for Mozilla, could come up with was, essentially, an `iframe`-like element whose properties (such as `width` and `height`) are treated in the DOM like normal elements (and thus can't be effected by element queries) with elements inside being able to query the width of that element. But that gets really ugly, is likewise slow, and they really only like the solution if it can be detected from the markup. Overall, not particularly good.\n\nThat all being said, as I've been working on [Style Prototypes](https://github.com/team-sass/generator-style-prototype), I really wanted element queries for the component guide in order to create truly reusable component guides. Understanding the inherent issues with element queries, I decided I wanted to write a little JavaScript library to try and provide some form of limited element queries like functionality, and so I built [eq.js](https://github.com/snugug/eq.js)\n\n## eq.js\n\n**eq.js** is a tiny little stand-alone JavaScript library (2.26KB minified, 1002B gzipped) that provides element query-like functionality for your projects. Unlike other JavaScript libraries that look to provide similar functionality, **eq.js** doesn't require jQuery or Sizzle to work, making its weight the only added weight to the page, and is designed to be blazing fast, utilizing techniques to reduce layout thrashing and increase perceived render speed such as grouping reads and writes together and firing the reads and writes through `requestAnimationFrame`. The [demo site](http://eqjs.io/) contains the performance benchmark page that was used to test performance, using more than 2,200 nodes, each requiring a query and applying a new set of styling. This benchmark is able to query all of the nodes and apply the correct attribute in ~35ms.\n\nCreated with a component guide in mind, it reduces many of the common pitfalls of element queries by reducing what you can query and when it gets queried down to a single item and provides a single interface for working with that query. **eq.js** will only query `min-width` as presented in a single data attribute, will only query it on `unload` and `onresize`, and allows you to access the queried `min-width` through a single attribute. It also provides an interface to allow users to fire a query for any selected nodes, allowing you to trigger queries on an as-needed basis. Usage is fairly easy, simply add a `data-eq-pts` attribute with `key: value` pairs of desired keywords and `min-width` values you'd like to use, each separated by a comma `,`.\n\n```html\n\u003Cdiv class=\"component\" data-eq-pts=\"small: 400, medium: 600, large: 900\">\n  \u003Ch1>Hello World\u003C/h1>\n\u003C/div>\n```\n\nWhen the correct size is available, a `data-eq-state` attribute will be added to the component with the `key` for the given `min-width`. This makes styling easy:\n\n```scss\n.container {\n  border: 2px solid red;\n  background-color: rgba(red, 0.25);\n\n  &[data-eq-state='small'] {\n    border-color: green;\n    background-color: rgba(green 0.25);\n  }\n\n  &[data-eq-state='medium'] {\n    border-color: orange;\n    background-color: rgba(orange, 0.25);\n  }\n\n  &[data-eq-state='large'] {\n    border-color: blue;\n    background-color: rgba(blue, 0.25);\n  }\n}\n```\n\nInstalling and using **eq.js** is fairly easy. You can either [download a release](https://github.com/Snugug/eq.js/releases) or install it through [Bower](http://bower.io/)\n\n```bash\nbower install eq.js --save\n```\n\nWhen adding **eq.js** to your site, make sure you load it in the `\u003Chead>` so that it's ready and available to for when `onload` is available as it directly affects styling on the page.\n\nHope you enjoy!","src/content/posts/element-queries.md","2d688849522c6ae2",{"html":1333,"metadata":1334},"\u003Cp>When building responsive sites, especially style and component guide driven responsive sites, eventually the idea of “why can’t we just query our element instead of the viewport” comes up. Sometimes the question is formed as “working around the lack of element queries”, sometimes as “media queries are a hack”, but no matter how it’s phrased, the question always makes the assumption that getting native element queries is a foregone certainty and seem to miss the fundamental issue with element queries: they can’t, really, be implemented natively.\u003C/p>\n\u003Cp>Tab Atkins has a \u003Ca href=\"http://www.xanthir.com/b4PR0\">great writeup on the issues of element queries\u003C/a>. There are circularity issues in both styling declaration (setting \u003Ccode>width: 400px\u003C/code> at a \u003Ccode>min-width: 450px\u003C/code> for instance) and in needing to get properties of elements based on the content placed inside of it (think \u003Ccode>inline\u003C/code> elements, just about any \u003Ccode>height\u003C/code> query). Add on top of this the need for your page to be rendered by the browser in order for the proper sizes to be calculated and then, potentially, rerendered again and, potentially, rerendered again, ad nauseam. In fact, the only real solution that Tab and Boris Zbarsky, a hacker for Mozilla, could come up with was, essentially, an \u003Ccode>iframe\u003C/code>-like element whose properties (such as \u003Ccode>width\u003C/code> and \u003Ccode>height\u003C/code>) are treated in the DOM like normal elements (and thus can’t be effected by element queries) with elements inside being able to query the width of that element. But that gets really ugly, is likewise slow, and they really only like the solution if it can be detected from the markup. Overall, not particularly good.\u003C/p>\n\u003Cp>That all being said, as I’ve been working on \u003Ca href=\"https://github.com/team-sass/generator-style-prototype\">Style Prototypes\u003C/a>, I really wanted element queries for the component guide in order to create truly reusable component guides. Understanding the inherent issues with element queries, I decided I wanted to write a little JavaScript library to try and provide some form of limited element queries like functionality, and so I built \u003Ca href=\"https://github.com/snugug/eq.js\">eq.js\u003C/a>\u003C/p>\n\u003Ch2 id=\"eqjs\">eq.js\u003C/h2>\n\u003Cp>\u003Cstrong>eq.js\u003C/strong> is a tiny little stand-alone JavaScript library (2.26KB minified, 1002B gzipped) that provides element query-like functionality for your projects. Unlike other JavaScript libraries that look to provide similar functionality, \u003Cstrong>eq.js\u003C/strong> doesn’t require jQuery or Sizzle to work, making its weight the only added weight to the page, and is designed to be blazing fast, utilizing techniques to reduce layout thrashing and increase perceived render speed such as grouping reads and writes together and firing the reads and writes through \u003Ccode>requestAnimationFrame\u003C/code>. The \u003Ca href=\"http://eqjs.io/\">demo site\u003C/a> contains the performance benchmark page that was used to test performance, using more than 2,200 nodes, each requiring a query and applying a new set of styling. This benchmark is able to query all of the nodes and apply the correct attribute in ~35ms.\u003C/p>\n\u003Cp>Created with a component guide in mind, it reduces many of the common pitfalls of element queries by reducing what you can query and when it gets queried down to a single item and provides a single interface for working with that query. \u003Cstrong>eq.js\u003C/strong> will only query \u003Ccode>min-width\u003C/code> as presented in a single data attribute, will only query it on \u003Ccode>unload\u003C/code> and \u003Ccode>onresize\u003C/code>, and allows you to access the queried \u003Ccode>min-width\u003C/code> through a single attribute. It also provides an interface to allow users to fire a query for any selected nodes, allowing you to trigger queries on an as-needed basis. Usage is fairly easy, simply add a \u003Ccode>data-eq-pts\u003C/code> attribute with \u003Ccode>key: value\u003C/code> pairs of desired keywords and \u003Ccode>min-width\u003C/code> values you’d like to use, each separated by a comma \u003Ccode>,\u003C/code>.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"html\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#A6E22E\"> class\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"component\"\u003C/span>\u003Cspan style=\"color:#A6E22E\"> data-eq-pts\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"small: 400, medium: 600, large: 900\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">h1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>Hello World&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">h1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>When the correct size is available, a \u003Ccode>data-eq-state\u003C/code> attribute will be added to the component with the \u003Ccode>key\u003C/code> for the given \u003Ccode>min-width\u003C/code>. This makes styling easy:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.container\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  border\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">2\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#66D9EF\"> solid\u003C/span>\u003Cspan style=\"color:#66D9EF\"> red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background-color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">rgba\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#AE81FF\">0.25\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\">[\u003C/span>\u003Cspan style=\"color:#A6E22E\">data-eq-state\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">small\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">] {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    border-color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background-color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">rgba\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 0.25\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\">[\u003C/span>\u003Cspan style=\"color:#A6E22E\">data-eq-state\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">medium\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">] {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    border-color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">orange\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background-color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">rgba\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#66D9EF\">orange\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#AE81FF\">0.25\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\">[\u003C/span>\u003Cspan style=\"color:#A6E22E\">data-eq-state\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">large\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">] {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    border-color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">blue\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background-color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">rgba\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#66D9EF\">blue\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#AE81FF\">0.25\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Installing and using \u003Cstrong>eq.js\u003C/strong> is fairly easy. You can either \u003Ca href=\"https://github.com/Snugug/eq.js/releases\">download a release\u003C/a> or install it through \u003Ca href=\"http://bower.io/\">Bower\u003C/a>\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">bower\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> eq.js\u003C/span>\u003Cspan style=\"color:#AE81FF\"> --save\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>When adding \u003Cstrong>eq.js\u003C/strong> to your site, make sure you load it in the \u003Ccode>&#x3C;head>\u003C/code> so that it’s ready and available to for when \u003Ccode>onload\u003C/code> is available as it directly affects styling on the page.\u003C/p>\n\u003Cp>Hope you enjoy!\u003C/p>",{"headings":1335,"localImagePaths":1339,"remoteImagePaths":1340,"frontmatter":1341,"imagePaths":1343},[1336],{"depth":80,"slug":1337,"text":1338},"eqjs","eq.js",[],[],{"title":1326,"published":1342,"summary":1328},"2013-11-11",[],"eleventy-plus-vite",{"id":1344,"data":1346,"body":1350,"filePath":1351,"digest":1352,"rendered":1353},{"title":1347,"published":1348,"summary":1349},"Eleventy + Vite",["Date","2021-05-13T00:00:00.000Z"],"A pattern I've started using combining Eleventy and Vite.","I really like [Eleventy](https://www.11ty.dev/) as a static site generator; it does all of the things I want from an SSG and it does it well. Well, except asset handling, like compiling, bundling, and managing my CSS and JavaScript. I think part of that is because setting up compilers and bundlers just is kinda an absolute drag, even if you know what you're doing. Except, that is, with [Vite](https://vitejs.dev/). Vite may just be the single best front-end development tool I've used in literal years. It's fast, it's got bells and whistles built-in, it's smart and un-opinionated enough that there's almost no overhead to get what you likely want, and it's super extensible. Combining the two felt obvious.\n\nEleventy and Vite both take slightly different approaches to compiling; Eleventy, everything's compiled up-front, whereas Vite things are compiled on-the-fly. Critically, because of this, Vite expects everything to be served from one folder, by default the top-level folder, but Eleventy expects things to be compiled to a folder for serving. While I\"m sure someone could get super creative with a combination of Vite and or Eleventy plugins to make the workflow I'm about to show cleaner, this setup is fast, efficient, and will have you rolling with both of them quickly.\n\n## Configure Vite\n\nFirst thing first, after installing Eleventy and Vite is to set up your Vite config. I'm going to assume that all of the working code is going to go into the `src` directory, so `src/js` for JavaScript, `src/css` for CSS, etc… and that the compiled output is going to go into the `public` directory. Switch these folders up as you need. To make this work from the Vite side, this is all you need in your `vite.config.js` file:\n\n```js\nconst { defineConfig } = require('vite');\n\nmodule.exports = defineConfig({\n  root: 'src',\n  clearScreen: false, // This is to show Eleventy output in the console along with Vite output\n  build: {\n    outDir: '../public', // The output directory is relative to the project root, so we need to put it back one folder to work\n  },\n});\n```\n\nThat's it! It sets the root directory Vite works from to the `src` folder, it sets the build directory to a sibling of the `src` folder called `public`, and it configures the command line interface so that you can see Eleventy and Vite output at the same time.\n\n## Configure Eleventy\n\nNext up is configuring Eleventy. Here, the only essential configuration is to change the output directory of Eleventy to Vite's root directory; this ensures the HTML is available for Vite to serve. This will make that directory _a little messy_ as all compiled HTML will get put in there, but for a quick and effective solution, I'm OK with it. To do so, make sure the following is set in your `.eleventy.js` file:\n\n```js\nmodule.exports = function (eleventy) {\n  return {\n    dir: {\n      output: 'src',\n    },\n  };\n};\n```\n\nAny other Eleventy config you want, you can put in there, too. Last thing you need to do to button this up is to add `src/**/*.html` to any ignore files you have (like `.gitignore`) so the in-development Eleventy compiled HTML is not included.\n\n## Add NPM Scripts\n\nTwo more steps! Almost done! This step is optional, but I highly recommend it: setting up NPM scripts to make working with all of this easier. My recommendation is to install the following dev dependencies:\n\n```bash\n$ npm i -D npm-run-all del-cli delete-empty\n```\n\nThese three packages, will, in order, let you run NPM scripts sequentially or in parallel from other npm scripts, let you delete items, and let you delete empty folders. These three combine to make a few really handy scripts possible:\n\n```json\n{\n  \"scripts\": {\n    \"prestart\": \"run-s clean\",\n    \"start\": \"run-p *:dev\",\n    \"prebuild\": \"run-s clean\",\n    \"build\": \"NODE_ENV=production run-s eleventy:build vite:build\",\n    \"clean\": \"run-s clean:files clean:empty\",\n    \"clean:files\": \"del 'src/**/*.html' public\",\n    \"clean:empty\": \"delete-empty src\",\n    \"eleventy:dev\": \"eleventy --watch\",\n    \"eleventy:build\": \"eleventy\",\n    \"vite:dev\": \"vite\",\n    \"vite:build\": \"vite build\"\n  }\n}\n```\n\nThese combine to give you, really, two scripts you're likely to run: `npm start` and `npm run build`. They do the following:\n\n`npm start`\n~ Before start is run, it deletes all of the HTML files from the `src` directory and removes the `public` directory, then deletes empty folders in the `src` directory that may be left over fom removing the HTML files. Once done, it runs all of the NPM scripts ending in `:dev`, so `eleventy:dev` and `vite:dev`, in parallel, which starts Eleventy in watch mode and Vite in dev mode.\n\n`npm run build`\n~ This is run with `NODE_ENV=production`, or \"in production mode\", which is a common signal that production optimizations should happen. Before build is run, it cleans up the files just like start did, then runs Eleventy's build first, then Vite's build second; this is to ensure that the HTML gets generated before Vite tries to do its thing with it.\n\n## Multi-Page Apps, Static Assets, and Vite\n\nVite, in development mode, work with multi-page apps just fine! Unfortunately, when it comes to build time, it only works on `src/index.html` by default. This is straightforward to remedy, though. First install [Fast Glob](https://www.npmjs.com/package/fast-glob) as a dev dependency (`npm i -D fast-glob`) and add the following to your `vite.config.js` file:\n\n```js\nconst glob = require('fast-glob');\nconst path = require('path');\n\n// Find all HTML files and build an object of names and paths to work from\nconst files = glob\n  .sync(path.resolve(__dirname, 'src') + '/**/*.html')\n  .reduce((acc, cur) => {\n    let name = cur\n      .replace(path.join(__dirname) + '/src/', '')\n      .replace('/index.html', '');\n    // If name is blank, make up a name for it, like 'home'\n    if (name === '') {\n      name = 'home';\n    }\n\n    acc[name] = cur;\n    return acc;\n  }, {});\n\nmodule.exports = defineConfig({\n  // ... Other config stuff\n  build: {\n    // ... Other build config stuff\n    rollupOptions: {\n      input: files,\n    },\n  },\n});\n```\n\nWhile a little complicated, what this does is find all of the HTML files in the `src` directory, figure out a name for the file by removing `/index.html`, and then building an array of names and HTML pages to use as input for Vite's Rollup configuration. This assumes that all pages that get assets have a `/index.html` file; if not, update the glob or the replacement accordingly. This is also going to generate a JavaScript file for each page, but because of how Vite handles imports, you should still get shared chunks between all of them. This is kind of the ugliest bit of this setup, and I'm sure it can be improved, but it's pretty good for a quick solve.\n\nAs for assets, like a `manifest.json`, `robots.txt`, or images, Vite expects those to be in a `public` folder in your root, so in this case, `src/public`. Usually not a big deal, but if you find those assets aren't getting checked in, make sure you're ignore files are ignoring `/public` for the roo public folder, not `public` which will ignore folders named public _anywhere_, including the one is `src`.\n\n## What's Next\n\nFor me, this is a very happy little setup. I'm sure there's more tweaking that can be done to make everything a bit more smooth and a bit easier to deal with, but this was the most minimal setup I could get to that consistently worked and, more importantly, gave me the awesome dev experience of the combined power of Vite and Eleventy. If you've got thoughts on this setup or this post, drop me a line on Twitter.\n\nEnjoy y'all!","src/content/posts/eleventy-plus-vite.md","22d23fe69dd8db58",{"html":1354,"metadata":1355},"\u003Cp>I really like \u003Ca href=\"https://www.11ty.dev/\">Eleventy\u003C/a> as a static site generator; it does all of the things I want from an SSG and it does it well. Well, except asset handling, like compiling, bundling, and managing my CSS and JavaScript. I think part of that is because setting up compilers and bundlers just is kinda an absolute drag, even if you know what you’re doing. Except, that is, with \u003Ca href=\"https://vitejs.dev/\">Vite\u003C/a>. Vite may just be the single best front-end development tool I’ve used in literal years. It’s fast, it’s got bells and whistles built-in, it’s smart and un-opinionated enough that there’s almost no overhead to get what you likely want, and it’s super extensible. Combining the two felt obvious.\u003C/p>\n\u003Cp>Eleventy and Vite both take slightly different approaches to compiling; Eleventy, everything’s compiled up-front, whereas Vite things are compiled on-the-fly. Critically, because of this, Vite expects everything to be served from one folder, by default the top-level folder, but Eleventy expects things to be compiled to a folder for serving. While I”m sure someone could get super creative with a combination of Vite and or Eleventy plugins to make the workflow I’m about to show cleaner, this setup is fast, efficient, and will have you rolling with both of them quickly.\u003C/p>\n\u003Ch2 id=\"configure-vite\">Configure Vite\u003C/h2>\n\u003Cp>First thing first, after installing Eleventy and Vite is to set up your Vite config. I’m going to assume that all of the working code is going to go into the \u003Ccode>src\u003C/code> directory, so \u003Ccode>src/js\u003C/code> for JavaScript, \u003Ccode>src/css\u003C/code> for CSS, etc… and that the compiled output is going to go into the \u003Ccode>public\u003C/code> directory. Switch these folders up as you need. To make this work from the Vite side, this is all you need in your \u003Ccode>vite.config.js\u003C/code> file:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"js\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> { defineConfig } \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#A6E22E\"> require\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'vite'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">module\u003C/span>\u003Cspan style=\"color:#F8F8F2\">.\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">exports\u003C/span>\u003Cspan style=\"color:#F92672\"> =\u003C/span>\u003Cspan style=\"color:#A6E22E\"> defineConfig\u003C/span>\u003Cspan style=\"color:#F8F8F2\">({\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  root: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'src'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  clearScreen: \u003C/span>\u003Cspan style=\"color:#AE81FF\">false\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#88846F\">// This is to show Eleventy output in the console along with Vite output\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  build: {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    outDir: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'../public'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#88846F\">// The output directory is relative to the project root, so we need to put it back one folder to work\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  },\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">});\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>That’s it! It sets the root directory Vite works from to the \u003Ccode>src\u003C/code> folder, it sets the build directory to a sibling of the \u003Ccode>src\u003C/code> folder called \u003Ccode>public\u003C/code>, and it configures the command line interface so that you can see Eleventy and Vite output at the same time.\u003C/p>\n\u003Ch2 id=\"configure-eleventy\">Configure Eleventy\u003C/h2>\n\u003Cp>Next up is configuring Eleventy. Here, the only essential configuration is to change the output directory of Eleventy to Vite’s root directory; this ensures the HTML is available for Vite to serve. This will make that directory \u003Cem>a little messy\u003C/em> as all compiled HTML will get put in there, but for a quick and effective solution, I’m OK with it. To do so, make sure the following is set in your \u003Ccode>.eleventy.js\u003C/code> file:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"js\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">module\u003C/span>\u003Cspan style=\"color:#F8F8F2\">.\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">exports\u003C/span>\u003Cspan style=\"color:#F92672\"> =\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\"> function\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#FD971F;font-style:italic\">eleventy\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  return\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    dir: {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      output: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'src'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    },\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  };\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">};\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Any other Eleventy config you want, you can put in there, too. Last thing you need to do to button this up is to add \u003Ccode>src/**/*.html\u003C/code> to any ignore files you have (like \u003Ccode>.gitignore\u003C/code>) so the in-development Eleventy compiled HTML is not included.\u003C/p>\n\u003Ch2 id=\"add-npm-scripts\">Add NPM Scripts\u003C/h2>\n\u003Cp>Two more steps! Almost done! This step is optional, but I highly recommend it: setting up NPM scripts to make working with all of this easier. My recommendation is to install the following dev dependencies:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">$\u003C/span>\u003Cspan style=\"color:#E6DB74\"> npm\u003C/span>\u003Cspan style=\"color:#E6DB74\"> i\u003C/span>\u003Cspan style=\"color:#AE81FF\"> -D\u003C/span>\u003Cspan style=\"color:#E6DB74\"> npm-run-all\u003C/span>\u003Cspan style=\"color:#E6DB74\"> del-cli\u003C/span>\u003Cspan style=\"color:#E6DB74\"> delete-empty\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>These three packages, will, in order, let you run NPM scripts sequentially or in parallel from other npm scripts, let you delete items, and let you delete empty folders. These three combine to make a few really handy scripts possible:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"json\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">{\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  \"scripts\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"prestart\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"run-s clean\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"start\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"run-p *:dev\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"prebuild\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"run-s clean\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"build\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"NODE_ENV=production run-s eleventy:build vite:build\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"clean\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"run-s clean:files clean:empty\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"clean:files\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"del 'src/**/*.html' public\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"clean:empty\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"delete-empty src\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"eleventy:dev\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"eleventy --watch\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"eleventy:build\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"eleventy\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"vite:dev\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"vite\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    \"vite:build\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#CFCFC2\">\"vite build\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>These combine to give you, really, two scripts you’re likely to run: \u003Ccode>npm start\u003C/code> and \u003Ccode>npm run build\u003C/code>. They do the following:\u003C/p>\n\u003Cp>\u003Ccode>npm start\u003C/code>\n~ Before start is run, it deletes all of the HTML files from the \u003Ccode>src\u003C/code> directory and removes the \u003Ccode>public\u003C/code> directory, then deletes empty folders in the \u003Ccode>src\u003C/code> directory that may be left over fom removing the HTML files. Once done, it runs all of the NPM scripts ending in \u003Ccode>:dev\u003C/code>, so \u003Ccode>eleventy:dev\u003C/code> and \u003Ccode>vite:dev\u003C/code>, in parallel, which starts Eleventy in watch mode and Vite in dev mode.\u003C/p>\n\u003Cp>\u003Ccode>npm run build\u003C/code>\n~ This is run with \u003Ccode>NODE_ENV=production\u003C/code>, or “in production mode”, which is a common signal that production optimizations should happen. Before build is run, it cleans up the files just like start did, then runs Eleventy’s build first, then Vite’s build second; this is to ensure that the HTML gets generated before Vite tries to do its thing with it.\u003C/p>\n\u003Ch2 id=\"multi-page-apps-static-assets-and-vite\">Multi-Page Apps, Static Assets, and Vite\u003C/h2>\n\u003Cp>Vite, in development mode, work with multi-page apps just fine! Unfortunately, when it comes to build time, it only works on \u003Ccode>src/index.html\u003C/code> by default. This is straightforward to remedy, though. First install \u003Ca href=\"https://www.npmjs.com/package/fast-glob\">Fast Glob\u003C/a> as a dev dependency (\u003Ccode>npm i -D fast-glob\u003C/code>) and add the following to your \u003Ccode>vite.config.js\u003C/code> file:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"js\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> glob \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#A6E22E\"> require\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'fast-glob'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> path \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#A6E22E\"> require\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'path'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Find all HTML files and build an object of names and paths to work from\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> files \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> glob\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  .\u003C/span>\u003Cspan style=\"color:#A6E22E\">sync\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(path.\u003C/span>\u003Cspan style=\"color:#A6E22E\">resolve\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(__dirname, \u003C/span>\u003Cspan style=\"color:#E6DB74\">'src'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) \u003C/span>\u003Cspan style=\"color:#F92672\">+\u003C/span>\u003Cspan style=\"color:#E6DB74\"> '/**/*.html'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  .\u003C/span>\u003Cspan style=\"color:#A6E22E\">reduce\u003C/span>\u003Cspan style=\"color:#F8F8F2\">((\u003C/span>\u003Cspan style=\"color:#FD971F;font-style:italic\">acc\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#FD971F;font-style:italic\">cur\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) \u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">=>\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    let\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> name \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> cur\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      .\u003C/span>\u003Cspan style=\"color:#A6E22E\">replace\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(path.\u003C/span>\u003Cspan style=\"color:#A6E22E\">join\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(__dirname) \u003C/span>\u003Cspan style=\"color:#F92672\">+\u003C/span>\u003Cspan style=\"color:#E6DB74\"> '/src/'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#E6DB74\">''\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      .\u003C/span>\u003Cspan style=\"color:#A6E22E\">replace\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'/index.html'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, \u003C/span>\u003Cspan style=\"color:#E6DB74\">''\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // If name is blank, make up a name for it, like 'home'\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (name \u003C/span>\u003Cspan style=\"color:#F92672\">===\u003C/span>\u003Cspan style=\"color:#E6DB74\"> ''\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      name \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'home'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    acc[name] \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> cur;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    return\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> acc;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }, {});\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">module\u003C/span>\u003Cspan style=\"color:#F8F8F2\">.\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">exports\u003C/span>\u003Cspan style=\"color:#F92672\"> =\u003C/span>\u003Cspan style=\"color:#A6E22E\"> defineConfig\u003C/span>\u003Cspan style=\"color:#F8F8F2\">({\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // ... Other config stuff\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  build: {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // ... Other build config stuff\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    rollupOptions: {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      input: files,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    },\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  },\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">});\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>While a little complicated, what this does is find all of the HTML files in the \u003Ccode>src\u003C/code> directory, figure out a name for the file by removing \u003Ccode>/index.html\u003C/code>, and then building an array of names and HTML pages to use as input for Vite’s Rollup configuration. This assumes that all pages that get assets have a \u003Ccode>/index.html\u003C/code> file; if not, update the glob or the replacement accordingly. This is also going to generate a JavaScript file for each page, but because of how Vite handles imports, you should still get shared chunks between all of them. This is kind of the ugliest bit of this setup, and I’m sure it can be improved, but it’s pretty good for a quick solve.\u003C/p>\n\u003Cp>As for assets, like a \u003Ccode>manifest.json\u003C/code>, \u003Ccode>robots.txt\u003C/code>, or images, Vite expects those to be in a \u003Ccode>public\u003C/code> folder in your root, so in this case, \u003Ccode>src/public\u003C/code>. Usually not a big deal, but if you find those assets aren’t getting checked in, make sure you’re ignore files are ignoring \u003Ccode>/public\u003C/code> for the roo public folder, not \u003Ccode>public\u003C/code> which will ignore folders named public \u003Cem>anywhere\u003C/em>, including the one is \u003Ccode>src\u003C/code>.\u003C/p>\n\u003Ch2 id=\"whats-next\">What’s Next\u003C/h2>\n\u003Cp>For me, this is a very happy little setup. I’m sure there’s more tweaking that can be done to make everything a bit more smooth and a bit easier to deal with, but this was the most minimal setup I could get to that consistently worked and, more importantly, gave me the awesome dev experience of the combined power of Vite and Eleventy. If you’ve got thoughts on this setup or this post, drop me a line on Twitter.\u003C/p>\n\u003Cp>Enjoy y’all!\u003C/p>",{"headings":1356,"localImagePaths":1372,"remoteImagePaths":1373,"frontmatter":1374,"imagePaths":1376},[1357,1360,1363,1366,1369],{"depth":80,"slug":1358,"text":1359},"configure-vite","Configure Vite",{"depth":80,"slug":1361,"text":1362},"configure-eleventy","Configure Eleventy",{"depth":80,"slug":1364,"text":1365},"add-npm-scripts","Add NPM Scripts",{"depth":80,"slug":1367,"text":1368},"multi-page-apps-static-assets-and-vite","Multi-Page Apps, Static Assets, and Vite",{"depth":80,"slug":1370,"text":1371},"whats-next","What’s Next",[],[],{"title":1347,"published":1375,"summary":1349},"2021-05-13",[],"empathy-vs-understanding",{"id":1377,"data":1379,"body":1383,"filePath":1384,"digest":1385,"rendered":1386},{"title":1380,"published":1381,"summary":1382},"Empathy vs Understanding",["Date","2015-04-06T00:00:00.000Z"],"In order to solve the problems of our users or to work better with each other, we need both empathy *and* understanding.","We are problem solvers. Whether it's design, development, engineering, crafting, or anything else in which there is a user, what is being done is problem solving. If we are doing our job right, our solution should solve real user needs in a way best suited for them. Often, this is described as \"having empathy for our users\"; however, the colloquial definition of empathy, \"to put oneself in another's shoes\" or \"to understand another's point of view\", isn't quite correct. These definitions conflate empathy with understanding. Because of this, we have a tendency to assume that if we have one, we have the other, but that is not true. In order to solve the problems of our users or to work better with each other, we need both empathy _and_ understanding. Exploring the etymology of each word will help us better see their differences.\n\n[**empathy** _(n.)_](http://www.etymonline.com/index.php?term=empathy) - Modeled on the German _Einfühlung_; from _ein_ \"in\" + _Fühlung_ \"feeling\". Coined in 1858 by the German philosopher Rudolf Lotze as a translation of the Greek _empatheia_ or \"passion, state of emotion\"; an assimilated form of _en_ \"in\" and _pathos_ \"feeling\". From a theory of art appreciation that maintains appreciation depends on the viewer's ability to project his personality into the viewed object.\n\n[**understand** _(v.)_](http://www.etymonline.com/index.php?term=understand) - Old English _understandan_, \"comprehend, grasp the idea of\", or probably more literally \"stand in the midst of\", from _under_ (which in this context is not the usual meaning \"beneath\" but from Old English _under_ from PIE _\\*nter-_ \"between, among\") and _standan_ \"to stand\".\n\nEmpathy looks to have one align with the _feelings_ of another, whereas understanding looks to have one align themselves with a set of _knowledge_. With this, we can start to identify when we are talking about empathy and when we are talking about understanding. When talking about empathy, we are talking about a state of being; how does a person feel, what do they see, what do they say, what do they do, what do they hear, is it causing them pain, is it causing them joy. With understanding, on the other hand, we are talking about knowledge and process; what is a person's background, what expertise do they bring to this situation and how is that important to their understanding, why did they come to the decision they have. In order to solve problems effectively, both the current state of being and the process and rational that led to that state of being need to be considered. Doing so will also allow us to think in ways we wouldn't otherwise be able to and find solutions we wouldn't otherwise see.\n\nOne example of where empathy and understanding are both needed is the perceived tension between design and development. It can often be summed up as \"developers don't empathize with designers\" and \"designers don't understand development\". Often, the colloquial definition of empathy instead is used and the tensions is summed up as \"we need teams that can empathize with each other\". That is not the problem. Instead, the problem likely is either teams are made up of specialized individuals who do not grasp the process and skill set of other specializations (and thus can only at best empathize but not understand), or there are specialized teams that likewise suffer from the same problem. These can be thought of as siloed individuals or teams. To solve this problem, those who are deeply specialized need to broaden their knowledge. They need to learn the processes and skills of specializations outside their own to be able to think like their coworkers and solve problems like they do. They need to become T-shaped. In simple terms; designers need to learn how to code, developers need to learn how to design, and both need to practice and use those skills every day. Everyone solving the same problem at the same time breeds both empathy and understanding and will help find solutions to problems that otherwise may go unseen.\n\nThe second example comes from user research. We do user research ideally to determine what problems our users have in order to determine what problems we should be solving. Often, though, this only focuses on empathizing with our users; gathering their pain points and reacting to them. The weird thing about asking users about what bothers them is that they tend to [focus on symptoms, not root causes](http://www.washington.edu/research/rapid/resources/toolsTemplates/root_cause_analysis.pdf). There's often something deeper about the way it fits into their understanding of a problem that is the cause of pain. If all we do is focus on empathy, there is a serious risk that what we focus on are just the symptoms, not the root causes. This means going beyond the superficial: beyond their role or title, beyond their age, beyond their gender, and uncovering why they think like they think, why they do what they do. Understanding the [problem domain](http://en.wikipedia.org/wiki/Problem_domain) being worked in and building [domain models](http://en.wikipedia.org/wiki/Domain_model) for that problem space will help us to think like our users and understand those root causes. In order to solve the right problems, we need to solve for both the symptoms and the root causes.\n\nThe point of all of this, of course, is not on the semantics of the words _empathy_ and _understanding_; they simply frame the conversation. Solving problems with and for others requires us to not only know how they _feel_ but know how they _think and work_. Knowing how they _feel_ means sensing their frustration, their joy, their confusion. It helps us to detect success and failure. Being able to know how they _think and work_, on the other hand, allows us to turn frustration into joy, or confusion into clarity. It allows us to determine concrete, productive actions to take.\n\nUltimately, if we want to be able to successfully identify what problems actually need to be solved, we need to comprehend not only _what our users feel_, but _understand the system they work in_ and _how it influences their decision making_. We need to be able to not just feel our users' pain, but be able to think like they do in their context. We need to be able to value what they value in the context they value it. We need to uncover the root causes of the symptoms we can see in order to solve the underlying problems. This cannot be limited to just those we solve problems for; we need to work this way with the people we work with. We need to be able to think like our co-workers do in their context in order to solve problems with them in faster, more creative, more sustainable ways. Everyone on a team need to care deeply and passionately about how their team members are working, how they are thinking and understanding the problem being solved, and their context in solving that problem. Teams need not only have both _empathy_ and _understanding_ for their users and their co-workers, but they need value having and practicing both.","src/content/posts/empathy-vs-understanding.md","a6177be6aea32abb",{"html":1387,"metadata":1388},"\u003Cp>We are problem solvers. Whether it’s design, development, engineering, crafting, or anything else in which there is a user, what is being done is problem solving. If we are doing our job right, our solution should solve real user needs in a way best suited for them. Often, this is described as “having empathy for our users”; however, the colloquial definition of empathy, “to put oneself in another’s shoes” or “to understand another’s point of view”, isn’t quite correct. These definitions conflate empathy with understanding. Because of this, we have a tendency to assume that if we have one, we have the other, but that is not true. In order to solve the problems of our users or to work better with each other, we need both empathy \u003Cem>and\u003C/em> understanding. Exploring the etymology of each word will help us better see their differences.\u003C/p>\n\u003Cp>\u003Ca href=\"http://www.etymonline.com/index.php?term=empathy\">\u003Cstrong>empathy\u003C/strong> \u003Cem>(n.)\u003C/em>\u003C/a> - Modeled on the German \u003Cem>Einfühlung\u003C/em>; from \u003Cem>ein\u003C/em> “in” + \u003Cem>Fühlung\u003C/em> “feeling”. Coined in 1858 by the German philosopher Rudolf Lotze as a translation of the Greek \u003Cem>empatheia\u003C/em> or “passion, state of emotion”; an assimilated form of \u003Cem>en\u003C/em> “in” and \u003Cem>pathos\u003C/em> “feeling”. From a theory of art appreciation that maintains appreciation depends on the viewer’s ability to project his personality into the viewed object.\u003C/p>\n\u003Cp>\u003Ca href=\"http://www.etymonline.com/index.php?term=understand\">\u003Cstrong>understand\u003C/strong> \u003Cem>(v.)\u003C/em>\u003C/a> - Old English \u003Cem>understandan\u003C/em>, “comprehend, grasp the idea of”, or probably more literally “stand in the midst of”, from \u003Cem>under\u003C/em> (which in this context is not the usual meaning “beneath” but from Old English \u003Cem>under\u003C/em> from PIE \u003Cem>*nter-\u003C/em> “between, among”) and \u003Cem>standan\u003C/em> “to stand”.\u003C/p>\n\u003Cp>Empathy looks to have one align with the \u003Cem>feelings\u003C/em> of another, whereas understanding looks to have one align themselves with a set of \u003Cem>knowledge\u003C/em>. With this, we can start to identify when we are talking about empathy and when we are talking about understanding. When talking about empathy, we are talking about a state of being; how does a person feel, what do they see, what do they say, what do they do, what do they hear, is it causing them pain, is it causing them joy. With understanding, on the other hand, we are talking about knowledge and process; what is a person’s background, what expertise do they bring to this situation and how is that important to their understanding, why did they come to the decision they have. In order to solve problems effectively, both the current state of being and the process and rational that led to that state of being need to be considered. Doing so will also allow us to think in ways we wouldn’t otherwise be able to and find solutions we wouldn’t otherwise see.\u003C/p>\n\u003Cp>One example of where empathy and understanding are both needed is the perceived tension between design and development. It can often be summed up as “developers don’t empathize with designers” and “designers don’t understand development”. Often, the colloquial definition of empathy instead is used and the tensions is summed up as “we need teams that can empathize with each other”. That is not the problem. Instead, the problem likely is either teams are made up of specialized individuals who do not grasp the process and skill set of other specializations (and thus can only at best empathize but not understand), or there are specialized teams that likewise suffer from the same problem. These can be thought of as siloed individuals or teams. To solve this problem, those who are deeply specialized need to broaden their knowledge. They need to learn the processes and skills of specializations outside their own to be able to think like their coworkers and solve problems like they do. They need to become T-shaped. In simple terms; designers need to learn how to code, developers need to learn how to design, and both need to practice and use those skills every day. Everyone solving the same problem at the same time breeds both empathy and understanding and will help find solutions to problems that otherwise may go unseen.\u003C/p>\n\u003Cp>The second example comes from user research. We do user research ideally to determine what problems our users have in order to determine what problems we should be solving. Often, though, this only focuses on empathizing with our users; gathering their pain points and reacting to them. The weird thing about asking users about what bothers them is that they tend to \u003Ca href=\"http://www.washington.edu/research/rapid/resources/toolsTemplates/root_cause_analysis.pdf\">focus on symptoms, not root causes\u003C/a>. There’s often something deeper about the way it fits into their understanding of a problem that is the cause of pain. If all we do is focus on empathy, there is a serious risk that what we focus on are just the symptoms, not the root causes. This means going beyond the superficial: beyond their role or title, beyond their age, beyond their gender, and uncovering why they think like they think, why they do what they do. Understanding the \u003Ca href=\"http://en.wikipedia.org/wiki/Problem_domain\">problem domain\u003C/a> being worked in and building \u003Ca href=\"http://en.wikipedia.org/wiki/Domain_model\">domain models\u003C/a> for that problem space will help us to think like our users and understand those root causes. In order to solve the right problems, we need to solve for both the symptoms and the root causes.\u003C/p>\n\u003Cp>The point of all of this, of course, is not on the semantics of the words \u003Cem>empathy\u003C/em> and \u003Cem>understanding\u003C/em>; they simply frame the conversation. Solving problems with and for others requires us to not only know how they \u003Cem>feel\u003C/em> but know how they \u003Cem>think and work\u003C/em>. Knowing how they \u003Cem>feel\u003C/em> means sensing their frustration, their joy, their confusion. It helps us to detect success and failure. Being able to know how they \u003Cem>think and work\u003C/em>, on the other hand, allows us to turn frustration into joy, or confusion into clarity. It allows us to determine concrete, productive actions to take.\u003C/p>\n\u003Cp>Ultimately, if we want to be able to successfully identify what problems actually need to be solved, we need to comprehend not only \u003Cem>what our users feel\u003C/em>, but \u003Cem>understand the system they work in\u003C/em> and \u003Cem>how it influences their decision making\u003C/em>. We need to be able to not just feel our users’ pain, but be able to think like they do in their context. We need to be able to value what they value in the context they value it. We need to uncover the root causes of the symptoms we can see in order to solve the underlying problems. This cannot be limited to just those we solve problems for; we need to work this way with the people we work with. We need to be able to think like our co-workers do in their context in order to solve problems with them in faster, more creative, more sustainable ways. Everyone on a team need to care deeply and passionately about how their team members are working, how they are thinking and understanding the problem being solved, and their context in solving that problem. Teams need not only have both \u003Cem>empathy\u003C/em> and \u003Cem>understanding\u003C/em> for their users and their co-workers, but they need value having and practicing both.\u003C/p>",{"headings":1389,"localImagePaths":1390,"remoteImagePaths":1391,"frontmatter":1392,"imagePaths":1394},[],[],[],{"title":1380,"published":1393,"summary":1382},"2015-04-06",[],"getting-started-with-grid",{"id":1395,"data":1397,"body":1401,"filePath":1402,"digest":1403,"rendered":1404},{"title":1398,"published":1399,"summary":1400},"Getting Started with Grid",["Date","2017-03-22T00:00:00.000Z"],"CSS Grid is out! I've started playing it, here are my first thoughts.","[CSS Grid](https://www.w3.org/TR/css3-grid-layout/)! _[It lives](http://caniuse.com/#search=grid)!_ While it may be a _hair_ too early (in my opinion) to start using in production, now's the time to start learning it! [MDN](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Grid_Layout), as always, has great documentation, and much like he did with [flexbox](https://css-tricks.com/snippets/css/a-guide-to-flexbox/) (which is still the only way I'm able to navigate flexbox), [Chris Coyier](https://twitter.com/chriscoyier) has a [fantastic grid guide](https://css-tricks.com/snippets/css/complete-guide-grid/) over on CSS-Tricks. [Jen Simmons](https://twitter.com/jensimmons) has a great set of [Grid learning resources](http://jensimmons.com/post/feb-27-2017/learn-css-grid) compiled for those looking to dive in to the deep end.\n\nI started digging in to it last week, and a funny thing happened happened: for the most part, it clicked! Don't get me wrong, it's an immensely complex spec, and I have no idea how _most_ of it works, but for the stuff I'm likely to use most often? The \"make a grid and stick stuff on it\" part? That stuff _just clicked_. It felt natural, it reminded me of [Singularity](https://github.com/at-import/Singularity). Flexbox has been out for a while, and I still can't really explain how it works, or get even the most basic of syntax right without referring to CSS-Tricks; for some reason, not so for Grid. So, for those coming from Singularity (or Susy, or Bootstrap, or Foundation, or any of those things), let's see how that knowledge can transfer over to Grid.\n\nThe first thing that's going to differ from old float based grid systems is that CSS Grid is not just a 1-dimensional system; items can be positioned and sized in 2 dimensions! That's _awesome_! In more advanced usage, which I think is still being explored (check out Jen Simmons' [Experimental Layout Lab](http://labs.jensimmons.com/) for cool layout ideas with Grid), I believe Grid's 2 dimensions are going to come in _really_ useful and will produce _really_ interesting and innovative layouts on the web. In my mind, the way I've been able to wrangle this (at least initially) is by thinking of Grid as two sets of 1-dimensional systems (let's see if this actually pans out), and thinking about it this way makes thinking in Grid pretty straight forward for me. So, let's dive in!\n\n## Defining a Grid\n\nAs far as I can tell, there are roughly an equal number of ways to define a grid as stars in the sky with Grid. While it may seem overwhelming at first (and I still don't quite know all the ways to do it), if coming from something like Singularity, just about every permutation available there is fairly straight forward to do with Grid! The secret sauce to most of this is a brand-new unit, the `fr` unit. For those familiar with Singularity, the `fr` unit is _roughly_ equal to Singularity's magic `1` number, which is \"one part of the available remaining free space\". In Singularity a grid that's defined `1 3 1` would be a 3 column grid where the first and third columns are 1/3 the width of the 2nd column. With CSS Grid, that'd be `1fr 3fr 1fr`, where the width of `fr` is the total width of free space (minus the grid gap, we'll get to that in a second) divided by 5 (total number of `fr` units). This works _really_ well for asymmetric grids, but it works just as well for symmetric grids. Familiar with Bootstrap? It's a 12 column grid where each column is the same percentage of the container. For repeating sections in a grid, the new `repeat()` function is available! While any grid definition can be repeated, to make a simple 12 column grid, it's `repeat(12, 1fr)`! These new `fr` units can be combined with any of the other units that are already available in CSS to form a grid, so don't worry about just using those! Throw these on `grid-template-columns` to define the columns of a grid, and `grid-template-rows` to define the rows of a grid.\n\nOnce we understand how to define a grid (and in CSS Grid, that can be columns _or_ rows), we likely want some space between each column. In Singularity and the like, that was called a \"gutter\". In Grid, it's called a `grid-gap`. Gaps can be defined with whatever units one would like, but there can only be one gap value for columns and one for rows, there can't be variable gaps between columns or rows. In CSS Grid, gaps are _only_ between columns, so there is no \"split gutter\" like there was in Singularity (but the `fr` unit plus container padding takes care of that).\n\nLet's put this all together! CSS Grid works by putting the grid styling on a container, and having the items inside it attached to the grid (more on that next). So, let's build a couple of grids!\n\n```scss\n.container {\n  display: grid; // Magic sauce! The new Grid display!\n  grid-template-columns: repeat(\n    16,\n    1fr\n  ); // Defining a 16 column grid where each column is 1/16 of the available space\n  grid-gap: 20px; // This is shorthand to define grid-column-gap (gap between columns) and grid-row-gap (gap between rows). Row gap will apply between rows even if a row template isn't defined\n}\n\n.layout {\n  display: grid;\n  grid-template-rows: 100vh 2fr 1fr 50px; // A funky set of rows, maybe for an article with a big lead?\n  grid-row-gap: 1em; // Gap between just the rows\n}\n```\n\n## Putting Stuff on a Grid\n\nOnce a grid's defined, how do we place something on it? In Singularity and the like, we used mixins called something along the lines of `span`. Well, now that Grid is out and it's in 2 dimensions, it's not as simple as `span`, we need to tell Grid _what_ we want to span! So, there are two new properties, `grid-column` and `grid-row` that we need to use to span rows or columns. Good news though! Grid has literally introduced `span` to define how many rows or columns to span! So, `grid-column: span 2` (yah, a slightly new syntax where it's `keyword value`) will tell Grid that, for this item, its width should be the width of two columns (the actual width depends on what those two columns are). Same thing for rows; `grid-row: span 3` will have an item that is the height of three rows. Now, the thing that I think made this click for me (and why I'm reminded of Singularity specifically) is that spanning on a grid isn't just about _how many_ columns or rows to span, but _where to start_! To do so, start with what column or row to start spanning at (a unitless number) and then define the span. So `grid-column: 2 / span 3` would span 3 columns, starting at the 2nd column (another slightly new syntax here, with the `/` acting as a separator in `value / value`). Let's put some things on an imaginary grid!\n\n```scss\n.item {\n  grid-column: 4 / span 2; // Span 2 columns, starting at the 4th column\n  grid-row: span 2; // Span 2 rows, regardless of what row .item is in\n}\n\n// This places item2 at a specific width, height, horizontal position, and vertical position\n.item2 {\n  grid-column: 2 / span 3; // Span 3 columns, starting at the 2nd column\n  grid-row: 3 / span 2; // Span 2 rows, starting at the 3rd row\n}\n```\n\n## CSS Grid Frameworks?\n\nAfter a little bit of playing around with Grid, I'm not really sure if there's a _need_ for CSS Grid based grid frameworks like there were with `float` based grids. The syntax for 70%-80% of the most common tasks I see myself doing with Grid is so straight forward that abstracting it in to a system feels heavier than its worth. I started experimenting with a very light-weight set of Sass helper mixins I'm calling [GRIDdle](https://github.com/at-import/griddle), but I'm not really sure of its worth yet; some of the mixins, for instance, take more effort to write than the actual property (yah, literally _property_) that it spits out.\n\nWhat I think is going to be much more common in the era of Grid is being able to really, successfully share layouts with each other. This is a much more exciting proposition for me as it's going to allow thinking about how to best display _content_ grow and mature in the same way that thinking about grids as layout tools have. It'll open up a whole set of interoperable layouts in style guides that otherwise would be constrained to the specific environment they live in. I'm hopeful that I'm going to get to use Grid in production soon, and kick the tires on just what responsive, art and content directed layouts look like in the real world, and be able to share that back. I've got some funky ideas to toy with as well, so maybe a \"fun with Grid\" post is soon to come as well.\n\nIn the mean time, go out and play! Grid is here!","src/content/posts/getting-started-with-grid.md","5fa04dea5ba93140",{"html":1405,"metadata":1406},"\u003Cp>\u003Ca href=\"https://www.w3.org/TR/css3-grid-layout/\">CSS Grid\u003C/a>! \u003Cem>\u003Ca href=\"http://caniuse.com/#search=grid\">It lives\u003C/a>!\u003C/em> While it may be a \u003Cem>hair\u003C/em> too early (in my opinion) to start using in production, now’s the time to start learning it! \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Grid_Layout\">MDN\u003C/a>, as always, has great documentation, and much like he did with \u003Ca href=\"https://css-tricks.com/snippets/css/a-guide-to-flexbox/\">flexbox\u003C/a> (which is still the only way I’m able to navigate flexbox), \u003Ca href=\"https://twitter.com/chriscoyier\">Chris Coyier\u003C/a> has a \u003Ca href=\"https://css-tricks.com/snippets/css/complete-guide-grid/\">fantastic grid guide\u003C/a> over on CSS-Tricks. \u003Ca href=\"https://twitter.com/jensimmons\">Jen Simmons\u003C/a> has a great set of \u003Ca href=\"http://jensimmons.com/post/feb-27-2017/learn-css-grid\">Grid learning resources\u003C/a> compiled for those looking to dive in to the deep end.\u003C/p>\n\u003Cp>I started digging in to it last week, and a funny thing happened happened: for the most part, it clicked! Don’t get me wrong, it’s an immensely complex spec, and I have no idea how \u003Cem>most\u003C/em> of it works, but for the stuff I’m likely to use most often? The “make a grid and stick stuff on it” part? That stuff \u003Cem>just clicked\u003C/em>. It felt natural, it reminded me of \u003Ca href=\"https://github.com/at-import/Singularity\">Singularity\u003C/a>. Flexbox has been out for a while, and I still can’t really explain how it works, or get even the most basic of syntax right without referring to CSS-Tricks; for some reason, not so for Grid. So, for those coming from Singularity (or Susy, or Bootstrap, or Foundation, or any of those things), let’s see how that knowledge can transfer over to Grid.\u003C/p>\n\u003Cp>The first thing that’s going to differ from old float based grid systems is that CSS Grid is not just a 1-dimensional system; items can be positioned and sized in 2 dimensions! That’s \u003Cem>awesome\u003C/em>! In more advanced usage, which I think is still being explored (check out Jen Simmons’ \u003Ca href=\"http://labs.jensimmons.com/\">Experimental Layout Lab\u003C/a> for cool layout ideas with Grid), I believe Grid’s 2 dimensions are going to come in \u003Cem>really\u003C/em> useful and will produce \u003Cem>really\u003C/em> interesting and innovative layouts on the web. In my mind, the way I’ve been able to wrangle this (at least initially) is by thinking of Grid as two sets of 1-dimensional systems (let’s see if this actually pans out), and thinking about it this way makes thinking in Grid pretty straight forward for me. So, let’s dive in!\u003C/p>\n\u003Ch2 id=\"defining-a-grid\">Defining a Grid\u003C/h2>\n\u003Cp>As far as I can tell, there are roughly an equal number of ways to define a grid as stars in the sky with Grid. While it may seem overwhelming at first (and I still don’t quite know all the ways to do it), if coming from something like Singularity, just about every permutation available there is fairly straight forward to do with Grid! The secret sauce to most of this is a brand-new unit, the \u003Ccode>fr\u003C/code> unit. For those familiar with Singularity, the \u003Ccode>fr\u003C/code> unit is \u003Cem>roughly\u003C/em> equal to Singularity’s magic \u003Ccode>1\u003C/code> number, which is “one part of the available remaining free space”. In Singularity a grid that’s defined \u003Ccode>1 3 1\u003C/code> would be a 3 column grid where the first and third columns are 1/3 the width of the 2nd column. With CSS Grid, that’d be \u003Ccode>1fr 3fr 1fr\u003C/code>, where the width of \u003Ccode>fr\u003C/code> is the total width of free space (minus the grid gap, we’ll get to that in a second) divided by 5 (total number of \u003Ccode>fr\u003C/code> units). This works \u003Cem>really\u003C/em> well for asymmetric grids, but it works just as well for symmetric grids. Familiar with Bootstrap? It’s a 12 column grid where each column is the same percentage of the container. For repeating sections in a grid, the new \u003Ccode>repeat()\u003C/code> function is available! While any grid definition can be repeated, to make a simple 12 column grid, it’s \u003Ccode>repeat(12, 1fr)\u003C/code>! These new \u003Ccode>fr\u003C/code> units can be combined with any of the other units that are already available in CSS to form a grid, so don’t worry about just using those! Throw these on \u003Ccode>grid-template-columns\u003C/code> to define the columns of a grid, and \u003Ccode>grid-template-rows\u003C/code> to define the rows of a grid.\u003C/p>\n\u003Cp>Once we understand how to define a grid (and in CSS Grid, that can be columns \u003Cem>or\u003C/em> rows), we likely want some space between each column. In Singularity and the like, that was called a “gutter”. In Grid, it’s called a \u003Ccode>grid-gap\u003C/code>. Gaps can be defined with whatever units one would like, but there can only be one gap value for columns and one for rows, there can’t be variable gaps between columns or rows. In CSS Grid, gaps are \u003Cem>only\u003C/em> between columns, so there is no “split gutter” like there was in Singularity (but the \u003Ccode>fr\u003C/code> unit plus container padding takes care of that).\u003C/p>\n\u003Cp>Let’s put this all together! CSS Grid works by putting the grid styling on a container, and having the items inside it attached to the grid (more on that next). So, let’s build a couple of grids!\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.container\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  display\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">grid\u003C/span>\u003Cspan style=\"color:#F8F8F2\">; \u003C/span>\u003Cspan style=\"color:#88846F\">// Magic sauce! The new Grid display!\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  grid-template-columns\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">repeat\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#AE81FF\">    16\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#AE81FF\">    1\u003C/span>\u003Cspan style=\"color:#F92672\">fr\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  ); \u003C/span>\u003Cspan style=\"color:#88846F\">// Defining a 16 column grid where each column is 1/16 of the available space\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  grid-gap\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">20\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">; \u003C/span>\u003Cspan style=\"color:#88846F\">// This is shorthand to define grid-column-gap (gap between columns) and grid-row-gap (gap between rows). Row gap will apply between rows even if a row template isn't defined\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.layout\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  display\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">grid\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  grid-template-rows\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">100\u003C/span>\u003Cspan style=\"color:#F92672\">vh\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F92672\">fr\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#F92672\">fr\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 50\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">; \u003C/span>\u003Cspan style=\"color:#88846F\">// A funky set of rows, maybe for an article with a big lead?\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  grid-row-gap\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">; \u003C/span>\u003Cspan style=\"color:#88846F\">// Gap between just the rows\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"putting-stuff-on-a-grid\">Putting Stuff on a Grid\u003C/h2>\n\u003Cp>Once a grid’s defined, how do we place something on it? In Singularity and the like, we used mixins called something along the lines of \u003Ccode>span\u003C/code>. Well, now that Grid is out and it’s in 2 dimensions, it’s not as simple as \u003Ccode>span\u003C/code>, we need to tell Grid \u003Cem>what\u003C/em> we want to span! So, there are two new properties, \u003Ccode>grid-column\u003C/code> and \u003Ccode>grid-row\u003C/code> that we need to use to span rows or columns. Good news though! Grid has literally introduced \u003Ccode>span\u003C/code> to define how many rows or columns to span! So, \u003Ccode>grid-column: span 2\u003C/code> (yah, a slightly new syntax where it’s \u003Ccode>keyword value\u003C/code>) will tell Grid that, for this item, its width should be the width of two columns (the actual width depends on what those two columns are). Same thing for rows; \u003Ccode>grid-row: span 3\u003C/code> will have an item that is the height of three rows. Now, the thing that I think made this click for me (and why I’m reminded of Singularity specifically) is that spanning on a grid isn’t just about \u003Cem>how many\u003C/em> columns or rows to span, but \u003Cem>where to start\u003C/em>! To do so, start with what column or row to start spanning at (a unitless number) and then define the span. So \u003Ccode>grid-column: 2 / span 3\u003C/code> would span 3 columns, starting at the 2nd column (another slightly new syntax here, with the \u003Ccode>/\u003C/code> acting as a separator in \u003Ccode>value / value\u003C/code>). Let’s put some things on an imaginary grid!\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.item\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  grid-column\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">4\u003C/span>\u003Cspan style=\"color:#F92672\"> /\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\"> span\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">; \u003C/span>\u003Cspan style=\"color:#88846F\">// Span 2 columns, starting at the 4th column\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  grid-row\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">span\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">; \u003C/span>\u003Cspan style=\"color:#88846F\">// Span 2 rows, regardless of what row .item is in\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// This places item2 at a specific width, height, horizontal position, and vertical position\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.item2\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  grid-column\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">2\u003C/span>\u003Cspan style=\"color:#F92672\"> /\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\"> span\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 3\u003C/span>\u003Cspan style=\"color:#F8F8F2\">; \u003C/span>\u003Cspan style=\"color:#88846F\">// Span 3 columns, starting at the 2nd column\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  grid-row\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">3\u003C/span>\u003Cspan style=\"color:#F92672\"> /\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\"> span\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">; \u003C/span>\u003Cspan style=\"color:#88846F\">// Span 2 rows, starting at the 3rd row\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"css-grid-frameworks\">CSS Grid Frameworks?\u003C/h2>\n\u003Cp>After a little bit of playing around with Grid, I’m not really sure if there’s a \u003Cem>need\u003C/em> for CSS Grid based grid frameworks like there were with \u003Ccode>float\u003C/code> based grids. The syntax for 70%-80% of the most common tasks I see myself doing with Grid is so straight forward that abstracting it in to a system feels heavier than its worth. I started experimenting with a very light-weight set of Sass helper mixins I’m calling \u003Ca href=\"https://github.com/at-import/griddle\">GRIDdle\u003C/a>, but I’m not really sure of its worth yet; some of the mixins, for instance, take more effort to write than the actual property (yah, literally \u003Cem>property\u003C/em>) that it spits out.\u003C/p>\n\u003Cp>What I think is going to be much more common in the era of Grid is being able to really, successfully share layouts with each other. This is a much more exciting proposition for me as it’s going to allow thinking about how to best display \u003Cem>content\u003C/em> grow and mature in the same way that thinking about grids as layout tools have. It’ll open up a whole set of interoperable layouts in style guides that otherwise would be constrained to the specific environment they live in. I’m hopeful that I’m going to get to use Grid in production soon, and kick the tires on just what responsive, art and content directed layouts look like in the real world, and be able to share that back. I’ve got some funky ideas to toy with as well, so maybe a “fun with Grid” post is soon to come as well.\u003C/p>\n\u003Cp>In the mean time, go out and play! Grid is here!\u003C/p>",{"headings":1407,"localImagePaths":1417,"remoteImagePaths":1418,"frontmatter":1419,"imagePaths":1421},[1408,1411,1414],{"depth":80,"slug":1409,"text":1410},"defining-a-grid","Defining a Grid",{"depth":80,"slug":1412,"text":1413},"putting-stuff-on-a-grid","Putting Stuff on a Grid",{"depth":80,"slug":1415,"text":1416},"css-grid-frameworks","CSS Grid Frameworks?",[],[],{"title":1398,"published":1420,"summary":1400},"2017-03-22",[],"illustrator-to-raphael-js-guide",{"id":1422,"data":1424,"body":1429,"filePath":1430,"digest":1431,"rendered":1432},{"title":1425,"published":1426,"summary":1427,"categories":1428},"Illustrator to Raphaël JS: A Guide",["Date","2011-03-01T00:00:00.000Z"],"A guide on moving SVGs created in Illustrator to Raphaël, a JavaScript SVG drawing library.",[14,55,42],"Over the summer, I came across an absolutely wonderful JavaScript library called [Raphaël](http://raphaeljs.com/) that blew me away. Using some maths and some patience, Raphaël allows you to to draw Scalable Vector Graphics (SVGs) through code in any browser, from Internet Explorer 6 all the way up to Mobile Safari. So when I sat down to create my ~~website~~ previous website design, I decided that I wanted to use Raphaël to build out the UI elements in my site that would otherwise be done using normal images. While that sounded great as a goal, it turned out to be harder than I had imagined it would be, in part due to information about getting graphics from Adobe Illustrator (my vector drawing program of choice) into Raphael code is sparse, at best. Here is the process I used, hopefully it can be useful to others.\n\nBefore going any further, it is worth noting some of the shortcomings of the Raphaël library and SVGs in general in their current incarnation and implementation in web design. First and foremost is that SVGs, while widely supported, aren't universally supported. While Raphaël does a great job of supporting Internet Explorer 6 through Mobile Safari, older mobile browsers and any stock BlackBerry browser below OS6 or stock Android browser below Honeycomb mostly don't support SVGs, so the end user sees nothing. Another issue is that the SVGs that are created cannot be inserted into a page's CSS and cannot be tiled like normal images can, which may (and has) presented a problem doing a full migration from images to SVGs. The final consideration to take into account when using Raphaël is that each item you draw must be associated with a unique CSS ID. While that doesn't sound like a big limitation, especially for one off graphics like a logo or, in my case, Snugug, it does present a problem if you want to do repeating UI elements in SVG, like the tips of the flags on my main scroll. That being said, I've devised a way to to draw Raphaël elements based on a an item's class which doesn't require a fork of the library, which will be presented below.\n\nWe are going to need four tools open and running before we start. First, we're going to need our Illustrator file open, second, we are going to need the [Raphael SVG Import tool](https://github.com/wout/raphael-svg-import) from GitHub, third, our source code opened in an editor, and fourth, a good web browser to view our work in. While Firefox with Firebug is a tried and true method for many, I personally prefer [Google Chrome](http://www.google.com/chrome), so I will be using that for this guide.\n\nThe first thing that we need to do is prepare our Illustrator image for import into Raphaël. There really isn't a science to this part, it's more of an art. Because the process we're going to be using will make us copy each object that forms our drawing individually, the fewer the number of objects the better. In the case of Snugug (pictured below), I broke him down into pieces, each hand was one piece, each fingernail another, the base fur for each hand another, etc… My personal suggestion is to merge as many small like items together as you can. For instance, the base fur for the head is made up of a solid shape and hand drawn lines that come out; I merged these together to create one solid object. The following are important item to bare in mind when preparing your file:\n\n- Raphaël handles gradients differently than we would hope, and the importer doesn't handle them at all, so replace gradients, at least for the export, with solid colours.\n- Raphaël doesn't support any of the stylize effects (with the possible exception of rounded corners) so do not use any of them in your export\n- Raphaël doesn't support 3D transformations of any sort\n- Raphaël doesn't support textures\n- If your drawing doesn't follow the [KISS Principle](http://en.wikipedia.org/wiki/KISS_principle), it probably won't work in Raphaël.\n\n![Snugug in Illustrator](/images/illustrator-raphael-js-guide/snugug-in-illustrator.png)\n\nNow that we have a file that we're ready to export into Raphaël, we simply need to go to the Import Tool and open demo.html in our browser (again, I choose Google Chrome). In Illustrator, go to File->Save As. Choose SVG (sag) as your Format and press Save. You will get a dialogue box with SVG options. Keep them all as is, what we're interested in is the Show SVG Code… and Web Preview… buttons.\n\n![SVG Options](/images/illustrator-raphael-js-guide/svg-options.png)\n\nFirst, press Web Preview… to make sure what you're going to wind up with is actually what you want. If it is, press Show SVG Code… This is where the magic happens. A .txt file will open up with your SVG Code! What you need to do is copy the SVG code, so from `\u003Csvg>` down. From there, go to demo.html and press the Import SVG button. A prompt will come up to enter your SVG code. Paste your SVG code in and press enter.\n\n![Import SVG](/images/illustrator-raphael-js-guide/import-svg.png)\n\n![Paste Code In](/images/illustrator-raphael-js-guide/paste-code-in.png)\n\nCongratulations! You have your SVG into Raphaël code, but chances are it doesn't look quite right, just look at poor Snugug!\n\n![Poor Snugug!](/images/illustrator-raphael-js-guide/poor-snugug.png)\n\nNow it's okay that it's messed up a little bit, what's wrong is actually just fills and lines, which we are going to fix when we put this into code with attributes. What's most important, and what this step ultimately is all about, is getting the paths out of the Illustrator SVG file in a Raphaël friendly manner. What we're going to do is CRTL+Click (Windows, right click) on an element and press Inspect Element of one of our items\n\n![Inspect Elements](/images/illustrator-raphael-js-guide/inspect-elements.png)\n\nWhen you do that, Chrome will pop up it's Element Inspector. The Element Inspector is a great tool, as it gives you all of the styles of the item you've selected, nests nested items, and highlights what you're looking at in place. I've inspected the element of the main fur, so that's highlighted as well as what I'm looking at\n\n![The Whole Shebang](/images/illustrator-raphael-js-guide/the-whole-shebang.png)\n\nNow, Chrome makes this even better! That element that's selected, we can copy that out of the Element Inspector! Do just that by pressing CMD+C (CTRL+C on Windows) and paste that text into your favorite text editor. What you're going to get is a big ol' mess of junk, but really all we need to do to get this into a format that we can use with Raphaël is to remove the tags surrounding the path. The tags for Snugug's head look like this (yours will be similar, and please bear with me while my syntax highlighting is broken):\n\n```javascript\n\u003Cpath fill=\"#f7941e\" stroke=\"#000000\" d=  style=\"stroke-width: 0px; \" stroke-width=\"0\">\u003C/path>\n```\n\nThose two things will surround quotes with the path inside. The path will start with M and end with Z. After you've deleted those two things, you've got yourself a path you can use with Raphaël!\n\nOpen up your source HTML code, link Raphaël and [jQuery](http://www.jquery.com/) to it, and create a div tag with an ID that you want to import your Raphael code into! I'm going to call mine snugug-head.\n\n```html\n\u003Chtml>\n  \u003Chead>\n    \u003Ctitle>Illustrator to Raphaël Import\u003C/title>\n    \u003Cscript type=\"text/javascript\" src=\"raphael-min.js\">\u003C/script>\n    \u003Cscript\n      type=\"text/javascript\"\n      src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js\"\n    >\u003C/script>\n  \u003C/head>\n  \u003Cbody>\n    \u003Cdiv id=\"snugug-head\">\u003C/div>\n  \u003C/body>\n\u003C/html>\n```\n\nNext, we want to set up a script to draw our path when the DOM is ready. In normal JavaScript, kinda hard to do, that's why we're using jQuery. There are three ways to do this in jQuery, but the one I like the best is:\n\n```javascript\n$(function () {});\n```\n\nRemember, this needs to go inside `\u003Cscript>` tags or attached as a separate JavaScript file. Inside the DOM Ready function, we are going to create three variables, one for our canvas that we're going to be drawing one, one for our attributes so we can use the same attributes in multiple places, and one for our actual path. First, let's set up the canvas.\n\n```scss\nvar snugug_paper = Raphael(\"snugug-head\", 235, 145);\n```\n\nSo what we've done here is create a variable called snugug-paper, calling the Raphael function with parameters snugug-head, 235, and 145. Snugug-head is the name of the ID we're going to be drawing on, 235 is the width of the canvas we're going to be using (should be the same as the width of our artboard in Illustrator), and 145 is the heigh of the canvas we're going to be using (again, should be the same as the height of our artboard in Illustrator). Next, we're going to create a variable for the attributes for our path. We do this instead of hardcoding the attributes after the path for reusability.\n\n```javascript\nvar snugug_fur = {\n  fill: '#f7941e',\n  stroke: 'none',\n};\n```\n\nHere, I want to have a single fill colour and no stroke. For full documentation as to what attributes you can assign, please read the Raphaël Documentation (link to docs). Now we only have one more thing to do before we've got this path in! Let's create a variable for our head!\n\n```javascript\nvar snugug_head = snugug_paper\n  .path(\n    'M178.563,83.791C176.97899999999998,81.086,174.393 ~ C120.03,98.23,119.357,100.115,118.5,102.097Z',\n  )\n  .attr(snugug_fur);\n```\n\nWhat we've done here is created a variable (that, by the way, is now manipulatable) called snugug_head and assigned it as a path draw inside of snugug_paper with the path coordinates that we extracted before and the attributes as defined in snugug_fur. Test your website out and you should see your drawing!\n\n![Snugug Head](/images/illustrator-raphael-js-guide/snugug-head.png)\n\nThere ya go! To get the rest of your drawing into Raphael, follow the same process as we just did! Remember that more than one path can be drawn on one canvas! Have fun!","src/content/posts/illustrator-to-raphael-js-guide.md","95b6a7cd0e538f82",{"html":1433,"metadata":1434},"\u003Cp>Over the summer, I came across an absolutely wonderful JavaScript library called \u003Ca href=\"http://raphaeljs.com/\">Raphaël\u003C/a> that blew me away. Using some maths and some patience, Raphaël allows you to to draw Scalable Vector Graphics (SVGs) through code in any browser, from Internet Explorer 6 all the way up to Mobile Safari. So when I sat down to create my \u003Cdel>website\u003C/del> previous website design, I decided that I wanted to use Raphaël to build out the UI elements in my site that would otherwise be done using normal images. While that sounded great as a goal, it turned out to be harder than I had imagined it would be, in part due to information about getting graphics from Adobe Illustrator (my vector drawing program of choice) into Raphael code is sparse, at best. Here is the process I used, hopefully it can be useful to others.\u003C/p>\n\u003Cp>Before going any further, it is worth noting some of the shortcomings of the Raphaël library and SVGs in general in their current incarnation and implementation in web design. First and foremost is that SVGs, while widely supported, aren’t universally supported. While Raphaël does a great job of supporting Internet Explorer 6 through Mobile Safari, older mobile browsers and any stock BlackBerry browser below OS6 or stock Android browser below Honeycomb mostly don’t support SVGs, so the end user sees nothing. Another issue is that the SVGs that are created cannot be inserted into a page’s CSS and cannot be tiled like normal images can, which may (and has) presented a problem doing a full migration from images to SVGs. The final consideration to take into account when using Raphaël is that each item you draw must be associated with a unique CSS ID. While that doesn’t sound like a big limitation, especially for one off graphics like a logo or, in my case, Snugug, it does present a problem if you want to do repeating UI elements in SVG, like the tips of the flags on my main scroll. That being said, I’ve devised a way to to draw Raphaël elements based on a an item’s class which doesn’t require a fork of the library, which will be presented below.\u003C/p>\n\u003Cp>We are going to need four tools open and running before we start. First, we’re going to need our Illustrator file open, second, we are going to need the \u003Ca href=\"https://github.com/wout/raphael-svg-import\">Raphael SVG Import tool\u003C/a> from GitHub, third, our source code opened in an editor, and fourth, a good web browser to view our work in. While Firefox with Firebug is a tried and true method for many, I personally prefer \u003Ca href=\"http://www.google.com/chrome\">Google Chrome\u003C/a>, so I will be using that for this guide.\u003C/p>\n\u003Cp>The first thing that we need to do is prepare our Illustrator image for import into Raphaël. There really isn’t a science to this part, it’s more of an art. Because the process we’re going to be using will make us copy each object that forms our drawing individually, the fewer the number of objects the better. In the case of Snugug (pictured below), I broke him down into pieces, each hand was one piece, each fingernail another, the base fur for each hand another, etc… My personal suggestion is to merge as many small like items together as you can. For instance, the base fur for the head is made up of a solid shape and hand drawn lines that come out; I merged these together to create one solid object. The following are important item to bare in mind when preparing your file:\u003C/p>\n\u003Cul>\n\u003Cli>Raphaël handles gradients differently than we would hope, and the importer doesn’t handle them at all, so replace gradients, at least for the export, with solid colours.\u003C/li>\n\u003Cli>Raphaël doesn’t support any of the stylize effects (with the possible exception of rounded corners) so do not use any of them in your export\u003C/li>\n\u003Cli>Raphaël doesn’t support 3D transformations of any sort\u003C/li>\n\u003Cli>Raphaël doesn’t support textures\u003C/li>\n\u003Cli>If your drawing doesn’t follow the \u003Ca href=\"http://en.wikipedia.org/wiki/KISS_principle\">KISS Principle\u003C/a>, it probably won’t work in Raphaël.\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cimg src=\"/images/illustrator-raphael-js-guide/snugug-in-illustrator.png\" alt=\"Snugug in Illustrator\">\u003C/p>\n\u003Cp>Now that we have a file that we’re ready to export into Raphaël, we simply need to go to the Import Tool and open demo.html in our browser (again, I choose Google Chrome). In Illustrator, go to File->Save As. Choose SVG (sag) as your Format and press Save. You will get a dialogue box with SVG options. Keep them all as is, what we’re interested in is the Show SVG Code… and Web Preview… buttons.\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/illustrator-raphael-js-guide/svg-options.png\" alt=\"SVG Options\">\u003C/p>\n\u003Cp>First, press Web Preview… to make sure what you’re going to wind up with is actually what you want. If it is, press Show SVG Code… This is where the magic happens. A .txt file will open up with your SVG Code! What you need to do is copy the SVG code, so from \u003Ccode>&#x3C;svg>\u003C/code> down. From there, go to demo.html and press the Import SVG button. A prompt will come up to enter your SVG code. Paste your SVG code in and press enter.\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/illustrator-raphael-js-guide/import-svg.png\" alt=\"Import SVG\">\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/illustrator-raphael-js-guide/paste-code-in.png\" alt=\"Paste Code In\">\u003C/p>\n\u003Cp>Congratulations! You have your SVG into Raphaël code, but chances are it doesn’t look quite right, just look at poor Snugug!\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/illustrator-raphael-js-guide/poor-snugug.png\" alt=\"Poor Snugug!\">\u003C/p>\n\u003Cp>Now it’s okay that it’s messed up a little bit, what’s wrong is actually just fills and lines, which we are going to fix when we put this into code with attributes. What’s most important, and what this step ultimately is all about, is getting the paths out of the Illustrator SVG file in a Raphaël friendly manner. What we’re going to do is CRTL+Click (Windows, right click) on an element and press Inspect Element of one of our items\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/illustrator-raphael-js-guide/inspect-elements.png\" alt=\"Inspect Elements\">\u003C/p>\n\u003Cp>When you do that, Chrome will pop up it’s Element Inspector. The Element Inspector is a great tool, as it gives you all of the styles of the item you’ve selected, nests nested items, and highlights what you’re looking at in place. I’ve inspected the element of the main fur, so that’s highlighted as well as what I’m looking at\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/illustrator-raphael-js-guide/the-whole-shebang.png\" alt=\"The Whole Shebang\">\u003C/p>\n\u003Cp>Now, Chrome makes this even better! That element that’s selected, we can copy that out of the Element Inspector! Do just that by pressing CMD+C (CTRL+C on Windows) and paste that text into your favorite text editor. What you’re going to get is a big ol’ mess of junk, but really all we need to do to get this into a format that we can use with Raphaël is to remove the tags surrounding the path. The tags for Snugug’s head look like this (yours will be similar, and please bear with me while my syntax highlighting is broken):\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"javascript\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">path\u003C/span>\u003Cspan style=\"color:#A6E22E\"> fill\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"#f7941e\"\u003C/span>\u003Cspan style=\"color:#A6E22E\"> stroke\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"#000000\"\u003C/span>\u003Cspan style=\"color:#A6E22E\"> d\u003C/span>\u003Cspan style=\"color:#F44747\">=\u003C/span>\u003Cspan style=\"color:#A6E22E\">  style\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"stroke-width: 0px; \"\u003C/span>\u003Cspan style=\"color:#A6E22E\"> stroke-width\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"0\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">path\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Those two things will surround quotes with the path inside. The path will start with M and end with Z. After you’ve deleted those two things, you’ve got yourself a path you can use with Raphaël!\u003C/p>\n\u003Cp>Open up your source HTML code, link Raphaël and \u003Ca href=\"http://www.jquery.com/\">jQuery\u003C/a> to it, and create a div tag with an ID that you want to import your Raphael code into! I’m going to call mine snugug-head.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"html\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">html\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">head\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">title\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>Illustrator to Raphaël Import&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">title\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#A6E22E\"> type\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"text/javascript\"\u003C/span>\u003Cspan style=\"color:#A6E22E\"> src\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"raphael-min.js\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">      type\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"text/javascript\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">      src\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"https://ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    >&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">head\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">body\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#A6E22E\"> id\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"snugug-head\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">div\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  &#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">body\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">html\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Next, we want to set up a script to draw our path when the DOM is ready. In normal JavaScript, kinda hard to do, that’s why we’re using jQuery. There are three ways to do this in jQuery, but the one I like the best is:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"javascript\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">$\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">function\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> () {});\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Remember, this needs to go inside \u003Ccode>&#x3C;script>\u003C/code> tags or attached as a separate JavaScript file. Inside the DOM Ready function, we are going to create three variables, one for our canvas that we’re going to be drawing one, one for our attributes so we can use the same attributes in multiple places, and one for our actual path. First, let’s set up the canvas.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">var\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> snugug_paper = Raphael(\"snugug-head\", 235, 145);\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>So what we’ve done here is create a variable called snugug-paper, calling the Raphael function with parameters snugug-head, 235, and 145. Snugug-head is the name of the ID we’re going to be drawing on, 235 is the width of the canvas we’re going to be using (should be the same as the width of our artboard in Illustrator), and 145 is the heigh of the canvas we’re going to be using (again, should be the same as the height of our artboard in Illustrator). Next, we’re going to create a variable for the attributes for our path. We do this instead of hardcoding the attributes after the path for reusability.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"javascript\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">var\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> snugug_fur \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  fill: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'#f7941e'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  stroke: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'none'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">};\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Here, I want to have a single fill colour and no stroke. For full documentation as to what attributes you can assign, please read the Raphaël Documentation (link to docs). Now we only have one more thing to do before we’ve got this path in! Let’s create a variable for our head!\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"javascript\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">var\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> snugug_head \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> snugug_paper\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  .\u003C/span>\u003Cspan style=\"color:#A6E22E\">path\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">    'M178.563,83.791C176.97899999999998,81.086,174.393 ~ C120.03,98.23,119.357,100.115,118.5,102.097Z'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  )\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  .\u003C/span>\u003Cspan style=\"color:#A6E22E\">attr\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(snugug_fur);\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>What we’ve done here is created a variable (that, by the way, is now manipulatable) called snugug_head and assigned it as a path draw inside of snugug_paper with the path coordinates that we extracted before and the attributes as defined in snugug_fur. Test your website out and you should see your drawing!\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/illustrator-raphael-js-guide/snugug-head.png\" alt=\"Snugug Head\">\u003C/p>\n\u003Cp>There ya go! To get the rest of your drawing into Raphael, follow the same process as we just did! Remember that more than one path can be drawn on one canvas! Have fun!\u003C/p>",{"headings":1435,"localImagePaths":1436,"remoteImagePaths":1437,"frontmatter":1438,"imagePaths":1441},[],[],[],{"title":1425,"published":1439,"summary":1427,"categories":1440},"2011-03-01",[14,55,42],[],"in-search-of-dynamic-range",{"id":1442,"data":1444,"body":1448,"filePath":1449,"digest":1450,"rendered":1451},{"title":1445,"published":1446,"summary":1447},"In search of dynamic range",["Date","2024-12-09T00:00:00.000Z"],"Thoughts on my journey as a photographer and my search for dynamic range.","I took my first photography class in I _think_ sophomore year of high school. I shot with an old Minolta X-700, which I think belonged to my mom, almost exclusively on Kodak Tri-X 400 black and white film, which I processed myself in class. I learned about composition, the rule of thirds, light, shadow, and how aperture, shutter speed, and ISO all work together to adjust how you shoot and the effects you can achieve. I loved it, and was pretty good at it; I won an award for a negative process architecture shot I did. I have that shot framed and hanging in my office, with all of my printed and mounted images there, too, along with all of the negatives I've ever shot.\n\nI got my first digital camera my senior year of high school, a Sony DCS-T33, a tiny point and shoot with an internal optical zoom with Zeiss glass. I absolutely loved that camera, and took it with me on my [first trip to Europe](https://snugug.photography/france-and-italy-2006) during the summer between high school and college.\n\nMy next camera was a Canon 7D, my first DSLR; my best friend, who had gotten me into photography to begin with, had the 5D and, while I couldn't justify the price of one, I could afford a 7D (I still go to him for photography advice to this day; neither of us are professional photographers, but he and his wife use to shoot weddings). I remember trying to get my camera insured as part of my renter's insurance; when I told the agent the cost of my gear, he said I needed to get business insurance. I assured him that no, I swear, this is just a hobby. Photography may be one of the most expensive hobbies in the world, but it was just a hobby.\n\nIt was with my 7D that my digital photographic style started to emerge. I had heard about this technique, High Dynamic Range, or HDR, photography where you take pictures and different exposures, underexposing some shots, overexposing some others, and stitch them together digitally. This brings up the shadows and brings down the highlights, getting you a picture with more flat lighting, and an almost ethereal look, across your picture that's especially good for when there are harsh lighting conditions, like shooting out a brightly lit window where you want to get both the inside and the outside lit well (you see HDR images, usually really badly processed ones, in real estate listings for this reason). Our eyes have excellent dynamic range and can handle this well; cameras can't. I decided I liked this look, a lot, and basically since getting my 7D every picture I've taken has been in sets of 3, for me to then go back and stitch together into an HDR.\n\nMy subject of choice has always been landscape and architecture, so my next camera was a Canon 6D, my first (and last, so far) full-frame camera. It also had a built-in GPS for geotagging, seemingly custom-designed for my kinda of photography. I lugged that gear with me, eventually amassing a decent sized collection of Canon glass and gigabytes of images, mostly triples of the same picture, in my pursuit of the dynamic range I got from shooting HDRs. I even was doing panoramas; imagine shooting a 5 or 10 image sequence for a panorama, and each one of those being 3 pictures! 30 individual shots to make up a single final image! Each trip, needing to go through literally thousands of images. It was a lot.\n\nI eventually got tired of lugging all that gear around, when a new camera came on the scene, the Fujifilm X-T1. I immediately was drawn to this camera. Unlike almost every other digital camera system out there, it had full manual controls for ISO, shutter speed, and aperture, set up just like my old Minolta! Combined with a digital viewfinder that showed the changes in real time, it made shooting in manual fun and easy, bringing me so much joy that I didn't mind I was moving away from my (excellent) Canon lens collection and to a crop-frame sensor from a full-frame. Photography was fun again! I did something pretty wild with the switch, too. I only shot with a 27mm pancake (~35mm equivalent) _for years_. I have the amazing Canon 16-35mm which was my go-to landscape and photography lens, the stellar 18-135mm walkaround zoom, and the legendary 70-200mm behemoth that wouldn't feel out of place on the sidelines of a sporting event. And I walked away from all of that for the feel of manual controls. But you know what stayed? Shooting three of everything, just to get that dynamic range.\n\nAround this time, something interesting started happening. The photography adage \"the best camera is the one you have with you\" (which I've always incorrectly attributed to Ansel Adams but I've just learned was coined by Chase Jarvis, and relatively recently) started to really hit home for me. My X-T1 was great, I could really bring it just about anywhere, but the advanced processing that my iPhone was doing with each picture I took really made it so easy to get really great results. It was (and still is) doing the same kind of processing I was doing to make HDR images, just invisibly, always in the background, making every picture everyone takes look great. That's a great thing! But I also think it's changed how I view my photography.\n\nFor my birthday this year, I got a new Fujifilm X-T5, a camera I've been holding out for for years. With it, I got the 16-55mm f/2.8 lens, one of Fuji's best (and something I'm salty they _just_ updated like a month ago). I no longer need something small to shoot with, my phone is plenty good for an every day shooter, I wanted a setup to get back to photography my phone can't do. It was around this time I started putting together [snugug.photography](https://snugug.photography/) as a way to share what I've taken over the years. It had me (and I'm no where close to done) going through and re-editing many of my old photographs with my accumulated years of knowledge and my new eye. And a funny thing started happening.\n\nThe more I went back to my old photos, the more I wasn't liking the HDR rendering I had been doing. It was a lot of effort, and on my older camera systems, it was producing closer to the shots I had in my mind, but with what was coming out of my X-T5, it was more and more looking like bad real estate photography again. Maybe I've gotten better at editing my photos, maybe my style has changed, or maybe what I'm looking for has evolved with what I'm able to do with my phone, but all of a sudden the way I had been shooting for like 15 years didn't quite feel right anymore.\n\nI just got back from a trip to London where I decided to try an experiment; could I go the whole trip without shooting any bracketed shots for HDR. The answer is no, but I came close! My first day, my photos are only _ok_, but I started playing again. Without being concerned with stacking, I started playing with shutter speed and aperture to get daytime long exposures and better focus in on the subject I really wanted. On Day 2 I figured out how to enable the histogram in my viewfinder to make sure I wasn't blowing out my whites, and how my camera's built-in dynamic range settings work (you can boost the single-image dynamic range in-camera kind of like how phones do, provided you have a high enough ISO, all without taking multiple shots and stitching them together). I started using the camera's back panel LCD to get different shooting angles. I learned I've got about a 50% hit rate for hand-held 1s exposures between the image stabilization in my lens and my camera. I felt more connected to my camera, to what I was shooting. It was like I rediscovered tools I had forgotten about because I had been focused on this one particular style of shooting. I still shot about 1600 images in a week, but most of them weren't bracketed, they were just, well, photos! And the results?\n\nI'll have the album up some time this month, but _wow_. I've got some shots of stained glass windows where everything around it is black, classic _classic_ HDR territory, and my X-T5's built-in dynamic range is _so good_ I can pull those shadows up to see everything while my highlights don't get blown out. Every single one of the shots I did in my old HDR style looks just as good, if not better, without the stacking. Better still, I can output _actual_ high dynamic range images (where the difference between the black and whites are large, as opposed to where the lighting is flattened through bracketing) using my Fuji RAW files that I can't do with my preferred HDR merge tool, and I'm liking those more anyway.\n\nWe'll see what next year holds, but I think after shooting for over 20 years, I've finally found the dynamic range I've been looking for, and I couldn't be happier as a photographer.","src/content/posts/in-search-of-dynamic-range.md","3cd5e2f888b59362",{"html":1452,"metadata":1453},"\u003Cp>I took my first photography class in I \u003Cem>think\u003C/em> sophomore year of high school. I shot with an old Minolta X-700, which I think belonged to my mom, almost exclusively on Kodak Tri-X 400 black and white film, which I processed myself in class. I learned about composition, the rule of thirds, light, shadow, and how aperture, shutter speed, and ISO all work together to adjust how you shoot and the effects you can achieve. I loved it, and was pretty good at it; I won an award for a negative process architecture shot I did. I have that shot framed and hanging in my office, with all of my printed and mounted images there, too, along with all of the negatives I’ve ever shot.\u003C/p>\n\u003Cp>I got my first digital camera my senior year of high school, a Sony DCS-T33, a tiny point and shoot with an internal optical zoom with Zeiss glass. I absolutely loved that camera, and took it with me on my \u003Ca href=\"https://snugug.photography/france-and-italy-2006\">first trip to Europe\u003C/a> during the summer between high school and college.\u003C/p>\n\u003Cp>My next camera was a Canon 7D, my first DSLR; my best friend, who had gotten me into photography to begin with, had the 5D and, while I couldn’t justify the price of one, I could afford a 7D (I still go to him for photography advice to this day; neither of us are professional photographers, but he and his wife use to shoot weddings). I remember trying to get my camera insured as part of my renter’s insurance; when I told the agent the cost of my gear, he said I needed to get business insurance. I assured him that no, I swear, this is just a hobby. Photography may be one of the most expensive hobbies in the world, but it was just a hobby.\u003C/p>\n\u003Cp>It was with my 7D that my digital photographic style started to emerge. I had heard about this technique, High Dynamic Range, or HDR, photography where you take pictures and different exposures, underexposing some shots, overexposing some others, and stitch them together digitally. This brings up the shadows and brings down the highlights, getting you a picture with more flat lighting, and an almost ethereal look, across your picture that’s especially good for when there are harsh lighting conditions, like shooting out a brightly lit window where you want to get both the inside and the outside lit well (you see HDR images, usually really badly processed ones, in real estate listings for this reason). Our eyes have excellent dynamic range and can handle this well; cameras can’t. I decided I liked this look, a lot, and basically since getting my 7D every picture I’ve taken has been in sets of 3, for me to then go back and stitch together into an HDR.\u003C/p>\n\u003Cp>My subject of choice has always been landscape and architecture, so my next camera was a Canon 6D, my first (and last, so far) full-frame camera. It also had a built-in GPS for geotagging, seemingly custom-designed for my kinda of photography. I lugged that gear with me, eventually amassing a decent sized collection of Canon glass and gigabytes of images, mostly triples of the same picture, in my pursuit of the dynamic range I got from shooting HDRs. I even was doing panoramas; imagine shooting a 5 or 10 image sequence for a panorama, and each one of those being 3 pictures! 30 individual shots to make up a single final image! Each trip, needing to go through literally thousands of images. It was a lot.\u003C/p>\n\u003Cp>I eventually got tired of lugging all that gear around, when a new camera came on the scene, the Fujifilm X-T1. I immediately was drawn to this camera. Unlike almost every other digital camera system out there, it had full manual controls for ISO, shutter speed, and aperture, set up just like my old Minolta! Combined with a digital viewfinder that showed the changes in real time, it made shooting in manual fun and easy, bringing me so much joy that I didn’t mind I was moving away from my (excellent) Canon lens collection and to a crop-frame sensor from a full-frame. Photography was fun again! I did something pretty wild with the switch, too. I only shot with a 27mm pancake (~35mm equivalent) \u003Cem>for years\u003C/em>. I have the amazing Canon 16-35mm which was my go-to landscape and photography lens, the stellar 18-135mm walkaround zoom, and the legendary 70-200mm behemoth that wouldn’t feel out of place on the sidelines of a sporting event. And I walked away from all of that for the feel of manual controls. But you know what stayed? Shooting three of everything, just to get that dynamic range.\u003C/p>\n\u003Cp>Around this time, something interesting started happening. The photography adage “the best camera is the one you have with you” (which I’ve always incorrectly attributed to Ansel Adams but I’ve just learned was coined by Chase Jarvis, and relatively recently) started to really hit home for me. My X-T1 was great, I could really bring it just about anywhere, but the advanced processing that my iPhone was doing with each picture I took really made it so easy to get really great results. It was (and still is) doing the same kind of processing I was doing to make HDR images, just invisibly, always in the background, making every picture everyone takes look great. That’s a great thing! But I also think it’s changed how I view my photography.\u003C/p>\n\u003Cp>For my birthday this year, I got a new Fujifilm X-T5, a camera I’ve been holding out for for years. With it, I got the 16-55mm f/2.8 lens, one of Fuji’s best (and something I’m salty they \u003Cem>just\u003C/em> updated like a month ago). I no longer need something small to shoot with, my phone is plenty good for an every day shooter, I wanted a setup to get back to photography my phone can’t do. It was around this time I started putting together \u003Ca href=\"https://snugug.photography/\">snugug.photography\u003C/a> as a way to share what I’ve taken over the years. It had me (and I’m no where close to done) going through and re-editing many of my old photographs with my accumulated years of knowledge and my new eye. And a funny thing started happening.\u003C/p>\n\u003Cp>The more I went back to my old photos, the more I wasn’t liking the HDR rendering I had been doing. It was a lot of effort, and on my older camera systems, it was producing closer to the shots I had in my mind, but with what was coming out of my X-T5, it was more and more looking like bad real estate photography again. Maybe I’ve gotten better at editing my photos, maybe my style has changed, or maybe what I’m looking for has evolved with what I’m able to do with my phone, but all of a sudden the way I had been shooting for like 15 years didn’t quite feel right anymore.\u003C/p>\n\u003Cp>I just got back from a trip to London where I decided to try an experiment; could I go the whole trip without shooting any bracketed shots for HDR. The answer is no, but I came close! My first day, my photos are only \u003Cem>ok\u003C/em>, but I started playing again. Without being concerned with stacking, I started playing with shutter speed and aperture to get daytime long exposures and better focus in on the subject I really wanted. On Day 2 I figured out how to enable the histogram in my viewfinder to make sure I wasn’t blowing out my whites, and how my camera’s built-in dynamic range settings work (you can boost the single-image dynamic range in-camera kind of like how phones do, provided you have a high enough ISO, all without taking multiple shots and stitching them together). I started using the camera’s back panel LCD to get different shooting angles. I learned I’ve got about a 50% hit rate for hand-held 1s exposures between the image stabilization in my lens and my camera. I felt more connected to my camera, to what I was shooting. It was like I rediscovered tools I had forgotten about because I had been focused on this one particular style of shooting. I still shot about 1600 images in a week, but most of them weren’t bracketed, they were just, well, photos! And the results?\u003C/p>\n\u003Cp>I’ll have the album up some time this month, but \u003Cem>wow\u003C/em>. I’ve got some shots of stained glass windows where everything around it is black, classic \u003Cem>classic\u003C/em> HDR territory, and my X-T5’s built-in dynamic range is \u003Cem>so good\u003C/em> I can pull those shadows up to see everything while my highlights don’t get blown out. Every single one of the shots I did in my old HDR style looks just as good, if not better, without the stacking. Better still, I can output \u003Cem>actual\u003C/em> high dynamic range images (where the difference between the black and whites are large, as opposed to where the lighting is flattened through bracketing) using my Fuji RAW files that I can’t do with my preferred HDR merge tool, and I’m liking those more anyway.\u003C/p>\n\u003Cp>We’ll see what next year holds, but I think after shooting for over 20 years, I’ve finally found the dynamic range I’ve been looking for, and I couldn’t be happier as a photographer.\u003C/p>",{"headings":1454,"localImagePaths":1455,"remoteImagePaths":1456,"frontmatter":1457,"imagePaths":1459},[],[],[],{"title":1445,"published":1458,"summary":1447},"2024-12-09",[],"installing-sass-and-compass-across-all-platforms",{"id":1460,"data":1462,"body":1467,"filePath":1468,"digest":1469,"rendered":1470},{"title":1463,"published":1464,"summary":1465,"archived":1466},"Installing Sass and Compass Across All Platforms",["Date","2012-11-04T00:00:00.000Z"],"How to install Ruby Sass and Compass globally across Mac, Windows, and Linux.",true,"One of the most frequent questions that gets asked of me is how to install Sass+Compass across platform. Without further adue, here are the instructions for the three major platforms.\n\n## Mac\n\nFortunately for us Mac users, Ruby and Ruby Gems comes pre-installed on our systems. Installing Sass+Compass is as easy as the following:\n\n```bash\nsudo gem install compass\n```\n\nYou will be asked to type in your user password. Do so, press enter, and you've got Sass+Compass installed.\n\n## Windows\n\nWindows is a little bit more complicated, but not particularly. Go to [RubyInstaller](http://rubyinstaller.org/), download the installer, and follow the wizard. It will install a program called \"Start Command Prompt with Ruby\"; open it and type in the following:\n\n```bash\ngem install compass\n```\n\n## Linux/Unix\n\nLinux/Unix systems are a little bit harder. These instructions assume that you've got access to `apt-get` installed. Open up your terminal and type in the following:\n\n```bash\nsudo apt-get install ruby-full build-essential\n```\n\n```bash\nsudo apt-get install rubygems\n```\n\n```bash\nexport PATH=/var/lib/gems/1.8/bin:$PATH\nsudo gem install compass\n```\n\nDone and done! Enjoy Sass+Compass!","src/content/posts/installing-sass-and-compass-across-all-platforms.md","a8b36fc7f305eae5",{"html":1471,"metadata":1472},"\u003Cp>One of the most frequent questions that gets asked of me is how to install Sass+Compass across platform. Without further adue, here are the instructions for the three major platforms.\u003C/p>\n\u003Ch2 id=\"mac\">Mac\u003C/h2>\n\u003Cp>Fortunately for us Mac users, Ruby and Ruby Gems comes pre-installed on our systems. Installing Sass+Compass is as easy as the following:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">sudo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> gem\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> compass\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>You will be asked to type in your user password. Do so, press enter, and you’ve got Sass+Compass installed.\u003C/p>\n\u003Ch2 id=\"windows\">Windows\u003C/h2>\n\u003Cp>Windows is a little bit more complicated, but not particularly. Go to \u003Ca href=\"http://rubyinstaller.org/\">RubyInstaller\u003C/a>, download the installer, and follow the wizard. It will install a program called “Start Command Prompt with Ruby”; open it and type in the following:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">gem\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> compass\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"linuxunix\">Linux/Unix\u003C/h2>\n\u003Cp>Linux/Unix systems are a little bit harder. These instructions assume that you’ve got access to \u003Ccode>apt-get\u003C/code> installed. Open up your terminal and type in the following:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">sudo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> apt-get\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> ruby-full\u003C/span>\u003Cspan style=\"color:#E6DB74\"> build-essential\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">sudo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> apt-get\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> rubygems\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">export\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> PATH\u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\">/var/lib/gems/1.8/bin:$PATH\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">sudo\u003C/span>\u003Cspan style=\"color:#E6DB74\"> gem\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> compass\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Done and done! Enjoy Sass+Compass!\u003C/p>",{"headings":1473,"localImagePaths":1483,"remoteImagePaths":1484,"frontmatter":1485,"imagePaths":1487},[1474,1477,1480],{"depth":80,"slug":1475,"text":1476},"mac","Mac",{"depth":80,"slug":1478,"text":1479},"windows","Windows",{"depth":80,"slug":1481,"text":1482},"linuxunix","Linux/Unix",[],[],{"title":1463,"published":1486,"summary":1465,"archived":1466},"2012-11-04",[],"introducing-breakpoint-media-queries-made-easy",{"id":1488,"data":1490,"body":1494,"filePath":1495,"digest":1496,"rendered":1497},{"title":1491,"published":1492,"summary":1493},"Introducing Breakpoint: Media Queries Made Easy",["Date","2012-06-27T00:00:00.000Z"],"Introducing Breakpoint, a Sass extension for making writing and maintaining media queries a breeze.","As anyone who has done Responsive Web Design will tell you, keeping track of your content based breakpoints ain't so easy. If you're writing plain old CSS, you would need to have a separate file or scattered inline comments telling you what each each number was meant for. Hell, even if you're using Sass, you're probably doing something similar… until now! Introducing [Breakpoint](https://github.com/canarymason/breakpoint); Media Queries Made Easy.\n\nBreakpoint is a [Compass Extension](http://compass-style.org) jointly developed by [Mason Wendell](http://thecodingdesigner.com/) and myself with the aim of solving your media query fatigue. Designed with a mobile first, future friendly mindset, Breakpoint will help you simplify and keep track of your most common media queries while remaining powerful and flexible enough to write any complex, compound media query you'd ever want. First, let's get you installed.\n\n```bash\ngem install breakpoint\n```\n\nIf you're creating a new project using Compass, you can require breakpoint from the get go, otherwise you're going to need to require it from your config.rb file.\n\n```bash\ncompass create \u003Cmy_project> -r breakpoint\n```\n\n```ruby\nrequire 'breakpoint'\n```\n\nFinally, import the Breakpoint partial at the top of your working file, or into your Base partial.\n\n```scss\n@import 'breakpoint';\n```\n\nThere you go! You now are ready to start using Breakpoint! Let's get started.\n\n## The Options\n\nBreakpoint comes with a few default options that you can change to suit your development needs.\n\n`$breakpoint-default-media` - This is the default media type you're targeting. We've made this 'all' so that your media queries apply everywhere, regardless of if you're on a handheld, screen, tv, etc… You can override this for all of your media queries by changing this, or override them on an individual basis by passing a secondary option into the breakpoint mixin for your media type.\n\n`$breakpoint-default-feature` - This is the default feature you're querying against. We've made this 'min-width' as we feel this is both the most common media query you're going to use, and is the proper mobile-first approach (as opposed to max-width). This feature gets used when Breakpoint sees your query is a single number. You can override this for all of your media queries by changing this, or override them on an individual basis by including the feature you want to query against when calling the breakpoint mixin.\n\n`$breakpoint-default-pair` - This is the default feature you're querying against when you pass in two numbers to the breakpoint mixin. This will prepend the min- and max- to the feature you want to use to create a min/max pair. We've made this 'width'. You can override this for all of your media queries by changing this, or override them on an individual basis by including the base feature (without min/max) you want to query against when calling the breakpoint mixin.\n\n`$breakpoint-to-ems` - Now here's my favorite option for Breakpoint. I know that it's much easier to think in PX, and much easier to get screen dimensions in PX, than it is in EMs, even though I know I should be writing all of my Media Queries in EMs for greater accessibility and future friendliness. By default this is set to _false_, but by setting it to _true_, you can write your media queries in whatever units you want, PX, %, or PT, and they will all be converted to EMs! How cool is that?\n\n## Cross Browser Compatibility\n\nBesides the awesome `$breakpoint-to-ems`, we've added in a little bonus to help make your media queries against high resolution devices cross browser compatible. Instead of querying `-webkit-device-pixel-ratio`, `-moz-device-pixel-ratio`, and `-o-device-pixel-ratio`, all of which have different, nonstandard syntaxes, you can query against simply `device-pixel-ratio` and we'll convert it into the standard `resolution` query for you! Fear not though, if you really want the prefixed versions, you can still use them for individual queries, but they won't work for min/max queries; we encourage you to use `device-pixel-ratio` for that.\n\n## Shut Up and Take My Media Queries!\n\nShow me how to use the damn thing already! Okay! What we're going to be doing is creating variables that we can name whatever we want with the features and values we want. Let's say our login form breaks at three different places, we can create the following three variables (I like prefixing breakpoint variables with bkpt, but it's not needed):\n\n```scss\n$bkpt-login-small: 370px;\n$bkpt-login-medium: 490px;\n$bkpt-login-large: 865px;\n```\n\nThen, in our Sass, we'd call the breakpoint media query with our variable, and we're set! Remember, we're building this Mobile First, so our first breakpoint is really our second set of rules!\n\n```scss\n#login {\n  background: red;\n\n  @include breakpoint($bkpt-login-small) {\n    background: orange;\n  }\n\n  @include breakpoint($bkpt-login-medium) {\n    background: yellow;\n  }\n\n  @include breakpoint($bkpt-login-large) {\n    background: green;\n  }\n}\n```\n\nAnd the CSS that it spits out? Super clean, super simple.\n\n```scss\n#login {\n  background: red;\n}\n\n@media (min-width: 370px) {\n  #foo {\n    background: orange;\n  }\n}\n\n@media (min-width: 490px) {\n  #foo {\n    background: yellow;\n  }\n}\n\n@media (min-width: 865px) {\n  #foo {\n    background: green;\n  }\n}\n```\n\nAnd if we've got `$breakpoint-to-ems` turned on?\n\n```scss\n#login {\n  background: red;\n}\n\n@media (min-width: 23.125em) {\n  #foo {\n    background: orange;\n  }\n}\n\n@media (min-width: 30.625em) {\n  #foo {\n    background: yellow;\n  }\n}\n\n@media (min-width: 54.0625em) {\n  #foo {\n    background: green;\n  }\n}\n```\n\nThat should cover 90% of your media queries, but you can get a little crazy if you want. Say you want to query between two values of a feature? Easy squeazy lemon peaty.\n\n```scss\n$bkpt-medium-not-wide: 500px 700px;\n$bkpt-medium-heigh: 300px 700px 'height';\n\n#foo {\n  color: purple;\n  background: yellow;\n\n  @include breakpoint($bkpt-medium-not-wide) {\n    color: blue;\n  }\n\n  @include breakpoint($bkpt-medium-height, 'screen') {\n    background: red;\n  }\n}\n```\n\nBecomes:\n\n```scss\n#foo {\n  color: purple;\n  background: yellow;\n}\n\n@media (min-width: 500px) and (max-width: 700px) {\n  #foo {\n    color: blue;\n  }\n}\n\n@media screen and (min-height: 300px) and (max-height: 700px) {\n  #foo {\n    background: red;\n  }\n}\n```\n\nFor more examples, check out [Breakpoint's Read Me](https://github.com/canarymason/breakpoint/blob/master/README.markdown). If you have any questions, ping either [@Snugug](http://twitter.com/#!/snugug) (me) or [@CodingDesigner](http://twitter.com/#!/codingdesigner) (Mason) on Twitter or leave a ticket for us on [GitHub](https://github.com/canarymason/breakpoint/issues).\n\nHappy coding, and may the Sass be with you!","src/content/posts/introducing-breakpoint-media-queries-made-easy.md","4880461ae5e1f234",{"html":1498,"metadata":1499},"\u003Cp>As anyone who has done Responsive Web Design will tell you, keeping track of your content based breakpoints ain’t so easy. If you’re writing plain old CSS, you would need to have a separate file or scattered inline comments telling you what each each number was meant for. Hell, even if you’re using Sass, you’re probably doing something similar… until now! Introducing \u003Ca href=\"https://github.com/canarymason/breakpoint\">Breakpoint\u003C/a>; Media Queries Made Easy.\u003C/p>\n\u003Cp>Breakpoint is a \u003Ca href=\"http://compass-style.org\">Compass Extension\u003C/a> jointly developed by \u003Ca href=\"http://thecodingdesigner.com/\">Mason Wendell\u003C/a> and myself with the aim of solving your media query fatigue. Designed with a mobile first, future friendly mindset, Breakpoint will help you simplify and keep track of your most common media queries while remaining powerful and flexible enough to write any complex, compound media query you’d ever want. First, let’s get you installed.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">gem\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> breakpoint\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>If you’re creating a new project using Compass, you can require breakpoint from the get go, otherwise you’re going to need to require it from your config.rb file.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">compass\u003C/span>\u003Cspan style=\"color:#E6DB74\"> create\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x3C;\u003C/span>\u003Cspan style=\"color:#E6DB74\">my_projec\u003C/span>\u003Cspan style=\"color:#F8F8F2\">t\u003C/span>\u003Cspan style=\"color:#F92672\">>\u003C/span>\u003Cspan style=\"color:#AE81FF\"> -r\u003C/span>\u003Cspan style=\"color:#E6DB74\"> breakpoint\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"ruby\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">require\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'breakpoint'\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Finally, import the Breakpoint partial at the top of your working file, or into your Base partial.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'breakpoint'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>There you go! You now are ready to start using Breakpoint! Let’s get started.\u003C/p>\n\u003Ch2 id=\"the-options\">The Options\u003C/h2>\n\u003Cp>Breakpoint comes with a few default options that you can change to suit your development needs.\u003C/p>\n\u003Cp>\u003Ccode>$breakpoint-default-media\u003C/code> - This is the default media type you’re targeting. We’ve made this ‘all’ so that your media queries apply everywhere, regardless of if you’re on a handheld, screen, tv, etc… You can override this for all of your media queries by changing this, or override them on an individual basis by passing a secondary option into the breakpoint mixin for your media type.\u003C/p>\n\u003Cp>\u003Ccode>$breakpoint-default-feature\u003C/code> - This is the default feature you’re querying against. We’ve made this ‘min-width’ as we feel this is both the most common media query you’re going to use, and is the proper mobile-first approach (as opposed to max-width). This feature gets used when Breakpoint sees your query is a single number. You can override this for all of your media queries by changing this, or override them on an individual basis by including the feature you want to query against when calling the breakpoint mixin.\u003C/p>\n\u003Cp>\u003Ccode>$breakpoint-default-pair\u003C/code> - This is the default feature you’re querying against when you pass in two numbers to the breakpoint mixin. This will prepend the min- and max- to the feature you want to use to create a min/max pair. We’ve made this ‘width’. You can override this for all of your media queries by changing this, or override them on an individual basis by including the base feature (without min/max) you want to query against when calling the breakpoint mixin.\u003C/p>\n\u003Cp>\u003Ccode>$breakpoint-to-ems\u003C/code> - Now here’s my favorite option for Breakpoint. I know that it’s much easier to think in PX, and much easier to get screen dimensions in PX, than it is in EMs, even though I know I should be writing all of my Media Queries in EMs for greater accessibility and future friendliness. By default this is set to \u003Cem>false\u003C/em>, but by setting it to \u003Cem>true\u003C/em>, you can write your media queries in whatever units you want, PX, %, or PT, and they will all be converted to EMs! How cool is that?\u003C/p>\n\u003Ch2 id=\"cross-browser-compatibility\">Cross Browser Compatibility\u003C/h2>\n\u003Cp>Besides the awesome \u003Ccode>$breakpoint-to-ems\u003C/code>, we’ve added in a little bonus to help make your media queries against high resolution devices cross browser compatible. Instead of querying \u003Ccode>-webkit-device-pixel-ratio\u003C/code>, \u003Ccode>-moz-device-pixel-ratio\u003C/code>, and \u003Ccode>-o-device-pixel-ratio\u003C/code>, all of which have different, nonstandard syntaxes, you can query against simply \u003Ccode>device-pixel-ratio\u003C/code> and we’ll convert it into the standard \u003Ccode>resolution\u003C/code> query for you! Fear not though, if you really want the prefixed versions, you can still use them for individual queries, but they won’t work for min/max queries; we encourage you to use \u003Ccode>device-pixel-ratio\u003C/code> for that.\u003C/p>\n\u003Ch2 id=\"shut-up-and-take-my-media-queries\">Shut Up and Take My Media Queries!\u003C/h2>\n\u003Cp>Show me how to use the damn thing already! Okay! What we’re going to be doing is creating variables that we can name whatever we want with the features and values we want. Let’s say our login form breaks at three different places, we can create the following three variables (I like prefixing breakpoint variables with bkpt, but it’s not needed):\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">$bkpt-login-small: \u003C/span>\u003Cspan style=\"color:#AE81FF\">370\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">$bkpt-login-medium: \u003C/span>\u003Cspan style=\"color:#AE81FF\">490\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">$bkpt-login-large: \u003C/span>\u003Cspan style=\"color:#AE81FF\">865\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Then, in our Sass, we’d call the breakpoint media query with our variable, and we’re set! Remember, we’re building this Mobile First, so our first breakpoint is really our second set of rules!\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">#login\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> breakpoint\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bkpt-login-small) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">orange\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> breakpoint\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bkpt-login-medium) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">yellow\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> breakpoint\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bkpt-login-large) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>And the CSS that it spits out? Super clean, super simple.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">#login\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">370\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">orange\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">490\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">yellow\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">865\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>And if we’ve got \u003Ccode>$breakpoint-to-ems\u003C/code> turned on?\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">#login\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">23.125\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">orange\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">30.625\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">yellow\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">54.0625\u003C/span>\u003Cspan style=\"color:#F92672\">em\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>That should cover 90% of your media queries, but you can get a little crazy if you want. Say you want to query between two values of a feature? Easy squeazy lemon peaty.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">$bkpt-medium-not-wide: \u003C/span>\u003Cspan style=\"color:#AE81FF\">500\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">$bkpt-medium-heigh: \u003C/span>\u003Cspan style=\"color:#AE81FF\">300\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'height'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">#foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">purple\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">yellow\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> breakpoint\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bkpt-medium-not-wide) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">blue\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> breakpoint\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bkpt-medium-height, \u003C/span>\u003Cspan style=\"color:#E6DB74\">'screen'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Becomes:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">#foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">purple\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">yellow\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">500\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) \u003C/span>\u003Cspan style=\"color:#F92672\">and\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">max-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    color\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">blue\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#66D9EF\"> screen\u003C/span>\u003Cspan style=\"color:#F92672\"> and\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">300\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) \u003C/span>\u003Cspan style=\"color:#F92672\">and\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">max-height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>For more examples, check out \u003Ca href=\"https://github.com/canarymason/breakpoint/blob/master/README.markdown\">Breakpoint’s Read Me\u003C/a>. If you have any questions, ping either \u003Ca href=\"http://twitter.com/#!/snugug\">@Snugug\u003C/a> (me) or \u003Ca href=\"http://twitter.com/#!/codingdesigner\">@CodingDesigner\u003C/a> (Mason) on Twitter or leave a ticket for us on \u003Ca href=\"https://github.com/canarymason/breakpoint/issues\">GitHub\u003C/a>.\u003C/p>\n\u003Cp>Happy coding, and may the Sass be with you!\u003C/p>",{"headings":1500,"localImagePaths":1510,"remoteImagePaths":1511,"frontmatter":1512,"imagePaths":1514},[1501,1504,1507],{"depth":80,"slug":1502,"text":1503},"the-options","The Options",{"depth":80,"slug":1505,"text":1506},"cross-browser-compatibility","Cross Browser Compatibility",{"depth":80,"slug":1508,"text":1509},"shut-up-and-take-my-media-queries","Shut Up and Take My Media Queries!",[],[],{"title":1491,"published":1513,"summary":1493},"2012-06-27",[],"introducing-starchart-studio",{"id":1515,"data":1517,"body":1521,"filePath":1522,"digest":1523,"rendered":1524},{"title":1518,"published":1519,"summary":1520},"Introducing Starchart Studio",["Date","2023-01-01T00:00:00.000Z"],"Introducing Starchart Studio, a component story tool for island architectures, powered by Astro","As hinted at on [Mastodon](https://mas.to/@snugug/109600326798344614), I've gone ahead and releaesd the first preview version of [**Starchart Studio**](https://www.npmjs.com/package/starchart-studio) - a component story tool similar to [Storybook](https://storybook.js.org/) designed for island architectures and powered by [Astro](https://astro.build/).\n\nWhy yet another story tool? Good question!\n\nWhen looking to integrate a tools like Storybook into a recent Astro project, I kept on running into hurdles or DX decisions I didn't love: most seem designed with SPA architectures in mind, support for various frameworks felt limited (usually React or Vue first), and none supported Astro components, which were going to make up a large portion of my Astro project. I wanted something that would work with anything I was likely to throw at it and didn't require tight coupling. So, as I'm likely to do, I made a thing.\n\n## Solving only the hard stuff\n\nAstro was a great starting place: it has built-in dynamic page and component rendering, a robust component model, support for lots of JS frameworks out-of-the-box, and is super flexible. Building a story tool on top of it was mostly defining a content model and DX patterns with very little novel code needing to be written. This left me with only really needing to \"solve the hard stuff\", aka Starchart's logic and DX. For that, I really only needed to figure out:\n\n- How to generate both stand-alone previews and full-story pages for one story input (1 to n page generation with different layouts)\n- How to list all components without asking the developer for duplicate work\n- How to connect state to components in a dynamic way\n\n### From one, many\n\nThe biggest \"bit\" of a story tool is having two or more views of the same story: the fully-featured story page and a stand-alone iframed page for the component to sit in isolation. I wanted to keep basic component stories to a single file, so I settled on [Astro's MDX integration](https://docs.astro.build/en/guides/integrations-guide/mdx/) as a base for stories. This allows developers to write Markdown documentation while also exporting an object with configuration, including a component that can be passed around and rendered. When [globbed](https://docs.astro.build/en/reference/api-reference/#markdown-files), they come with a bunch of useful properties, too, which can be used to build out robust systems if not used directly to generate pages.\n\nOne of properties is `file`. When combined with [`getStaticPaths`](https://docs.astro.build/en/reference/api-reference/#getstaticpaths) and dynamic params in filenames, you can create multiple related pages from a single input. Because this function is run server-side from Node, you can use Node built-ins without worry, like `path`. I grab the basename of the file, and generate two entries in `getStaticPaths`, one for the isolated component, and one for the fully-featured story page. I can even have different properties that get passed to those components (from `Astro.props`) from this, making it possible to further change exactly what's available on the page. This includes signaling if the page should be inline and, if so, choosing a different layout. The main `Starchart.astro` component basically exists to do just that:\n\n```jsx\n{\n  story.inline ? (\n    \u003CInlineStory\n      Component={story.Component}\n      props={story.properties}\n      slug={story.slug}\n    />\n  ) : (\n    \u003CBlockStory\n      Component={story.Component}\n      {...story.properties}\n      chart={chart}\n    />\n  );\n}\n```\n\n`chart`, in the above code sample, is actually the list of all components, and their URLs, ready to be made into nav of some sort. Getting this from an individual page is kinda tricky; `getStaticPaths` runs in isolation so it's hard to capture the glob and reuse it. When you use Starchart's `getStaticPaths` function, you're actually calling a method on a singleton class instance; that lets me save the results to a property and recall them during other function calls, which you make [to set up the story](\u003Chttps://github.com/Snugug/starchart-studio/tree/e3157140b472929f4e8666944d75dbd3c05bb8d8#:~:text=const%20starchart%20%3D%20StarchartStudio.chart(Astro)%3B>). As a side note, a singleton class to hold state is a pattern I find myself using quite often when with JS modules.\n\n### Dealing with state\n\nWith this basic setup and the built-in component model, I had prop-only components rendering! Inputs couldn't be changed, but I considered that a fair tradeoff considering they're designed to not be once loaded. But sometimes you have state, and that posed problems.\n\nI knew developers would need to define functions to connect form updates to their state management of choice, but Astros' [`define:vars`](https://docs.astro.build/en/reference/directives-reference/#definevars) for passing variables into script tags stringifies everything, so no functions allowed. While I maybe could work around this with an `exec`, it was strike one. Next, the system works using [dynamic tags](https://docs.astro.build/en/core-concepts/astro-components/#dynamic-tags) to render the component, but dynamic tags can't be hydrated. This unfortunately took me a while of spinning to realize; as it's only mentioned under dynamic tags and not in the hydration docs, but I got there. That was strike two. One more and this whole thing collapses. But fortunately, Astro's component model, while a hinderance here, actually saved me.\n\nSee, Astro is all about mixing islands of interactivity with static content. This means that you can make a static Astro component that has hydrated components in it, and that works fine. Because that component doesn't need to be hydrated, _it_ can then be dynamically loaded. And thus, a simple, if slightly inelegant, solution emerged: hydrated components need to be wrapped in a static component. We'll pass you all the props you need to render your component, just swap the direct component call in your story for your wrapped one. This also provides a clear place to add Starchart-specific code for managing state and events without coupling it into your production component.\n\nThe last bit is pretty straight-forward: the isolated component lives in an iframe, so `postmessage` to send data across that border, with a couple of custom events and some developer-facing helper functions to manage it all for them, so they just need to write how their state changes when it comes it.\n\n## Finishing touches and what's next\n\nThe last bit I added was a width slider to the preview area, inspired by Brad Frost's [ish.](https://bradfrost.com/blog/post/ish/). I absolutely loved ish. during my early responsive web design days, and with the rise of container queries, I feel like it's time to shine is once again here, but this time for components. I've started with a basic implementation, changing width, but I think I'd like to add height, too, and the size buttons: small-ish, medium-ish, large-ish, xl-ish, and of course, the disco mode.\n\nI also want to add the ability to include variants for a component. I haven't quite figured out how to do that yet, but with my solution for building inline pages squared away, it'll probably be a variation (get it, _get it_) on that.\n\nFinally, this needs some visual polish. I'll get to that.\n\nAnd a website. Every good OSS project these days has a website.\n\n## Putting it all together\n\nWith all of that, I've release version 0.2.1 (because no good initial release goes without an immediate point fix) of [Starchart Studio](https://www.npmjs.com/package/starchart-studio). The README has how to use it and the [repo](https://github.com/snugug/starchart-studio) has a working demo in the `src` directory. If you try it out, LMK!\n\n\u003Cvideo src=\"https://media.mas.to/masto-public/media_attachments/files/109/600/305/812/185/840/original/c1be52a89c8f86ac.mp4\" role=\"button\" tabindex=\"0\" aria-label=\"Screen recording of Astro-powered story tool in action. Starts with a card component, shows what props are available for the component, a description of the component, and a preview of the component in an iFrame, which is shown being resized on drag. Next switches to a counter component that shows both props and state, which is updated as the component is changed and when the state form item is changed.\" title=\"Screen recording of Astro-powered story tool in action. Starts with a card component, shows what props are available for the component, a description of the component, and a preview of the component in an iFrame, which is shown being resized on drag. Next switches to a counter component that shows both props and state, which is updated as the component is changed and when the state form item is changed.\" loop=\"\" autoplay=\"\" playsinline=\"\" style=\"position: static; top: 0px; left: 0px;\">\u003C/video>","src/content/posts/introducing-starchart-studio.md","59595adc66127e82",{"html":1525,"metadata":1526},"\u003Cp>As hinted at on \u003Ca href=\"https://mas.to/@snugug/109600326798344614\">Mastodon\u003C/a>, I’ve gone ahead and releaesd the first preview version of \u003Ca href=\"https://www.npmjs.com/package/starchart-studio\">\u003Cstrong>Starchart Studio\u003C/strong>\u003C/a> - a component story tool similar to \u003Ca href=\"https://storybook.js.org/\">Storybook\u003C/a> designed for island architectures and powered by \u003Ca href=\"https://astro.build/\">Astro\u003C/a>.\u003C/p>\n\u003Cp>Why yet another story tool? Good question!\u003C/p>\n\u003Cp>When looking to integrate a tools like Storybook into a recent Astro project, I kept on running into hurdles or DX decisions I didn’t love: most seem designed with SPA architectures in mind, support for various frameworks felt limited (usually React or Vue first), and none supported Astro components, which were going to make up a large portion of my Astro project. I wanted something that would work with anything I was likely to throw at it and didn’t require tight coupling. So, as I’m likely to do, I made a thing.\u003C/p>\n\u003Ch2 id=\"solving-only-the-hard-stuff\">Solving only the hard stuff\u003C/h2>\n\u003Cp>Astro was a great starting place: it has built-in dynamic page and component rendering, a robust component model, support for lots of JS frameworks out-of-the-box, and is super flexible. Building a story tool on top of it was mostly defining a content model and DX patterns with very little novel code needing to be written. This left me with only really needing to “solve the hard stuff”, aka Starchart’s logic and DX. For that, I really only needed to figure out:\u003C/p>\n\u003Cul>\n\u003Cli>How to generate both stand-alone previews and full-story pages for one story input (1 to n page generation with different layouts)\u003C/li>\n\u003Cli>How to list all components without asking the developer for duplicate work\u003C/li>\n\u003Cli>How to connect state to components in a dynamic way\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"from-one-many\">From one, many\u003C/h3>\n\u003Cp>The biggest “bit” of a story tool is having two or more views of the same story: the fully-featured story page and a stand-alone iframed page for the component to sit in isolation. I wanted to keep basic component stories to a single file, so I settled on \u003Ca href=\"https://docs.astro.build/en/guides/integrations-guide/mdx/\">Astro’s MDX integration\u003C/a> as a base for stories. This allows developers to write Markdown documentation while also exporting an object with configuration, including a component that can be passed around and rendered. When \u003Ca href=\"https://docs.astro.build/en/reference/api-reference/#markdown-files\">globbed\u003C/a>, they come with a bunch of useful properties, too, which can be used to build out robust systems if not used directly to generate pages.\u003C/p>\n\u003Cp>One of properties is \u003Ccode>file\u003C/code>. When combined with \u003Ca href=\"https://docs.astro.build/en/reference/api-reference/#getstaticpaths\">\u003Ccode>getStaticPaths\u003C/code>\u003C/a> and dynamic params in filenames, you can create multiple related pages from a single input. Because this function is run server-side from Node, you can use Node built-ins without worry, like \u003Ccode>path\u003C/code>. I grab the basename of the file, and generate two entries in \u003Ccode>getStaticPaths\u003C/code>, one for the isolated component, and one for the fully-featured story page. I can even have different properties that get passed to those components (from \u003Ccode>Astro.props\u003C/code>) from this, making it possible to further change exactly what’s available on the page. This includes signaling if the page should be inline and, if so, choosing a different layout. The main \u003Ccode>Starchart.astro\u003C/code> component basically exists to do just that:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"jsx\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">{\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  story.inline \u003C/span>\u003Cspan style=\"color:#F92672\">?\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">InlineStory\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">      Component\u003C/span>\u003Cspan style=\"color:#F92672\">={\u003C/span>\u003Cspan style=\"color:#F8F8F2\">story.Component\u003C/span>\u003Cspan style=\"color:#F92672\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">      props\u003C/span>\u003Cspan style=\"color:#F92672\">={\u003C/span>\u003Cspan style=\"color:#F8F8F2\">story.properties\u003C/span>\u003Cspan style=\"color:#F92672\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">      slug\u003C/span>\u003Cspan style=\"color:#F92672\">={\u003C/span>\u003Cspan style=\"color:#F8F8F2\">story.slug\u003C/span>\u003Cspan style=\"color:#F92672\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    />\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  ) \u003C/span>\u003Cspan style=\"color:#F92672\">:\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    &#x3C;\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">BlockStory\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">      Component\u003C/span>\u003Cspan style=\"color:#F92672\">={\u003C/span>\u003Cspan style=\"color:#F8F8F2\">story.Component\u003C/span>\u003Cspan style=\"color:#F92672\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">      {...\u003C/span>\u003Cspan style=\"color:#F8F8F2\">story.properties\u003C/span>\u003Cspan style=\"color:#F92672\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">      chart\u003C/span>\u003Cspan style=\"color:#F92672\">={\u003C/span>\u003Cspan style=\"color:#F8F8F2\">chart\u003C/span>\u003Cspan style=\"color:#F92672\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    />\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  );\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>\u003Ccode>chart\u003C/code>, in the above code sample, is actually the list of all components, and their URLs, ready to be made into nav of some sort. Getting this from an individual page is kinda tricky; \u003Ccode>getStaticPaths\u003C/code> runs in isolation so it’s hard to capture the glob and reuse it. When you use Starchart’s \u003Ccode>getStaticPaths\u003C/code> function, you’re actually calling a method on a singleton class instance; that lets me save the results to a property and recall them during other function calls, which you make \u003Ca href=\"https://github.com/Snugug/starchart-studio/tree/e3157140b472929f4e8666944d75dbd3c05bb8d8#:~:text=const%20starchart%20%3D%20StarchartStudio.chart(Astro)%3B\">to set up the story\u003C/a>. As a side note, a singleton class to hold state is a pattern I find myself using quite often when with JS modules.\u003C/p>\n\u003Ch3 id=\"dealing-with-state\">Dealing with state\u003C/h3>\n\u003Cp>With this basic setup and the built-in component model, I had prop-only components rendering! Inputs couldn’t be changed, but I considered that a fair tradeoff considering they’re designed to not be once loaded. But sometimes you have state, and that posed problems.\u003C/p>\n\u003Cp>I knew developers would need to define functions to connect form updates to their state management of choice, but Astros’ \u003Ca href=\"https://docs.astro.build/en/reference/directives-reference/#definevars\">\u003Ccode>define:vars\u003C/code>\u003C/a> for passing variables into script tags stringifies everything, so no functions allowed. While I maybe could work around this with an \u003Ccode>exec\u003C/code>, it was strike one. Next, the system works using \u003Ca href=\"https://docs.astro.build/en/core-concepts/astro-components/#dynamic-tags\">dynamic tags\u003C/a> to render the component, but dynamic tags can’t be hydrated. This unfortunately took me a while of spinning to realize; as it’s only mentioned under dynamic tags and not in the hydration docs, but I got there. That was strike two. One more and this whole thing collapses. But fortunately, Astro’s component model, while a hinderance here, actually saved me.\u003C/p>\n\u003Cp>See, Astro is all about mixing islands of interactivity with static content. This means that you can make a static Astro component that has hydrated components in it, and that works fine. Because that component doesn’t need to be hydrated, \u003Cem>it\u003C/em> can then be dynamically loaded. And thus, a simple, if slightly inelegant, solution emerged: hydrated components need to be wrapped in a static component. We’ll pass you all the props you need to render your component, just swap the direct component call in your story for your wrapped one. This also provides a clear place to add Starchart-specific code for managing state and events without coupling it into your production component.\u003C/p>\n\u003Cp>The last bit is pretty straight-forward: the isolated component lives in an iframe, so \u003Ccode>postmessage\u003C/code> to send data across that border, with a couple of custom events and some developer-facing helper functions to manage it all for them, so they just need to write how their state changes when it comes it.\u003C/p>\n\u003Ch2 id=\"finishing-touches-and-whats-next\">Finishing touches and what’s next\u003C/h2>\n\u003Cp>The last bit I added was a width slider to the preview area, inspired by Brad Frost’s \u003Ca href=\"https://bradfrost.com/blog/post/ish/\">ish.\u003C/a>. I absolutely loved ish. during my early responsive web design days, and with the rise of container queries, I feel like it’s time to shine is once again here, but this time for components. I’ve started with a basic implementation, changing width, but I think I’d like to add height, too, and the size buttons: small-ish, medium-ish, large-ish, xl-ish, and of course, the disco mode.\u003C/p>\n\u003Cp>I also want to add the ability to include variants for a component. I haven’t quite figured out how to do that yet, but with my solution for building inline pages squared away, it’ll probably be a variation (get it, \u003Cem>get it\u003C/em>) on that.\u003C/p>\n\u003Cp>Finally, this needs some visual polish. I’ll get to that.\u003C/p>\n\u003Cp>And a website. Every good OSS project these days has a website.\u003C/p>\n\u003Ch2 id=\"putting-it-all-together\">Putting it all together\u003C/h2>\n\u003Cp>With all of that, I’ve release version 0.2.1 (because no good initial release goes without an immediate point fix) of \u003Ca href=\"https://www.npmjs.com/package/starchart-studio\">Starchart Studio\u003C/a>. The README has how to use it and the \u003Ca href=\"https://github.com/snugug/starchart-studio\">repo\u003C/a> has a working demo in the \u003Ccode>src\u003C/code> directory. If you try it out, LMK!\u003C/p>\n\u003Cp>\u003Cvideo src=\"https://media.mas.to/masto-public/media_attachments/files/109/600/305/812/185/840/original/c1be52a89c8f86ac.mp4\" role=\"button\" tabindex=\"0\" aria-label=\"Screen recording of Astro-powered story tool in action. Starts with a card component, shows what props are available for the component, a description of the component, and a preview of the component in an iFrame, which is shown being resized on drag. Next switches to a counter component that shows both props and state, which is updated as the component is changed and when the state form item is changed.\" title=\"Screen recording of Astro-powered story tool in action. Starts with a card component, shows what props are available for the component, a description of the component, and a preview of the component in an iFrame, which is shown being resized on drag. Next switches to a counter component that shows both props and state, which is updated as the component is changed and when the state form item is changed.\" loop autoplay playsinline style=\"position: static; top: 0px; left: 0px;\">\u003C/video>\u003C/p>",{"headings":1527,"localImagePaths":1543,"remoteImagePaths":1544,"frontmatter":1545,"imagePaths":1547},[1528,1531,1534,1537,1540],{"depth":80,"slug":1529,"text":1530},"solving-only-the-hard-stuff","Solving only the hard stuff",{"depth":904,"slug":1532,"text":1533},"from-one-many","From one, many",{"depth":904,"slug":1535,"text":1536},"dealing-with-state","Dealing with state",{"depth":80,"slug":1538,"text":1539},"finishing-touches-and-whats-next","Finishing touches and what’s next",{"depth":80,"slug":1541,"text":1542},"putting-it-all-together","Putting it all together",[],[],{"title":1518,"published":1546,"summary":1520},"2023-01-01",[],"introducing-susy-next",{"id":1548,"data":1550,"body":1555,"filePath":1556,"digest":1557,"rendered":1558},{"title":1551,"published":1552,"updated":1553,"summary":1554,"archived":1466},"Introducing Susy Next",["Date","2013-01-29T00:00:00.000Z"],["Date","2013-04-03T00:00:00.000Z"],"As of April 3, 2013, Singularity is no longer being merged with Susy and is still being separately maintained. The original article is kept as a record.",":::message{.warning}\n**Update 1/04/2014**\n\nAt the time of this article's writing, Susy Next was to be the successor to Singularity. As of April 3rd of last year, the previous update, that is no longer the case. The two projects have taken divergent paths and pretty much this entire article is out of date. Both Susy Next and Singularity are being developed separately and both are still active projects.\n:::\n\n:::message{.warning}\n**Update 4/03/2013**\n\nWhile work on Susy Next continues, Scott and I have decided that there is room for Singularity and have restarted development on it, having [released a 1.0](http://snugug.com/musings/singularity-10). As such, right now, my recommendation is to use Singularity 1.0.\n:::\n\n\u003Chr>\n\nThis morning, at around 1am EST, the [Susy Next team](http://oddbird.net/2013/01/01/susy-next/) released the first alpha of of Susy Next. As [Eric says](http://oddbird.net/2013/01/29/susy-next-alpha-1/), this release is very sparse with really only the math engine in place; no user facing sugar, no tutorials, some functions uncommented, no documentation, nothing. The closest you'll get to a walkthrough of the power of what Susy Next can do is by taking a look at the code in the [test](https://github.com/ericam/susy/tree/susy-next/test) folder of the [Susy Next](https://github.com/ericam/susy/tree/susy-next) branch. To install it, type the following into your command line (you may need to `sudo` it)\n\n```bash\ngem install susy --pre\n```\n\nWe've released it in this state for a few reasons, but the biggest one is to get it into the hands of our users and have them rip it apart. Please, do! We want Susy Next to be the most flexible, user friendly, awesome grid system not only available for Sass, but any grid system. The goal of Susy Next is to provide the math and the logic for you to build the grids you want and you need, but in order to do that, we need your feedback. The things we'd like the most feedback on are the `add-grid` and `add-gutter` syntaxes, and the `span` syntax that you can see on [line 39 of `test/scss/math.scss`](https://github.com/ericam/susy/blob/susy-next/test/scss/math.scss). Line 39 and line 43 produce the same results. We encourage you to play, break, have fun, and post your thoughts to the [Susy Issue Queue](https://github.com/ericam/susy/issues?state=open) and tag them with the _Susy Next_ tag.\n\nSusy Next is a big leap forward for Susy. We have introduced asymmetric grids to the mix, integrated [Breakpoint](http://breakpoint-sass.com/) for media queries and no-query fallbacks, and are introducing a new natural language syntax to the mix to make working with Susy more semantic and user friendly (don't worry, if you like the good old fashioned quick and dirty direct method, that's still available). We're also developing Susy Next with extensibility in mind, setting the stage for a full output API for different output methods (it ships with both [Float and Isolation](http://snugug.com/musings/on-responsive-designs-dirty-little-secret) methods), which you can take a look at in both [`_api.scss`](https://github.com/ericam/susy/blob/susy-next/sass/susy/_api.scss) and [the `api`](https://github.com/ericam/susy/tree/susy-next/sass/susy/api) folders. We also encourage the community to go and build extensions they find useful, like a way to write class classes based on your grid, or Flexbox support, or [off-canvas](http://oddbird.net/2012/11/27/susy-off-canvas/) plugins; anything you can think of! Expect to hear more on Susy Next plugins in the coming weeks and months.\n\n### What Does This Mean For Singularity\n\nI've got some good news and I've got some bad news. Bad news first; now that we've got a working stable version of the Susy Next math engine, development has more or less totally stopped on Singularity and soon Scott and I will probably deprecate Singularity in the coming weeks. This means that no new development will happen on Singularity, although there may be crossports from Susy Next. The good news? Susy Next has 100% API compatibility with Singularity. Your grid and gutter definitions, as well as media queries and no-query fallbacks, your grid-spans and gutter-spans, they all work and all have the same API. We've simplified some of it, and we've dropped Padding support for the time being, so some of the additional parameter you've passed in if you're doing really advanced things aren't available, class output isn't built (but you can build it as a Susy Next plugin!), and lit/rtl and desktop-first development isn't finished yet on the current build of Susy Next (it's coming), but other than that, you shouldn't really need to change anything! So fear not loyal Singularity fan! While the name may be going away, the heart stays.","src/content/posts/introducing-susy-next.md","08d485c2a128c16e",{"html":1559,"metadata":1560},"\u003Cdiv class=\"warning message\" data-type=\"warning\">\u003Cp>\u003Cstrong>Update 1/04/2014\u003C/strong>\u003C/p>\u003Cp>At the time of this article’s writing, Susy Next was to be the successor to Singularity. As of April 3rd of last year, the previous update, that is no longer the case. The two projects have taken divergent paths and pretty much this entire article is out of date. Both Susy Next and Singularity are being developed separately and both are still active projects.\u003C/p>\u003C/div>\n\u003Cdiv class=\"warning message\" data-type=\"warning\">\u003Cp>\u003Cstrong>Update 4/03/2013\u003C/strong>\u003C/p>\u003Cp>While work on Susy Next continues, Scott and I have decided that there is room for Singularity and have restarted development on it, having \u003Ca href=\"http://snugug.com/musings/singularity-10\">released a 1.0\u003C/a>. As such, right now, my recommendation is to use Singularity 1.0.\u003C/p>\u003C/div>\n\u003Chr>\n\u003Cp>This morning, at around 1am EST, the \u003Ca href=\"http://oddbird.net/2013/01/01/susy-next/\">Susy Next team\u003C/a> released the first alpha of of Susy Next. As \u003Ca href=\"http://oddbird.net/2013/01/29/susy-next-alpha-1/\">Eric says\u003C/a>, this release is very sparse with really only the math engine in place; no user facing sugar, no tutorials, some functions uncommented, no documentation, nothing. The closest you’ll get to a walkthrough of the power of what Susy Next can do is by taking a look at the code in the \u003Ca href=\"https://github.com/ericam/susy/tree/susy-next/test\">test\u003C/a> folder of the \u003Ca href=\"https://github.com/ericam/susy/tree/susy-next\">Susy Next\u003C/a> branch. To install it, type the following into your command line (you may need to \u003Ccode>sudo\u003C/code> it)\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">gem\u003C/span>\u003Cspan style=\"color:#E6DB74\"> install\u003C/span>\u003Cspan style=\"color:#E6DB74\"> susy\u003C/span>\u003Cspan style=\"color:#AE81FF\"> --pre\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>We’ve released it in this state for a few reasons, but the biggest one is to get it into the hands of our users and have them rip it apart. Please, do! We want Susy Next to be the most flexible, user friendly, awesome grid system not only available for Sass, but any grid system. The goal of Susy Next is to provide the math and the logic for you to build the grids you want and you need, but in order to do that, we need your feedback. The things we’d like the most feedback on are the \u003Ccode>add-grid\u003C/code> and \u003Ccode>add-gutter\u003C/code> syntaxes, and the \u003Ccode>span\u003C/code> syntax that you can see on \u003Ca href=\"https://github.com/ericam/susy/blob/susy-next/test/scss/math.scss\">line 39 of \u003Ccode>test/scss/math.scss\u003C/code>\u003C/a>. Line 39 and line 43 produce the same results. We encourage you to play, break, have fun, and post your thoughts to the \u003Ca href=\"https://github.com/ericam/susy/issues?state=open\">Susy Issue Queue\u003C/a> and tag them with the \u003Cem>Susy Next\u003C/em> tag.\u003C/p>\n\u003Cp>Susy Next is a big leap forward for Susy. We have introduced asymmetric grids to the mix, integrated \u003Ca href=\"http://breakpoint-sass.com/\">Breakpoint\u003C/a> for media queries and no-query fallbacks, and are introducing a new natural language syntax to the mix to make working with Susy more semantic and user friendly (don’t worry, if you like the good old fashioned quick and dirty direct method, that’s still available). We’re also developing Susy Next with extensibility in mind, setting the stage for a full output API for different output methods (it ships with both \u003Ca href=\"http://snugug.com/musings/on-responsive-designs-dirty-little-secret\">Float and Isolation\u003C/a> methods), which you can take a look at in both \u003Ca href=\"https://github.com/ericam/susy/blob/susy-next/sass/susy/_api.scss\">\u003Ccode>_api.scss\u003C/code>\u003C/a> and \u003Ca href=\"https://github.com/ericam/susy/tree/susy-next/sass/susy/api\">the \u003Ccode>api\u003C/code>\u003C/a> folders. We also encourage the community to go and build extensions they find useful, like a way to write class classes based on your grid, or Flexbox support, or \u003Ca href=\"http://oddbird.net/2012/11/27/susy-off-canvas/\">off-canvas\u003C/a> plugins; anything you can think of! Expect to hear more on Susy Next plugins in the coming weeks and months.\u003C/p>\n\u003Ch3 id=\"what-does-this-mean-for-singularity\">What Does This Mean For Singularity\u003C/h3>\n\u003Cp>I’ve got some good news and I’ve got some bad news. Bad news first; now that we’ve got a working stable version of the Susy Next math engine, development has more or less totally stopped on Singularity and soon Scott and I will probably deprecate Singularity in the coming weeks. This means that no new development will happen on Singularity, although there may be crossports from Susy Next. The good news? Susy Next has 100% API compatibility with Singularity. Your grid and gutter definitions, as well as media queries and no-query fallbacks, your grid-spans and gutter-spans, they all work and all have the same API. We’ve simplified some of it, and we’ve dropped Padding support for the time being, so some of the additional parameter you’ve passed in if you’re doing really advanced things aren’t available, class output isn’t built (but you can build it as a Susy Next plugin!), and lit/rtl and desktop-first development isn’t finished yet on the current build of Susy Next (it’s coming), but other than that, you shouldn’t really need to change anything! So fear not loyal Singularity fan! While the name may be going away, the heart stays.\u003C/p>",{"headings":1561,"localImagePaths":1565,"remoteImagePaths":1566,"frontmatter":1567,"imagePaths":1570},[1562],{"depth":904,"slug":1563,"text":1564},"what-does-this-mean-for-singularity","What Does This Mean For Singularity",[],[],{"title":1551,"published":1568,"summary":1554,"updated":1569,"archived":1466},"2013-01-29","2013-04-03",[],"it-all-started-our-motion-designer",{"id":1571,"data":1573,"body":1577,"filePath":1578,"digest":1579,"rendered":1580},{"title":1574,"published":1575,"summary":1576},"It all started with our motion designer.",["Date","2015-06-06T00:00:00.000Z"],"Our team transformation all started with our motion designer…","It all started with our motion designer.\n\nHe thought that if he was going to make recommendations on how to animate on the Web, that he should learn how to do that, and try it himself. He asked our developer for help and she happily jumped right in. She built a little scaffold for him to use to get up and running quickly and taught him some basics, including how to get his stuff versioned with Git. He got excited and ran with it. He talked about it, he raved about it. It took our visual designer about 2 days of hearing him enthuse about it to get curious. On her own, she set up the scaffolding late one night. Her excitement could barely be contained in her group message. When she got in to work, she paired with our motion designer to learn Git. They both started working in code as well as in their design tools. This all happened within the first week of moving our team from an old waterfall, static comp first workflow to an agile, all encompassing one. Within a month, they had both submitted their first pull requests _ever_. Within two months, they had become such large advocates that they got our UX designer and primary researcher not only up to speed, but submitting her first pull request ever – she's become one of our most prolific contributors since. Three months in, and everyone from research to design to development to product and project management are all working together, in the same system, happy and in browser. They are also genuinely curious about the whole process, from content strategy through back end development.\n\nThree months ago, there was a lot of tension on our team. We had tried Agile (note the capital A) in the past, specifically Scrum, and we felt like it drug us down. I'm remote, and that took a toll on communication and trust because it was hard to get a hold of me to talk. It was hard to build relationships with each other because it's hard to have watercooler-type chat when you're 1500 miles from your team.\n\nSo, what changed?\n\nThe first change was ripping out traditional project management tools. For the speed we wanted to move, we needed something more nimble. Our goal was constant, transparent, indexed communication and feedback, and that's hard with heavy tools that are decoupled from the place you're working. Our code already lived on GitHub and its issue system is super robust, so we moved our process there. We created a style guide for issue tags to help organize everything. Each of our issues usually gets between three and five tags that change and move as the issue evolves.\n\nThe second change was adopting a real-time persistent text chat and communication platform. This may have been the most instrumental change in our team. Any time of day, from anywhere, we could all hang out and chat just like we were all in the same room. We pushed changes from GitHub into the chat, so we were all always up-to-date with what was happening. We were able to have structured conversations and not-so-structured conversations. Between GitHub and our chat room, we removed the need to have daily standup meetings, relegating it to a `#standup` hashtag in our chat. We stopped sending email, meetings basically evaporated, video chat and screen sharing was used to pair with each other when text chat wasn't enough. The team dynamic transformed from one where we were working not to get in each other's way to one where we were truly collaborating with each other in real-time. Our visual designer commented that this is the fastest she's ever received feedback on her work (the moment it's done, at its height 5+ times a day). Our UX designer joked that the team now talks more to me than they do with each other (and they're sitting next to each other).\n\nThe third change was adopting some Continuous Integration and Delivery practices, specifically automated testing and deployment practices. When we first deployed our CI system about half way through our project, our tests were failing. By this time, our team had gotten comfortable with most of our process, but this was new. Within two days of our CI system popping in to your chat room to announce that a PR had failed its tests, our team had come to _hate_ failing tests without needing to teach everyone what they were! When our tests finally went green, we had a mini celebration! Now we talk about our CI system like it's part of our team, happy when it's green, angry when it's red, and frustrated when a build errors, but we all intrinsically understand its importance. While so far I've been the only one to deploy the site, doing so doesn't require me; anyone from my team can simply merge in to `master` and deploy the site.\n\nSo, what have we learned from all of this? First and foremost, having designers work in code only works if they're enthusiastic to do so. Share your enthusiasm, and they'll see it and become enthusiastic too. Second, don't add structure to your process for structure's sake. Each team works differently, add only the structure they need to do their job. Use existing processes for guidance, but not everything from all process will work for every team. Third, get everyone talking about the same thing, at the same time, on the same tools, using as few tools as physically needed. Different tools for different people means knowledge is split and no one's ever able to truly get comfortable and happy with one of them. Find tools that work for how your team works, and build your process around that, not the other way around. Finally, push your team, but in doing so, give them the support and room to grow. You're asking them to put themselves out there, and that's hard for anyone to do. Many tools and things in our process were introduced gradually. If the process wasn't followed exactly, we let it slide and kept moving, knowing that we saw what happened and could learn from it. Individuals will grow at different rates, be okay with that. Delivering value is more important than following a process or using a certain set of tools or techniques. The easiest way for a team to do that will shake out as you and your team grow together. Pushing your team to grow personally will build their skills, let all individuals shine, and help you find what truly works best.\n\nTransforming your team starts with a spark, but grows from within. Don't force the spark to define your team, instead, let it inspire them.","src/content/posts/it-all-started-our-motion-designer.md","faed08c5ae6220f8",{"html":1581,"metadata":1582},"\u003Cp>It all started with our motion designer.\u003C/p>\n\u003Cp>He thought that if he was going to make recommendations on how to animate on the Web, that he should learn how to do that, and try it himself. He asked our developer for help and she happily jumped right in. She built a little scaffold for him to use to get up and running quickly and taught him some basics, including how to get his stuff versioned with Git. He got excited and ran with it. He talked about it, he raved about it. It took our visual designer about 2 days of hearing him enthuse about it to get curious. On her own, she set up the scaffolding late one night. Her excitement could barely be contained in her group message. When she got in to work, she paired with our motion designer to learn Git. They both started working in code as well as in their design tools. This all happened within the first week of moving our team from an old waterfall, static comp first workflow to an agile, all encompassing one. Within a month, they had both submitted their first pull requests \u003Cem>ever\u003C/em>. Within two months, they had become such large advocates that they got our UX designer and primary researcher not only up to speed, but submitting her first pull request ever – she’s become one of our most prolific contributors since. Three months in, and everyone from research to design to development to product and project management are all working together, in the same system, happy and in browser. They are also genuinely curious about the whole process, from content strategy through back end development.\u003C/p>\n\u003Cp>Three months ago, there was a lot of tension on our team. We had tried Agile (note the capital A) in the past, specifically Scrum, and we felt like it drug us down. I’m remote, and that took a toll on communication and trust because it was hard to get a hold of me to talk. It was hard to build relationships with each other because it’s hard to have watercooler-type chat when you’re 1500 miles from your team.\u003C/p>\n\u003Cp>So, what changed?\u003C/p>\n\u003Cp>The first change was ripping out traditional project management tools. For the speed we wanted to move, we needed something more nimble. Our goal was constant, transparent, indexed communication and feedback, and that’s hard with heavy tools that are decoupled from the place you’re working. Our code already lived on GitHub and its issue system is super robust, so we moved our process there. We created a style guide for issue tags to help organize everything. Each of our issues usually gets between three and five tags that change and move as the issue evolves.\u003C/p>\n\u003Cp>The second change was adopting a real-time persistent text chat and communication platform. This may have been the most instrumental change in our team. Any time of day, from anywhere, we could all hang out and chat just like we were all in the same room. We pushed changes from GitHub into the chat, so we were all always up-to-date with what was happening. We were able to have structured conversations and not-so-structured conversations. Between GitHub and our chat room, we removed the need to have daily standup meetings, relegating it to a \u003Ccode>#standup\u003C/code> hashtag in our chat. We stopped sending email, meetings basically evaporated, video chat and screen sharing was used to pair with each other when text chat wasn’t enough. The team dynamic transformed from one where we were working not to get in each other’s way to one where we were truly collaborating with each other in real-time. Our visual designer commented that this is the fastest she’s ever received feedback on her work (the moment it’s done, at its height 5+ times a day). Our UX designer joked that the team now talks more to me than they do with each other (and they’re sitting next to each other).\u003C/p>\n\u003Cp>The third change was adopting some Continuous Integration and Delivery practices, specifically automated testing and deployment practices. When we first deployed our CI system about half way through our project, our tests were failing. By this time, our team had gotten comfortable with most of our process, but this was new. Within two days of our CI system popping in to your chat room to announce that a PR had failed its tests, our team had come to \u003Cem>hate\u003C/em> failing tests without needing to teach everyone what they were! When our tests finally went green, we had a mini celebration! Now we talk about our CI system like it’s part of our team, happy when it’s green, angry when it’s red, and frustrated when a build errors, but we all intrinsically understand its importance. While so far I’ve been the only one to deploy the site, doing so doesn’t require me; anyone from my team can simply merge in to \u003Ccode>master\u003C/code> and deploy the site.\u003C/p>\n\u003Cp>So, what have we learned from all of this? First and foremost, having designers work in code only works if they’re enthusiastic to do so. Share your enthusiasm, and they’ll see it and become enthusiastic too. Second, don’t add structure to your process for structure’s sake. Each team works differently, add only the structure they need to do their job. Use existing processes for guidance, but not everything from all process will work for every team. Third, get everyone talking about the same thing, at the same time, on the same tools, using as few tools as physically needed. Different tools for different people means knowledge is split and no one’s ever able to truly get comfortable and happy with one of them. Find tools that work for how your team works, and build your process around that, not the other way around. Finally, push your team, but in doing so, give them the support and room to grow. You’re asking them to put themselves out there, and that’s hard for anyone to do. Many tools and things in our process were introduced gradually. If the process wasn’t followed exactly, we let it slide and kept moving, knowing that we saw what happened and could learn from it. Individuals will grow at different rates, be okay with that. Delivering value is more important than following a process or using a certain set of tools or techniques. The easiest way for a team to do that will shake out as you and your team grow together. Pushing your team to grow personally will build their skills, let all individuals shine, and help you find what truly works best.\u003C/p>\n\u003Cp>Transforming your team starts with a spark, but grows from within. Don’t force the spark to define your team, instead, let it inspire them.\u003C/p>",{"headings":1583,"localImagePaths":1584,"remoteImagePaths":1585,"frontmatter":1586,"imagePaths":1588},[],[],[],{"title":1574,"published":1587,"summary":1576},"2015-06-06",[],"lighthouse-web-performance-architecture-and-you",{"id":1589,"data":1591,"body":1595,"filePath":1596,"digest":1597,"rendered":1598},{"title":1592,"published":1593,"summary":1594},"Lighthouse, Web Performance, Architecture, And You",["Date","2018-03-07T00:00:00.000Z"],"A primer on how the performance auditing tool Lighthouse works, thoughts on web performance and was of improving it, and how the two can be used as a basis for architectural discussions.","In my most recent project, I've been using Google's Lighthouse audit tool to understand the performance profile of what I'm building. I wound up getting our target pages to around a 97 performance _without_ the use of many of the advanced performance techniques usually required, and without Service Workers. We accomplished this by keeping performance as a key audit in all the work we delivered, and heavily leveraging knowledge of Lighthouse and Web Performance from the inception of our project, influencing everything down to our architecture. Sharing this high-level knowledge will hopefully make it easier for others to do the same.\n\n## What is Lighthouse, and How It Works\n\n[Lighthouse](https://github.com/GoogleChrome/lighthouse) is a performance audit tool available as a Chrome extension, Node module, and under the Audit tab in Chrome's Dev Tools built by Google's Chrome team (world-recognized as leading experts on web performance in the world). Lighthouse performs the following 4 audits, all on a scale from 1-100 (100 being the best):\n\n- **Progressive Web App** - Percentage of items from Google's [Progressive Web App Checklist](https://developers.google.com/web/progressive-web-apps/checklist) that are complete\n- **Performance** - Grade based on the user-centered [RAIL Performance Model](https://developers.google.com/web/fundamentals/performance/rail) and real-world performance work the Chrome team, and other experts on web performance around the world, have done, as well as how browsers handle the rendering of a page. The _Focus on the user_ section of perception of performance delays comes from direct research they and others have done on the limits of human perception. The recommendations in RAIL stem from those perceptions.\n- **Accessibility** - Percentage of the provided selection of automated accessibility provided by the [aXe](https://github.com/dequelabs/axe-core) accessibility testing engine that pass. Importantly, these are not all of the accessibility tests that _can_ be run by aXe, and they only cover things that can be tested through automation; many aspects of accessibility testing cannot be tested automatically.\n- **Best Practices** - Roughly the percentage of the provided modern best practices the Chrome team recommends websites implement.\n\nWhen running tests, Lighthouse by default runs from a cold cache (no files in cache), emulating 3G networks speeds and average mobile device hardware by throttling the network and slowing down the CPU by 4x from the machine's default speed. The reason this is done is to attempt to emulate real-world browsing conditions for users on average mobile hardware (slow networks, slow hardware, small and likely flushed caches); the fastest growing, and in many areas, largest demographic of Internet users. Worldwide performance experts emphasize this group both for that reason and, much like mobile-first responsive web design, making a website perform under those constraints will result in excellent experiences on other combinations, where the reverse is not strictly true. Globally, expert performance recommendations and expectations are built on this model, as well as the performance perception concepts presented in RAIL.\n\nWhen including a Progressive Web App audit, Lighthouse will run multiple tests to see how a site performs offline with a warm cache.\n\nAny Chrome extensions you may have in place that may affect what is loaded on a page (such as ad or tracking blockers) will apply to Lighthouse tests, so be cognizant of that when running lighthouse tests. For the most accurate audit, I recommend running Lighthouse from a live website in a state with no chrome extensions (except Lighthouse) enabled; incognito mode is good for this.\n\nWithin Lighthouse's **Performance** metrics, there are a handful of specific numbers that may not make sense immediately:\n\n- **First Meaningful Paint** - The number of `ms` it takes for the primary content of a page to be rendered\n- **First Contentful Paint** - The number of `ms` it takes for _any_ content defined in the DOM (text, images, a canvas render, etc…) to be rendered. This is [on track to be added to Lighthouse](https://github.com/GoogleChrome/lighthouse/issues/4629) but not in what's presented below\n- **First Interactive** - The number of `ms` it takes (to the start of the timeframe)for the main JS thread to be idle enough to handle user input. In an upcoming version of Lighthouse, this will be likely be renamed to something like _First Idle_\n- **Consistently Interactive** - The number of `ms` it takes to the start of 5 full seconds of network and main thread idle time (see the [Time to Interactive definition from the original PR](https://github.com/GoogleChrome/lighthouse/commit/d0d38292d4fa0ee6b552b750dc8130b85563ac3b) for how this is calculated). In an upcoming version of Lighthouse, this will likely be renamed to _Time to Interactive_ (or TTI)\n- **Perceptual Speed Index** - A score based on then the perception of a complete page render is calculated, as well as a weighted score compared to an ideal Speed Index based on RAIL. See the [Official WebPagetest Speed Index Documentation](https://sites.google.com/a/webpagetest.org/docs/using-webpagetest/metrics/speed-index) for how the metric is calculated works.\n- **Estimated Input Latency** - The estimated number of `ms` it takes for an user input request to trigger a response, as well as a score compared to an ideal input latency based on RAIL. The value provided describes is the 90th Percentile, so it's estimating that 90% of inputs will have the provided latency or less, while 10% will have this latency or more. [It describes](https://github.com/GoogleChrome/lighthouse/issues/28) the availability of the main thread as a proxy metric for input latency.\n\n## Understanding Web Performance and Where to Optimize\n\nOne of my primary uses for Lighthouse is using it to understand the performance characteristics of a page, so understanding how different resources affect performance is important in understanding _why_ Lighthouse scores and makes the recommendations it does, as well as helping us understand how we can improve. When talking performance bottlenecks, while every KB costs the same over-the-wire (while being downloaded), not every KB has the same effect once it hits the browser. **1KB JS > 1KB Images > 1KB CSS > 1KB HTML**.\n\n- _JavaScript_ has cost not only over-the-wire, but has a significant parsing and execution overhead per KB, much more so than other types of bytes. It also blocks the main thread when being parsed and executed, which means the rest of the browser stops moving while JavaScript is \"thinking\". Finally, while the browser can optimize JavaScript, it's [just-in-time](https://hacks.mozilla.org/2017/02/a-crash-course-in-just-in-time-jit-compilers/) optimization, and dependent upon how the end-user writes their code (unlike other bytes which the browser can optimize the handling of much more easily). Code splitting, route-based loading, the [PRPL Pattern](https://developers.google.com/web/fundamentals/performance/prpl-pattern/), and progressive enhancement are all strategies of providing JavaScript-powered functionality while reducing the overall impact of JavaScript to the user, but because of its cost the most effective method is reducing the overall JavaScript footprint. Remember! JavaScript parsing and execution is [especially bad on non-developer-laptop devices](https://www.youtube.com/watch?v=4bZvq3nodf4), often [2-5 times longer on phones as on desktops](https://medium.com/reloading/javascript-start-up-performance-69200f43b201).\n- _Images_ are next-most expensive as they're less able to be compressed and you tend to need more of them to \"get your point across\" than other bytes. In addition, some formats are better than others at different things, so knowing when to use one type of image over another is important in optimizing performance. All else equal, JPEG usually produces smaller file sizes for photograph-style images than PNGs, but at the cost of image quality loss (which often is OK for graphic images, less OK for fine details or line art). PNGs are usually lossless (good for fine-details) and support transparency, but generally produce a larger file size when used for graphic images. WebP ([supported](https://caniuse.com/#search=webp) in Chromium browsers with Webkit and Geko experimenting) are lossless like PNGs but very compressed, resulting in images that are usually much smaller than JPEGs or PNGs with the advantages of PNGs, including animation support. SVGs are great for iconography and other non-graphic images (like logos), can be styled with CSS, and are text under-the-hood so they can be inlined in to HTML and compressed. Knowing which image format to use, optimizing them before sending, and migrating to inline SVGs for icons and logos can have a large impact on overall file size, as can loading only the large graphical images that are needed in the current display (lazy loading).\n- _CSS_ has an over-the-wire cost and block the main thread like JavaScript does, but instead of being executed like JavaScript it is transformed in to a fast, easy to work with tree-like data structure called the CSS Object Model (CSSOM). This makes the execution of blazing fast (to the point where it's usually the last thing that needs optimization), and you generally need less of it to \"get your point across\" (with well-structured CSS). Using strong CSS naming conventions (like [BEM](http://getbem.com/), optimizing and reducing selector specificity CSS, inlining CSS needed for initial view and lazy-loading the rest, and removing unused CSS selectors are all ways of improving both the cost of CSS and perceived performance related to CSS.\n- _HTML_ is the basis of a website and browsers are, like CSS, blazing fast at dealing with it. You can even stream HTML to a browser so it can start progressively rendering before the full document is complete. HTML is converted in to a tree-like data structure called the Document Object Model (DOM), which the browser uses to both render the HTML and, combined with the CSSOM, style the rendered HTML. JavaScript can interact with the DOM to manipulate it, but if not careful, can also [block the parsing of HTML](https://bitsofco.de/async-vs-defer/). From Lighthouse: _\"A large DOM can increase memory usage, cause longer style calculations, and produce costly layout reflows\"_, which is why Light house recommends \u003C1500 total nodes (items) in the DOM, fewer than 32 nested items deep (DOM Depth), and fewer than 60 nodes per child.\n\nThe number of files sent over-the-wire is also important as browsers allow only a limited number (\u003C10) parallel connections from a single domain; the more things being requested at once from the same domain, the higher the likelihood that an asset will need to wait to be downloaded. HTTP2/Push can help with this by returning more than one item per request, but it's not a panacea as it ignores browser cache, which is likely to cause a problem if not coupled with something like a Service Worker to more precisely control how a user's cache works to prevent extra downloads. Needing to draw resources from multiple domains also incurs performance problems as each new domain needs to go through the networking handshake the first time it's used on a page load, adding overhead. A balance should be struck, with a good rule of thumb being loading about 6 items per domain, and trying to only include a new domain only if more than one resource is coming from it.\n\nFinally, some things are discovered really late in the render process (custom fonts are a good example, not being found until CSS has been downloaded, parsed, and a selector matches that requires the custom font). [Preloading/Prefetching](https://www.smashingmagazine.com/2016/02/preload-what-is-it-good-for/) can help get these resources available for the browser to use _before_ they're actually discovered for use, reducing the time it takes to get it active.\n\nOver-the-wire costs for all resources can be drastically reduced for warm caches (2nd+ page load) by introducing a [Service Worker] to control the browser's cache, allowing you to go so far as provide full _offline_ support for assets. Be careful with Service Workers, though, as they're still a little bit difficult to get right, cache invalidation being [one of the two hard things in Computer Science](https://martinfowler.com/bliki/TwoHardThings.html). That said, Jeremy Keith has a blog post on a [minimal viable service worker](https://adactio.com/journal/13540) that's a good first view of a useful, functional service worker to start from.\n\n## Lighthouse in Architectural Discussions\n\nAs part of my recent work, I worked with another team to discuss potential architectural changes through the lens of Lighthouse's audit and the web performance overview above. They knew they had a performance problem, but seeing just how stark it was through Lighthouse was eye-opening, almost shocking. One of the tricky things about performance (much like mobile experience back in the early days of Responsive Web Design) is it's hard to quantify how bad the problem is if the site is abandoned before web analytics kicks in. From Google to Amazon to [Walmart](http://www.webperformancetoday.com/2012/02/28/4-awesome-slides-showing-how-page-speed-correlates-to-business-metrics-at-walmart-com/) we know that even a 100ms improvement in web performance has a direct correlation to conversions, revenue, and SEO, so we agreed upon a hypothesis that improving their performance would improve their analytics, and started to discuss how we could improve.\n\nThe first thing we did was talk about how different user experiences should affect the architectural choices and why some trade-offs in performance make more sense depending on these user experiences. We generally boiled down web experiences in to three categories:\n\n- **Static** - These experiences mostly have content that is displayed to the user with very little interaction between different elements on a page. The full content and URL of a page usually changes with an interaction instead of causing a small change elsewhere on the page. Blogs, tutorials, and news and marketing sites are usually examples of static experiences.\n- **Dynamic** - These experiences mostly have a single view with many moving parts that change often. Sometimes these change with user input, sometimes they change with new incoming information, sometimes both. Changes in the display aren't easily correlated with a logical stand-alone URL. Dashboards, games, and apps are all examples of usually dynamic experiences.\n- **Stynamic** (because I'm funny) - These experiences are somewhere in the middle; I tend to find they are mostly static experiences with dynamic parts scattered throughout. Many sites have part of the experience that falls in between, like a real-time news feed or comment system on an article.\n\nI generally encourage always sending some form of meaningful HTML over-the-wire regardless of major experience category. This can be a fully-rendered page, a partially-rendered page, or even an [App Shell](https://developers.google.com/web/fundamentals/architecture/app-shell). I encourage this to improve perceived performance and given the browser a leg-up in rendering the final experience. We saw in Lighthouse (and confirmed through other means) that no meaningful HTML was being served over-the-wire to a user, and that was a big cause of the slow First Meaningful Paint score in Lighthouse.\n\nWe then discussed rendering patterns for the different kinds of experiences. I find that **static** and **stynamic** experiences tend to benefit greatly from almost exclusive full server-side rendering, with [progressive enhancement](https://alistapart.com/article/understandingprogressiveenhancement) on the client-side for any small dynamic pieces of the experience that exist. I bias towards using the least amount of JavaScript possible to do this progressive enhancement, using as few dependencies as possible to do so and ensuring dependencies are light-weight, and to not block the DOM while the enhancement is being set up. An optimized HTML page sent from the server can often be similar in size to the JSON payload that would be required to render it client-side, and through streaming and having a warm cache can be as fast or faster than rendering client-side, so subsequent page loads delivered from the server I also recommend.\n\nWhen it comes to **dynamic** experiences, it's a little harder. You still want to send down meaningful content, but what to send will really vary by need. For instance, even with the JavaScript overhead of the fairly large dependency of D3, I found that client-rendering a complex graph was better for performance client-side (in many circumstances) than server-side as the generated SVG was very large. So, finding the right balance of what should be server-rendered to kick off the dynamic experience and what should be client-rendered is something that is going to need to be experimented with. Lighthouse is a good tool to use to check your assumptions here! No matter the first render, I find that most teams I work with are OK with the tradeoffs of a larger JavaScript payload to bring in client-rendering functionality for dynamic experiences.\n\nWhat we found, looking through Lighthouse and examining their project, was that all of the functionality we saw fell under either a _static_ experience or a _stynamic_ experience, yet they had architected it as a a _dynamic_ experience! This meant a very large (~2.8MB main JavaScript file, not including other assets or JavaScript files!) upfront cost to users to set up client rendering and then, of course, render the actual page (remember that you need both JavaScript parsed and running _and_ HTML parsed _and_ the model for the content to be rendered in order _start_ client rendering, and then need to rely on the user's varied devices to do the actual rendering, and _then_ write the new HTML before a user can see it!).\n\nWith this insight, we looked at the Opportunities section in Lighthouse's Performance section and used that as a discussion point to start to talk about what low-hanging fruit we could tackle to improve performance, and what was going to require some deeper architectural changes. Our goal is to use Lighthouse to chew down this performance debt little by little, testing and either confirming or nullifying our assumptions as we go.","src/content/posts/lighthouse-web-performance-architecture-and-you.md","53264e224a65170d",{"html":1599,"metadata":1600},"\u003Cp>In my most recent project, I’ve been using Google’s Lighthouse audit tool to understand the performance profile of what I’m building. I wound up getting our target pages to around a 97 performance \u003Cem>without\u003C/em> the use of many of the advanced performance techniques usually required, and without Service Workers. We accomplished this by keeping performance as a key audit in all the work we delivered, and heavily leveraging knowledge of Lighthouse and Web Performance from the inception of our project, influencing everything down to our architecture. Sharing this high-level knowledge will hopefully make it easier for others to do the same.\u003C/p>\n\u003Ch2 id=\"what-is-lighthouse-and-how-it-works\">What is Lighthouse, and How It Works\u003C/h2>\n\u003Cp>\u003Ca href=\"https://github.com/GoogleChrome/lighthouse\">Lighthouse\u003C/a> is a performance audit tool available as a Chrome extension, Node module, and under the Audit tab in Chrome’s Dev Tools built by Google’s Chrome team (world-recognized as leading experts on web performance in the world). Lighthouse performs the following 4 audits, all on a scale from 1-100 (100 being the best):\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Progressive Web App\u003C/strong> - Percentage of items from Google’s \u003Ca href=\"https://developers.google.com/web/progressive-web-apps/checklist\">Progressive Web App Checklist\u003C/a> that are complete\u003C/li>\n\u003Cli>\u003Cstrong>Performance\u003C/strong> - Grade based on the user-centered \u003Ca href=\"https://developers.google.com/web/fundamentals/performance/rail\">RAIL Performance Model\u003C/a> and real-world performance work the Chrome team, and other experts on web performance around the world, have done, as well as how browsers handle the rendering of a page. The \u003Cem>Focus on the user\u003C/em> section of perception of performance delays comes from direct research they and others have done on the limits of human perception. The recommendations in RAIL stem from those perceptions.\u003C/li>\n\u003Cli>\u003Cstrong>Accessibility\u003C/strong> - Percentage of the provided selection of automated accessibility provided by the \u003Ca href=\"https://github.com/dequelabs/axe-core\">aXe\u003C/a> accessibility testing engine that pass. Importantly, these are not all of the accessibility tests that \u003Cem>can\u003C/em> be run by aXe, and they only cover things that can be tested through automation; many aspects of accessibility testing cannot be tested automatically.\u003C/li>\n\u003Cli>\u003Cstrong>Best Practices\u003C/strong> - Roughly the percentage of the provided modern best practices the Chrome team recommends websites implement.\u003C/li>\n\u003C/ul>\n\u003Cp>When running tests, Lighthouse by default runs from a cold cache (no files in cache), emulating 3G networks speeds and average mobile device hardware by throttling the network and slowing down the CPU by 4x from the machine’s default speed. The reason this is done is to attempt to emulate real-world browsing conditions for users on average mobile hardware (slow networks, slow hardware, small and likely flushed caches); the fastest growing, and in many areas, largest demographic of Internet users. Worldwide performance experts emphasize this group both for that reason and, much like mobile-first responsive web design, making a website perform under those constraints will result in excellent experiences on other combinations, where the reverse is not strictly true. Globally, expert performance recommendations and expectations are built on this model, as well as the performance perception concepts presented in RAIL.\u003C/p>\n\u003Cp>When including a Progressive Web App audit, Lighthouse will run multiple tests to see how a site performs offline with a warm cache.\u003C/p>\n\u003Cp>Any Chrome extensions you may have in place that may affect what is loaded on a page (such as ad or tracking blockers) will apply to Lighthouse tests, so be cognizant of that when running lighthouse tests. For the most accurate audit, I recommend running Lighthouse from a live website in a state with no chrome extensions (except Lighthouse) enabled; incognito mode is good for this.\u003C/p>\n\u003Cp>Within Lighthouse’s \u003Cstrong>Performance\u003C/strong> metrics, there are a handful of specific numbers that may not make sense immediately:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>First Meaningful Paint\u003C/strong> - The number of \u003Ccode>ms\u003C/code> it takes for the primary content of a page to be rendered\u003C/li>\n\u003Cli>\u003Cstrong>First Contentful Paint\u003C/strong> - The number of \u003Ccode>ms\u003C/code> it takes for \u003Cem>any\u003C/em> content defined in the DOM (text, images, a canvas render, etc…) to be rendered. This is \u003Ca href=\"https://github.com/GoogleChrome/lighthouse/issues/4629\">on track to be added to Lighthouse\u003C/a> but not in what’s presented below\u003C/li>\n\u003Cli>\u003Cstrong>First Interactive\u003C/strong> - The number of \u003Ccode>ms\u003C/code> it takes (to the start of the timeframe)for the main JS thread to be idle enough to handle user input. In an upcoming version of Lighthouse, this will be likely be renamed to something like \u003Cem>First Idle\u003C/em>\u003C/li>\n\u003Cli>\u003Cstrong>Consistently Interactive\u003C/strong> - The number of \u003Ccode>ms\u003C/code> it takes to the start of 5 full seconds of network and main thread idle time (see the \u003Ca href=\"https://github.com/GoogleChrome/lighthouse/commit/d0d38292d4fa0ee6b552b750dc8130b85563ac3b\">Time to Interactive definition from the original PR\u003C/a> for how this is calculated). In an upcoming version of Lighthouse, this will likely be renamed to \u003Cem>Time to Interactive\u003C/em> (or TTI)\u003C/li>\n\u003Cli>\u003Cstrong>Perceptual Speed Index\u003C/strong> - A score based on then the perception of a complete page render is calculated, as well as a weighted score compared to an ideal Speed Index based on RAIL. See the \u003Ca href=\"https://sites.google.com/a/webpagetest.org/docs/using-webpagetest/metrics/speed-index\">Official WebPagetest Speed Index Documentation\u003C/a> for how the metric is calculated works.\u003C/li>\n\u003Cli>\u003Cstrong>Estimated Input Latency\u003C/strong> - The estimated number of \u003Ccode>ms\u003C/code> it takes for an user input request to trigger a response, as well as a score compared to an ideal input latency based on RAIL. The value provided describes is the 90th Percentile, so it’s estimating that 90% of inputs will have the provided latency or less, while 10% will have this latency or more. \u003Ca href=\"https://github.com/GoogleChrome/lighthouse/issues/28\">It describes\u003C/a> the availability of the main thread as a proxy metric for input latency.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"understanding-web-performance-and-where-to-optimize\">Understanding Web Performance and Where to Optimize\u003C/h2>\n\u003Cp>One of my primary uses for Lighthouse is using it to understand the performance characteristics of a page, so understanding how different resources affect performance is important in understanding \u003Cem>why\u003C/em> Lighthouse scores and makes the recommendations it does, as well as helping us understand how we can improve. When talking performance bottlenecks, while every KB costs the same over-the-wire (while being downloaded), not every KB has the same effect once it hits the browser. \u003Cstrong>1KB JS > 1KB Images > 1KB CSS > 1KB HTML\u003C/strong>.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cem>JavaScript\u003C/em> has cost not only over-the-wire, but has a significant parsing and execution overhead per KB, much more so than other types of bytes. It also blocks the main thread when being parsed and executed, which means the rest of the browser stops moving while JavaScript is “thinking”. Finally, while the browser can optimize JavaScript, it’s \u003Ca href=\"https://hacks.mozilla.org/2017/02/a-crash-course-in-just-in-time-jit-compilers/\">just-in-time\u003C/a> optimization, and dependent upon how the end-user writes their code (unlike other bytes which the browser can optimize the handling of much more easily). Code splitting, route-based loading, the \u003Ca href=\"https://developers.google.com/web/fundamentals/performance/prpl-pattern/\">PRPL Pattern\u003C/a>, and progressive enhancement are all strategies of providing JavaScript-powered functionality while reducing the overall impact of JavaScript to the user, but because of its cost the most effective method is reducing the overall JavaScript footprint. Remember! JavaScript parsing and execution is \u003Ca href=\"https://www.youtube.com/watch?v=4bZvq3nodf4\">especially bad on non-developer-laptop devices\u003C/a>, often \u003Ca href=\"https://medium.com/reloading/javascript-start-up-performance-69200f43b201\">2-5 times longer on phones as on desktops\u003C/a>.\u003C/li>\n\u003Cli>\u003Cem>Images\u003C/em> are next-most expensive as they’re less able to be compressed and you tend to need more of them to “get your point across” than other bytes. In addition, some formats are better than others at different things, so knowing when to use one type of image over another is important in optimizing performance. All else equal, JPEG usually produces smaller file sizes for photograph-style images than PNGs, but at the cost of image quality loss (which often is OK for graphic images, less OK for fine details or line art). PNGs are usually lossless (good for fine-details) and support transparency, but generally produce a larger file size when used for graphic images. WebP (\u003Ca href=\"https://caniuse.com/#search=webp\">supported\u003C/a> in Chromium browsers with Webkit and Geko experimenting) are lossless like PNGs but very compressed, resulting in images that are usually much smaller than JPEGs or PNGs with the advantages of PNGs, including animation support. SVGs are great for iconography and other non-graphic images (like logos), can be styled with CSS, and are text under-the-hood so they can be inlined in to HTML and compressed. Knowing which image format to use, optimizing them before sending, and migrating to inline SVGs for icons and logos can have a large impact on overall file size, as can loading only the large graphical images that are needed in the current display (lazy loading).\u003C/li>\n\u003Cli>\u003Cem>CSS\u003C/em> has an over-the-wire cost and block the main thread like JavaScript does, but instead of being executed like JavaScript it is transformed in to a fast, easy to work with tree-like data structure called the CSS Object Model (CSSOM). This makes the execution of blazing fast (to the point where it’s usually the last thing that needs optimization), and you generally need less of it to “get your point across” (with well-structured CSS). Using strong CSS naming conventions (like \u003Ca href=\"http://getbem.com/\">BEM\u003C/a>, optimizing and reducing selector specificity CSS, inlining CSS needed for initial view and lazy-loading the rest, and removing unused CSS selectors are all ways of improving both the cost of CSS and perceived performance related to CSS.\u003C/li>\n\u003Cli>\u003Cem>HTML\u003C/em> is the basis of a website and browsers are, like CSS, blazing fast at dealing with it. You can even stream HTML to a browser so it can start progressively rendering before the full document is complete. HTML is converted in to a tree-like data structure called the Document Object Model (DOM), which the browser uses to both render the HTML and, combined with the CSSOM, style the rendered HTML. JavaScript can interact with the DOM to manipulate it, but if not careful, can also \u003Ca href=\"https://bitsofco.de/async-vs-defer/\">block the parsing of HTML\u003C/a>. From Lighthouse: \u003Cem>“A large DOM can increase memory usage, cause longer style calculations, and produce costly layout reflows”\u003C/em>, which is why Light house recommends &#x3C;1500 total nodes (items) in the DOM, fewer than 32 nested items deep (DOM Depth), and fewer than 60 nodes per child.\u003C/li>\n\u003C/ul>\n\u003Cp>The number of files sent over-the-wire is also important as browsers allow only a limited number (&#x3C;10) parallel connections from a single domain; the more things being requested at once from the same domain, the higher the likelihood that an asset will need to wait to be downloaded. HTTP2/Push can help with this by returning more than one item per request, but it’s not a panacea as it ignores browser cache, which is likely to cause a problem if not coupled with something like a Service Worker to more precisely control how a user’s cache works to prevent extra downloads. Needing to draw resources from multiple domains also incurs performance problems as each new domain needs to go through the networking handshake the first time it’s used on a page load, adding overhead. A balance should be struck, with a good rule of thumb being loading about 6 items per domain, and trying to only include a new domain only if more than one resource is coming from it.\u003C/p>\n\u003Cp>Finally, some things are discovered really late in the render process (custom fonts are a good example, not being found until CSS has been downloaded, parsed, and a selector matches that requires the custom font). \u003Ca href=\"https://www.smashingmagazine.com/2016/02/preload-what-is-it-good-for/\">Preloading/Prefetching\u003C/a> can help get these resources available for the browser to use \u003Cem>before\u003C/em> they’re actually discovered for use, reducing the time it takes to get it active.\u003C/p>\n\u003Cp>Over-the-wire costs for all resources can be drastically reduced for warm caches (2nd+ page load) by introducing a [Service Worker] to control the browser’s cache, allowing you to go so far as provide full \u003Cem>offline\u003C/em> support for assets. Be careful with Service Workers, though, as they’re still a little bit difficult to get right, cache invalidation being \u003Ca href=\"https://martinfowler.com/bliki/TwoHardThings.html\">one of the two hard things in Computer Science\u003C/a>. That said, Jeremy Keith has a blog post on a \u003Ca href=\"https://adactio.com/journal/13540\">minimal viable service worker\u003C/a> that’s a good first view of a useful, functional service worker to start from.\u003C/p>\n\u003Ch2 id=\"lighthouse-in-architectural-discussions\">Lighthouse in Architectural Discussions\u003C/h2>\n\u003Cp>As part of my recent work, I worked with another team to discuss potential architectural changes through the lens of Lighthouse’s audit and the web performance overview above. They knew they had a performance problem, but seeing just how stark it was through Lighthouse was eye-opening, almost shocking. One of the tricky things about performance (much like mobile experience back in the early days of Responsive Web Design) is it’s hard to quantify how bad the problem is if the site is abandoned before web analytics kicks in. From Google to Amazon to \u003Ca href=\"http://www.webperformancetoday.com/2012/02/28/4-awesome-slides-showing-how-page-speed-correlates-to-business-metrics-at-walmart-com/\">Walmart\u003C/a> we know that even a 100ms improvement in web performance has a direct correlation to conversions, revenue, and SEO, so we agreed upon a hypothesis that improving their performance would improve their analytics, and started to discuss how we could improve.\u003C/p>\n\u003Cp>The first thing we did was talk about how different user experiences should affect the architectural choices and why some trade-offs in performance make more sense depending on these user experiences. We generally boiled down web experiences in to three categories:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Static\u003C/strong> - These experiences mostly have content that is displayed to the user with very little interaction between different elements on a page. The full content and URL of a page usually changes with an interaction instead of causing a small change elsewhere on the page. Blogs, tutorials, and news and marketing sites are usually examples of static experiences.\u003C/li>\n\u003Cli>\u003Cstrong>Dynamic\u003C/strong> - These experiences mostly have a single view with many moving parts that change often. Sometimes these change with user input, sometimes they change with new incoming information, sometimes both. Changes in the display aren’t easily correlated with a logical stand-alone URL. Dashboards, games, and apps are all examples of usually dynamic experiences.\u003C/li>\n\u003Cli>\u003Cstrong>Stynamic\u003C/strong> (because I’m funny) - These experiences are somewhere in the middle; I tend to find they are mostly static experiences with dynamic parts scattered throughout. Many sites have part of the experience that falls in between, like a real-time news feed or comment system on an article.\u003C/li>\n\u003C/ul>\n\u003Cp>I generally encourage always sending some form of meaningful HTML over-the-wire regardless of major experience category. This can be a fully-rendered page, a partially-rendered page, or even an \u003Ca href=\"https://developers.google.com/web/fundamentals/architecture/app-shell\">App Shell\u003C/a>. I encourage this to improve perceived performance and given the browser a leg-up in rendering the final experience. We saw in Lighthouse (and confirmed through other means) that no meaningful HTML was being served over-the-wire to a user, and that was a big cause of the slow First Meaningful Paint score in Lighthouse.\u003C/p>\n\u003Cp>We then discussed rendering patterns for the different kinds of experiences. I find that \u003Cstrong>static\u003C/strong> and \u003Cstrong>stynamic\u003C/strong> experiences tend to benefit greatly from almost exclusive full server-side rendering, with \u003Ca href=\"https://alistapart.com/article/understandingprogressiveenhancement\">progressive enhancement\u003C/a> on the client-side for any small dynamic pieces of the experience that exist. I bias towards using the least amount of JavaScript possible to do this progressive enhancement, using as few dependencies as possible to do so and ensuring dependencies are light-weight, and to not block the DOM while the enhancement is being set up. An optimized HTML page sent from the server can often be similar in size to the JSON payload that would be required to render it client-side, and through streaming and having a warm cache can be as fast or faster than rendering client-side, so subsequent page loads delivered from the server I also recommend.\u003C/p>\n\u003Cp>When it comes to \u003Cstrong>dynamic\u003C/strong> experiences, it’s a little harder. You still want to send down meaningful content, but what to send will really vary by need. For instance, even with the JavaScript overhead of the fairly large dependency of D3, I found that client-rendering a complex graph was better for performance client-side (in many circumstances) than server-side as the generated SVG was very large. So, finding the right balance of what should be server-rendered to kick off the dynamic experience and what should be client-rendered is something that is going to need to be experimented with. Lighthouse is a good tool to use to check your assumptions here! No matter the first render, I find that most teams I work with are OK with the tradeoffs of a larger JavaScript payload to bring in client-rendering functionality for dynamic experiences.\u003C/p>\n\u003Cp>What we found, looking through Lighthouse and examining their project, was that all of the functionality we saw fell under either a \u003Cem>static\u003C/em> experience or a \u003Cem>stynamic\u003C/em> experience, yet they had architected it as a a \u003Cem>dynamic\u003C/em> experience! This meant a very large (~2.8MB main JavaScript file, not including other assets or JavaScript files!) upfront cost to users to set up client rendering and then, of course, render the actual page (remember that you need both JavaScript parsed and running \u003Cem>and\u003C/em> HTML parsed \u003Cem>and\u003C/em> the model for the content to be rendered in order \u003Cem>start\u003C/em> client rendering, and then need to rely on the user’s varied devices to do the actual rendering, and \u003Cem>then\u003C/em> write the new HTML before a user can see it!).\u003C/p>\n\u003Cp>With this insight, we looked at the Opportunities section in Lighthouse’s Performance section and used that as a discussion point to start to talk about what low-hanging fruit we could tackle to improve performance, and what was going to require some deeper architectural changes. Our goal is to use Lighthouse to chew down this performance debt little by little, testing and either confirming or nullifying our assumptions as we go.\u003C/p>",{"headings":1601,"localImagePaths":1611,"remoteImagePaths":1612,"frontmatter":1613,"imagePaths":1615},[1602,1605,1608],{"depth":80,"slug":1603,"text":1604},"what-is-lighthouse-and-how-it-works","What is Lighthouse, and How It Works",{"depth":80,"slug":1606,"text":1607},"understanding-web-performance-and-where-to-optimize","Understanding Web Performance and Where to Optimize",{"depth":80,"slug":1609,"text":1610},"lighthouse-in-architectural-discussions","Lighthouse in Architectural Discussions",[],[],{"title":1592,"published":1614,"summary":1594},"2018-03-07",[],"modern-cutting-the-mustard",{"id":1616,"data":1618,"body":1622,"filePath":1623,"digest":1624,"rendered":1625},{"title":1619,"published":1620,"summary":1621},"A Modern Take on Cutting the Mustard",["Date","2018-07-29T00:00:00.000Z"],"By taking advantage of JavaScript module support, we can update the Cutting the Mustard progressive enhancement technique to allow for modern JavaScript syntaxes and features!","One of the easiest ways to [progressively enhance](https://alistapart.com/article/understandingprogressiveenhancement) your web experience is the [Cutting the Mustard](http://responsivenews.co.uk/post/18948466399/cutting-the-mustard) technique. The essence of Cutting the Mustard is:\n\n1. Provide an accessible base-line experience for everyone using semantic HTML and CSS\n2. Write a test for a minimum subset of JavaScript functionality to support.\n   - If the test _passes_, enhance the experience with modern JavaScript\n   - If the test _fails_, enhance enhance the experience with older JavaScript (and usually a subset of the modern JavaScript's functionality)\n\nThe original test was developed by the BBC team to distinguish between HTML5 browsers and non-HTML5 browsers. That test was fairly straight forward:\n\n```js\nif (\n  'querySelector' in document &&\n  'localStorage' in window &&\n  'addEventListener' in window\n) {\n  // Enhance for HTML5 browsers\n}\n```\n\nThis works really well! The enhancements being looked for are all functions that hang off of `document` or `window` and can looked for using checks, so we use these tests even in browsers that don't support that functionality! Our progressive enhancement life is wonderful!\n\n## Enter ES2015+\n\nStarting with ES2015, or ES6, new JavaScript functionality started to be added that couldn't be tested for by checking if a property exists; it introduced some actual new JavaScript syntax, like `const`, `let`, arrow functions, and classes. The problem we now face wanting to test for support of these new syntaxes is that we can't even _write_ the new syntax and deliver it to browsers that don't support it without errors! This is because, unlike HTML and CSS which can gracefully ignore unsupported syntax, JavaScript can't! How, then, can we Cut the Mustard in a way that won't cause errors in unsupported browsers without compiling or transpiling our modern JavaScript syntax?\n\n**JavaScript Modules to the Rescue**\n\n## Using Modules to Cut the Mustard\n\nLet's get straight to the code, then we'll explain it:\n\n```html\n\u003Cscript type=\"module\" src=\"./mustard.js\">\u003C/script>\n\u003Cscript nomodule src=\"./no-mustard.js\">\u003C/script>\n\n\u003C!-- Can be done inline too -->\n\n\u003Cscript type=\"module\">\n  import mustard from './mustard.js';\n\u003C/script>\n\n\u003Cscript nomodule type=\"text/javascript\">\n  console.log('No Mustard!');\n\u003C/script>\n```\n\nWhen JavaScript modules were introduced, two new bits of HTML syntax were introduced that make this all possible: `type=\"module\"` for `\u003Cscript>` tags, and the `nomodule` attribute.\n\nIn all browsers that [support JavaScript module via `script` tags](https://caniuse.com/#feat=es6-module), `\u003Cscript type=\"module\">` will be interpreted as a JavaScript module and loaded and run as expected, but for browsers that don't recognize that type, it'll just be ignored because it's unknown HTML syntax! Easy Peasy! Mustard, cut.\n\nWe can also \"test\" for the opposite by including the `nomodule` attribute. In all browsers that support `type=\"module\"` (except Safari 10.1 and iOS Safari 10.3), adding the `nomodule` attribute to out `\u003Cscript>` tags will have that JavaScdipt ignored in module-supporting browsers while it'll load and run as expected in all other browsers! While it's not _absolutely perfect_ coverage (less than 1% of browsers globally will fall in to this category at the time of this writing), it's likely good enough for most production work.\n\n## What's Our New Baseline\n\nUsing JavaScript modules as our new baseline gives us a [great modern baseline](https://caniuse.com/#compare=edge+16,firefox+60,chrome+61,safari+10.1,opera+48,ios_saf+10.3,and_chr+67,and_ff+60) of HTML, CSS, and JavaScript functionality that we can just _know_ is available to us. Some JavaScript highlights from this list are:\n\n- [`const`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/const) and partial [`let`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/let) support\n- [Promises](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise) and [async functions](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function)\n- [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)\n- [Arrow functions](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions)\n- [Rest parameters](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/rest_parameters)\n- [Classes](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes)\n- [Template Literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals)\n- [Generators](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator)\n- And, of course, [JavaScript Modules](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/import)\n\nThat's quite a bit of new syntax we get _out of the box_ by setting our baseline to JavaScript modules. This is, of course, in addition to everything we can test for and use that's _not_ based on new syntax, like Service Workers and Intersection Observers. We can even do it on a feature-by-feature basis:\n\n```js\nif ('IntersectionObserver' in window) {\n  // Intersection Observers, GO!\n}\n```\n\nWith the power of JavaScript modules as a modern Cutting the Mustard technique, we have a modern JavaScript baseline we can code to. Combined with our tried-and-true progressive enhancement feature testing, it may finally be time to put down our compilers and transpilers and start delivering cutting-edge JavaScript straight from editor to browser.","src/content/posts/modern-cutting-the-mustard.md","cfe89a729a4ce3f1",{"html":1626,"metadata":1627},"\u003Cp>One of the easiest ways to \u003Ca href=\"https://alistapart.com/article/understandingprogressiveenhancement\">progressively enhance\u003C/a> your web experience is the \u003Ca href=\"http://responsivenews.co.uk/post/18948466399/cutting-the-mustard\">Cutting the Mustard\u003C/a> technique. The essence of Cutting the Mustard is:\u003C/p>\n\u003Col>\n\u003Cli>Provide an accessible base-line experience for everyone using semantic HTML and CSS\u003C/li>\n\u003Cli>Write a test for a minimum subset of JavaScript functionality to support.\n\u003Cul>\n\u003Cli>If the test \u003Cem>passes\u003C/em>, enhance the experience with modern JavaScript\u003C/li>\n\u003Cli>If the test \u003Cem>fails\u003C/em>, enhance enhance the experience with older JavaScript (and usually a subset of the modern JavaScript’s functionality)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>\n\u003Cp>The original test was developed by the BBC team to distinguish between HTML5 browsers and non-HTML5 browsers. That test was fairly straight forward:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"js\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">  'querySelector'\u003C/span>\u003Cspan style=\"color:#F92672\"> in\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> document \u003C/span>\u003Cspan style=\"color:#F92672\">&#x26;&#x26;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">  'localStorage'\u003C/span>\u003Cspan style=\"color:#F92672\"> in\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> window \u003C/span>\u003Cspan style=\"color:#F92672\">&#x26;&#x26;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">  'addEventListener'\u003C/span>\u003Cspan style=\"color:#F92672\"> in\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> window\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Enhance for HTML5 browsers\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This works really well! The enhancements being looked for are all functions that hang off of \u003Ccode>document\u003C/code> or \u003Ccode>window\u003C/code> and can looked for using checks, so we use these tests even in browsers that don’t support that functionality! Our progressive enhancement life is wonderful!\u003C/p>\n\u003Ch2 id=\"enter-es2015\">Enter ES2015+\u003C/h2>\n\u003Cp>Starting with ES2015, or ES6, new JavaScript functionality started to be added that couldn’t be tested for by checking if a property exists; it introduced some actual new JavaScript syntax, like \u003Ccode>const\u003C/code>, \u003Ccode>let\u003C/code>, arrow functions, and classes. The problem we now face wanting to test for support of these new syntaxes is that we can’t even \u003Cem>write\u003C/em> the new syntax and deliver it to browsers that don’t support it without errors! This is because, unlike HTML and CSS which can gracefully ignore unsupported syntax, JavaScript can’t! How, then, can we Cut the Mustard in a way that won’t cause errors in unsupported browsers without compiling or transpiling our modern JavaScript syntax?\u003C/p>\n\u003Cp>\u003Cstrong>JavaScript Modules to the Rescue\u003C/strong>\u003C/p>\n\u003Ch2 id=\"using-modules-to-cut-the-mustard\">Using Modules to Cut the Mustard\u003C/h2>\n\u003Cp>Let’s get straight to the code, then we’ll explain it:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"html\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#A6E22E\"> type\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"module\"\u003C/span>\u003Cspan style=\"color:#A6E22E\"> src\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"./mustard.js\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#A6E22E\"> nomodule\u003C/span>\u003Cspan style=\"color:#A6E22E\"> src\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"./no-mustard.js\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">&#x3C;!-- Can be done inline too -->\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#A6E22E\"> type\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"module\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  import\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> mustard \u003C/span>\u003Cspan style=\"color:#F92672\">from\u003C/span>\u003Cspan style=\"color:#E6DB74\"> './mustard.js'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#A6E22E\"> nomodule\u003C/span>\u003Cspan style=\"color:#A6E22E\"> type\u003C/span>\u003Cspan style=\"color:#F8F8F2\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\">\"text/javascript\"\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  console.\u003C/span>\u003Cspan style=\"color:#A6E22E\">log\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'No Mustard!'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;/\u003C/span>\u003Cspan style=\"color:#F92672\">script\u003C/span>\u003Cspan style=\"color:#F8F8F2\">>\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>When JavaScript modules were introduced, two new bits of HTML syntax were introduced that make this all possible: \u003Ccode>type=\"module\"\u003C/code> for \u003Ccode>&#x3C;script>\u003C/code> tags, and the \u003Ccode>nomodule\u003C/code> attribute.\u003C/p>\n\u003Cp>In all browsers that \u003Ca href=\"https://caniuse.com/#feat=es6-module\">support JavaScript module via \u003Ccode>script\u003C/code> tags\u003C/a>, \u003Ccode>&#x3C;script type=\"module\">\u003C/code> will be interpreted as a JavaScript module and loaded and run as expected, but for browsers that don’t recognize that type, it’ll just be ignored because it’s unknown HTML syntax! Easy Peasy! Mustard, cut.\u003C/p>\n\u003Cp>We can also “test” for the opposite by including the \u003Ccode>nomodule\u003C/code> attribute. In all browsers that support \u003Ccode>type=\"module\"\u003C/code> (except Safari 10.1 and iOS Safari 10.3), adding the \u003Ccode>nomodule\u003C/code> attribute to out \u003Ccode>&#x3C;script>\u003C/code> tags will have that JavaScdipt ignored in module-supporting browsers while it’ll load and run as expected in all other browsers! While it’s not \u003Cem>absolutely perfect\u003C/em> coverage (less than 1% of browsers globally will fall in to this category at the time of this writing), it’s likely good enough for most production work.\u003C/p>\n\u003Ch2 id=\"whats-our-new-baseline\">What’s Our New Baseline\u003C/h2>\n\u003Cp>Using JavaScript modules as our new baseline gives us a \u003Ca href=\"https://caniuse.com/#compare=edge+16,firefox+60,chrome+61,safari+10.1,opera+48,ios_saf+10.3,and_chr+67,and_ff+60\">great modern baseline\u003C/a> of HTML, CSS, and JavaScript functionality that we can just \u003Cem>know\u003C/em> is available to us. Some JavaScript highlights from this list are:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/const\">\u003Ccode>const\u003C/code>\u003C/a> and partial \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/let\">\u003Ccode>let\u003C/code>\u003C/a> support\u003C/li>\n\u003Cli>\u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise\">Promises\u003C/a> and \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function\">async functions\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API\">\u003Ccode>fetch\u003C/code>\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions\">Arrow functions\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/rest_parameters\">Rest parameters\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes\">Classes\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals\">Template Literals\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator\">Generators\u003C/a>\u003C/li>\n\u003Cli>And, of course, \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/import\">JavaScript Modules\u003C/a>\u003C/li>\n\u003C/ul>\n\u003Cp>That’s quite a bit of new syntax we get \u003Cem>out of the box\u003C/em> by setting our baseline to JavaScript modules. This is, of course, in addition to everything we can test for and use that’s \u003Cem>not\u003C/em> based on new syntax, like Service Workers and Intersection Observers. We can even do it on a feature-by-feature basis:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"js\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#E6DB74\">'IntersectionObserver'\u003C/span>\u003Cspan style=\"color:#F92672\"> in\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> window) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Intersection Observers, GO!\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>With the power of JavaScript modules as a modern Cutting the Mustard technique, we have a modern JavaScript baseline we can code to. Combined with our tried-and-true progressive enhancement feature testing, it may finally be time to put down our compilers and transpilers and start delivering cutting-edge JavaScript straight from editor to browser.\u003C/p>",{"headings":1628,"localImagePaths":1638,"remoteImagePaths":1639,"frontmatter":1640,"imagePaths":1642},[1629,1632,1635],{"depth":80,"slug":1630,"text":1631},"enter-es2015","Enter ES2015+",{"depth":80,"slug":1633,"text":1634},"using-modules-to-cut-the-mustard","Using Modules to Cut the Mustard",{"depth":80,"slug":1636,"text":1637},"whats-our-new-baseline","What’s Our New Baseline",[],[],{"title":1619,"published":1641,"summary":1621},"2018-07-29",[],"nyc-camp-presentation",{"id":1643,"data":1645,"body":1649,"filePath":1650,"digest":1651,"rendered":1652},{"title":1646,"published":1647,"summary":1648},"NYC Camp Presentation",["Date","2012-07-22T00:00:00.000Z"],"The slides from my NYC Camp 2012 presentation along with some links.","A big thanks to everyone who came out to my presentation yesterday. My slides can be [downloaded here](https://snugug.com/documents/nyc-camp-presentation/session.pdf) and have lots of good links in there for continued learning. The responsive image solution I built for Drupal is [Borealis](http://drupal.org/project/borealis). If you have any questions, let me know in a comment below or by pinging me on Twitter [@Snugug](http://twitter.com/snugug). Enjoy!","src/content/posts/nyc-camp-presentation.md","fc0d7d2398c53bfc",{"html":1653,"metadata":1654},"\u003Cp>A big thanks to everyone who came out to my presentation yesterday. My slides can be \u003Ca href=\"https://snugug.com/documents/nyc-camp-presentation/session.pdf\">downloaded here\u003C/a> and have lots of good links in there for continued learning. The responsive image solution I built for Drupal is \u003Ca href=\"http://drupal.org/project/borealis\">Borealis\u003C/a>. If you have any questions, let me know in a comment below or by pinging me on Twitter \u003Ca href=\"http://twitter.com/snugug\">@Snugug\u003C/a>. Enjoy!\u003C/p>",{"headings":1655,"localImagePaths":1656,"remoteImagePaths":1657,"frontmatter":1658,"imagePaths":1660},[],[],[],{"title":1646,"published":1659,"summary":1648},"2012-07-22",[],"override-theme-functions-drupal-7-module",{"id":1661,"data":1663,"body":1667,"filePath":1668,"digest":1669,"rendered":1670},{"title":1664,"published":1665,"summary":1666},"Override Theme Functions from Drupal 7 Module",["Date","2012-08-05T00:00:00.000Z"],"Ever need to really override a core or contrib module's theme output? You won't believe what you can do with this one weird hook!","Have you ever really, truly hated the theme output of Drupal core or contrib module and really wanted to override it? In your theme function, it's easy enough, `function YOURTHEME_themename($vars)`. That's all fine and dandy, but what if you really want to do it from a module, like, say, if you're creating a [responsive image solution](http://drupal.org/project/borealis) and need to add a noscript fallback? Well, I can now tell you that yes you can! It's as simple as one overlooked hook and, well, writing you own function! Let's take a look at how.\n\nThis whole thing boils down to one hook, [`hook_theme_registry_alter`\n](http://api.drupal.org/api/drupal/modules%21system%21system.api.php/function/hook_theme_registry_alter/7). The hook is pretty simple, it goes a little something like this:\n\n```php\n/**\n * Implements hook_theme_registry_alter\n */\nfunction mymodule__theme_registry_alter(&$theme_registry) {\n  $theme_registry['theme_name']['theme path'] = 'path/to/your/module';\n  $theme_registry['theme_name']['function'] = 'mymodule_function_name';\n}\n```\n\n`'theme_name'` is the name of the theme function you want to change, so if you wanted to alter the image style theme, you'd put \u003Cpre>'image_style'\u003C/pre> there. The theme path is the path to the module where the function is stored, but not the file itself, so you can plug in the output of [`drupal_get_path()`](http://api.drupal.org/api/drupal/includes%21common.inc/function/drupal_get_path/7) directly into it. All of the previous `hook_preprocess` and `hook_process` functions that are already written for the theme you're overriding will still work, so you can happily use this and be compatible with other modules!\n\nA couple of things to note about your custom function. First, you don't need to write a full theme function to use this, just a plain old function will do as long as it takes the same input as the original function. Second, if you want to use the output of another theme function, especially, say, the one you're overriding so you can add to its output, you can call the function directly (in the case of image style, you can call `php theme_image_style($vars)`) and keep on going. And don't forget to return something!","src/content/posts/override-theme-functions-drupal-7-module.md","e50994b5ff4fd7dd",{"html":1671,"metadata":1672},"\u003Cp>Have you ever really, truly hated the theme output of Drupal core or contrib module and really wanted to override it? In your theme function, it’s easy enough, \u003Ccode>function YOURTHEME_themename($vars)\u003C/code>. That’s all fine and dandy, but what if you really want to do it from a module, like, say, if you’re creating a \u003Ca href=\"http://drupal.org/project/borealis\">responsive image solution\u003C/a> and need to add a noscript fallback? Well, I can now tell you that yes you can! It’s as simple as one overlooked hook and, well, writing you own function! Let’s take a look at how.\u003C/p>\n\u003Cp>This whole thing boils down to one hook, \u003Ca href=\"http://api.drupal.org/api/drupal/modules%21system%21system.api.php/function/hook_theme_registry_alter/7\">\u003Ccode>hook_theme_registry_alter\u003C/code>\n\u003C/a>. The hook is pretty simple, it goes a little something like this:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"php\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">/**\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\"> * Implements hook_theme_registry_alter\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\"> */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">function\u003C/span>\u003Cspan style=\"color:#A6E22E\"> mymodule__theme_registry_alter\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#F92672\">&#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\">$theme_registry) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  $theme_registry[\u003C/span>\u003Cspan style=\"color:#E6DB74\">'theme_name'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">][\u003C/span>\u003Cspan style=\"color:#E6DB74\">'theme path'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">] \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'path/to/your/module'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  $theme_registry[\u003C/span>\u003Cspan style=\"color:#E6DB74\">'theme_name'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">][\u003C/span>\u003Cspan style=\"color:#E6DB74\">'function'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">] \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'mymodule_function_name'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>\u003Ccode>'theme_name'\u003C/code> is the name of the theme function you want to change, so if you wanted to alter the image style theme, you’d put \u003C/p>\u003Cpre>‘image_style’\u003C/pre> there. The theme path is the path to the module where the function is stored, but not the file itself, so you can plug in the output of \u003Ca href=\"http://api.drupal.org/api/drupal/includes%21common.inc/function/drupal_get_path/7\">\u003Ccode>drupal_get_path()\u003C/code>\u003C/a> directly into it. All of the previous \u003Ccode>hook_preprocess\u003C/code> and \u003Ccode>hook_process\u003C/code> functions that are already written for the theme you’re overriding will still work, so you can happily use this and be compatible with other modules!\u003Cp>\u003C/p>\n\u003Cp>A couple of things to note about your custom function. First, you don’t need to write a full theme function to use this, just a plain old function will do as long as it takes the same input as the original function. Second, if you want to use the output of another theme function, especially, say, the one you’re overriding so you can add to its output, you can call the function directly (in the case of image style, you can call \u003Ccode>php theme_image_style($vars)\u003C/code>) and keep on going. And don’t forget to return something!\u003C/p>",{"headings":1673,"localImagePaths":1674,"remoteImagePaths":1675,"frontmatter":1676,"imagePaths":1678},[],[],[],{"title":1664,"published":1677,"summary":1666},"2012-08-05",[],"measure-tester",{"id":1679,"data":1681,"body":1685,"filePath":1686,"digest":1687,"rendered":1688},{"title":1682,"published":1683,"summary":1684},"Measure Tester",["Date","2013-03-29T00:00:00.000Z"],"A tool to help measure your measure, helping you design for an ideal reading experience.","I'm a big fan of nice typography (stopping you before you yell and scream about my last site design, I was experimenting!). One of the key pieces to having great typography is having a great measure, or as it's probably more commonly referred to, line length. For the English language, the ideal measure as I've been taught is generally between 2 and 3 times the length of our alphabet, including spaces. So, when I'm building and designing sites, one of the factors I take into consideration when choosing breakpoints is the text's measure. This will vary by font family, font weight, and font size. Because of this, I find I need to check my measure quite often.\n\nI've built myself two tools to do just this. The first one is a [.txt file](https://snugug.com/documents/measure-tester/Measure%20Tester.txt) where I can simply paste in my measure and visually see if it it's too large or too small. The second one is an [Alfred Workflow](https://snugug.com/documents/measure-tester/Measure%20Tester.alfredworkflow) for the new [Alfred 2.0](http://www.alfredapp.com/) (if you don't already use Alfred, you should really start, the basic version is free). For the Alfred workflow, I believe you need the Powerpack, which I think is worth it. The Measure workflow will allow you to type 'measure' in to Alfred, then paste in your copied line, and it'll notify you whether or not you've got an ideal measure. Hope you enjoy!","src/content/posts/measure-tester.md","1751b1e9a5c77713",{"html":1689,"metadata":1690},"\u003Cp>I’m a big fan of nice typography (stopping you before you yell and scream about my last site design, I was experimenting!). One of the key pieces to having great typography is having a great measure, or as it’s probably more commonly referred to, line length. For the English language, the ideal measure as I’ve been taught is generally between 2 and 3 times the length of our alphabet, including spaces. So, when I’m building and designing sites, one of the factors I take into consideration when choosing breakpoints is the text’s measure. This will vary by font family, font weight, and font size. Because of this, I find I need to check my measure quite often.\u003C/p>\n\u003Cp>I’ve built myself two tools to do just this. The first one is a \u003Ca href=\"https://snugug.com/documents/measure-tester/Measure%20Tester.txt\">.txt file\u003C/a> where I can simply paste in my measure and visually see if it it’s too large or too small. The second one is an \u003Ca href=\"https://snugug.com/documents/measure-tester/Measure%20Tester.alfredworkflow\">Alfred Workflow\u003C/a> for the new \u003Ca href=\"http://www.alfredapp.com/\">Alfred 2.0\u003C/a> (if you don’t already use Alfred, you should really start, the basic version is free). For the Alfred workflow, I believe you need the Powerpack, which I think is worth it. The Measure workflow will allow you to type ‘measure’ in to Alfred, then paste in your copied line, and it’ll notify you whether or not you’ve got an ideal measure. Hope you enjoy!\u003C/p>",{"headings":1691,"localImagePaths":1692,"remoteImagePaths":1693,"frontmatter":1694,"imagePaths":1696},[],[],[],{"title":1682,"published":1695,"summary":1684},"2013-03-29",[],"performance-sketches",{"id":1697,"data":1699,"body":1703,"filePath":1704,"digest":1705,"rendered":1706},{"title":1700,"published":1701,"summary":1702},"Performance Sketches",["Date","2015-06-24T00:00:00.000Z"],"Creating and enforcing performance budgets are hard to begin with, but getting everyone to understand the impact of their choices on the performance of a project can be doubly so. Having a way to \"sketch\" performance can help onboard new team members to the concept of performance budgets.","Performance is a complex dance between browsers, devices, networks, technology, marketing, branding, content strategy, and visual design. It's no wonder, then, that often it gets left to the end of a project to actually work out. Creating and enforcing performance budgets are hard to begin with, but getting everyone to understand the impact of their choices on the performance of a project can be doubly so. Designing in browser (either by actually designing there, or getting there quickly, iterating there, and deciding there) can help with this as it brings performance to the forefront of the project and provides a way to test ideas from the beginning. But, there still needs to be a way to \"sketch\" a project's performance before we get in browser. Having a way to \"sketch\" performance can help onboard new team members to the concept of [performance budgets](http://timkadlec.com/2013/01/setting-a-performance-budget/) earlier and allow teams to have a way of discussing performance while whiteboarding and sketching themselves, an invaluable part of the iteration process.\n\nWhen talking about performance, both [download and on-page performance](http://pointnorth.io/#performance) are essential in understanding the overall performance of a project. Download performance is much easier to quantify than on-page performance; the former being simply size and network speed whereas the later is both of those things plus execution time and device power. As such, when sketching performance, items that mostly don't affect on-page performance are going to resemble only their download size, whereas items that do affect on-page performance are going to resemble their download size multiplied by a factor to represent that affect.\n\nPerformance sketching starts with a point goal. The project's performance budget [speed index](https://sites.google.com/a/webpagetest.org/docs/using-webpagetest/metrics/speed-index) goals will be the point goal for the performance sketches. Testing with [Web Page Test](http://www.webpagetest.org/), the two speed index goals I start all projects with are **Chrome/Cable connection at 1000** and **Motorola E (mobile device)/Regular 3G connection at 3000**. These two speed index goals provide good bookends from slow devices/connections to fast devices/connections in markets where 3G mobile bandwidth is highly available. So, the point goals would be 1000 for large screen views and 3000 for small screen views.\n\nOnce point goals are decided upon, the next step is to actually sketch out the cost for ideas. What follows is by no means a comprehensive list of common design and development patterns and the cost to assign to them. If the total cost is greater than a project's point goal, that is [not ideal](https://github.com/munificent/vigil) and work should be done to fix that. None of the items below are mutually exclusive; for instance, if a project uses a CSS framework and needs custom styling on top of the CSS framework, both items must be counted. If there are multiple unique items on a page, for instance multiple images, each each unique item must be counted individually. Items can (and should) be combined to sketch out a [component](http://pointnorth.io/#components). When sketching non-desktop displays, the total cost should be multiplied by **4**.\n\n- Initial HTML (whole page): **20 points**\n- Custom styling (whole page): **40 points**\n- CSS Framework (Bootstrap, Foundation, etc…. Styling only): **150 points**\n- Full-width high res image (divide point total for different sized images): **250 points**\n- Individual custom font weight/style: **60 points**\n- Simple SVG: **5 points**\n- Complex SVG: **15 points**\n- Icon: **2 points** (each individual unique icon must be counted, repeated icons don't need to be)\n- HTML5 Video (>= 25 seconds): **250 points**\n- HTML5 Video (\u003C 25 seconds): **50 points**\n- JavaScript DOM manipulation framework (jQuery, Zepto, etc…): **340 points**\n- JavaScript MVC framework (Angular, React, etc…): **625 points**\n- Interaction requiring JavaScript (per component): **20 points**\n- Layout requiring JavaScript (per component): **100 points**\n- Movement requiring JavaScript (per component): **200 points**\n- Action triggered on scroll (per component): **400 points**\n- Repeated component with new content: **1/2 total component cost** (content counted separately)\n\nInitial HTML is going to be required once for all pages. This can be increased/decreased based on how much content is actually being displayed (single page sites, for instance, should cost more). Custom styling, likewise, will be required once for all pages and may increase based on how much one-off styling there is (current cost is based on a [systems-based design approach](http://daverupert.com/2013/04/responsive-deliverables/)). The rest of the suggestions more or less provide the building blocks for coming up with the cost of a project, but can also be combined to determine the cost for individual components. For instance, a carousel containing 4 items may have a cost breakdown of:\n\n- 4 quarter-width high res images: **250 points**\n- Interaction requiring JavaScript: **20 points**\n- Layout requiring JavaScript: **100 points**\n- Movement requiring JavaScript: **200 points**\n\nAll told, a single carousel component would cost **320 points** with **250 points** for content for a total cost of **570 points**. Subsequent carousels would cost an additional **160** points plus **250 points** for content or a total of **410 points**.\n\nThis should hopefully provide some common ground for designers, developers, PMs, and product owners to talk about performance from the beginning of the project instead of waiting until everything is coded up to discuss it. Of course, these performance sketches aren't law, and actual testing will be needed to ensure what is produced meets the final performance budget, and your numbers may vary. For a much more comprehensive dive in to designing with performance in mind, I highly recommend reading what [Lara Hogan](http://larahogan.me/) has written on the subject. Now go [make the web faster](https://developers.google.com/speed/).","src/content/posts/performance-sketches.md","ec64b2e67a713d21",{"html":1707,"metadata":1708},"\u003Cp>Performance is a complex dance between browsers, devices, networks, technology, marketing, branding, content strategy, and visual design. It’s no wonder, then, that often it gets left to the end of a project to actually work out. Creating and enforcing performance budgets are hard to begin with, but getting everyone to understand the impact of their choices on the performance of a project can be doubly so. Designing in browser (either by actually designing there, or getting there quickly, iterating there, and deciding there) can help with this as it brings performance to the forefront of the project and provides a way to test ideas from the beginning. But, there still needs to be a way to “sketch” a project’s performance before we get in browser. Having a way to “sketch” performance can help onboard new team members to the concept of \u003Ca href=\"http://timkadlec.com/2013/01/setting-a-performance-budget/\">performance budgets\u003C/a> earlier and allow teams to have a way of discussing performance while whiteboarding and sketching themselves, an invaluable part of the iteration process.\u003C/p>\n\u003Cp>When talking about performance, both \u003Ca href=\"http://pointnorth.io/#performance\">download and on-page performance\u003C/a> are essential in understanding the overall performance of a project. Download performance is much easier to quantify than on-page performance; the former being simply size and network speed whereas the later is both of those things plus execution time and device power. As such, when sketching performance, items that mostly don’t affect on-page performance are going to resemble only their download size, whereas items that do affect on-page performance are going to resemble their download size multiplied by a factor to represent that affect.\u003C/p>\n\u003Cp>Performance sketching starts with a point goal. The project’s performance budget \u003Ca href=\"https://sites.google.com/a/webpagetest.org/docs/using-webpagetest/metrics/speed-index\">speed index\u003C/a> goals will be the point goal for the performance sketches. Testing with \u003Ca href=\"http://www.webpagetest.org/\">Web Page Test\u003C/a>, the two speed index goals I start all projects with are \u003Cstrong>Chrome/Cable connection at 1000\u003C/strong> and \u003Cstrong>Motorola E (mobile device)/Regular 3G connection at 3000\u003C/strong>. These two speed index goals provide good bookends from slow devices/connections to fast devices/connections in markets where 3G mobile bandwidth is highly available. So, the point goals would be 1000 for large screen views and 3000 for small screen views.\u003C/p>\n\u003Cp>Once point goals are decided upon, the next step is to actually sketch out the cost for ideas. What follows is by no means a comprehensive list of common design and development patterns and the cost to assign to them. If the total cost is greater than a project’s point goal, that is \u003Ca href=\"https://github.com/munificent/vigil\">not ideal\u003C/a> and work should be done to fix that. None of the items below are mutually exclusive; for instance, if a project uses a CSS framework and needs custom styling on top of the CSS framework, both items must be counted. If there are multiple unique items on a page, for instance multiple images, each each unique item must be counted individually. Items can (and should) be combined to sketch out a \u003Ca href=\"http://pointnorth.io/#components\">component\u003C/a>. When sketching non-desktop displays, the total cost should be multiplied by \u003Cstrong>4\u003C/strong>.\u003C/p>\n\u003Cul>\n\u003Cli>Initial HTML (whole page): \u003Cstrong>20 points\u003C/strong>\u003C/li>\n\u003Cli>Custom styling (whole page): \u003Cstrong>40 points\u003C/strong>\u003C/li>\n\u003Cli>CSS Framework (Bootstrap, Foundation, etc…. Styling only): \u003Cstrong>150 points\u003C/strong>\u003C/li>\n\u003Cli>Full-width high res image (divide point total for different sized images): \u003Cstrong>250 points\u003C/strong>\u003C/li>\n\u003Cli>Individual custom font weight/style: \u003Cstrong>60 points\u003C/strong>\u003C/li>\n\u003Cli>Simple SVG: \u003Cstrong>5 points\u003C/strong>\u003C/li>\n\u003Cli>Complex SVG: \u003Cstrong>15 points\u003C/strong>\u003C/li>\n\u003Cli>Icon: \u003Cstrong>2 points\u003C/strong> (each individual unique icon must be counted, repeated icons don’t need to be)\u003C/li>\n\u003Cli>HTML5 Video (>= 25 seconds): \u003Cstrong>250 points\u003C/strong>\u003C/li>\n\u003Cli>HTML5 Video (&#x3C; 25 seconds): \u003Cstrong>50 points\u003C/strong>\u003C/li>\n\u003Cli>JavaScript DOM manipulation framework (jQuery, Zepto, etc…): \u003Cstrong>340 points\u003C/strong>\u003C/li>\n\u003Cli>JavaScript MVC framework (Angular, React, etc…): \u003Cstrong>625 points\u003C/strong>\u003C/li>\n\u003Cli>Interaction requiring JavaScript (per component): \u003Cstrong>20 points\u003C/strong>\u003C/li>\n\u003Cli>Layout requiring JavaScript (per component): \u003Cstrong>100 points\u003C/strong>\u003C/li>\n\u003Cli>Movement requiring JavaScript (per component): \u003Cstrong>200 points\u003C/strong>\u003C/li>\n\u003Cli>Action triggered on scroll (per component): \u003Cstrong>400 points\u003C/strong>\u003C/li>\n\u003Cli>Repeated component with new content: \u003Cstrong>1/2 total component cost\u003C/strong> (content counted separately)\u003C/li>\n\u003C/ul>\n\u003Cp>Initial HTML is going to be required once for all pages. This can be increased/decreased based on how much content is actually being displayed (single page sites, for instance, should cost more). Custom styling, likewise, will be required once for all pages and may increase based on how much one-off styling there is (current cost is based on a \u003Ca href=\"http://daverupert.com/2013/04/responsive-deliverables/\">systems-based design approach\u003C/a>). The rest of the suggestions more or less provide the building blocks for coming up with the cost of a project, but can also be combined to determine the cost for individual components. For instance, a carousel containing 4 items may have a cost breakdown of:\u003C/p>\n\u003Cul>\n\u003Cli>4 quarter-width high res images: \u003Cstrong>250 points\u003C/strong>\u003C/li>\n\u003Cli>Interaction requiring JavaScript: \u003Cstrong>20 points\u003C/strong>\u003C/li>\n\u003Cli>Layout requiring JavaScript: \u003Cstrong>100 points\u003C/strong>\u003C/li>\n\u003Cli>Movement requiring JavaScript: \u003Cstrong>200 points\u003C/strong>\u003C/li>\n\u003C/ul>\n\u003Cp>All told, a single carousel component would cost \u003Cstrong>320 points\u003C/strong> with \u003Cstrong>250 points\u003C/strong> for content for a total cost of \u003Cstrong>570 points\u003C/strong>. Subsequent carousels would cost an additional \u003Cstrong>160\u003C/strong> points plus \u003Cstrong>250 points\u003C/strong> for content or a total of \u003Cstrong>410 points\u003C/strong>.\u003C/p>\n\u003Cp>This should hopefully provide some common ground for designers, developers, PMs, and product owners to talk about performance from the beginning of the project instead of waiting until everything is coded up to discuss it. Of course, these performance sketches aren’t law, and actual testing will be needed to ensure what is produced meets the final performance budget, and your numbers may vary. For a much more comprehensive dive in to designing with performance in mind, I highly recommend reading what \u003Ca href=\"http://larahogan.me/\">Lara Hogan\u003C/a> has written on the subject. Now go \u003Ca href=\"https://developers.google.com/speed/\">make the web faster\u003C/a>.\u003C/p>",{"headings":1709,"localImagePaths":1710,"remoteImagePaths":1711,"frontmatter":1712,"imagePaths":1714},[],[],[],{"title":1700,"published":1713,"summary":1702},"2015-06-24",[],"persona-alignment",{"id":1715,"data":1717,"body":1721,"filePath":1722,"digest":1723,"rendered":1724},{"title":1718,"published":1719,"summary":1720},"Persona Alignment",["Date","2017-01-18T00:00:00.000Z"],"Dungeons and Dragons character alignment, but to make user personas","Last Sunday, I moved to Austin, TX to start working on a new team at IBM, previously called Whitewater, now the Agile and Talent Transformation and Operations organization (this is a whole different blog post; stay tuned). Since joining, I've been working with our design lead to help refine the personas and goals for our part of the organization for the year. While working on personas, and after re-reading Indi Young's [Describing Personas](https://medium.com/@indiyoung/describing-personas-af992e3fc527#.eo05pwcjr) again, as I [tend to do](https://twitter.com/Snugug/status/821458794643234816) whenever I start in to persona work, it dawned on me: after stripping out things that may bring cause unconscious bias, I saw a pattern emerge.\n\nI have been playing Dungeons and Dragons (D&D if you will) kind of on-and-off since being introduced to Advanced Dungeons & Dragons at a nerdy camp in high school. In fact, Snugug comes from the first character I made to play with my friends in high school (a half orc, half ogre barbarian that was strong enough to rip enemies in half with his bare hands, but was dumb enough to have been convinced a horse was a dog). One of the core mechanics of fleshing out a character in D&D is [character alignment](\u003Chttps://en.wikipedia.org/wiki/Alignment_(Dungeons_%26_Dragons)>). Characters exist on a grid, marking their lawful to chaotic alignment, and good to evil alignment.\n\n- **Lawful** - honorable, trustworthy, obedient to authority, reliable\n- **Neutral** - average respect for authority, but no compulsion one way or the other to follow the rules or rebel. Honest, but can be tempted\n- **Chaotic** - freedom, adaptability, and flexibility.\n- _Good_ - altruistic, respectful of life, willing to sacrifice themselves for others\n- _Neutral_ - committed to others by personal relationships only; won't hurt the innocent, but won't make sacrifices either\n- _Evil_ - willing to harm, oppress, or kill others\n\nWith these, a grid can be built, and characters can be placed!\n\n|             | Lawful         | Neutral      | Chaotic         |\n| ----------- | -------------- | ------------ | --------------- |\n| **Good**    | Lawful Good    | Good Neutral | Chaotic Good    |\n| **Neutral** | Lawful Neutral | True Neutral | Chaotic Neutral |\n| **Evil**    | Lawful Evil    | Evil Neutral | Chaotic Evil    |\n\nRobin Hood would be an example of Chaotic Good. He's altruistic, willing to sacrifice himself for others, but does so well outside of the the law. General Leia Organa would be lawful good, Han Solo would be Chaotic Neutral, and Darth Vader would be Lawful Evil.\n\nHaving this in the back of my head, the pattern I saw emerge was that the personas we were talking about all wound up having a combination of characteristics that could be mapped like D&D alignment! Our particular users are all at some point in their journey to become Agile practitioners, and all wind up having different thoughts on if that's a good idea or not. We wound up with the following _Persona Alignment Chart_ to describe our personas:\n\n- **Hero** - excited about adoption, understands the value of Agile to drive better outcomes, wants to help bring their team along\n- **Townsfolk** - willing to work in Agile, but not convinced of its value\n- **Anti-Hero** - believes that Agile may not be the best way to work, may try and work to convince team that other ways of working are more beneficial\n- _Green_ - new to Agile skills and terminology, has little to no experience working on an Agile team\n- _Local_ - familiar with some Agile skills and terminology, has some experience working on an Agile team\n- _Veteran_ - very familiar with Agile skills and terminology, usually opinionated about specific Agile methodologies, has lots of experience working on Agile teams\n\n|             | Hero         | Townsfolk         | Anti-Hero         |\n| ----------- | ------------ | ----------------- | ----------------- |\n| **Green**   | Green Hero   | Green Townsfolk   | Green Anti-Hero   |\n| **Local**   | Local Hero   | Local Townsfolk   | Local Anti-Hero   |\n| **Veteran** | Veteran Hero | Veteran Townsfolk | Veteran Anti-Hero |\n\nFrom this alignment chart, our personas emerge. Someone who is new to Agile but is really excited about adopting it for their team would be a Green Hero, maybe someone in leadership who's just returned from a conference. Someone whose team made the transition to Agile from Waterfall and found it difficult to adapt and their work suffer may be a Local Anti-Hero who wants to go back to Waterfall. Someone who has a long career on Agile teams and just kinda views it as the way their teams work and nothing more may be a Veteran Townsfolk. For our work, we thought that focusing our goals for this year on the Green Townsfolk (who we think are likely many of our users), the Local Anti-Hero (as we're likely going to come up against resistance in a giant change initiative), and the Veteran Hero (our ideal user so we know the goal to hit) is likely the way to go.\n\nWhile I don't think building personas this way will work for all use cases, for us I think it's going to work pretty well. The next step, of course, is rolling up character sheets for our personas, and our team (cause at this point I feel we might as well play a campaign).","src/content/posts/persona-alignment.md","85baa624d01d80de",{"html":1725,"metadata":1726},"\u003Cp>Last Sunday, I moved to Austin, TX to start working on a new team at IBM, previously called Whitewater, now the Agile and Talent Transformation and Operations organization (this is a whole different blog post; stay tuned). Since joining, I’ve been working with our design lead to help refine the personas and goals for our part of the organization for the year. While working on personas, and after re-reading Indi Young’s \u003Ca href=\"https://medium.com/@indiyoung/describing-personas-af992e3fc527#.eo05pwcjr\">Describing Personas\u003C/a> again, as I \u003Ca href=\"https://twitter.com/Snugug/status/821458794643234816\">tend to do\u003C/a> whenever I start in to persona work, it dawned on me: after stripping out things that may bring cause unconscious bias, I saw a pattern emerge.\u003C/p>\n\u003Cp>I have been playing Dungeons and Dragons (D&#x26;D if you will) kind of on-and-off since being introduced to Advanced Dungeons &#x26; Dragons at a nerdy camp in high school. In fact, Snugug comes from the first character I made to play with my friends in high school (a half orc, half ogre barbarian that was strong enough to rip enemies in half with his bare hands, but was dumb enough to have been convinced a horse was a dog). One of the core mechanics of fleshing out a character in D&#x26;D is \u003Ca href=\"https://en.wikipedia.org/wiki/Alignment_(Dungeons_%26_Dragons)\">character alignment\u003C/a>. Characters exist on a grid, marking their lawful to chaotic alignment, and good to evil alignment.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Lawful\u003C/strong> - honorable, trustworthy, obedient to authority, reliable\u003C/li>\n\u003Cli>\u003Cstrong>Neutral\u003C/strong> - average respect for authority, but no compulsion one way or the other to follow the rules or rebel. Honest, but can be tempted\u003C/li>\n\u003Cli>\u003Cstrong>Chaotic\u003C/strong> - freedom, adaptability, and flexibility.\u003C/li>\n\u003Cli>\u003Cem>Good\u003C/em> - altruistic, respectful of life, willing to sacrifice themselves for others\u003C/li>\n\u003Cli>\u003Cem>Neutral\u003C/em> - committed to others by personal relationships only; won’t hurt the innocent, but won’t make sacrifices either\u003C/li>\n\u003Cli>\u003Cem>Evil\u003C/em> - willing to harm, oppress, or kill others\u003C/li>\n\u003C/ul>\n\u003Cp>With these, a grid can be built, and characters can be placed!\u003C/p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003Ctable>\u003Cthead>\u003Ctr>\u003Cth>\u003C/th>\u003Cth>Lawful\u003C/th>\u003Cth>Neutral\u003C/th>\u003Cth>Chaotic\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd>\u003Cstrong>Good\u003C/strong>\u003C/td>\u003Ctd>Lawful Good\u003C/td>\u003Ctd>Good Neutral\u003C/td>\u003Ctd>Chaotic Good\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Cstrong>Neutral\u003C/strong>\u003C/td>\u003Ctd>Lawful Neutral\u003C/td>\u003Ctd>True Neutral\u003C/td>\u003Ctd>Chaotic Neutral\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Cstrong>Evil\u003C/strong>\u003C/td>\u003Ctd>Lawful Evil\u003C/td>\u003Ctd>Evil Neutral\u003C/td>\u003Ctd>Chaotic Evil\u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\n\u003Cp>Robin Hood would be an example of Chaotic Good. He’s altruistic, willing to sacrifice himself for others, but does so well outside of the the law. General Leia Organa would be lawful good, Han Solo would be Chaotic Neutral, and Darth Vader would be Lawful Evil.\u003C/p>\n\u003Cp>Having this in the back of my head, the pattern I saw emerge was that the personas we were talking about all wound up having a combination of characteristics that could be mapped like D&#x26;D alignment! Our particular users are all at some point in their journey to become Agile practitioners, and all wind up having different thoughts on if that’s a good idea or not. We wound up with the following \u003Cem>Persona Alignment Chart\u003C/em> to describe our personas:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Hero\u003C/strong> - excited about adoption, understands the value of Agile to drive better outcomes, wants to help bring their team along\u003C/li>\n\u003Cli>\u003Cstrong>Townsfolk\u003C/strong> - willing to work in Agile, but not convinced of its value\u003C/li>\n\u003Cli>\u003Cstrong>Anti-Hero\u003C/strong> - believes that Agile may not be the best way to work, may try and work to convince team that other ways of working are more beneficial\u003C/li>\n\u003Cli>\u003Cem>Green\u003C/em> - new to Agile skills and terminology, has little to no experience working on an Agile team\u003C/li>\n\u003Cli>\u003Cem>Local\u003C/em> - familiar with some Agile skills and terminology, has some experience working on an Agile team\u003C/li>\n\u003Cli>\u003Cem>Veteran\u003C/em> - very familiar with Agile skills and terminology, usually opinionated about specific Agile methodologies, has lots of experience working on Agile teams\u003C/li>\n\u003C/ul>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003Ctable>\u003Cthead>\u003Ctr>\u003Cth>\u003C/th>\u003Cth>Hero\u003C/th>\u003Cth>Townsfolk\u003C/th>\u003Cth>Anti-Hero\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd>\u003Cstrong>Green\u003C/strong>\u003C/td>\u003Ctd>Green Hero\u003C/td>\u003Ctd>Green Townsfolk\u003C/td>\u003Ctd>Green Anti-Hero\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Cstrong>Local\u003C/strong>\u003C/td>\u003Ctd>Local Hero\u003C/td>\u003Ctd>Local Townsfolk\u003C/td>\u003Ctd>Local Anti-Hero\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Cstrong>Veteran\u003C/strong>\u003C/td>\u003Ctd>Veteran Hero\u003C/td>\u003Ctd>Veteran Townsfolk\u003C/td>\u003Ctd>Veteran Anti-Hero\u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\n\u003Cp>From this alignment chart, our personas emerge. Someone who is new to Agile but is really excited about adopting it for their team would be a Green Hero, maybe someone in leadership who’s just returned from a conference. Someone whose team made the transition to Agile from Waterfall and found it difficult to adapt and their work suffer may be a Local Anti-Hero who wants to go back to Waterfall. Someone who has a long career on Agile teams and just kinda views it as the way their teams work and nothing more may be a Veteran Townsfolk. For our work, we thought that focusing our goals for this year on the Green Townsfolk (who we think are likely many of our users), the Local Anti-Hero (as we’re likely going to come up against resistance in a giant change initiative), and the Veteran Hero (our ideal user so we know the goal to hit) is likely the way to go.\u003C/p>\n\u003Cp>While I don’t think building personas this way will work for all use cases, for us I think it’s going to work pretty well. The next step, of course, is rolling up character sheets for our personas, and our team (cause at this point I feel we might as well play a campaign).\u003C/p>",{"headings":1727,"localImagePaths":1728,"remoteImagePaths":1729,"frontmatter":1730,"imagePaths":1732},[],[],[],{"title":1718,"published":1731,"summary":1720},"2017-01-18",[],"principles-responsive-web-design",{"id":1733,"data":1735,"body":1740,"filePath":1741,"digest":1742,"rendered":1743},{"title":1736,"published":1737,"summary":1738,"categories":1739},"Principles of Responsive Web Design",["Date","2012-05-24T00:00:00.000Z"],"I've spent almost the last year learning about and really digging into responsive Web design and I've gotta say, there are very few things that excite me more in front end development today. It is the beginning of a new era of the Web.",[55,29],"I've spent almost the last year learning about and really digging into responsive Web design and I've gotta say, there are very few things that excite me more in front end development today. It is the beginning of a new era of the Web, an era that has its root in the launch of the iPhone five years ago which brought with it a fully capable Web browser to the pockets of the masses. There was really only one issues with this, up until this point, just about every website had been designed for a desktop screen and therefore didn't look or work their best at the new small form factor. A couple of years later, the Web development community got a new way of thinking about Web design when [Ethan Marcotte's Responsive Web Design](http://www.alistapart.com/articles/responsive-web-design/ 'A List Apart: Articles: Responsive Web Design') and [Luke Wroblewski's Mobile First Design](http://www.lukew.com/ff/entry.asp?933 'LukeW | Mobile First') philosophies were published. (As an aside, both Ethan and Luke have written books on the subjects that you should absolutely read, which are available as a bundle from [A Book Apart](http://www.abookapart.com/products/mobile-first-responsive-web-design-bundle 'A Book Apart, Mobile First and Responsive Web Design Bundle')). With this knowledge in hand, and shaped by personal experience and other expert's research and teachings, I went about forming my personal Principles of Responsive Design. Below is an attempt to codify my knowledge so that I can share it with the communities I'm lucky enough to be a part of, and so I never again have a less than ideal browsing experience on any of the devices I choose to surf the Web with.\n\n## The Web is a Medium\n\nOf all of the concepts of responsive Web design (thus-forth known as RWD), this is the most important one, it's _raison d'être_. Since the web's inception, and through this day, we have been trying make the Web behave like print design, to differing degrees of success. In order for RWD to flourish, we need to take to heart the words of [Ethan Maracotte](https://twitter.com/globalmoxie/statuses/192282944944091136): \"the Web is an inherently unstable medium.\"\n\nWhile there are many similarities between print and Web as mediums, and many concepts from print translate well onto the web, many more do not belong, the most prevalent being a fixed size. There is a reason fixed sized websites are so prominent, it's because it is very easy to design to a known size, a page metaphor if you will, especially for print designers who are use to working with set paper dimensions. It's easier to control your design when you control its dimensions, so designers took to determining what dimensions a \"web page\" should be, and we all generally settled on a 960px grid based on statistics about desktop browser size. There's just one problem with that, as [Brad Frost has brilliantly put it](http://bradfrostweb.com/blog/web/responsive-web-design-missing-the-point/ 'Responsive Web Design: Missing the Point | Brad Frost Web'):\n\n![What is the Web](/images/principles-responsive-web-design/the-web.jpg 'What is the Web')\n\n> The point of creating [responsive] sites is to create functional (and hopefully optimal) user experiences for a growing number of web-enabled devices and contexts.\n>\n> ~ Brad Frost\n\nPrint is easy; we can control the colors, the print size, the font size, we even have a pretty good idea about where, when, even how far away it is going to be viewed. There is a very limited number of ways to interact with print media, and those are fairly easy to control. In these respects, the Web is the polar opposite of Print, and rapidly becoming more so. As Brad says, RWD is a design process aimed at rectifying inherent lack of stability in the medium. It requires new ways of thinking about design, of user interaction, of user experience; a truly holistic approach to the wants, needs, and capabilities of an ever increasing number of Web connected devices. RWD is the groundwork for us to start to embrace the instability and move us away from the want to always be in absolute control of our designs, because when you look at the Web through RWD tinted glasses, pixel perfect will drop from your vocabulary faster than a missile that has all of a sudden become a pot of petunias.\n\nWith that being said, all is not lost in the need to control our design. Thanks to a feature in modern Web browsers called media queries, we as designers now have the tools needed to be able to transform our designs when they no longer are optimal for our content. We are able to not just shift columns around, but potentially providing an entirely new experience when our designs break; by embracing the instability, we are able to potentially provide previously unimaginable flexibility with our designs. There's just one problem with the existing design workflow: [you can't articulate fluidity on paper.](https://twitter.com/brad_frost/statuses/195245787150688256). We, as designers, need to close our print tools and open up our Web tools if we are going to succeed in developing responsive websites. Just like how we use the print medium itself to sketch, draw, paint, and create print items, we need to use the Web as its own medium for creation. We need to start designing our websites where they are going to live and with the tools used to bring them to life. We need to start designing in our browsers.\n\n## Design In Browser\n\nA static Photoshop mock isn't cool. You know what is cool? A living mock. Anyone who has ever translated a Photoshop mock into a website knows the hassle of needing to translate print designs into the language of the Web. With the widespread implementation of most of the visual flair we are accustomed to from Photoshop built into modern Web browsers (even fancy Web fonts!), we have the toolset needed to create stunning websites without any graphics at all, all within our browsers. What this means, to borrow a phrase from my friend Mason Wendell, is that all designers should be [Coding Designers](https://github.com/canarymason/survival-kit). Yes, this means that all designers need to know HTML and CSS; if they don't, it's like a chef that knows where to buy the best ingredients but not how to prepare them.\n\nLet me step back a minute; it's not that Photoshop isn't cool, it's that using _any_ bitmap tool for RWD to build anything except bitmap images is functionally impractical. Not only do you have all of the limitations already inherit with using a print tool to design for the Web, you also run into the issue of needing to create different mocks for every content based break point, which is not only hard to do in a bitmap tool, but it's a hell of a lot of extra mocks you're going to need to make. Practically, that's hours of extra work plus hours extra for each design iteration. Designing in browser allows you to iterate quickly over the full range potential break points. Throw in version control, and you've got a quick and easy way to show multiple mocks with real content very easily.\n\nDesigning your website in browser also gives you insight into your design you wouldn't have otherwise, such as how it looks with real and variable content, how it looks and how it needs to change as browser size increases and decreases, how the design actually performs, how it renders in a wide array of devices and browsers, in an array of circumstances (like on a train, on the street, at your desk, in the coffee shop down the block), and a slew of other things. It also provides quite a few benefits to the design process, like a final product that can either be used or very easily translated at the end of the design process and, if using a CSS preprocessor like [Sass](http://sass-lang.com/ 'Sass - Syntactically Awesome Stylesheets') (which I highly recommend you do), major style elements, such as colors and typography, can be changed very easily on the fly and rendered nearly instantaneously. Designing in browser allows you to build the products of the Web with the tools of the Web in the languages of the web.\n\n## Mobile First\n\nIf you're building a RWD site, you need to, as championed by Luke W, design for Mobile First. By designing for the Mobile First, you are setting a lowest common denominator to build from; one of slow connection speeds, impatient users, unconventional input methods, underpowered browsers, and amazingly cool APIs. But, when discussing Mobile First design, it is worth separating design and development. Many projects understand and implement, to some extent, the development side of Mobile First while neglecting the design side, unfortunately usually to the detriment of the end user.\n\nBefore we continue, let me step back and define what I mean when I say mobile. To quote Cennydd Bowles \"[mobile is a user state, not a device](https://twitter.com/brad_frost/statuses/192281875434319872).\" When I mention mobile, I'm talking about a user potentially on the go, probably on an unreliable connection with medium to low bandwidth who, to use [Kristofer Layton's Theory of Mobile Motivation](http://kristoferlayon.files.wordpress.com/2012/03/klayonsxsw2012.pdf), values content and navigation above built-in social sharing and visual and technical flair. They are usually on small devices with quirky browsers, using anything and everything but a mouse to navigate, and value their time highly. [As Gomez reports](http://www.gomez.com/wp-content/downloads/19986_WhatMobileUsersWant_Wp.pdf) 75% of Mobile users are willing to abandon a site if it takes more than 5 seconds to load with 80% willing to spend more time on a website if the experience was fast and reliable. The cost of not taking the mobile user into account? 57% will neither return to your site after a bad experience nor recommend it to others. [Mobile users make up 88% of the US Adult Population](http://pewinternet.org/Commentary/2012/February/Pew-Internet-Mobile.aspx) with 46% of the US Adult population using a smartphone, a year over year increase of more than 1% of the population _per month_. There are now more than [five times the number of mobile device activations per day than human births](https://twitter.com/Snugug/statuses/182849284054581250), each one of them a mobile user. If you are not designing with the mobile user in mind first, you are neglecting your users.\n\nNow, what does this mean for development? Well, actually, Mobile First development can be a fairly easy concept to grasp as it is really no more than a reiteration of Web development best practices: keep load times as low as possible, keep assets as small as possible, keep http requests to a minimum, make sure you site doesn't break if a browser feature is unavailable, and build using browser-independent modern Web standards (HTML, CSS, and JavaScript). When talking about Mobile First, we are also usually talking about HTML5 as well, so to these best practices we should also add light, semantic markup which, by it's nature, begs for a content-first approach to your site. Your source order should match the importance of content.\n\nMobile First design, on the other hand, is much less tangible, and requires a shift in thinking. There are three parts to Mobile First design (and really design in general): User Interface, User Experience, and Information Architecture (UI, UX and IA). In order to have a successful site, all three of these need to be done right, and all three of these should start Mobile First.\n\n> Mobile devices require software development teams to [focus on only the most important data and actions](http://www.lukew.com/ff/entry.asp?870) in an application. There simply isn't room in a 320 by 480 pixel screen for extraneous, unnecessary elements. You have to prioritize.\n>\n> So when a team designs Mobile First, the end result is an experience focused on the key tasks users want to accomplish without the extraneous detours and general interface debris that litter today's desktop-accessed Web sites. That's good user experience and good for business.\n>\n> ~ Luke Wroblewski\n\nA Mobile First design approach requires you to step back and take a good, hard look at what is most important to your visitors and can give you leverage to cut cruft from your website. Luke has a phrase he likes to use when describing a mobile user: \"[[they have] one eyeball and one thumb](http://www.alistapart.com/articles/organizing-mobile/)\". What this means is a mobile user is going to devote limited resources to trying to figure out your website and if you haven't architected your site to present your content as quickly and easily as possible, you're mobile user isn't going to see it.\n\nBut, this doesn't mean you should make a curated mobile experience, oh no! [Our job is not to willy-nilly strip out useful features. Anytime you say, somebody won't want that on mobile, that's not mobile content… you're wrong.](http://globalmoxie.com/jhc/prez/mobile-myths.pdf) Anything a user can, will, and expect to be able to do sitting in front of a desktop computer they can, will, and expect to be able to do from their handheld one; [people use any platform to do anything](http://www.cxpartners.co.uk/cxblog/mobile-app-or-mobile-web/). As [Josh Clark puts it](https://twitter.com/brad_frost/statuses/192198577605455874), \"the myth that \"mobile = less\" mentality is wrong and damaging. Don't confuse context with intent.\" In fact, as [Cennydd Bowles says](https://twitter.com/globalmoxie/statuses/192280314452779008), \"assuming user intent from simple device context is a \"classic error.\"\" Your site needs one to one content parity regardless of the device or screen size it is being viewed from. Use tools like location and time to determine context and assist in rearranging content, but not device and not to remove content.\n\nBy thinking about our sites in a Mobile First and content first approach, we are able to better architect our sites, which in turn leads to building better UX for our visitors and by then by extension, a better UI. Additionally, because this approach forces us to IA and UX for Mobile First, we are able to carry over our \"one eye, one thumb\" thinking to our \"desktop\" (re: large width) layout, improving _everyone's_ experience and not just the mobile user's. Even devices and browsers we may otherwise consider unsupported.\n\n## Progressive Enhancement and Graceful Degradation\n\nBoth Progressive Enhancement and Graceful Degradation are two sides of the same coin: best practices for Web design. Progressive Enhancement is a ground up approach to Web design where you design for the lowest common denominator and, as features become available, you add more. This approach fits in most nicely with our Mobile First design approach which, in fact, is a form of Progressive Enhancement. Graceful Degradation, on the other hand, is a top down approach where you build a feature and then provide fallbacks when features are not available. Anything and everything you build should keep these concepts in mind because they both strive for the same end goal: being able to display your content no matter the device used to access it, including those you may consider unsupported. This a core tenant of the Web as a medium. Always bear in mind that the Web is an inherently unstable medium, and if we think in a Progressive Enhancement mindset, [that means that layout is itself an enhancement](https://twitter.com/globalmoxie/statuses/192282944944091136).\n\nSpeaking of layout and Progressive Enhancement, Joni Korpi has a [great article about just that](http://jonikorpi.com/leaving-old-IE-behind/). The gist of it is that, instead of trying to mimic media queries on unsupported browsers _including Internet Explorer 8 and below_, you serve a single column website and use media queries to build out your layout, instead of designing a desktop layout and using media queries to shrink it. This is the ideal for Mobile First design as well as it will serve a fluid, single column layout to mobile devices of a certain size and outdated browsers. The best part about this approach to layout is its hack free, JavaScipt free, almost thought free lowest common denominator.\n\nOne important thing that is an absolute must if you're building progressively is that, under no circumstances, should you be browser sniffing or using device detection to see if a user can use your site. Not only are these methods unreliable but they're unsustainable as well. For instance, there are currently five desktop versions of Internet Explorer and at least two mobile versions, Google Chrome's UA is set up to trick browsers into thinking it's Firefox, and there are over one thousand different types of Android devices either currently or previously on the market worldwide. If you want to make sure your user can use a feature, do the logical thing and _feature detect_. There is an amazing tool called [Modernizr](http://modernizr.com/) that is designed specifically to do feature based section to aid with development. If you absolutely must have a feature that isn't available, there are amazing polyfills and shivs being written to combat browsers lacking in features. Don't deny your user your content because of how they got to it, make sure it works, on some level, regardless.\n\n## The Fluid Grid and Content Breakpoints\n\nAs [Scott Kellum jested](https://twitter.com/ScottKellum/statuses/182461146660474880): \"You can tell a site is “web 3.0” if it’s built on a grid.\" It's funny 'cause it's true. A responsive site really needs to be built on a grid, _any grid_, as long as it's something you stick to and can scale in a fluid manner. Now this isn't to say your grid cannot change as you scale, but you need to build to a grid and the grid needs to be fluid.\n\nAs [John Albin so precisely puts](http://zen-grids.com), if you're going to be doing RWD, you really need to be using a CSS Preprocessor (of which we would both recommend [Sass](http://sass-lang.com)). The concept of a grid is easy, but when actually trying to implement one, especially a fluid one, the math can get complicated very quick, and grid classes are not only not semantic but break the separation of concerns between HTML and CSS. Both of these issues are solved by using a CSS Preprocessor to deal with the math for you, and to put your widths straight on the selects you're targeting instead of needing to edit your HTML to deal with styling. If you take a look at my source, you won't see any grid classes, only light, semantic widths and margins built with the use of Sass, [Susy](http://susy.oddbird.net/), and [Aura](https://github.com/snugug/aura).\n\nWith a grid set up, lets talk about physically designing on a fluid grid. Following our Mobile First mindset, the very first thing we design is our single column layout, more commonly described as our small screen or mobile layout. As [Brian and Stephanie Reiger say](https://twitter.com/brad_frost/statuses/192282902472564740), \"the absence of support for media queries is indeed the first media query.\" [Ethan Marcotte reiterates that point](https://twitter.com/brad_frost/statuses/192282883929554944):\n\n> Avoid starting large then shrinking down. Approach layout from a Mobile First approach. Fits in with progressive enhancement.\n\nAfter a single column theme has been built, what next? The are many advocates of, and many responsive frameworks that work by, setting your breakpoint, or where your design changes, based off of known device sizes. This usually means non-retina iOS dimensions in landscape and portrait with maybe the addition of one in between iPhone and iPad and maybe one wide Desktop dimension. If you think that Android, Blackberry, and Windows Phone 7 all have a standard screen size that you could also break to, [let me](http://en.wikipedia.org/wiki/List_of_Windows_Phone_devices 'Windows Phone') [dash those](http://supportforums.blackberry.com/t5/Java-Development/List-of-Blackberry-Devices-with-resolution/td-p/556066 'Blackberry') [hopes and dreams](http://en.wikipedia.org/wiki/Comparison_of_Android_devices 'Android'). Overall, this seems amazingly short sighted to me (and pretty much everyone doing RWD professionally) and, possibly more importantly, neglects one of the core tenants of RWD: the Web is an inherently unstable medium. But even more practical than that, why would you want to shoehorn your design into known device dimensions when building breakpoints based on when your content needs it ensures it looks it's best on _all_ platforms.\n\n> Start with the small screen first, then expand until it looks like shit. TIME FOR A BREAKPOINT!\n>\n> ~ [Stephen Hay](https://twitter.com/brad_frost/statuses/191977076000161793)\n\nContent based breakpoints are surprisingly easy, as Stephen says, keep expanding your window until your content looks crap, then put a breakpoint there. There are a plethora of tools out there to get your window's screen size for your break point so there's no excuse not to do it this way. If you're using Sass 3.2 or higher, in fact, your life just became super easy! Instead of needing to remember all of your breakpoints by number, you can remember them by name! You can write a mixin like the following for all of your breakpoints:\n\n```scss\n// Four breakpoints: foo, bar, baz, and qux.\n//\n// Foo assumes the defaults of min-width and screen. Foo will gen @media screen and (min-width: 500px)\n// Bar changes min-width to max, but assumes screen as well. Bar will gen @media screen and (max-width: 700px)\n// Baz wants to use min-width, but change media type, so min-width needs to be re-declare. Baz will gen @media tv and (min-width: 700px)\n// Qux goes all out and has a full unique media query. Qux will get @media tv and (max-width: 900px)\n\n$breakpoints:\n  'foo' 500px,\n  'bar' 700px 'max-width',\n  'baz' 700px 'min-width' tv,\n  'qux' 900px 'max-width' tv;\n\n// Let's call respond-to!\n#waldo {\n  background: red;\n\n  @include respond-to('foo') {\n    background: green;\n  }\n\n  @include respond-to('bar') {\n    background: yellow;\n  }\n\n  @include respond-to('baz') {\n    background: purple;\n  }\n\n  @include respond-to('qux') {\n    background: orange;\n  }\n}\n\n// Our Output:\n#waldo {\n  background: red;\n}\n\n@media screen and (min-width: 500px) {\n  #waldo {\n    background: green;\n  }\n}\n\n@media screen and (max-width: 700px) {\n  #waldo {\n    background: yellow;\n  }\n}\n\n@media tv and (min-width: 700px) {\n  #waldo {\n    background: purple;\n  }\n}\n\n@media tv and (max-width: 900px) {\n  #waldo {\n    background: orange;\n  }\n}\n```\n\n```scss\n// Our respond-to mixin, with the new hotness?\n// A little more complicated than previous respond-to mixins, but now runs off of a variable. This is also Rev 1 so if someone can help me make it better, I'm all ears.\n// We need to start with a defaulted breakpoints variable.\n\n$breakpoints: false !default;\n\n@mixin respond-to($context) {\n  @if $breakpoints != false {\n    // Check to see if the 2nd item is a number. If it is, we've got a single query\n    @if type-of(nth($breakpoints, 2)) == 'number' {\n      // Check to see if the context matches the breakpoint namespace\n      @if $context == nth($breakpoints, 1) {\n        // Call Media Query Generator\n        @include media-query-gen($breakpoints) {\n          @content;\n        }\n      }\n    }\n    // Else, loop over all of them\n    @else {\n      // Loop over each breakpoint and check context\n      @each $bkpt in $breakpoints {\n        // If context is correctâ€¦\n        @if $context == nth($bkpt, 1) {\n          // Call the generator!\n          @include media-query-gen($bkpt) {\n            @content;\n          }\n        }\n      }\n    }\n  }\n}\n\n// This functionality gets used twice so I turned it into its own mixin.\n\n@mixin media-query-gen($bpt) {\n  // Get length of breakpoint variable, minus the namespace\n  $length: length($bpt);\n  // Go through all of the breakpoint items, starting at the second, and add them to a variable to be passed into the media query mixin\n  $mq: false !default;\n  @for $i from 2 through $length {\n    // If it's the first item, override $mq\n    @if $i == 2 {\n      $mq: nth($bpt, $i);\n    }\n    // Else, join $mq\n    @else {\n      $mq: join($mq, nth($bpt, $i));\n    }\n  }\n  // Call Media Query mixin\n  @include media-query($mq) {\n    @content;\n  }\n}\n\n// Slightly modified version of my Media Query Mixin (https://gist.github.com/2490750) from earlier, modified to accommodate list input\n@mixin media-query($value, $operator: 'min-width', $query: 'screen') {\n  // If a list is passed in for value, break it into value, operator, and query\n  @if type-of($value) == 'list' {\n    $mq: $value;\n\n    @for $i from 1 through length($mq) {\n      @if $i == 1 {\n        $value: nth($mq, 1);\n      } @else if $i == 2 {\n        $operator: nth($mq, 2);\n      } @else if $i == 3 {\n        $query: nth($mq, 3);\n      }\n    }\n  }\n\n  @media #{$query} and (#{$operator}: #{$value}) {\n    @content;\n  }\n}\n```\n\nThe other issue I have with device based breakpoints is all they do is enforce the printed page metaphor with varying fixed page sizes instead of a single one (think designing a flyer, a brochure, and a business card instead of a website). As [Rachel Hinman says](https://twitter.com/brad_frost/statuses/192239397855440896), \"the \"page\" metaphor holds us back from creating truly great mobile experiences\". Device breakpoints are a wolf in sheep's clothing; passing itself off for RWD when in reality it's more of the same static design (even with a fluid grid).\n\n## Design Natural User Interfaces, not Graphical Ones\n\nIf there is one thing to come out of the iPhone that is the fundamental defining feature of the device, multitouch would be it. It's an entirely new way of interacting with the content on your screen by actually _interacting with it_. [Pinch, swipe, tap, hold](http://www.lukew.com/ff/entry.asp?1071); these simple gestures are such a change from the point, hover, click nature of desktop interaction that many of the traditional graphical enhancements relied upon need to be rethought or thrown out altogether. As [Rachel Hinman says](https://twitter.com/globalmoxie/statuses/192247950817234944), \"the legacy inertia of [graphical user interfaces] holds back [natural user interfaces] progress\" and that \"buttons are hacks\". So what's a dev to do? Mobile First and Progressive Enhancement to the rescue! Build uncluttered, easy to use, large user interfaces (fingers are a much larger input device than the pixel perfect precision of a mouse) and do not rely upon proxy navigation of your content (hover states, for instance, _do not work_ on Mobile). If touch is available, utilize it! If you don't know what touch gestures are available, [Luke W has you covered once again](http://www.lukew.com/ff/entry.asp?1071). Make galleries and carousels swipeable! Turn context menus into hold menus! If not, make sure you have fallbacks! The point of Natural User Interfaces, like Mobile First, isn't to absolutely do away with Graphical ones, but rather to take our design queues from it, design towards that ideal, and present a gracefully degraded solution when our ideal isn't met.\n\nOne of the best examples of a true Natural User Interface is an iOS app called [Clear](http://www.realmacsoftware.com/clear/). Clear is a todo app where you pinch, pull, swipe, and tap to accomplish all of the normal todo actions, with the difference being that the controls _are_ the interface, and a beautiful interface it is. One of the toughest things with Natural User Interfaces is building interactions that need no explanation (or whose explanation can be hinted at while using), and Clear does this marvelously. What's more, if you're saying to yourself \"but that's a native app, we can't do that in browser!\", take a look at [HTML5 Clear](https://github.com/yyx990803/HTML5-Clear-v2). Check out the Clear promo video below to get a sense of how a great Natural User Interface works.\n\n@[vimeo](https://vimeo.com/37182785)\n\nSomewhere about this time, if you've been designing according to these principles, you're going to have an epiphany. When designing responsively from a content first perspective on a semantic framework, you're going to realize that, even totally devoid of CSS and JavaScript, your site is mobile optimized. As Scott Kellum says, this is a big deal because \"after this epiphany it becomes impossible to set styles then override them when no style at all will do just fine.\" Let this epiphany guide you toward the Natural UI light and away from the Graphical UI dark.\n\nAn important point to this, though, is that Natural does not mean \"mimicking the UI of native apps.\" Natural means natural to anyone on any platform, not natural to those on iOS or Android. As [Cennyyd Bowles says](https://twitter.com/bdconf/statuses/192280842272374784), \"if you're trying to make a cat look more like a dog, just buy a dog.\" Don't fake native app UI, if you want a native app, build a native app, and, for the love of god, whatever you do, don't put a back button on your website. Every Web browser in existence has a built in back button that works better than yours, is more device agnostic than yours, and is more well integrated than yours. Now I can get behind swiping back and forth for forward and back in history (go ahead, try it now, two fingers for those devices that support it), but don't you dare put an actual back button on your site.\n\n## And, In The End, the Love You Take is Equal to the Love You Make\n\nTo me, these Principles of Responsive Design all boil down to one thing: being [Future Friendly](http://futurefriend.ly/resources.html). Gartner predicts that [by next year, mobile devices will surpass desktop devices as the most common way to access the Internet worldwide](http://www.gartner.com/it/page.jsp?id=1278413). I feel as if that needs repeating. Not in 10 years, not in 5 years, not even in 1 year. In less than 8 months, worldwide, a user will be more likely to access your website from a mobile device than a desktop device. The writing is on the wall already, with more than 2 times the number of mobile device activations than [traditional computers sold per day](http://www.worldometers.info/computers/). Because of this we, as the keepers of the web, need to take these principles to heart when we talk to our clients and build our sites. By treating the Web as its own medium, by designing in browser instead of bitmap editors, by designing for Mobile First, by building our sites progressively, by making layout changes content based and device agnostic, and by designing natural user interfaces better suited for both mobile and desktop as opposed to graphical for only desktop, we will be building websites that are best viewed on any Web enabled device for the foreseeable future. To borrow a phrase from Gandhi, we need to be the change we want to see in the web.","src/content/posts/principles-responsive-web-design.md","5169061a21a7ef62",{"html":1744,"metadata":1745},"\u003Cp>I’ve spent almost the last year learning about and really digging into responsive Web design and I’ve gotta say, there are very few things that excite me more in front end development today. It is the beginning of a new era of the Web, an era that has its root in the launch of the iPhone five years ago which brought with it a fully capable Web browser to the pockets of the masses. There was really only one issues with this, up until this point, just about every website had been designed for a desktop screen and therefore didn’t look or work their best at the new small form factor. A couple of years later, the Web development community got a new way of thinking about Web design when \u003Ca href=\"http://www.alistapart.com/articles/responsive-web-design/\" title=\"A List Apart: Articles: Responsive Web Design\">Ethan Marcotte’s Responsive Web Design\u003C/a> and \u003Ca href=\"http://www.lukew.com/ff/entry.asp?933\" title=\"LukeW | Mobile First\">Luke Wroblewski’s Mobile First Design\u003C/a> philosophies were published. (As an aside, both Ethan and Luke have written books on the subjects that you should absolutely read, which are available as a bundle from \u003Ca href=\"http://www.abookapart.com/products/mobile-first-responsive-web-design-bundle\" title=\"A Book Apart, Mobile First and Responsive Web Design Bundle\">A Book Apart\u003C/a>). With this knowledge in hand, and shaped by personal experience and other expert’s research and teachings, I went about forming my personal Principles of Responsive Design. Below is an attempt to codify my knowledge so that I can share it with the communities I’m lucky enough to be a part of, and so I never again have a less than ideal browsing experience on any of the devices I choose to surf the Web with.\u003C/p>\n\u003Ch2 id=\"the-web-is-a-medium\">The Web is a Medium\u003C/h2>\n\u003Cp>Of all of the concepts of responsive Web design (thus-forth known as RWD), this is the most important one, it’s \u003Cem>raison d’être\u003C/em>. Since the web’s inception, and through this day, we have been trying make the Web behave like print design, to differing degrees of success. In order for RWD to flourish, we need to take to heart the words of \u003Ca href=\"https://twitter.com/globalmoxie/statuses/192282944944091136\">Ethan Maracotte\u003C/a>: “the Web is an inherently unstable medium.”\u003C/p>\n\u003Cp>While there are many similarities between print and Web as mediums, and many concepts from print translate well onto the web, many more do not belong, the most prevalent being a fixed size. There is a reason fixed sized websites are so prominent, it’s because it is very easy to design to a known size, a page metaphor if you will, especially for print designers who are use to working with set paper dimensions. It’s easier to control your design when you control its dimensions, so designers took to determining what dimensions a “web page” should be, and we all generally settled on a 960px grid based on statistics about desktop browser size. There’s just one problem with that, as \u003Ca href=\"http://bradfrostweb.com/blog/web/responsive-web-design-missing-the-point/\" title=\"Responsive Web Design: Missing the Point | Brad Frost Web\">Brad Frost has brilliantly put it\u003C/a>:\u003C/p>\n\u003Cp>\u003Cimg src=\"/images/principles-responsive-web-design/the-web.jpg\" alt=\"What is the Web\" title=\"What is the Web\">\u003C/p>\n\u003Cblockquote>\n\u003Cp>The point of creating [responsive] sites is to create functional (and hopefully optimal) user experiences for a growing number of web-enabled devices and contexts.\u003C/p>\n\u003Cp>~ Brad Frost\u003C/p>\n\u003C/blockquote>\n\u003Cp>Print is easy; we can control the colors, the print size, the font size, we even have a pretty good idea about where, when, even how far away it is going to be viewed. There is a very limited number of ways to interact with print media, and those are fairly easy to control. In these respects, the Web is the polar opposite of Print, and rapidly becoming more so. As Brad says, RWD is a design process aimed at rectifying inherent lack of stability in the medium. It requires new ways of thinking about design, of user interaction, of user experience; a truly holistic approach to the wants, needs, and capabilities of an ever increasing number of Web connected devices. RWD is the groundwork for us to start to embrace the instability and move us away from the want to always be in absolute control of our designs, because when you look at the Web through RWD tinted glasses, pixel perfect will drop from your vocabulary faster than a missile that has all of a sudden become a pot of petunias.\u003C/p>\n\u003Cp>With that being said, all is not lost in the need to control our design. Thanks to a feature in modern Web browsers called media queries, we as designers now have the tools needed to be able to transform our designs when they no longer are optimal for our content. We are able to not just shift columns around, but potentially providing an entirely new experience when our designs break; by embracing the instability, we are able to potentially provide previously unimaginable flexibility with our designs. There’s just one problem with the existing design workflow: \u003Ca href=\"https://twitter.com/brad_frost/statuses/195245787150688256\">you can’t articulate fluidity on paper.\u003C/a>. We, as designers, need to close our print tools and open up our Web tools if we are going to succeed in developing responsive websites. Just like how we use the print medium itself to sketch, draw, paint, and create print items, we need to use the Web as its own medium for creation. We need to start designing our websites where they are going to live and with the tools used to bring them to life. We need to start designing in our browsers.\u003C/p>\n\u003Ch2 id=\"design-in-browser\">Design In Browser\u003C/h2>\n\u003Cp>A static Photoshop mock isn’t cool. You know what is cool? A living mock. Anyone who has ever translated a Photoshop mock into a website knows the hassle of needing to translate print designs into the language of the Web. With the widespread implementation of most of the visual flair we are accustomed to from Photoshop built into modern Web browsers (even fancy Web fonts!), we have the toolset needed to create stunning websites without any graphics at all, all within our browsers. What this means, to borrow a phrase from my friend Mason Wendell, is that all designers should be \u003Ca href=\"https://github.com/canarymason/survival-kit\">Coding Designers\u003C/a>. Yes, this means that all designers need to know HTML and CSS; if they don’t, it’s like a chef that knows where to buy the best ingredients but not how to prepare them.\u003C/p>\n\u003Cp>Let me step back a minute; it’s not that Photoshop isn’t cool, it’s that using \u003Cem>any\u003C/em> bitmap tool for RWD to build anything except bitmap images is functionally impractical. Not only do you have all of the limitations already inherit with using a print tool to design for the Web, you also run into the issue of needing to create different mocks for every content based break point, which is not only hard to do in a bitmap tool, but it’s a hell of a lot of extra mocks you’re going to need to make. Practically, that’s hours of extra work plus hours extra for each design iteration. Designing in browser allows you to iterate quickly over the full range potential break points. Throw in version control, and you’ve got a quick and easy way to show multiple mocks with real content very easily.\u003C/p>\n\u003Cp>Designing your website in browser also gives you insight into your design you wouldn’t have otherwise, such as how it looks with real and variable content, how it looks and how it needs to change as browser size increases and decreases, how the design actually performs, how it renders in a wide array of devices and browsers, in an array of circumstances (like on a train, on the street, at your desk, in the coffee shop down the block), and a slew of other things. It also provides quite a few benefits to the design process, like a final product that can either be used or very easily translated at the end of the design process and, if using a CSS preprocessor like \u003Ca href=\"http://sass-lang.com/\" title=\"Sass - Syntactically Awesome Stylesheets\">Sass\u003C/a> (which I highly recommend you do), major style elements, such as colors and typography, can be changed very easily on the fly and rendered nearly instantaneously. Designing in browser allows you to build the products of the Web with the tools of the Web in the languages of the web.\u003C/p>\n\u003Ch2 id=\"mobile-first\">Mobile First\u003C/h2>\n\u003Cp>If you’re building a RWD site, you need to, as championed by Luke W, design for Mobile First. By designing for the Mobile First, you are setting a lowest common denominator to build from; one of slow connection speeds, impatient users, unconventional input methods, underpowered browsers, and amazingly cool APIs. But, when discussing Mobile First design, it is worth separating design and development. Many projects understand and implement, to some extent, the development side of Mobile First while neglecting the design side, unfortunately usually to the detriment of the end user.\u003C/p>\n\u003Cp>Before we continue, let me step back and define what I mean when I say mobile. To quote Cennydd Bowles “\u003Ca href=\"https://twitter.com/brad_frost/statuses/192281875434319872\">mobile is a user state, not a device\u003C/a>.” When I mention mobile, I’m talking about a user potentially on the go, probably on an unreliable connection with medium to low bandwidth who, to use \u003Ca href=\"http://kristoferlayon.files.wordpress.com/2012/03/klayonsxsw2012.pdf\">Kristofer Layton’s Theory of Mobile Motivation\u003C/a>, values content and navigation above built-in social sharing and visual and technical flair. They are usually on small devices with quirky browsers, using anything and everything but a mouse to navigate, and value their time highly. \u003Ca href=\"http://www.gomez.com/wp-content/downloads/19986_WhatMobileUsersWant_Wp.pdf\">As Gomez reports\u003C/a> 75% of Mobile users are willing to abandon a site if it takes more than 5 seconds to load with 80% willing to spend more time on a website if the experience was fast and reliable. The cost of not taking the mobile user into account? 57% will neither return to your site after a bad experience nor recommend it to others. \u003Ca href=\"http://pewinternet.org/Commentary/2012/February/Pew-Internet-Mobile.aspx\">Mobile users make up 88% of the US Adult Population\u003C/a> with 46% of the US Adult population using a smartphone, a year over year increase of more than 1% of the population \u003Cem>per month\u003C/em>. There are now more than \u003Ca href=\"https://twitter.com/Snugug/statuses/182849284054581250\">five times the number of mobile device activations per day than human births\u003C/a>, each one of them a mobile user. If you are not designing with the mobile user in mind first, you are neglecting your users.\u003C/p>\n\u003Cp>Now, what does this mean for development? Well, actually, Mobile First development can be a fairly easy concept to grasp as it is really no more than a reiteration of Web development best practices: keep load times as low as possible, keep assets as small as possible, keep http requests to a minimum, make sure you site doesn’t break if a browser feature is unavailable, and build using browser-independent modern Web standards (HTML, CSS, and JavaScript). When talking about Mobile First, we are also usually talking about HTML5 as well, so to these best practices we should also add light, semantic markup which, by it’s nature, begs for a content-first approach to your site. Your source order should match the importance of content.\u003C/p>\n\u003Cp>Mobile First design, on the other hand, is much less tangible, and requires a shift in thinking. There are three parts to Mobile First design (and really design in general): User Interface, User Experience, and Information Architecture (UI, UX and IA). In order to have a successful site, all three of these need to be done right, and all three of these should start Mobile First.\u003C/p>\n\u003Cblockquote>\n\u003Cp>Mobile devices require software development teams to \u003Ca href=\"http://www.lukew.com/ff/entry.asp?870\">focus on only the most important data and actions\u003C/a> in an application. There simply isn’t room in a 320 by 480 pixel screen for extraneous, unnecessary elements. You have to prioritize.\u003C/p>\n\u003Cp>So when a team designs Mobile First, the end result is an experience focused on the key tasks users want to accomplish without the extraneous detours and general interface debris that litter today’s desktop-accessed Web sites. That’s good user experience and good for business.\u003C/p>\n\u003Cp>~ Luke Wroblewski\u003C/p>\n\u003C/blockquote>\n\u003Cp>A Mobile First design approach requires you to step back and take a good, hard look at what is most important to your visitors and can give you leverage to cut cruft from your website. Luke has a phrase he likes to use when describing a mobile user: “\u003Ca href=\"http://www.alistapart.com/articles/organizing-mobile/\">[they have] one eyeball and one thumb\u003C/a>”. What this means is a mobile user is going to devote limited resources to trying to figure out your website and if you haven’t architected your site to present your content as quickly and easily as possible, you’re mobile user isn’t going to see it.\u003C/p>\n\u003Cp>But, this doesn’t mean you should make a curated mobile experience, oh no! \u003Ca href=\"http://globalmoxie.com/jhc/prez/mobile-myths.pdf\">Our job is not to willy-nilly strip out useful features. Anytime you say, somebody won’t want that on mobile, that’s not mobile content… you’re wrong.\u003C/a> Anything a user can, will, and expect to be able to do sitting in front of a desktop computer they can, will, and expect to be able to do from their handheld one; \u003Ca href=\"http://www.cxpartners.co.uk/cxblog/mobile-app-or-mobile-web/\">people use any platform to do anything\u003C/a>. As \u003Ca href=\"https://twitter.com/brad_frost/statuses/192198577605455874\">Josh Clark puts it\u003C/a>, “the myth that “mobile = less” mentality is wrong and damaging. Don’t confuse context with intent.” In fact, as \u003Ca href=\"https://twitter.com/globalmoxie/statuses/192280314452779008\">Cennydd Bowles says\u003C/a>, “assuming user intent from simple device context is a “classic error.\"\" Your site needs one to one content parity regardless of the device or screen size it is being viewed from. Use tools like location and time to determine context and assist in rearranging content, but not device and not to remove content.\u003C/p>\n\u003Cp>By thinking about our sites in a Mobile First and content first approach, we are able to better architect our sites, which in turn leads to building better UX for our visitors and by then by extension, a better UI. Additionally, because this approach forces us to IA and UX for Mobile First, we are able to carry over our “one eye, one thumb” thinking to our “desktop” (re: large width) layout, improving \u003Cem>everyone’s\u003C/em> experience and not just the mobile user’s. Even devices and browsers we may otherwise consider unsupported.\u003C/p>\n\u003Ch2 id=\"progressive-enhancement-and-graceful-degradation\">Progressive Enhancement and Graceful Degradation\u003C/h2>\n\u003Cp>Both Progressive Enhancement and Graceful Degradation are two sides of the same coin: best practices for Web design. Progressive Enhancement is a ground up approach to Web design where you design for the lowest common denominator and, as features become available, you add more. This approach fits in most nicely with our Mobile First design approach which, in fact, is a form of Progressive Enhancement. Graceful Degradation, on the other hand, is a top down approach where you build a feature and then provide fallbacks when features are not available. Anything and everything you build should keep these concepts in mind because they both strive for the same end goal: being able to display your content no matter the device used to access it, including those you may consider unsupported. This a core tenant of the Web as a medium. Always bear in mind that the Web is an inherently unstable medium, and if we think in a Progressive Enhancement mindset, \u003Ca href=\"https://twitter.com/globalmoxie/statuses/192282944944091136\">that means that layout is itself an enhancement\u003C/a>.\u003C/p>\n\u003Cp>Speaking of layout and Progressive Enhancement, Joni Korpi has a \u003Ca href=\"http://jonikorpi.com/leaving-old-IE-behind/\">great article about just that\u003C/a>. The gist of it is that, instead of trying to mimic media queries on unsupported browsers \u003Cem>including Internet Explorer 8 and below\u003C/em>, you serve a single column website and use media queries to build out your layout, instead of designing a desktop layout and using media queries to shrink it. This is the ideal for Mobile First design as well as it will serve a fluid, single column layout to mobile devices of a certain size and outdated browsers. The best part about this approach to layout is its hack free, JavaScipt free, almost thought free lowest common denominator.\u003C/p>\n\u003Cp>One important thing that is an absolute must if you’re building progressively is that, under no circumstances, should you be browser sniffing or using device detection to see if a user can use your site. Not only are these methods unreliable but they’re unsustainable as well. For instance, there are currently five desktop versions of Internet Explorer and at least two mobile versions, Google Chrome’s UA is set up to trick browsers into thinking it’s Firefox, and there are over one thousand different types of Android devices either currently or previously on the market worldwide. If you want to make sure your user can use a feature, do the logical thing and \u003Cem>feature detect\u003C/em>. There is an amazing tool called \u003Ca href=\"http://modernizr.com/\">Modernizr\u003C/a> that is designed specifically to do feature based section to aid with development. If you absolutely must have a feature that isn’t available, there are amazing polyfills and shivs being written to combat browsers lacking in features. Don’t deny your user your content because of how they got to it, make sure it works, on some level, regardless.\u003C/p>\n\u003Ch2 id=\"the-fluid-grid-and-content-breakpoints\">The Fluid Grid and Content Breakpoints\u003C/h2>\n\u003Cp>As \u003Ca href=\"https://twitter.com/ScottKellum/statuses/182461146660474880\">Scott Kellum jested\u003C/a>: “You can tell a site is “web 3.0” if it’s built on a grid.” It’s funny ‘cause it’s true. A responsive site really needs to be built on a grid, \u003Cem>any grid\u003C/em>, as long as it’s something you stick to and can scale in a fluid manner. Now this isn’t to say your grid cannot change as you scale, but you need to build to a grid and the grid needs to be fluid.\u003C/p>\n\u003Cp>As \u003Ca href=\"http://zen-grids.com\">John Albin so precisely puts\u003C/a>, if you’re going to be doing RWD, you really need to be using a CSS Preprocessor (of which we would both recommend \u003Ca href=\"http://sass-lang.com\">Sass\u003C/a>). The concept of a grid is easy, but when actually trying to implement one, especially a fluid one, the math can get complicated very quick, and grid classes are not only not semantic but break the separation of concerns between HTML and CSS. Both of these issues are solved by using a CSS Preprocessor to deal with the math for you, and to put your widths straight on the selects you’re targeting instead of needing to edit your HTML to deal with styling. If you take a look at my source, you won’t see any grid classes, only light, semantic widths and margins built with the use of Sass, \u003Ca href=\"http://susy.oddbird.net/\">Susy\u003C/a>, and \u003Ca href=\"https://github.com/snugug/aura\">Aura\u003C/a>.\u003C/p>\n\u003Cp>With a grid set up, lets talk about physically designing on a fluid grid. Following our Mobile First mindset, the very first thing we design is our single column layout, more commonly described as our small screen or mobile layout. As \u003Ca href=\"https://twitter.com/brad_frost/statuses/192282902472564740\">Brian and Stephanie Reiger say\u003C/a>, “the absence of support for media queries is indeed the first media query.” \u003Ca href=\"https://twitter.com/brad_frost/statuses/192282883929554944\">Ethan Marcotte reiterates that point\u003C/a>:\u003C/p>\n\u003Cblockquote>\n\u003Cp>Avoid starting large then shrinking down. Approach layout from a Mobile First approach. Fits in with progressive enhancement.\u003C/p>\n\u003C/blockquote>\n\u003Cp>After a single column theme has been built, what next? The are many advocates of, and many responsive frameworks that work by, setting your breakpoint, or where your design changes, based off of known device sizes. This usually means non-retina iOS dimensions in landscape and portrait with maybe the addition of one in between iPhone and iPad and maybe one wide Desktop dimension. If you think that Android, Blackberry, and Windows Phone 7 all have a standard screen size that you could also break to, \u003Ca href=\"http://en.wikipedia.org/wiki/List_of_Windows_Phone_devices\" title=\"Windows Phone\">let me\u003C/a> \u003Ca href=\"http://supportforums.blackberry.com/t5/Java-Development/List-of-Blackberry-Devices-with-resolution/td-p/556066\" title=\"Blackberry\">dash those\u003C/a> \u003Ca href=\"http://en.wikipedia.org/wiki/Comparison_of_Android_devices\" title=\"Android\">hopes and dreams\u003C/a>. Overall, this seems amazingly short sighted to me (and pretty much everyone doing RWD professionally) and, possibly more importantly, neglects one of the core tenants of RWD: the Web is an inherently unstable medium. But even more practical than that, why would you want to shoehorn your design into known device dimensions when building breakpoints based on when your content needs it ensures it looks it’s best on \u003Cem>all\u003C/em> platforms.\u003C/p>\n\u003Cblockquote>\n\u003Cp>Start with the small screen first, then expand until it looks like shit. TIME FOR A BREAKPOINT!\u003C/p>\n\u003Cp>~ \u003Ca href=\"https://twitter.com/brad_frost/statuses/191977076000161793\">Stephen Hay\u003C/a>\u003C/p>\n\u003C/blockquote>\n\u003Cp>Content based breakpoints are surprisingly easy, as Stephen says, keep expanding your window until your content looks crap, then put a breakpoint there. There are a plethora of tools out there to get your window’s screen size for your break point so there’s no excuse not to do it this way. If you’re using Sass 3.2 or higher, in fact, your life just became super easy! Instead of needing to remember all of your breakpoints by number, you can remember them by name! You can write a mixin like the following for all of your breakpoints:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Four breakpoints: foo, bar, baz, and qux.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">//\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Foo assumes the defaults of min-width and screen. Foo will gen @media screen and (min-width: 500px)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Bar changes min-width to max, but assumes screen as well. Bar will gen @media screen and (max-width: 700px)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Baz wants to use min-width, but change media type, so min-width needs to be re-declare. Baz will gen @media tv and (min-width: 700px)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Qux goes all out and has a full unique media query. Qux will get @media tv and (max-width: 900px)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">$breakpoints:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">  'foo'\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 500\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">  'bar'\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'max-width'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">  'baz'\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'min-width'\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> tv,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E6DB74\">  'qux'\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 900\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'max-width'\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> tv;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Let's call respond-to!\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">#waldo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> respond-to\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'foo'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> respond-to\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'bar'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">yellow\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> respond-to\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'baz'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">purple\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> respond-to\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'qux'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">orange\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Our Output:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">#waldo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">red\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#66D9EF\"> screen\u003C/span>\u003Cspan style=\"color:#F92672\"> and\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">500\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #waldo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">green\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#66D9EF\"> screen\u003C/span>\u003Cspan style=\"color:#F92672\"> and\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">max-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #waldo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">yellow\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F44747\"> tv\u003C/span>\u003Cspan style=\"color:#F92672\"> and\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">min-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">700\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #waldo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">purple\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@media\u003C/span>\u003Cspan style=\"color:#F44747\"> tv\u003C/span>\u003Cspan style=\"color:#F92672\"> and\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">max-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#AE81FF\">900\u003C/span>\u003Cspan style=\"color:#F92672\">px\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  #waldo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">orange\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Our respond-to mixin, with the new hotness?\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// A little more complicated than previous respond-to mixins, but now runs off of a variable. This is also Rev 1 so if someone can help me make it better, I'm all ears.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// We need to start with a defaulted breakpoints variable.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">$breakpoints: false \u003C/span>\u003Cspan style=\"color:#F92672\">!default\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@mixin\u003C/span>\u003Cspan style=\"color:#A6E22E\"> respond-to\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($context) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $breakpoints \u003C/span>\u003Cspan style=\"color:#F92672\">!=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> false {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Check to see if the 2nd item is a number. If it is, we've got a single query\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @if\u003C/span>\u003Cspan style=\"color:#66D9EF\"> type-of\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#66D9EF\">nth\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($breakpoints, \u003C/span>\u003Cspan style=\"color:#AE81FF\">2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">==\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'number'\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">      // Check to see if the context matches the breakpoint namespace\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">      @if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $context \u003C/span>\u003Cspan style=\"color:#F92672\">==\u003C/span>\u003Cspan style=\"color:#66D9EF\"> nth\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($breakpoints, \u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">        // Call Media Query Generator\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">        @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> media-query-gen\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($breakpoints) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">          @content\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">        }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Else, loop over all of them\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @else \u003C/span>\u003Cspan style=\"color:#F8F8F2\">{\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">      // Loop over each breakpoint and check context\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">      @each\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $bkpt \u003C/span>\u003Cspan style=\"color:#F92672\">in\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $breakpoints {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">        // If context is correctâ€¦\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">        @if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $context \u003C/span>\u003Cspan style=\"color:#F92672\">==\u003C/span>\u003Cspan style=\"color:#66D9EF\"> nth\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bkpt, \u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">          // Call the generator!\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">          @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> media-query-gen\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bkpt) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">            @content\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">          }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">        }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// This functionality gets used twice so I turned it into its own mixin.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@mixin\u003C/span>\u003Cspan style=\"color:#A6E22E\"> media-query-gen\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bpt) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Get length of breakpoint variable, minus the namespace\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  $length: \u003C/span>\u003Cspan style=\"color:#66D9EF\">length\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bpt);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Go through all of the breakpoint items, starting at the second, and add them to a variable to be passed into the media query mixin\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  $mq: false \u003C/span>\u003Cspan style=\"color:#F92672\">!default\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @for\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $i \u003C/span>\u003Cspan style=\"color:#F92672\">from\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F92672\"> through\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $length {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // If it's the first item, override $mq\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $i \u003C/span>\u003Cspan style=\"color:#F92672\">==\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      $mq: \u003C/span>\u003Cspan style=\"color:#66D9EF\">nth\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bpt, $i);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Else, join $mq\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @else \u003C/span>\u003Cspan style=\"color:#F8F8F2\">{\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      $mq: \u003C/span>\u003Cspan style=\"color:#66D9EF\">join\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($mq, \u003C/span>\u003Cspan style=\"color:#66D9EF\">nth\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($bpt, $i));\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Call Media Query mixin\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> media-query\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($mq) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @content\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Slightly modified version of my Media Query Mixin (https://gist.github.com/2490750) from earlier, modified to accommodate list input\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@mixin\u003C/span>\u003Cspan style=\"color:#A6E22E\"> media-query\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($value, $operator: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'min-width'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, $query: \u003C/span>\u003Cspan style=\"color:#E6DB74\">'screen'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // If a list is passed in for value, break it into value, operator, and query\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @if\u003C/span>\u003Cspan style=\"color:#66D9EF\"> type-of\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($value) \u003C/span>\u003Cspan style=\"color:#F92672\">==\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'list'\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    $mq: $value;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @for\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $i \u003C/span>\u003Cspan style=\"color:#F92672\">from\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#F92672\"> through\u003C/span>\u003Cspan style=\"color:#66D9EF\"> length\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($mq) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">      @if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $i \u003C/span>\u003Cspan style=\"color:#F92672\">==\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">        $value: \u003C/span>\u003Cspan style=\"color:#66D9EF\">nth\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($mq, \u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      } \u003C/span>\u003Cspan style=\"color:#F92672\">@else if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $i \u003C/span>\u003Cspan style=\"color:#F92672\">==\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">        $operator: \u003C/span>\u003Cspan style=\"color:#66D9EF\">nth\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($mq, \u003C/span>\u003Cspan style=\"color:#AE81FF\">2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      } \u003C/span>\u003Cspan style=\"color:#F92672\">@else if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $i \u003C/span>\u003Cspan style=\"color:#F92672\">==\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 3\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">        $query: \u003C/span>\u003Cspan style=\"color:#66D9EF\">nth\u003C/span>\u003Cspan style=\"color:#F8F8F2\">($mq, \u003C/span>\u003Cspan style=\"color:#AE81FF\">3\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">      }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @media\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> #{$query} \u003C/span>\u003Cspan style=\"color:#F92672\">and\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (#{$operator}: #{$value}) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @content\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>The other issue I have with device based breakpoints is all they do is enforce the printed page metaphor with varying fixed page sizes instead of a single one (think designing a flyer, a brochure, and a business card instead of a website). As \u003Ca href=\"https://twitter.com/brad_frost/statuses/192239397855440896\">Rachel Hinman says\u003C/a>, “the “page” metaphor holds us back from creating truly great mobile experiences”. Device breakpoints are a wolf in sheep’s clothing; passing itself off for RWD when in reality it’s more of the same static design (even with a fluid grid).\u003C/p>\n\u003Ch2 id=\"design-natural-user-interfaces-not-graphical-ones\">Design Natural User Interfaces, not Graphical Ones\u003C/h2>\n\u003Cp>If there is one thing to come out of the iPhone that is the fundamental defining feature of the device, multitouch would be it. It’s an entirely new way of interacting with the content on your screen by actually \u003Cem>interacting with it\u003C/em>. \u003Ca href=\"http://www.lukew.com/ff/entry.asp?1071\">Pinch, swipe, tap, hold\u003C/a>; these simple gestures are such a change from the point, hover, click nature of desktop interaction that many of the traditional graphical enhancements relied upon need to be rethought or thrown out altogether. As \u003Ca href=\"https://twitter.com/globalmoxie/statuses/192247950817234944\">Rachel Hinman says\u003C/a>, “the legacy inertia of [graphical user interfaces] holds back [natural user interfaces] progress” and that “buttons are hacks”. So what’s a dev to do? Mobile First and Progressive Enhancement to the rescue! Build uncluttered, easy to use, large user interfaces (fingers are a much larger input device than the pixel perfect precision of a mouse) and do not rely upon proxy navigation of your content (hover states, for instance, \u003Cem>do not work\u003C/em> on Mobile). If touch is available, utilize it! If you don’t know what touch gestures are available, \u003Ca href=\"http://www.lukew.com/ff/entry.asp?1071\">Luke W has you covered once again\u003C/a>. Make galleries and carousels swipeable! Turn context menus into hold menus! If not, make sure you have fallbacks! The point of Natural User Interfaces, like Mobile First, isn’t to absolutely do away with Graphical ones, but rather to take our design queues from it, design towards that ideal, and present a gracefully degraded solution when our ideal isn’t met.\u003C/p>\n\u003Cp>One of the best examples of a true Natural User Interface is an iOS app called \u003Ca href=\"http://www.realmacsoftware.com/clear/\">Clear\u003C/a>. Clear is a todo app where you pinch, pull, swipe, and tap to accomplish all of the normal todo actions, with the difference being that the controls \u003Cem>are\u003C/em> the interface, and a beautiful interface it is. One of the toughest things with Natural User Interfaces is building interactions that need no explanation (or whose explanation can be hinted at while using), and Clear does this marvelously. What’s more, if you’re saying to yourself “but that’s a native app, we can’t do that in browser!”, take a look at \u003Ca href=\"https://github.com/yyx990803/HTML5-Clear-v2\">HTML5 Clear\u003C/a>. Check out the Clear promo video below to get a sense of how a great Natural User Interface works.\u003C/p>\n\u003Cp>@\u003Ca href=\"https://vimeo.com/37182785\">vimeo\u003C/a>\u003C/p>\n\u003Cp>Somewhere about this time, if you’ve been designing according to these principles, you’re going to have an epiphany. When designing responsively from a content first perspective on a semantic framework, you’re going to realize that, even totally devoid of CSS and JavaScript, your site is mobile optimized. As Scott Kellum says, this is a big deal because “after this epiphany it becomes impossible to set styles then override them when no style at all will do just fine.” Let this epiphany guide you toward the Natural UI light and away from the Graphical UI dark.\u003C/p>\n\u003Cp>An important point to this, though, is that Natural does not mean “mimicking the UI of native apps.” Natural means natural to anyone on any platform, not natural to those on iOS or Android. As \u003Ca href=\"https://twitter.com/bdconf/statuses/192280842272374784\">Cennyyd Bowles says\u003C/a>, “if you’re trying to make a cat look more like a dog, just buy a dog.” Don’t fake native app UI, if you want a native app, build a native app, and, for the love of god, whatever you do, don’t put a back button on your website. Every Web browser in existence has a built in back button that works better than yours, is more device agnostic than yours, and is more well integrated than yours. Now I can get behind swiping back and forth for forward and back in history (go ahead, try it now, two fingers for those devices that support it), but don’t you dare put an actual back button on your site.\u003C/p>\n\u003Ch2 id=\"and-in-the-end-the-love-you-take-is-equal-to-the-love-you-make\">And, In The End, the Love You Take is Equal to the Love You Make\u003C/h2>\n\u003Cp>To me, these Principles of Responsive Design all boil down to one thing: being \u003Ca href=\"http://futurefriend.ly/resources.html\">Future Friendly\u003C/a>. Gartner predicts that \u003Ca href=\"http://www.gartner.com/it/page.jsp?id=1278413\">by next year, mobile devices will surpass desktop devices as the most common way to access the Internet worldwide\u003C/a>. I feel as if that needs repeating. Not in 10 years, not in 5 years, not even in 1 year. In less than 8 months, worldwide, a user will be more likely to access your website from a mobile device than a desktop device. The writing is on the wall already, with more than 2 times the number of mobile device activations than \u003Ca href=\"http://www.worldometers.info/computers/\">traditional computers sold per day\u003C/a>. Because of this we, as the keepers of the web, need to take these principles to heart when we talk to our clients and build our sites. By treating the Web as its own medium, by designing in browser instead of bitmap editors, by designing for Mobile First, by building our sites progressively, by making layout changes content based and device agnostic, and by designing natural user interfaces better suited for both mobile and desktop as opposed to graphical for only desktop, we will be building websites that are best viewed on any Web enabled device for the foreseeable future. To borrow a phrase from Gandhi, we need to be the change we want to see in the web.\u003C/p>",{"headings":1746,"localImagePaths":1768,"remoteImagePaths":1769,"frontmatter":1770,"imagePaths":1773},[1747,1750,1753,1756,1759,1762,1765],{"depth":80,"slug":1748,"text":1749},"the-web-is-a-medium","The Web is a Medium",{"depth":80,"slug":1751,"text":1752},"design-in-browser","Design In Browser",{"depth":80,"slug":1754,"text":1755},"mobile-first","Mobile First",{"depth":80,"slug":1757,"text":1758},"progressive-enhancement-and-graceful-degradation","Progressive Enhancement and Graceful Degradation",{"depth":80,"slug":1760,"text":1761},"the-fluid-grid-and-content-breakpoints","The Fluid Grid and Content Breakpoints",{"depth":80,"slug":1763,"text":1764},"design-natural-user-interfaces-not-graphical-ones","Design Natural User Interfaces, not Graphical Ones",{"depth":80,"slug":1766,"text":1767},"and-in-the-end-the-love-you-take-is-equal-to-the-love-you-make","And, In The End, the Love You Take is Equal to the Love You Make",[],[],{"title":1736,"published":1771,"summary":1738,"categories":1772},"2012-05-24",[55,29],[],"progressive-enhancement-code-pattern-using-sass-and-modernizr",{"id":1774,"data":1776,"body":1780,"filePath":1781,"digest":1782,"rendered":1783},{"title":1777,"published":1778,"summary":1779},"Progressive Enhancement Code Pattern Using Sass and Modernizr",["Date","2012-06-25T00:00:00.000Z"],"Designing your websites in a progressive way is one of the best and easiest ways to ensure that a user coming to your site, no matter the way they access it, is going to be able to use your website.","Designing your websites in a [progressive way](http://en.wikipedia.org/wiki/Progressive_enhancement) is one of the best and easiest ways to ensure that a user coming to your site, no matter the way they access it, is going to be able to use your website. It's essential for everything on the web from accessibility to responsive web design, and doing it properly, _id est_ through feature detection with JavaScript and CSS enhancements instead of through [browser detection](http://css-tricks.com/browser-detection-is-bad/) and UA targeted source files, will not only save you maintenance headaches when future devices come out, but may [save you some embarrassment as well](http://wtfmobileweb.com/). Enter my two favorite Front End tools: [Sass](http://sass-lang.com)+[Compass](http://compass-style.org) and [Modernizr](http://modernizr.com/).\n\nSass is a CSS Preprocessing language and Compass is a kickass framework built on top of it. Modernizr is modern feature detection. Both rock, and here's a simple Progressive Enhancement code pattern I've been using leveraging Modernizr's CSS class hooks and Sass nesting.\n\n```scss\n////////////////////////\n// Sass Input\n////////////////////////\n.foo {\n  /* Properties shared between detected features go here. */\n  .feature & {\n    /* Custom properties if the feature is present. */\n  }\n  .no-feature &,\n  .no-js & {\n    /* Default properties if the feature is not present, or JavaScript is disabled and therefore Modernizr didn't fire. */\n  }\n}\n```\n\n```scss\n/*************\nCSS Output\n**************/\n.foo {\n  /* Properties shared between detected features go here. */\n}\n.feature .foo {\n  /* Custom properties if the feature is present. */\n}\n\n.no-feature .foo,\n.no-js .foo {\n  /* Default properties if the feature is not present, or JavaScript is disabled and therefore Modernizr didn't fire. */\n}\n```\n\nWhat I'm doing in this pattern is defining properties directly underneath `.foo` that should be applied regardless of if the feature I'm looking for is available (anything from box model to design), then I'm nesting the Modernizr feature detection parent selectors underneath, allowing me to see both my feature-present (`.feature &`) and feature-absent (`.no-feature &`) styling in line, making future maintenance easier by leaps and bounds. I include the `.no-js &` as a comma-separated addition to the feature-absent both because there are some users with JavaScript disabled (and seeing as how Modernizr is a JavaScript based solution, it then won't fire), and because [all of your users are non-JS while they're downloading your JS](http://twitter.com/zeldman/status/215088145971159042). Neat, but what about in practice? Let's throw Compass into the mix and reinvent the replace-text wheel.\n\n```scss\n// Compass Image Sprites for our PNGs\n@import 'social/*.png';\n\n// Twitter Class!\n.twitter {\n  // Put the height/width of the image in\n  height: image-height('social/twitter.png');\n  width: image-width('social/twitter.png');\n  // Hide text. Use squish-text() if the element is inline\n  @include hide-text();\n  // No repeating backgrounds, please.\n  background-repeat: no-repeat;\n  // SVG\n  .svg & {\n    // Inline the SVG so that advanced browsers and future tech doesn't need the extra HTTP requests for the SVG\n    background-image: inline-image('social/twitter.svg');\n    // Background size only needed if the SVG is larger than the PNG.\n    background-size: image-width('social/twitter.png')\n      image-height('social/twitter.png');\n  }\n  // Default\n  .no-svg &,\n  .no-js & {\n    // Call the Sprite'd image's position.\n    @include social-sprite(twitter);\n  }\n}\n```\n\nSo what exactly is all of that? We're going to combine the power of Compass image sprites, dimension helpers, and inlining capabilities to build a future friendly image replacement complete with progressive enhancement up to SVG to make our image replacement resolution independent (yay!). First step is first, we import our Social png icons to create a [Compass Image Sprite](http://compass-style.org/help/tutorials/spriting/). Yes, this will build a full image sprite from individual images; it rocks. Next, we're going to use the [Compass Image Dimension Helpers](http://compass-style.org/reference/compass/helpers/image-dimensions/) to grab the height and width of the PNG image so we don't need to hard code them, making them super dynamic if we choose to change the size of our images later; Compass will handle all of the changes for us in the background. We're then going to grab the hide-text [Text Replacement Mixin](http://compass-style.org/reference/compass/typography/text/replacement/) to hide our text. The final piece of our generic styling is to stop our background from repeating, because we don't want that on a text replacement.\n\nNow onto the fun stuff, the Modernizr powered feature detection. First up, SVG. For it's background-image property, we're going to use the [Inline Image Data Helper](http://compass-style.org/reference/compass/helpers/inline-data/) to Base64 Encode our SVG, reducing HTTP requests for modern browsers and caching the image with the CSS at the cost of a slightly larger CSS file (a tradeoff I'm okay with making). If we want, say, if our SVG is of larger dimensions than our PNG, we can write a background-size property and set it to the same dimensions as our PNG to ensure the two stay in lock-step (we could feature detect for background-size, but according to the awesome Caniuse.com, all browsers that [support SVG](http://caniuse.com/svg) also [support unprefixed background-size](http://caniuse.com/background-img-opts), and I'm cool with assuming that). Finally, for our no-js and no-svg folks, we include the sprite placement for our icon, thus completing the circle. The net result of all of this? For modern browsers, they make 0 additional HTTP requests for our image replacement (which is resolution independent), get our image replacement cached with the CSS, and shouldn't download the image sprite because none of the sprite selectors apply to anything on page! For older browsers, while they will have slightly larger download sizes for their CSS, that then gets cached and they only need 1 additional HTTP request to grab their icons.\n\nI can hear you now, though, saying: \"Hey Sam, that looks like a lot I've got to write each and every time! Can't you make it easier?\" Yes. Yes I can. Presenting the **Progressive Enhancement Text Replace Mixin**.\n\n```scss\n////////////////////////\n// Progressive Enhancement Text Replace Mixin\n//\n// - $image-name: Name of the image file without extension.\n// - $path-from-images: The path from your images folder where the .png and .svg are stored. They should be stored in the same folder.\n// - $sprite-name: The name of the folder your files are stored in in order to name the sprite. See Compass Image Spriting for more info.\n// - $inline: Whether or not the parent item is an inline item. If the item is inline, squish-text() needs to be used. Defaults to false.\n////////////////////////\n@mixin replace-text-pe(\n  $image-name,\n  $path-from-images,\n  $sprite-name,\n  $inline: false\n) {\n  // Put the height/width of the image in\n  height: image-height('#{$path-from-images}/#{$image-name}.png');\n  width: image-width('#{$path-from-images}/#{$image-name}.png');\n  // Hide text. Use squish-text() if the element is inline\n  @if $inline {\n    @include squish-text();\n  } @else {\n    @include hide-text();\n  }\n  // No repeating backgrounds, please.\n  background-repeat: no-repeat;\n  // SVG\n  .svg & {\n    // Inline the SVG so that advanced browsers and future tech doesn't need the extra HTTP requests for the SVG\n    background-image: inline-image('#{$path-from-images}/#{$image-name}.svg');\n    // Background size only needed if the SVG is larger than the PNG.\n    background-size: image-width('#{$path-from-images}/#{$image-name}.png')\n      image-height('#{$path-from-images}/#{$image-name}.png');\n  }\n  // Default\n  .no-svg &,\n  .no-js & {\n    // Call the Sprite'd image's position.\n    @include #{$sprite-name}-sprite(#{$image-name});\n  }\n}\n```\n\nHope people find this useful. If there are any bugs in the mixin, let me know and I'll update the mixin here. Happy coding!","src/content/posts/progressive-enhancement-code-pattern-using-sass-and-modernizr.md","b2258d2c6edfcdf3",{"html":1784,"metadata":1785},"\u003Cp>Designing your websites in a \u003Ca href=\"http://en.wikipedia.org/wiki/Progressive_enhancement\">progressive way\u003C/a> is one of the best and easiest ways to ensure that a user coming to your site, no matter the way they access it, is going to be able to use your website. It’s essential for everything on the web from accessibility to responsive web design, and doing it properly, \u003Cem>id est\u003C/em> through feature detection with JavaScript and CSS enhancements instead of through \u003Ca href=\"http://css-tricks.com/browser-detection-is-bad/\">browser detection\u003C/a> and UA targeted source files, will not only save you maintenance headaches when future devices come out, but may \u003Ca href=\"http://wtfmobileweb.com/\">save you some embarrassment as well\u003C/a>. Enter my two favorite Front End tools: \u003Ca href=\"http://sass-lang.com\">Sass\u003C/a>+\u003Ca href=\"http://compass-style.org\">Compass\u003C/a> and \u003Ca href=\"http://modernizr.com/\">Modernizr\u003C/a>.\u003C/p>\n\u003Cp>Sass is a CSS Preprocessing language and Compass is a kickass framework built on top of it. Modernizr is modern feature detection. Both rock, and here’s a simple Progressive Enhancement code pattern I’ve been using leveraging Modernizr’s CSS class hooks and Sass nesting.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">////////////////////////\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Sass Input\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">////////////////////////\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  /* Properties shared between detected features go here. */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .feature\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    /* Custom properties if the feature is present. */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .no-feature\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .no-js\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    /* Default properties if the feature is not present, or JavaScript is disabled and therefore Modernizr didn't fire. */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">/*************\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">CSS Output\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">**************/\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  /* Properties shared between detected features go here. */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.feature\u003C/span>\u003Cspan style=\"color:#A6E22E\"> .foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  /* Custom properties if the feature is present. */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.no-feature\u003C/span>\u003Cspan style=\"color:#A6E22E\"> .foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.no-js\u003C/span>\u003Cspan style=\"color:#A6E22E\"> .foo\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  /* Default properties if the feature is not present, or JavaScript is disabled and therefore Modernizr didn't fire. */\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>What I’m doing in this pattern is defining properties directly underneath \u003Ccode>.foo\u003C/code> that should be applied regardless of if the feature I’m looking for is available (anything from box model to design), then I’m nesting the Modernizr feature detection parent selectors underneath, allowing me to see both my feature-present (\u003Ccode>.feature &#x26;\u003C/code>) and feature-absent (\u003Ccode>.no-feature &#x26;\u003C/code>) styling in line, making future maintenance easier by leaps and bounds. I include the \u003Ccode>.no-js &#x26;\u003C/code> as a comma-separated addition to the feature-absent both because there are some users with JavaScript disabled (and seeing as how Modernizr is a JavaScript based solution, it then won’t fire), and because \u003Ca href=\"http://twitter.com/zeldman/status/215088145971159042\">all of your users are non-JS while they’re downloading your JS\u003C/a>. Neat, but what about in practice? Let’s throw Compass into the mix and reinvent the replace-text wheel.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Compass Image Sprites for our PNGs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@import\u003C/span>\u003Cspan style=\"color:#E6DB74\"> 'social/*.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Twitter Class!\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">.twitter\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Put the height/width of the image in\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">image-height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'social/twitter.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">image-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'social/twitter.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Hide text. Use squish-text() if the element is inline\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> hide-text\u003C/span>\u003Cspan style=\"color:#F8F8F2\">();\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // No repeating backgrounds, please.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background-repeat\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">no-repeat\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // SVG\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .svg\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Inline the SVG so that advanced browsers and future tech doesn't need the extra HTTP requests for the SVG\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background-image\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">inline-image\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'social/twitter.svg'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Background size only needed if the SVG is larger than the PNG.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background-size\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">image-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'social/twitter.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF\">      image-height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'social/twitter.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Default\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .no-svg\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .no-js\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Call the Sprite'd image's position.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> social-sprite\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(twitter);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>So what exactly is all of that? We’re going to combine the power of Compass image sprites, dimension helpers, and inlining capabilities to build a future friendly image replacement complete with progressive enhancement up to SVG to make our image replacement resolution independent (yay!). First step is first, we import our Social png icons to create a \u003Ca href=\"http://compass-style.org/help/tutorials/spriting/\">Compass Image Sprite\u003C/a>. Yes, this will build a full image sprite from individual images; it rocks. Next, we’re going to use the \u003Ca href=\"http://compass-style.org/reference/compass/helpers/image-dimensions/\">Compass Image Dimension Helpers\u003C/a> to grab the height and width of the PNG image so we don’t need to hard code them, making them super dynamic if we choose to change the size of our images later; Compass will handle all of the changes for us in the background. We’re then going to grab the hide-text \u003Ca href=\"http://compass-style.org/reference/compass/typography/text/replacement/\">Text Replacement Mixin\u003C/a> to hide our text. The final piece of our generic styling is to stop our background from repeating, because we don’t want that on a text replacement.\u003C/p>\n\u003Cp>Now onto the fun stuff, the Modernizr powered feature detection. First up, SVG. For it’s background-image property, we’re going to use the \u003Ca href=\"http://compass-style.org/reference/compass/helpers/inline-data/\">Inline Image Data Helper\u003C/a> to Base64 Encode our SVG, reducing HTTP requests for modern browsers and caching the image with the CSS at the cost of a slightly larger CSS file (a tradeoff I’m okay with making). If we want, say, if our SVG is of larger dimensions than our PNG, we can write a background-size property and set it to the same dimensions as our PNG to ensure the two stay in lock-step (we could feature detect for background-size, but according to the awesome Caniuse.com, all browsers that \u003Ca href=\"http://caniuse.com/svg\">support SVG\u003C/a> also \u003Ca href=\"http://caniuse.com/background-img-opts\">support unprefixed background-size\u003C/a>, and I’m cool with assuming that). Finally, for our no-js and no-svg folks, we include the sprite placement for our icon, thus completing the circle. The net result of all of this? For modern browsers, they make 0 additional HTTP requests for our image replacement (which is resolution independent), get our image replacement cached with the CSS, and shouldn’t download the image sprite because none of the sprite selectors apply to anything on page! For older browsers, while they will have slightly larger download sizes for their CSS, that then gets cached and they only need 1 additional HTTP request to grab their icons.\u003C/p>\n\u003Cp>I can hear you now, though, saying: “Hey Sam, that looks like a lot I’ve got to write each and every time! Can’t you make it easier?” Yes. Yes I can. Presenting the \u003Cstrong>Progressive Enhancement Text Replace Mixin\u003C/strong>.\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"scss\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">////////////////////////\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Progressive Enhancement Text Replace Mixin\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">//\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// - $image-name: Name of the image file without extension.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// - $path-from-images: The path from your images folder where the .png and .svg are stored. They should be stored in the same folder.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// - $sprite-name: The name of the folder your files are stored in in order to name the sprite. See Compass Image Spriting for more info.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// - $inline: Whether or not the parent item is an inline item. If the item is inline, squish-text() needs to be used. Defaults to false.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">////////////////////////\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">@mixin\u003C/span>\u003Cspan style=\"color:#A6E22E\"> replace-text-pe\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  $image-name,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  $path-from-images,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  $sprite-name,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  $inline: false\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Put the height/width of the image in\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">image-height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$path-from-images}\u003C/span>\u003Cspan style=\"color:#E6DB74\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$image-name}\u003C/span>\u003Cspan style=\"color:#E6DB74\">.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">image-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$path-from-images}\u003C/span>\u003Cspan style=\"color:#E6DB74\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$image-name}\u003C/span>\u003Cspan style=\"color:#E6DB74\">.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Hide text. Use squish-text() if the element is inline\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  @if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> $inline {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> squish-text\u003C/span>\u003Cspan style=\"color:#F8F8F2\">();\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  } \u003C/span>\u003Cspan style=\"color:#F92672\">@else \u003C/span>\u003Cspan style=\"color:#F8F8F2\">{\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @include\u003C/span>\u003Cspan style=\"color:#A6E22E\"> hide-text\u003C/span>\u003Cspan style=\"color:#F8F8F2\">();\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // No repeating backgrounds, please.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  background-repeat\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">no-repeat\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // SVG\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .svg\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Inline the SVG so that advanced browsers and future tech doesn't need the extra HTTP requests for the SVG\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background-image\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">inline-image\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$path-from-images}\u003C/span>\u003Cspan style=\"color:#E6DB74\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$image-name}\u003C/span>\u003Cspan style=\"color:#E6DB74\">.svg'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Background size only needed if the SVG is larger than the PNG.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    background-size\u003C/span>\u003Cspan style=\"color:#F8F8F2\">: \u003C/span>\u003Cspan style=\"color:#66D9EF\">image-width\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$path-from-images}\u003C/span>\u003Cspan style=\"color:#E6DB74\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$image-name}\u003C/span>\u003Cspan style=\"color:#E6DB74\">.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF\">      image-height\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$path-from-images}\u003C/span>\u003Cspan style=\"color:#E6DB74\">/\u003C/span>\u003Cspan style=\"color:#F8F8F2\">#{$image-name}\u003C/span>\u003Cspan style=\"color:#E6DB74\">.png'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Default\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .no-svg\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\">,\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  .no-js\u003C/span>\u003Cspan style=\"color:#F92672\"> &#x26;\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Call the Sprite'd image's position.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">    @include\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> #{$sprite-name}-sprite(#{$image-name});\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Hope people find this useful. If there are any bugs in the mixin, let me know and I’ll update the mixin here. Happy coding!\u003C/p>",{"headings":1786,"localImagePaths":1787,"remoteImagePaths":1788,"frontmatter":1789,"imagePaths":1791},[],[],[],{"title":1777,"published":1790,"summary":1779},"2012-06-25",[],"responsive-designs-dirty-little-secret",{"id":1792,"data":1794,"body":1799,"filePath":1800,"digest":1801,"rendered":1802},{"title":1795,"published":1796,"updated":1797,"summary":1798,"archived":1466},"On Responsive Design's Dirty Little Secret",["Date","2012-12-01T00:00:00.000Z"],["Date","2013-01-29T00:00:00.000Z"],"After having extensive conversations with John Albin Wilkins, I've realized that some of the basic assumptions I made when I first went to test this are in fact incorrect and that I was working under the wrong mental model. I am keeping up the original article as record.",":::message{.warning}\n**Update 1/29/2013**\n\nAfter having extensive conversations with John Albin Wilkins, I've realized that some of the basic assumptions I made when I first went to test this are in fact incorrect and that I was working under the wrong mental model. When working under the correct mental model, the Isolation method clears rows perfectly fine; however, it's a mental model significantly differently than the one I'm use to and anyone who has used traditional Float style grids or Susy are use to. I am keeping up the original article as record.\n:::\n\nIf, for some reason, over the past few months you haven't read [John Albin Wilkins'](https://twitter.com/johnalbin) article [Responsive Design’s Dirty Little Secret](http://palantir.net/blog/responsive-design-s-dirty-little-secret). I highly suggest reading the whole article, as this is more or less a response to it. The basic gist of it is that browsers are really _really_ bad at rounding percentages, and where it becomes a real issue is with percentage widths in Responsive Web Design. The issue stems from the fact that some browsers, when handed (or calculate) non-whole-pixel value, round only in one direction and not how we would round if we were doing it by hand. IE6 and IE7 round up, Opera and Webkit round down, and FireFox does sub-pixel rendering, which in a nutshell means they round correctly. This is an issue because, when calculating a bunch of fluid grids in, say, a responsive grid, the rounding errors compound upon themselves so being one pixel off on each of ten columns means the last column is 10 pixels off. This can present serious layout problems.\n\nExcept that it doesn't.\n\nWe are going to be talking in terms of layouts as this is where the problem presents itself most usually. So, before we go any further, let's define a couple of terms.\n\n- **Float Method**: The \"standard\" method for laying out items. A List Apart has a great writeup on [CSS Floats](http://www.alistapart.com/articles/css-floats-101/). Simply slap a percentage width on your item, use a CSS Float to push it around, and you're set. Susceptible to compounding rounding errors.\n- **Isolation Method**: The \"new\" way proposed by John in the above linked article. A bit more advanced. Named Isolation method as the method isolates the sub-pixel rounding issues. While still using percentage widths and CSS floats to push your item around, to finely tune the position you need to know where on the grid your item sits. Not susceptible to compounding rousing errors.\n- **Float Clearing**: When working with items in CSS, if you want a container of a float based layout (witch both Float and Isolation methods are) to accommodate the the floats, you need to clear said floats. Peter-Paul Koch has a [great introductory writeup](http://www.quirksmode.org/css/clearing.html) on the subject.\n- **Row Clearing**: Row clearing is related to float clearing. If you've got row of items, you generally don't want one row to bleed into another. Row clearing makes sure that this happens.\n\nNow here's where things get interesting.\n\n## Sub-Pixel Says What?\n\nWhile John's article makes some very valid points about sub-pixel rounding in his article, the truth of the matter is that it's not as big of an issue as John makes it out to be on most browsers today. While he mentions IE6 and IE7 being total crap and rounding up and Webkit and Opera being no better and always rounding down, conveniently missing from that list is IE8 and up. Tyler Tate has a great writeup on [Sub-Pixel Rounding in IE](http://tylertate.com/blog/2012/01/05/subpixel-rounding.html) which says, as it turns out, that IE8 and IE9 (and thus, presumably IE10) all do the same Sub-Pixel Rounding awesomeness that FireFox does! Oh, and Google Chrome? That does it too! So with an eye toward modern browsers, let's take a look at who is exactly still effected by this issue.\n\nAccording to the [W3Counter October 2012 Global Web Stats](http://www.w3counter.com/globalstats.php) Top 10 Browsers, the current version of Chrome (which has the sub-pixel fix) has a 25.15% market share, IE8 and 9 have a combined 21.93% market share, and FireFox has a combined total 22.1% market share. That's a grand total of 69.18% of global browser market totally unaffected by this Sub-Pixel Rendering issue. IE7 has a market share of 4.77%, with IE6 less than that (or unreported, can't quite find exactly which). So, those two most atrocious offenders we shouldn't need to worry about much anymore (unless, of course, you're targeting, say, China). The rest of the 26 some odd percent is a combination of old browsers, Safari, and Mobile browsers which all (generally speaking) suffer from some sort of sub-pixel rounding issue, most of them having the round down issue. The long and short of the question \"is sub-pixel rendering an issue for my site\" is a matter of \"it depends\".\n\n## The Hidden Cost Of Outsmarting The Browser\n\nYup, mobile is still an issue. But remember that 10 pixel issue we had at the start? Well that's a worst case scenario, in fact the whole sub-pixel rendering issue, is enflamed not because of how pervasive the issue is in general usage, but rather at these worst case scenarios. Besides, there are bigger things that we need to consider when working with Responsive Web Design.\n\nWhile the Isolation method most certainly will solve the sub-pixel rounding issue across browsers, and especially on mobile where browser choice is limited and sub-pixel rendering issues are rampant, it does something that, in my opinion, is even worse than being a pixel or two off here and there. **The Isolation method out and out breaks standard row clearing**.\n\n## Isolation Method's Dirty Little Secret\n\nTake a look at what standard row clearing looks like.\n\n\u003C!-- ![Float Row Clearing](/sites/default/files/field/image/Float%20Row%20Clearing.png) -->\n\nUsing the Float method, we get nice cleared rows with absolutely no extra markup. Why is this important? Well, for Responsive Web Design, we send one set of HTML down to the user and alter the layout using CSS. The Float method makes changing our layouts really easy without changing our markup because of its inherit row clearing abilities. Simply change your margins, widths, and floats at your given breakpoints and you've got a new grid! It's awesome, it works really well, and it's how [Susy](http://susy.oddbird.net/), one of my favorite Sass powered grid systems, works. But yes, it's still affected by the sub-pixel rounding issue.\n\nLet's take a look at what row clearing looks like with the Isolation method.\n\n\u003C!-- ![Isolation Row Clearing](/sites/default/files/field/image/Isolation%20Row%20Clearing.png) -->\n\nThose dark green parts? Those are the parts of the two rows that overlap each other. Yup! You read (and see) that right! The isolation method fixes the sub-pixel rounding issues by introducing an even worse issue, breaking row clearing! While float clearing still works, as you can see, rows clear based on the height of the last item in the row, not the tallest as in the Float method. Well how do we solve this? **_Welcome back wrapper divs!_** That's right! In order to fix row clearing with the Isolation method, each row needs to be wrapped in a clearfixed div! And for each change in row arrangement you make as you change layouts, you need wrapper divs for each row! It's not without its place in Responsive Web Design. If you've got major pieces of a site that are already cordoned off or naturally have wrappers around the rows you need, the Isolation method is a great method to use. This is what [Zen Grids](http://zengrids.com/) uses.\n\n## Well Which One Should I Use?\n\nAs with all great question in Web Development, the answer is, it depends. I tend to prefer the tradeoffs from Float method to the Isolation method, but many many people prefer the Isolation method. I tend to find that the sub-pixel rendering issues with the Float method don't bite me in most of my day to day usage, but your mileage will vary.\n\n\u003Chr>\n\n## Postscript: What If I Want To Use Both?\n\nWell now that's an interesting question. Because both the Float and the Isolation method have different use cases and do different things well, I find that sometimes I want to use the Float method and sometimes I want to use the Isolation method. To my knowledge, there's only one grid system that allows you to switch your method based on when you need it. That's [Singularity GS](https://github.com/scottkellum/singularity). Currently in the 1.0 preview (`gem install singularitygs --pre`) and then in the 1.0 itself and going forward, you can choose which output method you want to use and when! By default, Singularity will use the Isolation method, but if set a the variable `$output: 'float';`, TADA! You've switched to the Float method. But wait, you say. What if I want to swap between the two? Well in Singularity's `grid-span` mixin, if you include the optional `$output` variable and set it to `'float'` or `'isolation'`. For example, if you had all of your output set to Float method you could change a single output to Isolation method by doing the following: `@include grid-span(1, 1, $output: 'isolation') {}`. I've been using this for a while, and I like it a lot.","src/content/posts/responsive-designs-dirty-little-secret.md","bcbb73f5fc029c8e",{"html":1803,"metadata":1804},"\u003Cdiv class=\"warning message\" data-type=\"warning\">\u003Cp>\u003Cstrong>Update 1/29/2013\u003C/strong>\u003C/p>\u003Cp>After having extensive conversations with John Albin Wilkins, I’ve realized that some of the basic assumptions I made when I first went to test this are in fact incorrect and that I was working under the wrong mental model. When working under the correct mental model, the Isolation method clears rows perfectly fine; however, it’s a mental model significantly differently than the one I’m use to and anyone who has used traditional Float style grids or Susy are use to. I am keeping up the original article as record.\u003C/p>\u003C/div>\n\u003Cp>If, for some reason, over the past few months you haven’t read \u003Ca href=\"https://twitter.com/johnalbin\">John Albin Wilkins’\u003C/a> article \u003Ca href=\"http://palantir.net/blog/responsive-design-s-dirty-little-secret\">Responsive Design’s Dirty Little Secret\u003C/a>. I highly suggest reading the whole article, as this is more or less a response to it. The basic gist of it is that browsers are really \u003Cem>really\u003C/em> bad at rounding percentages, and where it becomes a real issue is with percentage widths in Responsive Web Design. The issue stems from the fact that some browsers, when handed (or calculate) non-whole-pixel value, round only in one direction and not how we would round if we were doing it by hand. IE6 and IE7 round up, Opera and Webkit round down, and FireFox does sub-pixel rendering, which in a nutshell means they round correctly. This is an issue because, when calculating a bunch of fluid grids in, say, a responsive grid, the rounding errors compound upon themselves so being one pixel off on each of ten columns means the last column is 10 pixels off. This can present serious layout problems.\u003C/p>\n\u003Cp>Except that it doesn’t.\u003C/p>\n\u003Cp>We are going to be talking in terms of layouts as this is where the problem presents itself most usually. So, before we go any further, let’s define a couple of terms.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Float Method\u003C/strong>: The “standard” method for laying out items. A List Apart has a great writeup on \u003Ca href=\"http://www.alistapart.com/articles/css-floats-101/\">CSS Floats\u003C/a>. Simply slap a percentage width on your item, use a CSS Float to push it around, and you’re set. Susceptible to compounding rounding errors.\u003C/li>\n\u003Cli>\u003Cstrong>Isolation Method\u003C/strong>: The “new” way proposed by John in the above linked article. A bit more advanced. Named Isolation method as the method isolates the sub-pixel rounding issues. While still using percentage widths and CSS floats to push your item around, to finely tune the position you need to know where on the grid your item sits. Not susceptible to compounding rousing errors.\u003C/li>\n\u003Cli>\u003Cstrong>Float Clearing\u003C/strong>: When working with items in CSS, if you want a container of a float based layout (witch both Float and Isolation methods are) to accommodate the the floats, you need to clear said floats. Peter-Paul Koch has a \u003Ca href=\"http://www.quirksmode.org/css/clearing.html\">great introductory writeup\u003C/a> on the subject.\u003C/li>\n\u003Cli>\u003Cstrong>Row Clearing\u003C/strong>: Row clearing is related to float clearing. If you’ve got row of items, you generally don’t want one row to bleed into another. Row clearing makes sure that this happens.\u003C/li>\n\u003C/ul>\n\u003Cp>Now here’s where things get interesting.\u003C/p>\n\u003Ch2 id=\"sub-pixel-says-what\">Sub-Pixel Says What?\u003C/h2>\n\u003Cp>While John’s article makes some very valid points about sub-pixel rounding in his article, the truth of the matter is that it’s not as big of an issue as John makes it out to be on most browsers today. While he mentions IE6 and IE7 being total crap and rounding up and Webkit and Opera being no better and always rounding down, conveniently missing from that list is IE8 and up. Tyler Tate has a great writeup on \u003Ca href=\"http://tylertate.com/blog/2012/01/05/subpixel-rounding.html\">Sub-Pixel Rounding in IE\u003C/a> which says, as it turns out, that IE8 and IE9 (and thus, presumably IE10) all do the same Sub-Pixel Rounding awesomeness that FireFox does! Oh, and Google Chrome? That does it too! So with an eye toward modern browsers, let’s take a look at who is exactly still effected by this issue.\u003C/p>\n\u003Cp>According to the \u003Ca href=\"http://www.w3counter.com/globalstats.php\">W3Counter October 2012 Global Web Stats\u003C/a> Top 10 Browsers, the current version of Chrome (which has the sub-pixel fix) has a 25.15% market share, IE8 and 9 have a combined 21.93% market share, and FireFox has a combined total 22.1% market share. That’s a grand total of 69.18% of global browser market totally unaffected by this Sub-Pixel Rendering issue. IE7 has a market share of 4.77%, with IE6 less than that (or unreported, can’t quite find exactly which). So, those two most atrocious offenders we shouldn’t need to worry about much anymore (unless, of course, you’re targeting, say, China). The rest of the 26 some odd percent is a combination of old browsers, Safari, and Mobile browsers which all (generally speaking) suffer from some sort of sub-pixel rounding issue, most of them having the round down issue. The long and short of the question “is sub-pixel rendering an issue for my site” is a matter of “it depends”.\u003C/p>\n\u003Ch2 id=\"the-hidden-cost-of-outsmarting-the-browser\">The Hidden Cost Of Outsmarting The Browser\u003C/h2>\n\u003Cp>Yup, mobile is still an issue. But remember that 10 pixel issue we had at the start? Well that’s a worst case scenario, in fact the whole sub-pixel rendering issue, is enflamed not because of how pervasive the issue is in general usage, but rather at these worst case scenarios. Besides, there are bigger things that we need to consider when working with Responsive Web Design.\u003C/p>\n\u003Cp>While the Isolation method most certainly will solve the sub-pixel rounding issue across browsers, and especially on mobile where browser choice is limited and sub-pixel rendering issues are rampant, it does something that, in my opinion, is even worse than being a pixel or two off here and there. \u003Cstrong>The Isolation method out and out breaks standard row clearing\u003C/strong>.\u003C/p>\n\u003Ch2 id=\"isolation-methods-dirty-little-secret\">Isolation Method’s Dirty Little Secret\u003C/h2>\n\u003Cp>Take a look at what standard row clearing looks like.\u003C/p>\n\u003C!-- ![Float Row Clearing](/sites/default/files/field/image/Float%20Row%20Clearing.png) -->\n\u003Cp>Using the Float method, we get nice cleared rows with absolutely no extra markup. Why is this important? Well, for Responsive Web Design, we send one set of HTML down to the user and alter the layout using CSS. The Float method makes changing our layouts really easy without changing our markup because of its inherit row clearing abilities. Simply change your margins, widths, and floats at your given breakpoints and you’ve got a new grid! It’s awesome, it works really well, and it’s how \u003Ca href=\"http://susy.oddbird.net/\">Susy\u003C/a>, one of my favorite Sass powered grid systems, works. But yes, it’s still affected by the sub-pixel rounding issue.\u003C/p>\n\u003Cp>Let’s take a look at what row clearing looks like with the Isolation method.\u003C/p>\n\u003C!-- ![Isolation Row Clearing](/sites/default/files/field/image/Isolation%20Row%20Clearing.png) -->\n\u003Cp>Those dark green parts? Those are the parts of the two rows that overlap each other. Yup! You read (and see) that right! The isolation method fixes the sub-pixel rounding issues by introducing an even worse issue, breaking row clearing! While float clearing still works, as you can see, rows clear based on the height of the last item in the row, not the tallest as in the Float method. Well how do we solve this? \u003Cstrong>\u003Cem>Welcome back wrapper divs!\u003C/em>\u003C/strong> That’s right! In order to fix row clearing with the Isolation method, each row needs to be wrapped in a clearfixed div! And for each change in row arrangement you make as you change layouts, you need wrapper divs for each row! It’s not without its place in Responsive Web Design. If you’ve got major pieces of a site that are already cordoned off or naturally have wrappers around the rows you need, the Isolation method is a great method to use. This is what \u003Ca href=\"http://zengrids.com/\">Zen Grids\u003C/a> uses.\u003C/p>\n\u003Ch2 id=\"well-which-one-should-i-use\">Well Which One Should I Use?\u003C/h2>\n\u003Cp>As with all great question in Web Development, the answer is, it depends. I tend to prefer the tradeoffs from Float method to the Isolation method, but many many people prefer the Isolation method. I tend to find that the sub-pixel rendering issues with the Float method don’t bite me in most of my day to day usage, but your mileage will vary.\u003C/p>\n\u003Chr>\n\u003Ch2 id=\"postscript-what-if-i-want-to-use-both\">Postscript: What If I Want To Use Both?\u003C/h2>\n\u003Cp>Well now that’s an interesting question. Because both the Float and the Isolation method have different use cases and do different things well, I find that sometimes I want to use the Float method and sometimes I want to use the Isolation method. To my knowledge, there’s only one grid system that allows you to switch your method based on when you need it. That’s \u003Ca href=\"https://github.com/scottkellum/singularity\">Singularity GS\u003C/a>. Currently in the 1.0 preview (\u003Ccode>gem install singularitygs --pre\u003C/code>) and then in the 1.0 itself and going forward, you can choose which output method you want to use and when! By default, Singularity will use the Isolation method, but if set a the variable \u003Ccode>$output: 'float';\u003C/code>, TADA! You’ve switched to the Float method. But wait, you say. What if I want to swap between the two? Well in Singularity’s \u003Ccode>grid-span\u003C/code> mixin, if you include the optional \u003Ccode>$output\u003C/code> variable and set it to \u003Ccode>'float'\u003C/code> or \u003Ccode>'isolation'\u003C/code>. For example, if you had all of your output set to Float method you could change a single output to Isolation method by doing the following: \u003Ccode>@include grid-span(1, 1, $output: 'isolation') {}\u003C/code>. I’ve been using this for a while, and I like it a lot.\u003C/p>",{"headings":1805,"localImagePaths":1821,"remoteImagePaths":1822,"frontmatter":1823,"imagePaths":1825},[1806,1809,1812,1815,1818],{"depth":80,"slug":1807,"text":1808},"sub-pixel-says-what","Sub-Pixel Says What?",{"depth":80,"slug":1810,"text":1811},"the-hidden-cost-of-outsmarting-the-browser","The Hidden Cost Of Outsmarting The Browser",{"depth":80,"slug":1813,"text":1814},"isolation-methods-dirty-little-secret","Isolation Method’s Dirty Little Secret",{"depth":80,"slug":1816,"text":1817},"well-which-one-should-i-use","Well Which One Should I Use?",{"depth":80,"slug":1819,"text":1820},"postscript-what-if-i-want-to-use-both","Postscript: What If I Want To Use Both?",[],[],{"title":1795,"published":1824,"summary":1798,"updated":1568,"archived":1466},"2012-12-01",[],"responsive-nirvana",{"id":1826,"data":1828,"body":1832,"filePath":1833,"digest":1834,"rendered":1835},{"title":1829,"published":1830,"summary":1831},"Responsive Nirvana",["Date","2013-04-26T00:00:00.000Z"],"While they've been soft launched for a few weeks now, I'm crazy excited to announce that we've finally, officially, launched [Singularity 1.0](https://github.com/Team-Sass/Singularity) and [Breakpoint 2.0](https://github.com/team-sass/breakpoint).","While they've been soft launched for a few weeks now, I'm crazy excited to announce that we've finally, officially, launched [Singularity 1.0](https://github.com/Team-Sass/Singularity) and [Breakpoint 2.0](https://github.com/team-sass/breakpoint). To me, these two tools represent the next generation of Responsive Web Design with Sass and provide me with an awesome happy place. They've allowed me to create and iterate over responsive designs faster and easier than I've ever been able to before while still allowing me to maintain full control. They provide for me a responsive web design nirvana and I can't wait for everyone to start using them.\n\n## Singularity 1.0\n\nSingularity is a little bit different than most other grid systems you've come across. To begin with, it's not a grid system _per se_, but rather a grid framework to allow you to make your own grid system. Singularity is divided into three parts, a syntax layer, a math engine, and an output layer.\n\nThe math engine is really Singularity's secret sauce; all of the calculations are based on the supplied grid definitions themselves as opposed to the container in which the grid resides. This allows two things: the first is that it allows either symmetric or asymmetric grids to be specified, awesome! The second is that, because the math engine is container independent, you can use your girds anywhere, in any container, and they'll work precisely as expected. After all, grids are just a percentage of a whole, no matter what the whole is.\n\nThe syntax layer and output layer set Singularity apart as well. While Singularity's default output style is [Isolation](https://github.com/Team-Sass/Singularity/wiki/Output-Styles#isolation), it also comes with the more traditional [Float](https://github.com/Team-Sass/Singularity/wiki/Output-Styles#float) output style. More important than those two output styles coming with Singularity, though, is that Singularity is designed to allow you to create custom output styles allowing you total control of your output. This means that when CSS Grids land, or when Flexbox is more widely supported, you will continue to be able to use Singularity for your grids with these new output styles. You can even choose output styles on the fly, letting you mix and match as you'd like. Each output style can also supply its own [Output Span](https://github.com/Team-Sass/Singularity/wiki/Spanning-The-Grid#output-span), allowing each output style to define a syntax that makes most sense to that output.\n\n## Breakpoint 2.0\n\nBreakpoint 2.0 is everything that you loved from the original Breakpoint, just made _that much more awesome_. It's still just as easy to use as before, but it's now been super powered. You can now include [Media Types](https://github.com/Team-Sass/breakpoint/wiki/Advanced-Media-Queries#media-types) and [No Query Fallbacks](https://github.com/Team-Sass/breakpoint/wiki/No-Query-Fallbacks) straight in your variable definitions, your No Query Fallbacks files can now [target specific fallbacks](https://github.com/Team-Sass/breakpoint/wiki/No-Query-Fallbacks#separate-fallback-file-specific-fallbacks), and Breakpoint now supports [Or Queries](https://github.com/Team-Sass/breakpoint/wiki/Advanced-Media-Queries#or-queries), giving you better control over exactly what constitutes a successful query. We've also updated our [Cross Browser Resolution Media Queries](https://github.com/Team-Sass/breakpoint/wiki/Advanced-Media-Queries#resolution-media-queries) to use standard queries and produce better output, and we've even rolled [Respond-to](https://github.com/Team-Sass/breakpoint/wiki/Respond-To) into Breakpoint Core, allowing use of both syntaxes out of the box and as you need them.\n\n## In Action\n\nThose who have had an opportunity over the past few weeks to see my RWD with Sass+Compass talk will have seen both of these in use, even if they didn't quite know it. Once the video for my talk is online, I'll be sure to link to it, but until then, if you'd like to see code examples of these tools in action, along with [Toolkit](https://github.com/team-sass/toolkit), my slides [are available online](http://snugug.github.io/RWD-with-Sass-Compass/#/).","src/content/posts/responsive-nirvana.md","b347dabe4e5499e2",{"html":1836,"metadata":1837},"\u003Cp>While they’ve been soft launched for a few weeks now, I’m crazy excited to announce that we’ve finally, officially, launched \u003Ca href=\"https://github.com/Team-Sass/Singularity\">Singularity 1.0\u003C/a> and \u003Ca href=\"https://github.com/team-sass/breakpoint\">Breakpoint 2.0\u003C/a>. To me, these two tools represent the next generation of Responsive Web Design with Sass and provide me with an awesome happy place. They’ve allowed me to create and iterate over responsive designs faster and easier than I’ve ever been able to before while still allowing me to maintain full control. They provide for me a responsive web design nirvana and I can’t wait for everyone to start using them.\u003C/p>\n\u003Ch2 id=\"singularity-10\">Singularity 1.0\u003C/h2>\n\u003Cp>Singularity is a little bit different than most other grid systems you’ve come across. To begin with, it’s not a grid system \u003Cem>per se\u003C/em>, but rather a grid framework to allow you to make your own grid system. Singularity is divided into three parts, a syntax layer, a math engine, and an output layer.\u003C/p>\n\u003Cp>The math engine is really Singularity’s secret sauce; all of the calculations are based on the supplied grid definitions themselves as opposed to the container in which the grid resides. This allows two things: the first is that it allows either symmetric or asymmetric grids to be specified, awesome! The second is that, because the math engine is container independent, you can use your girds anywhere, in any container, and they’ll work precisely as expected. After all, grids are just a percentage of a whole, no matter what the whole is.\u003C/p>\n\u003Cp>The syntax layer and output layer set Singularity apart as well. While Singularity’s default output style is \u003Ca href=\"https://github.com/Team-Sass/Singularity/wiki/Output-Styles#isolation\">Isolation\u003C/a>, it also comes with the more traditional \u003Ca href=\"https://github.com/Team-Sass/Singularity/wiki/Output-Styles#float\">Float\u003C/a> output style. More important than those two output styles coming with Singularity, though, is that Singularity is designed to allow you to create custom output styles allowing you total control of your output. This means that when CSS Grids land, or when Flexbox is more widely supported, you will continue to be able to use Singularity for your grids with these new output styles. You can even choose output styles on the fly, letting you mix and match as you’d like. Each output style can also supply its own \u003Ca href=\"https://github.com/Team-Sass/Singularity/wiki/Spanning-The-Grid#output-span\">Output Span\u003C/a>, allowing each output style to define a syntax that makes most sense to that output.\u003C/p>\n\u003Ch2 id=\"breakpoint-20\">Breakpoint 2.0\u003C/h2>\n\u003Cp>Breakpoint 2.0 is everything that you loved from the original Breakpoint, just made \u003Cem>that much more awesome\u003C/em>. It’s still just as easy to use as before, but it’s now been super powered. You can now include \u003Ca href=\"https://github.com/Team-Sass/breakpoint/wiki/Advanced-Media-Queries#media-types\">Media Types\u003C/a> and \u003Ca href=\"https://github.com/Team-Sass/breakpoint/wiki/No-Query-Fallbacks\">No Query Fallbacks\u003C/a> straight in your variable definitions, your No Query Fallbacks files can now \u003Ca href=\"https://github.com/Team-Sass/breakpoint/wiki/No-Query-Fallbacks#separate-fallback-file-specific-fallbacks\">target specific fallbacks\u003C/a>, and Breakpoint now supports \u003Ca href=\"https://github.com/Team-Sass/breakpoint/wiki/Advanced-Media-Queries#or-queries\">Or Queries\u003C/a>, giving you better control over exactly what constitutes a successful query. We’ve also updated our \u003Ca href=\"https://github.com/Team-Sass/breakpoint/wiki/Advanced-Media-Queries#resolution-media-queries\">Cross Browser Resolution Media Queries\u003C/a> to use standard queries and produce better output, and we’ve even rolled \u003Ca href=\"https://github.com/Team-Sass/breakpoint/wiki/Respond-To\">Respond-to\u003C/a> into Breakpoint Core, allowing use of both syntaxes out of the box and as you need them.\u003C/p>\n\u003Ch2 id=\"in-action\">In Action\u003C/h2>\n\u003Cp>Those who have had an opportunity over the past few weeks to see my RWD with Sass+Compass talk will have seen both of these in use, even if they didn’t quite know it. Once the video for my talk is online, I’ll be sure to link to it, but until then, if you’d like to see code examples of these tools in action, along with \u003Ca href=\"https://github.com/team-sass/toolkit\">Toolkit\u003C/a>, my slides \u003Ca href=\"http://snugug.github.io/RWD-with-Sass-Compass/#/\">are available online\u003C/a>.\u003C/p>",{"headings":1838,"localImagePaths":1848,"remoteImagePaths":1849,"frontmatter":1850,"imagePaths":1852},[1839,1842,1845],{"depth":80,"slug":1840,"text":1841},"singularity-10","Singularity 1.0",{"depth":80,"slug":1843,"text":1844},"breakpoint-20","Breakpoint 2.0",{"depth":80,"slug":1846,"text":1847},"in-action","In Action",[],[],{"title":1829,"published":1851,"summary":1831},"2013-04-26",[],"return-of-the-cms",{"id":1853,"data":1855,"body":1859,"filePath":1860,"digest":1861,"rendered":1862},{"title":1856,"published":1857,"summary":1858},"Return of the CMS",["Date","2022-11-07T00:00:00.000Z"],"After rebuilding my blog on a new generation headless CMS, I've rethought whether flat Markdown files in site code is worth the complexity, especially for JAMStack sites.","I really didn't like writing my last blog post. It wasn't the content. I really don't like maintaining content as flat markdown files. It's something I thought was great for a Avery long time, but the more I do it, both personally and professionally, the more I hate it. I got my start in content management systems and, while I would never return to a fat stack CMS like Drupal or Wordpress, I missed the simplicity of structured meta fields and a `textarea`, so I decided to make a change.\n\n## The tyranny of the unstructured text box\n\nBack when I worked at NBCUniversal, a friend of mine (also named Sam, we were \"backend Sam and front-end Sam, or together, the Sams) used the phrase the phrase \"the tyranny of the unstructured text box\" to describe how, when presented with something totally unstructured like a blank text area, the possibilities of what to do with it can become overwhelming. Because of that, we wind up creating structure to fill the void. What I've come to realize is there's no more tyrannical of an unstructured text box than an empty Markdown file.\n\nI love Markdown. This post is written in Markdown. I take notes in Markdown. But there may not be a greater text box tyrant than Markdown. For every project where the primary content structure is Markdown, I need to make the following _additional_ decisions:\n\n- What flavor of Markdown am I going to use?\n- What subset of features of that flavor am I going to allow?\n- What missing features do I need?\n- What should the syntax for those features be?\n- What renderer should I use?\n- How can I validate the content written?\n- How can I attach meta-information to my markdown (like title, publishing date, and the like)\n- How can I validate that meta-information to make sure ita structured right each time?\n- How tightly do I need to couple my codebase to my particular duct-tape and string Markdown architecture?\n- Can I use Markdown at all or do I need to use a variant, like MDX?\n\nAnd the list goes on. The decisions I made for ChromeOS.dev have changed a number of times over it's short lifespan, but the result is always a pretty fat stack for anything non-trivial. To solve some of these problems, I've even gone so far as to write [JSON Schema powered linters](https://github.com/chromeos/chromeos.dev/tree/main/lib/linting) for the YAML frontmatter. Complexity upon complexity just to avoid a CMS. But even then, am I even really doing that?\n\nHighly structured YAML frontmatter for meta-information. Folder based content structure. References by the grace of our build system and hopefully unique, manually-managed IDs. What I have is really an unstructured CMS whose database has been splatted across dozens of files and folders and whose rules are hidden away in opaque logic. After working this way for years, I'll take a web form, please.\n\n## Return of the CMS\n\nLike I said at the top, I've been doing CMSes for a long time. I started my career working in Drupal (even back then 10+ years ago advocating for what are now known as headless CMSes). I took a stab at building one while at IBM we called Punchcard. I've even tried CMSes that live on top of flat Markdown files, like the Netlify CMS. With all this in my back pocket I've gotta say, the current generation of headless CMSes are _really_ good.\n\n:::message{.info}\nWhile individual definitions may vary, to me, a headless CMS is one that focuses on managing content but _not_ on rendering the page a user sees (the \"head\"). It instead provides APIs for other systems to pull the content and display it.\n:::\n\nI've never like fat stack CMSes because I always found they did a bad job at rendering the final website; in my Drupal days I worked really hard to undo most of what it gave me on the front-end. With Markdown files treated as code, you've got the same tight coupling problem, but in reverse! You've got a \"bodyless\" CMS! The tight coupling of code to content can also lead to awkward states where to deploy a feature you need to deploy content, or vice versa. For a few, small things this may be OK, but when looking to scale, thing get tough. In addition to all of the above things you need to look out for, you also now need to figure out:\n\n- How to let others who aren't familiar with the codebase submit content\n- How to review said content (which usually has a different set of needs than code)\n- How to stage content not ready to be published\n- _Where_ to stage content not ready to be published\n- How to schedule content to go live\n- How to reference other content and make sure it stays in sync\n\nAnd again, the list goes on, especially if working with non-developers or you need to localize the content.\n\nThe good news is pretty much every one of the current generation of headless CMSes does all this, and does it well. It then becomes finding what their UX and DX differences are, and choosing one. Heck, you can even be like me and keep writing in Markdown (for now, anyway) and move all of the content management bits to the CMS. Where it always should have been.\n\nThis blog post is a great example. I wrote this whole post on my phone, sitting in my backyard. Without a CMS, I would have needed to get a copy of my codebase, copy my blog post entry template, edit it, write, deal with Git from my phone, then either run everything on my computer later or rely on CI to make sure nothing I did broke any of my \"rules\". With my CMS, I had form fields and a text box. Revisions were automatically saved and I can pick back up anywhere. I know what's missing and what's not. It's great.\n\n## The great decomplecting\n\nSo what has this done for my codebase? Well, I now have a separate codebase for my CMS that I need to manage, but it's now only focused on one thing. Less net complexity for my content. I like it. I also mostly don't need to touch it again, so that's a one-time complexity sink.\n\nFor my codebase I've gone from dozens and dozens of files to, like, 10? A handful of components and a couple of layouts. It's so much easier for me to grok my codebase now and see what connects where and how. Piles and piles of complexity removed. I love it. And, because my content isn't tightly coupled to my code, I _also_ mostly don't need to touch it, either! From one tight coupled system where I need to touch everything to do anything to two loosely coupled systems that I basically don't need to touch to make any content changes.\n\n---\n\nSo I'm all in on the new generation of headless CMSes. For me, they solve almost all of the problems I have with managing individual Markdown files and, ultimately, make it easier for me to both write new content and maintain my site's codebase. If you've been thinking about it, especially if you've got a JAMStack site, you should consider the switch, too.","src/content/posts/return-of-the-cms.md","288fb641721655bf",{"html":1863,"metadata":1864},"\u003Cp>I really didn’t like writing my last blog post. It wasn’t the content. I really don’t like maintaining content as flat markdown files. It’s something I thought was great for a Avery long time, but the more I do it, both personally and professionally, the more I hate it. I got my start in content management systems and, while I would never return to a fat stack CMS like Drupal or Wordpress, I missed the simplicity of structured meta fields and a \u003Ccode>textarea\u003C/code>, so I decided to make a change.\u003C/p>\n\u003Ch2 id=\"the-tyranny-of-the-unstructured-text-box\">The tyranny of the unstructured text box\u003C/h2>\n\u003Cp>Back when I worked at NBCUniversal, a friend of mine (also named Sam, we were “backend Sam and front-end Sam, or together, the Sams) used the phrase the phrase “the tyranny of the unstructured text box” to describe how, when presented with something totally unstructured like a blank text area, the possibilities of what to do with it can become overwhelming. Because of that, we wind up creating structure to fill the void. What I’ve come to realize is there’s no more tyrannical of an unstructured text box than an empty Markdown file.\u003C/p>\n\u003Cp>I love Markdown. This post is written in Markdown. I take notes in Markdown. But there may not be a greater text box tyrant than Markdown. For every project where the primary content structure is Markdown, I need to make the following \u003Cem>additional\u003C/em> decisions:\u003C/p>\n\u003Cul>\n\u003Cli>What flavor of Markdown am I going to use?\u003C/li>\n\u003Cli>What subset of features of that flavor am I going to allow?\u003C/li>\n\u003Cli>What missing features do I need?\u003C/li>\n\u003Cli>What should the syntax for those features be?\u003C/li>\n\u003Cli>What renderer should I use?\u003C/li>\n\u003Cli>How can I validate the content written?\u003C/li>\n\u003Cli>How can I attach meta-information to my markdown (like title, publishing date, and the like)\u003C/li>\n\u003Cli>How can I validate that meta-information to make sure ita structured right each time?\u003C/li>\n\u003Cli>How tightly do I need to couple my codebase to my particular duct-tape and string Markdown architecture?\u003C/li>\n\u003Cli>Can I use Markdown at all or do I need to use a variant, like MDX?\u003C/li>\n\u003C/ul>\n\u003Cp>And the list goes on. The decisions I made for ChromeOS.dev have changed a number of times over it’s short lifespan, but the result is always a pretty fat stack for anything non-trivial. To solve some of these problems, I’ve even gone so far as to write \u003Ca href=\"https://github.com/chromeos/chromeos.dev/tree/main/lib/linting\">JSON Schema powered linters\u003C/a> for the YAML frontmatter. Complexity upon complexity just to avoid a CMS. But even then, am I even really doing that?\u003C/p>\n\u003Cp>Highly structured YAML frontmatter for meta-information. Folder based content structure. References by the grace of our build system and hopefully unique, manually-managed IDs. What I have is really an unstructured CMS whose database has been splatted across dozens of files and folders and whose rules are hidden away in opaque logic. After working this way for years, I’ll take a web form, please.\u003C/p>\n\u003Ch2 id=\"return-of-the-cms\">Return of the CMS\u003C/h2>\n\u003Cp>Like I said at the top, I’ve been doing CMSes for a long time. I started my career working in Drupal (even back then 10+ years ago advocating for what are now known as headless CMSes). I took a stab at building one while at IBM we called Punchcard. I’ve even tried CMSes that live on top of flat Markdown files, like the Netlify CMS. With all this in my back pocket I’ve gotta say, the current generation of headless CMSes are \u003Cem>really\u003C/em> good.\u003C/p>\n\u003Cdiv class=\"info message\" data-type=\"info\">\u003Cp>While individual definitions may vary, to me, a headless CMS is one that focuses on managing content but \u003Cem>not\u003C/em> on rendering the page a user sees (the “head”). It instead provides APIs for other systems to pull the content and display it.\u003C/p>\u003C/div>\n\u003Cp>I’ve never like fat stack CMSes because I always found they did a bad job at rendering the final website; in my Drupal days I worked really hard to undo most of what it gave me on the front-end. With Markdown files treated as code, you’ve got the same tight coupling problem, but in reverse! You’ve got a “bodyless” CMS! The tight coupling of code to content can also lead to awkward states where to deploy a feature you need to deploy content, or vice versa. For a few, small things this may be OK, but when looking to scale, thing get tough. In addition to all of the above things you need to look out for, you also now need to figure out:\u003C/p>\n\u003Cul>\n\u003Cli>How to let others who aren’t familiar with the codebase submit content\u003C/li>\n\u003Cli>How to review said content (which usually has a different set of needs than code)\u003C/li>\n\u003Cli>How to stage content not ready to be published\u003C/li>\n\u003Cli>\u003Cem>Where\u003C/em> to stage content not ready to be published\u003C/li>\n\u003Cli>How to schedule content to go live\u003C/li>\n\u003Cli>How to reference other content and make sure it stays in sync\u003C/li>\n\u003C/ul>\n\u003Cp>And again, the list goes on, especially if working with non-developers or you need to localize the content.\u003C/p>\n\u003Cp>The good news is pretty much every one of the current generation of headless CMSes does all this, and does it well. It then becomes finding what their UX and DX differences are, and choosing one. Heck, you can even be like me and keep writing in Markdown (for now, anyway) and move all of the content management bits to the CMS. Where it always should have been.\u003C/p>\n\u003Cp>This blog post is a great example. I wrote this whole post on my phone, sitting in my backyard. Without a CMS, I would have needed to get a copy of my codebase, copy my blog post entry template, edit it, write, deal with Git from my phone, then either run everything on my computer later or rely on CI to make sure nothing I did broke any of my “rules”. With my CMS, I had form fields and a text box. Revisions were automatically saved and I can pick back up anywhere. I know what’s missing and what’s not. It’s great.\u003C/p>\n\u003Ch2 id=\"the-great-decomplecting\">The great decomplecting\u003C/h2>\n\u003Cp>So what has this done for my codebase? Well, I now have a separate codebase for my CMS that I need to manage, but it’s now only focused on one thing. Less net complexity for my content. I like it. I also mostly don’t need to touch it again, so that’s a one-time complexity sink.\u003C/p>\n\u003Cp>For my codebase I’ve gone from dozens and dozens of files to, like, 10? A handful of components and a couple of layouts. It’s so much easier for me to grok my codebase now and see what connects where and how. Piles and piles of complexity removed. I love it. And, because my content isn’t tightly coupled to my code, I \u003Cem>also\u003C/em> mostly don’t need to touch it, either! From one tight coupled system where I need to touch everything to do anything to two loosely coupled systems that I basically don’t need to touch to make any content changes.\u003C/p>\n\u003Chr>\n\u003Cp>So I’m all in on the new generation of headless CMSes. For me, they solve almost all of the problems I have with managing individual Markdown files and, ultimately, make it easier for me to both write new content and maintain my site’s codebase. If you’ve been thinking about it, especially if you’ve got a JAMStack site, you should consider the switch, too.\u003C/p>",{"headings":1865,"localImagePaths":1873,"remoteImagePaths":1874,"frontmatter":1875,"imagePaths":1877},[1866,1869,1870],{"depth":80,"slug":1867,"text":1868},"the-tyranny-of-the-unstructured-text-box","The tyranny of the unstructured text box",{"depth":80,"slug":1853,"text":1856},{"depth":80,"slug":1871,"text":1872},"the-great-decomplecting","The great decomplecting",[],[],{"title":1856,"published":1876,"summary":1858},"2022-11-07",[],"sanity-astro-and-github-oh-my",{"id":1878,"data":1880,"body":1885,"filePath":1886,"digest":1887,"rendered":1888},{"title":1881,"published":1882,"summary":1883,"categories":1884},"Sanity, Astro, and GitHub Oh My!",["Date","2022-11-25T00:00:00.000Z"],"Why I chose Sanity and Astro for my site rebuild, and how I got continuous deployment working for both using GitHub Actions from a monorepo-like setup.",[55],"Following my realization that I no longer want to deal with [flat Markdown files](/musings/return-of-the-cms/), I decided I wanted to rebuild my site. I had a few requirements for doing so: I needed the ability to manage fairly complex content models (my recipes are weirdly complicated to model), I needed migration to be quick because I didn't want to spend a bunch of time on it, and I needed to be able to generate pages from API calls. This lead me on a journey to totally rebasing my site's stack.\n\n## Content management\n\nI've got a long history with content management systems; I got my start, as a career, as a back-end developer, as a front-end developer, as a content strategist, as public speaker, and as a project leader in [Drupal](https://drupal.org/). My first four jobs were all doing work in and around content management. When I left NBCUniversal for IBM, I did so in no small part to expand my knowledge outside of CMS-driven sites, only to work on building an early Node.js headless CMS we called [Punchcard](https://github.com/punchcard-cms). By the time I left, I was once a again working on a Drupal powered website. Needless to say, I have a lot of _feelings_ about content management systems.\n\nLike I mentioned in [Return of the CMS](/musings/return-of-the-cms/), the current field of headless CMSes ticks a lot of CMS boxes for me. After looking at a bunch of them and talking with a few other people, I decided to try my hand at migrating my content to [Sanity](https://sanity.io/). There's a bunch I really like about Sanity: content modeling is super solid, including the ability to model complex, repeatable, and repeatable complex fields and it's super customizable. It even has one of my \"pet peev\" features that I find missing from most content management systems: differentiating between fields that are required to publish and those required to save (in Sanity, fields marked \"required\" are required for publishing, but it's data model makes none strictly required to save, which is good enough for my needs). So I went to work. I also really like the idea of [PortableText](https://github.com/portabletext/portabletext), a JSON spec for defining structured block content that can be used for everything from WYSIWYG editors to HTML, Markdown, and more, although I confess I haven't implemented it yet.\n\nI dove in to see what I could do. I made a few test posts using their blog template as a starting point. It worked well. I ran it locally and poked around with the API; by default it's got its own query language called [GROQ](https://www.sanity.io/docs/how-queries-work) which works well enough; they also offer GraphQL but I never really loved that so I haven't enabled that yet. After an initial proof of concept, I moved all my content types into it, and was happy.\n\nWhen I initially built out my instance, I had used v2. Sanity v3 is [coming soon](https://www.sanity.io/blog/sanity-studio-v3-developer-preview) and is currently in release candidate. Whereas v2 feels very much like a fully cusom tack, v3 has been totally rebuilt, runs [Vite](https://vitejs.dev/) (which I love) and now feels like a regular webapp. Some plugins (like the markdown editor I'm writing this in) are still a work-in-progress, but I like the codebase so much more I'm mostly OK with it. So, content codebse sorted, now my front-end.\n\n## Site codebase\n\nMy previous site was built on [Eleventy](https://11ty.dev/) and I was mostly happy with that for a long time. But the more I used it, the more some rough edges started to annoy me. I don't have much JavaScript on my site, but I've got some, and I've got a lot of CSS and even with my [solution for 11ty and Vite](/musings/eleventy-plus-vite/), they still feel like two separate things trying to compete for ownership of my `dev` script. I've also lost patience with the templating solutions provided; work on my [health tracking app](/musings/a-beginners-guide-to-diabetes/#tracking-my-health) with [Svelte](https://svelte.dev/) has made me realize just how much is missing from those systems. Then there's page generation. I've done a lot of work figuring out how to scale this in 11ty and I don't love the overriding of pagination to accomplish this. Finally, while I really love 11ty's data cascade, once I remove my flat Markdown files, a lot of their utility goes away. So started exploring other options.\n\nI looked at a bunch of other static site generators (SSGs), with a focus on low to zero JS output and support for modern templating options. I eventually settled on [Astro](https://astro.build/); like 11ty it's aggressive about not outputting JavaScript, even for non-Astro components, and it deeply integrates with Vite, which I also really like (although I wish link and script tags would get compiled like they do for standard Vite builds). But it was my experience when I started integrating the content API that I really decided it was worth a full rebuild.\n\nUnlike 11ty, page generation in Astro is done based on folder structure, but file names can have params in them, which feels much more like building routes in a dynamic server. This, to me, feels really natural when coupled with an API. A lot of the struggle I had with managing layouts and cascading data and generating pages disappears with this paradigm. Adding in modern component frameworks for handling reusable UI (instead of Nunjucks macros or shortcodes) also made me more productive, to the point where I was able not only to rebuild my site in a weekend, but do a top-to-bottom refresh of it while adding new features (hello RSS feed and sitemap) to boot!\n\nWith Sanity and Astro, I think I've finally found a winning combo for me blogging more and doing a better job at maintaining my website. The only thing I needed to figure out was continuous deployment now that my content and my site are disconnected.\n\n## Continuous deployment\n\nI've loved [GitHub Actions](https://github.com/features/actions) for a long time, but their documentation is a little obtuse and testing is hard and mostly done live, so it took me a while to figure out how to combine all of the above into a nice package.\n\nThe first, and most important bit, was finding the [`repository_dispatch`](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#repository_dispatch) workflow trigger that lets GitHub Actions run off of a webhook call! Perfect, I thought, as Sanity can be configured to send webhooks when content deploys! Except, and rightfully so, the webhook that GitHub actions requires is pretty secured; it requires a a beta fine-grained GitHub access token with read and write code access and has a max 1-year lifespan, and the structure of the webhook needs to be very specific. Unfortunately, this means Sanity can't just call the action directly, you need something in the middle. A serverless function would be great here, but I wound up going with [Pipedream](https://pipedream.com/). Even now, I don't know why specific dispatch names don't work, but a generic one does, so that's still a work-in-progress, but it works, so that's what matters!\n\nThe second thing I needed to do was figure out how to keep my CMS codebase and my site codebase together in the same repo, because I didn't want to maintain them in different places. To do this, I leaned on the [`paths`](https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#onpushpull_requestpull_request_targetpathspaths-ignore) workflow push filter, letting me run different GitHub Actions depending on whether code was pushed to my CMS or to my site. While experimenting with this, I also found that if you have multiple GitHub Actions with jobs with the same id (like `test-build`) and make that required for a protected branch, it'll work regardless of which Action runs! This means I can protect my main branch regardless of if I'm working on my CMS or my site!\n\nTo keep everything secure, I use a combo of `.env` files locally with my Sanity project and a Sanity API token for reading content for my site, and have GitHub Secrets to supply those during my GitHub Actions build. To deploy my Sanity studio, I do the same, but have a separate deploy token that gets injected during my Action run. The only thing that was a little annoying is the environment variables when working with Sanity is that the required names are specific, so you can't choose the names you want and pass them in where you want. That's easy to overcome, though.\n\n---\n\nI'm super excited about this new setup and workflow, and am making plans for how to expand on it to allow for previews using Astro's server-side render (SSR) mode. I also have been playing with [pnpm](https://pnpm.io/) and migrated my codebase to that, too, with this, and I'm really loving that, too. The only gotcha here was getting [Husky](https://typicode.github.io/husky/#/) to work right, the `prepare` script needs to run from the site root and the hooks need to `cd` to the folder they're in. If you want to see how the above shakes out, here's some deep links to my [site source](https://github.com/Snugug/blog/tree/e85221063403074088e6ddeb804d88648d88d29e) as it looks at time of publishing:\n\n- GitHub Actions\n  - [Site build/deploy](https://github.com/Snugug/blog/blob/e85221063403074088e6ddeb804d88648d88d29e/.github/workflows/tbd-site.yml)\n  - [CMS build/deploy](https://github.com/Snugug/blog/blob/e85221063403074088e6ddeb804d88648d88d29e/.github/workflows/tbd-cms.yml)\n- Codebases\n  - [CMS](https://github.com/Snugug/blog/tree/e85221063403074088e6ddeb804d88648d88d29e/cms)\n  - [Site](https://github.com/Snugug/blog/tree/e85221063403074088e6ddeb804d88648d88d29e/site)\n- Husky\n  - [Husky prepare for CMS](https://github.com/Snugug/blog/blob/e85221063403074088e6ddeb804d88648d88d29e/cms/package.json#L15)\n  - [`pre-commit` hook](https://github.com/Snugug/blog/blob/e85221063403074088e6ddeb804d88648d88d29e/cms/.husky/pre-commit)","src/content/posts/sanity-astro-and-github-oh-my.md","61321e355c2efa6b",{"html":1889,"metadata":1890},"\u003Cp>Following my realization that I no longer want to deal with \u003Ca href=\"/musings/return-of-the-cms/\">flat Markdown files\u003C/a>, I decided I wanted to rebuild my site. I had a few requirements for doing so: I needed the ability to manage fairly complex content models (my recipes are weirdly complicated to model), I needed migration to be quick because I didn’t want to spend a bunch of time on it, and I needed to be able to generate pages from API calls. This lead me on a journey to totally rebasing my site’s stack.\u003C/p>\n\u003Ch2 id=\"content-management\">Content management\u003C/h2>\n\u003Cp>I’ve got a long history with content management systems; I got my start, as a career, as a back-end developer, as a front-end developer, as a content strategist, as public speaker, and as a project leader in \u003Ca href=\"https://drupal.org/\">Drupal\u003C/a>. My first four jobs were all doing work in and around content management. When I left NBCUniversal for IBM, I did so in no small part to expand my knowledge outside of CMS-driven sites, only to work on building an early Node.js headless CMS we called \u003Ca href=\"https://github.com/punchcard-cms\">Punchcard\u003C/a>. By the time I left, I was once a again working on a Drupal powered website. Needless to say, I have a lot of \u003Cem>feelings\u003C/em> about content management systems.\u003C/p>\n\u003Cp>Like I mentioned in \u003Ca href=\"/musings/return-of-the-cms/\">Return of the CMS\u003C/a>, the current field of headless CMSes ticks a lot of CMS boxes for me. After looking at a bunch of them and talking with a few other people, I decided to try my hand at migrating my content to \u003Ca href=\"https://sanity.io/\">Sanity\u003C/a>. There’s a bunch I really like about Sanity: content modeling is super solid, including the ability to model complex, repeatable, and repeatable complex fields and it’s super customizable. It even has one of my “pet peev” features that I find missing from most content management systems: differentiating between fields that are required to publish and those required to save (in Sanity, fields marked “required” are required for publishing, but it’s data model makes none strictly required to save, which is good enough for my needs). So I went to work. I also really like the idea of \u003Ca href=\"https://github.com/portabletext/portabletext\">PortableText\u003C/a>, a JSON spec for defining structured block content that can be used for everything from WYSIWYG editors to HTML, Markdown, and more, although I confess I haven’t implemented it yet.\u003C/p>\n\u003Cp>I dove in to see what I could do. I made a few test posts using their blog template as a starting point. It worked well. I ran it locally and poked around with the API; by default it’s got its own query language called \u003Ca href=\"https://www.sanity.io/docs/how-queries-work\">GROQ\u003C/a> which works well enough; they also offer GraphQL but I never really loved that so I haven’t enabled that yet. After an initial proof of concept, I moved all my content types into it, and was happy.\u003C/p>\n\u003Cp>When I initially built out my instance, I had used v2. Sanity v3 is \u003Ca href=\"https://www.sanity.io/blog/sanity-studio-v3-developer-preview\">coming soon\u003C/a> and is currently in release candidate. Whereas v2 feels very much like a fully cusom tack, v3 has been totally rebuilt, runs \u003Ca href=\"https://vitejs.dev/\">Vite\u003C/a> (which I love) and now feels like a regular webapp. Some plugins (like the markdown editor I’m writing this in) are still a work-in-progress, but I like the codebase so much more I’m mostly OK with it. So, content codebse sorted, now my front-end.\u003C/p>\n\u003Ch2 id=\"site-codebase\">Site codebase\u003C/h2>\n\u003Cp>My previous site was built on \u003Ca href=\"https://11ty.dev/\">Eleventy\u003C/a> and I was mostly happy with that for a long time. But the more I used it, the more some rough edges started to annoy me. I don’t have much JavaScript on my site, but I’ve got some, and I’ve got a lot of CSS and even with my \u003Ca href=\"/musings/eleventy-plus-vite/\">solution for 11ty and Vite\u003C/a>, they still feel like two separate things trying to compete for ownership of my \u003Ccode>dev\u003C/code> script. I’ve also lost patience with the templating solutions provided; work on my \u003Ca href=\"/musings/a-beginners-guide-to-diabetes/#tracking-my-health\">health tracking app\u003C/a> with \u003Ca href=\"https://svelte.dev/\">Svelte\u003C/a> has made me realize just how much is missing from those systems. Then there’s page generation. I’ve done a lot of work figuring out how to scale this in 11ty and I don’t love the overriding of pagination to accomplish this. Finally, while I really love 11ty’s data cascade, once I remove my flat Markdown files, a lot of their utility goes away. So started exploring other options.\u003C/p>\n\u003Cp>I looked at a bunch of other static site generators (SSGs), with a focus on low to zero JS output and support for modern templating options. I eventually settled on \u003Ca href=\"https://astro.build/\">Astro\u003C/a>; like 11ty it’s aggressive about not outputting JavaScript, even for non-Astro components, and it deeply integrates with Vite, which I also really like (although I wish link and script tags would get compiled like they do for standard Vite builds). But it was my experience when I started integrating the content API that I really decided it was worth a full rebuild.\u003C/p>\n\u003Cp>Unlike 11ty, page generation in Astro is done based on folder structure, but file names can have params in them, which feels much more like building routes in a dynamic server. This, to me, feels really natural when coupled with an API. A lot of the struggle I had with managing layouts and cascading data and generating pages disappears with this paradigm. Adding in modern component frameworks for handling reusable UI (instead of Nunjucks macros or shortcodes) also made me more productive, to the point where I was able not only to rebuild my site in a weekend, but do a top-to-bottom refresh of it while adding new features (hello RSS feed and sitemap) to boot!\u003C/p>\n\u003Cp>With Sanity and Astro, I think I’ve finally found a winning combo for me blogging more and doing a better job at maintaining my website. The only thing I needed to figure out was continuous deployment now that my content and my site are disconnected.\u003C/p>\n\u003Ch2 id=\"continuous-deployment\">Continuous deployment\u003C/h2>\n\u003Cp>I’ve loved \u003Ca href=\"https://github.com/features/actions\">GitHub Actions\u003C/a> for a long time, but their documentation is a little obtuse and testing is hard and mostly done live, so it took me a while to figure out how to combine all of the above into a nice package.\u003C/p>\n\u003Cp>The first, and most important bit, was finding the \u003Ca href=\"https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#repository_dispatch\">\u003Ccode>repository_dispatch\u003C/code>\u003C/a> workflow trigger that lets GitHub Actions run off of a webhook call! Perfect, I thought, as Sanity can be configured to send webhooks when content deploys! Except, and rightfully so, the webhook that GitHub actions requires is pretty secured; it requires a a beta fine-grained GitHub access token with read and write code access and has a max 1-year lifespan, and the structure of the webhook needs to be very specific. Unfortunately, this means Sanity can’t just call the action directly, you need something in the middle. A serverless function would be great here, but I wound up going with \u003Ca href=\"https://pipedream.com/\">Pipedream\u003C/a>. Even now, I don’t know why specific dispatch names don’t work, but a generic one does, so that’s still a work-in-progress, but it works, so that’s what matters!\u003C/p>\n\u003Cp>The second thing I needed to do was figure out how to keep my CMS codebase and my site codebase together in the same repo, because I didn’t want to maintain them in different places. To do this, I leaned on the \u003Ca href=\"https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#onpushpull_requestpull_request_targetpathspaths-ignore\">\u003Ccode>paths\u003C/code>\u003C/a> workflow push filter, letting me run different GitHub Actions depending on whether code was pushed to my CMS or to my site. While experimenting with this, I also found that if you have multiple GitHub Actions with jobs with the same id (like \u003Ccode>test-build\u003C/code>) and make that required for a protected branch, it’ll work regardless of which Action runs! This means I can protect my main branch regardless of if I’m working on my CMS or my site!\u003C/p>\n\u003Cp>To keep everything secure, I use a combo of \u003Ccode>.env\u003C/code> files locally with my Sanity project and a Sanity API token for reading content for my site, and have GitHub Secrets to supply those during my GitHub Actions build. To deploy my Sanity studio, I do the same, but have a separate deploy token that gets injected during my Action run. The only thing that was a little annoying is the environment variables when working with Sanity is that the required names are specific, so you can’t choose the names you want and pass them in where you want. That’s easy to overcome, though.\u003C/p>\n\u003Chr>\n\u003Cp>I’m super excited about this new setup and workflow, and am making plans for how to expand on it to allow for previews using Astro’s server-side render (SSR) mode. I also have been playing with \u003Ca href=\"https://pnpm.io/\">pnpm\u003C/a> and migrated my codebase to that, too, with this, and I’m really loving that, too. The only gotcha here was getting \u003Ca href=\"https://typicode.github.io/husky/#/\">Husky\u003C/a> to work right, the \u003Ccode>prepare\u003C/code> script needs to run from the site root and the hooks need to \u003Ccode>cd\u003C/code> to the folder they’re in. If you want to see how the above shakes out, here’s some deep links to my \u003Ca href=\"https://github.com/Snugug/blog/tree/e85221063403074088e6ddeb804d88648d88d29e\">site source\u003C/a> as it looks at time of publishing:\u003C/p>\n\u003Cul>\n\u003Cli>GitHub Actions\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://github.com/Snugug/blog/blob/e85221063403074088e6ddeb804d88648d88d29e/.github/workflows/tbd-site.yml\">Site build/deploy\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://github.com/Snugug/blog/blob/e85221063403074088e6ddeb804d88648d88d29e/.github/workflows/tbd-cms.yml\">CMS build/deploy\u003C/a>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>Codebases\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://github.com/Snugug/blog/tree/e85221063403074088e6ddeb804d88648d88d29e/cms\">CMS\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://github.com/Snugug/blog/tree/e85221063403074088e6ddeb804d88648d88d29e/site\">Site\u003C/a>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>Husky\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://github.com/Snugug/blog/blob/e85221063403074088e6ddeb804d88648d88d29e/cms/package.json#L15\">Husky prepare for CMS\u003C/a>\u003C/li>\n\u003Cli>\u003Ca href=\"https://github.com/Snugug/blog/blob/e85221063403074088e6ddeb804d88648d88d29e/cms/.husky/pre-commit\">\u003Ccode>pre-commit\u003C/code> hook\u003C/a>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>",{"headings":1891,"localImagePaths":1901,"remoteImagePaths":1902,"frontmatter":1903,"imagePaths":1906},[1892,1895,1898],{"depth":80,"slug":1893,"text":1894},"content-management","Content management",{"depth":80,"slug":1896,"text":1897},"site-codebase","Site codebase",{"depth":80,"slug":1899,"text":1900},"continuous-deployment","Continuous deployment",[],[],{"title":1881,"published":1904,"summary":1883,"categories":1905},"2022-11-25",[55],[],"saying-goodbye-to-singularity",{"id":1907,"data":1909,"body":1913,"filePath":1914,"digest":1915,"rendered":1916},{"title":1910,"published":1911,"summary":1912},"Saying Goodbye to Singularity",["Date","2017-04-23T00:00:00.000Z"],"With a very heavy heart, today I am stopping further development on Singularity.","I'm currently sitting in Pune, India. It's my first day here. Yesterday ended about 35 hours of travel and layovers for me to get here. I should have been exhausted last night. Instead, I churned in my bed and was suddenly and unexpectedly wide awake at 2am with one thing on my mind: [Singularity](https://github.com/at-import/Singularity).\n\n[Scott Kellum](https://www.scottkellum.com/)'s [first commit](https://github.com/at-import/Singularity/commit/d13cd4b1907802708a1e40e61a531bca5d409405) to Singularity was March 7th, 2012. My first, [July 26, 2012](https://github.com/at-import/Singularity/commit/7636c89ca07627e03c9c2accd97b1e3fb48f43af). I didn't know Scott very well when I jumped in to help with Singularity, but that soon changed. That's to me one of the powers of Open Source; forging friendships from strangers over crazy ideas about code.\n\nSingularity has been a pretty constant in my career since then. My very first conference talk, [Responsive Web Design with Sass+Compass](http://snugug.github.io/RWD-with-Sass-Compass/#/), was all about the power of Breakpoint of media queries and Sunglarity for actually _designing responsively_. Singularity was also the driving factor to get accepted to my first conference talk outside of the Drupal world. All through this time, working on it, and really its sister [Breakpoint](https://github.com/at-import/breakpoint) as well, has been the single thing that has done more to shape how I understand modern web design and development.\n\nSingularity has been a home for me to experiment and grow; at 389 commits, 545,246 additions, and 538,031 deletions to the codebase, it wouldn't be unfair to say I almost learned to code with Singularity. It's where I cut my teeth on testing Sass, on making Sass available to PHP developers, to distributing Ruby gems, Bower package, and Eyeglass modules, all from one codebase. I played with architecture, module settings, dynamic APIs in Sass! Some of the things I wanted to do were _so crazy_ I'm honestly surprised it worked at all! Singularity's Responsive Grids by magic of Breakpoint? I'm looking at you. Those 1,083,277 lines changed in Singularity, more than just about anything else, are my growth as a developer.\n\nI wrote the blog post [introducing Singularity 1.0](https://snugug.com/musings/singularity-10/) 4 years and 20 days ago. A lot has changed since then. First came Flexbox, then [CSS Grid](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Grid_Layout). As Scott put it [in a Tweet to me this morning](https://twitter.com/ScottKellum/status/855943712748298240):\n\n> 💫 @Snugug and I worked on a crazy new idea back in the day. With CSS grid layout those crazy ideas are regular CSS\n\nLast night, sitting in my bed in Pune, after I had finished, it's that realization that swept over me. With it, a wave of grief. It took me another another hour to update the README, and then, choking back tears, I issues [Pull Request #238 - Feature/css grids](https://github.com/at-import/Singularity/pull/238). This morning, seeing Scott's tweet and comment on that PR, and no longer able to hold my tears back, I merged #238 and released [Singularity 1.8](https://github.com/at-import/Singularity/releases/tag/v1.8.0), thus ending further development on Singularity.\n\nThank you to everyone who has used Singularity. Thank you for your support. Thank you for joining us while we stumbled through these crazy ideas. It means the world to me.","src/content/posts/saying-goodbye-to-singularity.md","daf3fbeaedeea925",{"html":1917,"metadata":1918},"\u003Cp>I’m currently sitting in Pune, India. It’s my first day here. Yesterday ended about 35 hours of travel and layovers for me to get here. I should have been exhausted last night. Instead, I churned in my bed and was suddenly and unexpectedly wide awake at 2am with one thing on my mind: \u003Ca href=\"https://github.com/at-import/Singularity\">Singularity\u003C/a>.\u003C/p>\n\u003Cp>\u003Ca href=\"https://www.scottkellum.com/\">Scott Kellum\u003C/a>’s \u003Ca href=\"https://github.com/at-import/Singularity/commit/d13cd4b1907802708a1e40e61a531bca5d409405\">first commit\u003C/a> to Singularity was March 7th, 2012. My first, \u003Ca href=\"https://github.com/at-import/Singularity/commit/7636c89ca07627e03c9c2accd97b1e3fb48f43af\">July 26, 2012\u003C/a>. I didn’t know Scott very well when I jumped in to help with Singularity, but that soon changed. That’s to me one of the powers of Open Source; forging friendships from strangers over crazy ideas about code.\u003C/p>\n\u003Cp>Singularity has been a pretty constant in my career since then. My very first conference talk, \u003Ca href=\"http://snugug.github.io/RWD-with-Sass-Compass/#/\">Responsive Web Design with Sass+Compass\u003C/a>, was all about the power of Breakpoint of media queries and Sunglarity for actually \u003Cem>designing responsively\u003C/em>. Singularity was also the driving factor to get accepted to my first conference talk outside of the Drupal world. All through this time, working on it, and really its sister \u003Ca href=\"https://github.com/at-import/breakpoint\">Breakpoint\u003C/a> as well, has been the single thing that has done more to shape how I understand modern web design and development.\u003C/p>\n\u003Cp>Singularity has been a home for me to experiment and grow; at 389 commits, 545,246 additions, and 538,031 deletions to the codebase, it wouldn’t be unfair to say I almost learned to code with Singularity. It’s where I cut my teeth on testing Sass, on making Sass available to PHP developers, to distributing Ruby gems, Bower package, and Eyeglass modules, all from one codebase. I played with architecture, module settings, dynamic APIs in Sass! Some of the things I wanted to do were \u003Cem>so crazy\u003C/em> I’m honestly surprised it worked at all! Singularity’s Responsive Grids by magic of Breakpoint? I’m looking at you. Those 1,083,277 lines changed in Singularity, more than just about anything else, are my growth as a developer.\u003C/p>\n\u003Cp>I wrote the blog post \u003Ca href=\"https://snugug.com/musings/singularity-10/\">introducing Singularity 1.0\u003C/a> 4 years and 20 days ago. A lot has changed since then. First came Flexbox, then \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Grid_Layout\">CSS Grid\u003C/a>. As Scott put it \u003Ca href=\"https://twitter.com/ScottKellum/status/855943712748298240\">in a Tweet to me this morning\u003C/a>:\u003C/p>\n\u003Cblockquote>\n\u003Cp>💫 @Snugug and I worked on a crazy new idea back in the day. With CSS grid layout those crazy ideas are regular CSS\u003C/p>\n\u003C/blockquote>\n\u003Cp>Last night, sitting in my bed in Pune, after I had finished, it’s that realization that swept over me. With it, a wave of grief. It took me another another hour to update the README, and then, choking back tears, I issues \u003Ca href=\"https://github.com/at-import/Singularity/pull/238\">Pull Request #238 - Feature/css grids\u003C/a>. This morning, seeing Scott’s tweet and comment on that PR, and no longer able to hold my tears back, I merged #238 and released \u003Ca href=\"https://github.com/at-import/Singularity/releases/tag/v1.8.0\">Singularity 1.8\u003C/a>, thus ending further development on Singularity.\u003C/p>\n\u003Cp>Thank you to everyone who has used Singularity. Thank you for your support. Thank you for joining us while we stumbled through these crazy ideas. It means the world to me.\u003C/p>",{"headings":1919,"localImagePaths":1920,"remoteImagePaths":1921,"frontmatter":1922,"imagePaths":1924},[],[],[],{"title":1910,"published":1923,"summary":1912},"2017-04-23",[],"strategy-team-culture-and-organizational-change",{"id":1925,"data":1927,"body":1931,"filePath":1932,"digest":1933,"rendered":1934},{"title":1928,"published":1929,"summary":1930},"Strategy, Team Culture, and Organizational Change",["Date","2023-11-17T00:00:00.000Z"],"How strategy, culture, and organizational change influence each other based on a number of influential books I've read and my lived experience working through, teaching, and helping lead change initiatives.","Throughout my career, at just about every place I've worked, I've been in the thick of some kind of change. At the New York State Senate, it was the modernization of IT infrastructure. At NBCUniversal, it was the introduction of Responsive Web Design, Content Strategy, and Agile. At IBM, it was [design and dev collaboration](/musings/it-all-started-our-motion-designer/). And the [adoption of Slack](https://medium.com/design-ibm/listen-to-the-wild-ducks-how-ibm-adopted-slack-2bcfd3732680) and GitHub. And [building front-end development community](https://github.com/Snugug/building-fed/blob/master/notes.md) and teaching modern development through Hackademy. All within a larger culture shift focusing on design. At Google, it's been the transition from ChromeOS Apps to Progressive Web Apps and Fugu APIs, and the introduction of [ChromeOS.dev](https://chromeos.dev/en) as a space for ChromeOS to come together to share our technical and partner work. While I may not have seen it at the time, they all have the same things in common: even if they were small or fairly self-contained, they all required a strategy to keep them focused and needed a cultural and organizational shift to actually pull off.\n\nAs I've grown in my understanding of these topics and related topics, connections have emerged. How strategy underpins how you should approach organizational change, and how organizational change is inherently cultural change. Who to target when in the process, and how to understand if it's likely to resonate, then stick, with the target audience. This isn't a definitive guide, there are plenty referenced, but this should help you get started in your journey (and get this out of my head into a place others can benefit from it).\n\n## Readings\n\nI often joke that [I only read while on vacation](/musings/book-recommendations/), and then, only really business books; I'm slowly building my own MBA while on the beaches of Jamaica. From my years of doing this, I've picked out a few key readings that have shaped how I think about strategy, culture, and organizational change (SCOC) and divided them into two groups: core readings and supplemental readings. The core readings are the primary building blocks of knowledge, whereas the supplemental readings add additional insights that can strengthen how you think about the core readings and approach work in general.\n\n### Core readings\n\n- [Leading Change](https://www.kotterinc.com/bookshelf/leading-change/) - John Kotter. Describes the 8-step process that's needed for change to start and stick inside organizations.\n- [Good Strategy / Bad Strategy: The Difference and Why It Matters](https://www.goodreads.com/en/book/show/11721966) - Richard Rumelt. Lays out a foundation for all strategies called the “Strategic Kernel”, describes the difference between good strategy and bad strategy, and how strategy relates to vision and mission.\n- [Organizational Culture and Leadership](https://www.wiley.com/en-us/Organizational+Culture+and+Leadership%2C+5th+Edition-p-9781119212041) - Edgar Schein, Peter Schein. Defines what culture is, how it arises, its parts (both visible and invisible), different concepts that come up when examining cultures, and how micro and macro cultures interact with each other.\n- [Dynamics of Effective Teams](https://rework.withgoogle.com/guides/understanding-team-effectiveness/steps/identify-dynamics-of-effective-teams/) - Google re:Work. Google research on effective teams, specifically focusing on the five pillars that they identified as the most important indicators of success.\n\n### Supplemental readings\n\n- [The Field Guide to Understanding Human Error](https://www.routledge.com/The-Field-Guide-to-Understanding-Human-Error/Dekker/p/book/9781472439055) - Sidney Dekker. Proposes that there's an old way to think about errors focused on individual blame, a new blameless way to think about them, and why the new way is better for understanding systems, actions, and working to fix problems. This new way is foundational to Resilience Engineering, blameless retrospectives, and even identifying problems that may form part of a strategic kernel\n- [The Structure of Scientific Revolutions](https://www.goodreads.com/book/show/61539.The_Structure_of_Scientific_Revolutions) - Thomas Kuhn. A scientist's approach to the history of science, challenging the long-held belief that scientific progress happened linearly. Most importantly, it introduces the concept of “paradigm shift” as we know it today, which provides important insight into the first step of _Leading Change_: having a sense of urgency.\n- [Diffusion of Innovations](https://www.simonandschuster.com/books/Diffusion-of-Innovations-5th-Edition/Everett-M-Rogers/9780743258234) - Everett Rogers. A set of research, followed by analysis, describing how new ideas, especially new technology, takes root. The concepts presented can be used to understand who to target and when during organizational change.\n- Design Thinking ([Ideo](https://designthinking.ideo.com/), [IBM](https://www.ibm.com/design/thinking/page/toolkit)). A human-centered approach to problem solving and innovation approachable by everyone, not just “designers”. Helpful for ideating on problems and potential solutions, especially useful when creating coherent actions in a strategic kernel, identifying patterns in cultures, and prioritizing work.\n\n## Important terms and concepts\n\nWhile both the core and supplemental readings, and the related works mentioned in them, are really worth reading, there's a lot going on in them (I've got nearly 40 pages of personal notes between Good Strategy / Bad Strategy and Organizational Culture and Leadership alone). There are some terms and concepts, though, that really stick out for me, and form the basis of how I think and talk about SCOC. While many of the definitions are taken directly from their source, some are instead amalgamations from different sources based on my understanding of how things work together or how I've come to teach the concepts over time. While it may seem counter-intuitive, I generally start with the core concepts from the supplemental readings, as I feel they form a a set of building blocks to better understand the core readings.\n\nBlameless errors\n: From _The Field Guide to Understanding Human Error_. The “old” way of thinking about error is, roughly, that someone did something wrong; they didn't follow the rules or they intentionally or unintentionally missed something or skipped a step. It's therefore their fault that something went wrong and they're to blame. The “new” way to think about error is through context. Assume the actor is trying to do their best, and if they didn't follow the rules or missed or skipped something, it's because they were trying to route around problems that would have prevented them from completing their task in good faith (for instance, lots of false positives in tests could condition them to skip testing, which may let a bug through). Examine when things go wrong through the eyes of the actor, the context they're in, and the context they had at the time, not from an omnipotent point of view after. Work should then be done to reduce problems in the systems and contexts in which those decisions were made, instead of, for instance, blaming the actor for not following procedure correctly. In software engineering, this is the core concept for “blameless retrospectives”.\n\nParadigm shift\n: From _The Structure of Scientific Revolutions_. A paradigm is the current way something exists. In the book, it's the set of scientific principles currently considered mainstream, but it could be the current team culture, current software engineering practices, current organizational structure, etc…. A paradigm shift happens when a new paradigm arises and wins enough followers over to break from the previous paradigm, leaving it behind. New paradigms arise when practitioners (often those new to the paradigm, like young scientists entering the field) feel that the current paradigm no longer meets their needs (for instance, doesn't fully explain the results of their experiments) and seek out a new way of understanding their work to resolve those issues. In _Leading Change_, this would be described as a “sense of urgency” (defined below). An old paradigm shifts to a new paradigm when enough members of the old paradigm agree that the problems the new paradigm aims to solve are worth solving and that the new paradigm also solves their problems, too. New paradigms will not take hold if they aren't able to satisfy the needs of the majority of the practitioners from the previous paradigm.\n\nDiffusion curve\n: From _Diffusion of Innovations_. While there are a number of different rearticulations of this theory, I use the terms from the original book. The theory discusses how new ideas (innovations) spread. The [Wikipedia article](https://en.wikipedia.org/wiki/Diffusion_of_innovations) is an excellent summary of the theory, but the key items I take with me when thinking about how to apply this to SCOC are the elements that go into the diffusion of an innovation, and the adoption curve.\n\nThe key elements of diffusion are:\n\n- **Innovation** - The actual idea, practice, or object that is perceived as new and someone would like others to adopt. Can, for instance, be a new paradigm, a new piece of technology, or a new organization structure.\n- **Adopters** - The people (individuals or groups) that the innovation is meant for\n- **Communication channels** - How information is transferred between adopters and innovators.\n- **Time** - Adoption almost never happens instantaneously.\n- **Social systems** - Micro and macro cultural influences on adopters.\n\nBecause of the social systems adopters find themselves in and the communication channels they have (especially with how “close” to the progenitor of an innovation), adoption can be broken down into 5 cohorts: innovators, early adopters, early majority, late majority, and laggards\n\n#[Diffusion of Innovations adoption curve, showing the breakdown of each adoption cohort. Image from Wikipedia.](https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Diffusion_of_ideas.svg/1920px-Diffusion_of_ideas.svg.png)\n\n- **Innovators** - Individuals who are willing and able to take risks on adopting a new innovation, usually thanks to high social status, financial stability, and/or close contact with the source of an innovation and other innovators. They have a high tolerance for failure and can absorb the cost of failure with their existing resources. They usually make up the first roughly 2.5% of adopters. When looking to apply this to SCOC work, these are the individuals or groups who are eager to try something new, knowing that their work isn't likely to be negatively affected if the change doesn't succeed, are willing to work through learning pains, are happy to help shape the direction of the work, and can see a large positive future if it works out.\n- **Early adopters** - Looked to as thought leaders within all adopter categories. They have similar resources to innovators, but are more picky in what they choose to adopt, less willing to take risks if something ultimately fails. Because of this, they hold a key communication position across the adopter board. They usually make up the next roughly 13.5% of adopters. In SCOC work, find the individuals or groups that others look to for guidance, are far enough from the innovation progenitor that their opinions are viewed as genuine endorsements, and are willing to put in work to help spread the innovation.\n- **Early majority** - Usually individuals or groups with average resources who aren't considered thought leaders. They're one of the largest cohorts, at roughly 34% of all adopters, and usually only start adopting after some time has passed. The point at which the early majority starts adopting an innovation is the tipping point where an innovation moves from niche appeal to mass and self-sustaining adoption. This is sometimes called “the marketing chasm” or when an innovation reaches “critical mass”. In SCOC work, look for individuals or groups who are willing to adopt after having been convinced by innovators and early adopters that the innovation will be a net positive for them.\n- **Late majority** - The late majority starts after around 50% of an innovation's potential audience has adopted. They approach innovation with a high degree of skepticism and will only adopt after they've seen it be successfully adopted elsewhere. They tend to have a smaller amount of resources than average and make up the next roughly 34% of adoption. In SCOC work, this is a group that'll need to be convinced that the innovation won't have a negative impact on them, as opposed to a net positive effect.\n- **Laggards** - The final group, making up the last roughly 16% of adoption, laggards typically will only adopt a new innovation when they have no other choice but to do so. They're typically highly skeptical of change and have the lowest amount of resources to expend on change. In SCOC work, this cohort will only likely change at the end of a transition period and after new norms have been rooted in the culture or organization. Members of this cohort are also most likely to be _detractors_ in a change process (negative change agents). While these individuals are typically characterized as having a low amount of resources to expend, don't confuse this for not having high status in a culture or organization; laggards can be executives that are opposed to change and, while they may have lots of resources, have little to none to spend on change because of their opposition.\n\nStrategy\n: From _Good Strategy/Bad Strategy_. Strategy is the alignment of goals (overall values and desires) into actions and objectives (specific operational targets). A good strategy has one, or only a few, key objectives that will lead to favorable outcomes and create cascading benefits. It defines critical challenges and tie those challenges to actions. It is constrained and has a good chance of success. Bad strategy is a list of things to do, or a restatement of the desired state of affairs or the challenge ahead. It contains fluff, doesn't face the challenge head-on, is a statement of desire rather than plans for overcoming obstacles, and either fails to address critical issues or is impractical. Ultimately, a good strategy is a coherent set of actions backed by an argument (the Strategic Kernel). Strategy is also distinct from vision, mission, or values statements:\n\n- **Vision statement** - An aspirational view of the future \\\n  _Provide access to the world's information in one click_\n- **Mission statement** - The purpose of your work \\\n  _Organize the world's information and make it universally accessible and useful._\n- **Values statement** - Core cultural beliefs \\\n  _Don't be evil_\n\nStrategy is often formed within the bounds of these goals, but strategy's purpose is overcoming a challenge; these items may set what challenges are to be faced and how you may prefer to think about them, but they themselves won't help you solve problems. Strategy does.\n\nStrategic Kernel\n: From _Good Strategy/Bad Strategy_. While there are many things that may make up a strategy, all strategy shares at least three things in common: a diagnosis, a guiding policy, and coherent actions.\n\n- **Diagnosis** - Explains the challenge, simplifying and identifying critical things the strategy is meant to overcome. A diagnosis should define a domain of action and should favor leverage over outcomes (problems, not solutions). It doesn't need to explain everything, but the problems being tackled need to be addressable and they need to be addressable in a given timespan.\n- **Guiding policy** - The overall approach chosen to overcome the problems identified in the diagnosis. I often refer to these as the strategy's “guard rails” as they're meant to channel actions in a certain direction without defining what should be done. Guiding policies should _not_ be goals or visions of end states. Great guiding policies should draw upon sources of advantage, or create advantage by anticipating the actions and reactions of others.\n- **Coherent actions** - The coordinated steps designed to carry out the guiding policy. It doesn't need to include all actions, but needs to include enough to bring high-level concepts down to earth. The actions should coordinate and build upon each other. They're made coherent by being consistent, with coordinated deployment of resources, imposed by policy and design. Incoherent actions are in conflict with the guiding policy or in pursuit of unrelated challenges. Agile Epics, or IBM Design Thinking Hills, are good first sets of actions to be drawn up here.\n\nCulture\n: From _Organizational Culture and Leadership_. Culture is:\n\n> The accumulated shared learning of a group as it solves its problems of external adaptation [(the environment they exist in)] and internal integration [(the human problems that arise in collective life)]\n\nMore succinctly, culture is how groups have learned to solve problems and organize in response to internal and external pressures; it is a learned phenomenon. Culture is pervasive, dealing with all aspects of how a group functions and how it is taught to new members. For a group to have a culture, it needs a level of stability. As such, not all groups have cultures, only ones that need to learn to do things together and have more or less constant membership will. Culture is made up of three items: artifacts, espoused beliefs and values, and basic underlying assumptions.\n\n- **Artifacts** - Physical manifestations of culture (language, processes, etc…). You cannot understand a culture by its artifacts alone, you need to talk to an individual to understand the importance of them (for instance, pyramids as temples versus graves).\n- **Espoused beliefs and values** - What the culture says is important to it. An individual's beliefs become group values only after they've been tested and and have been proven to be able to consistently solve a problem. Some beliefs cannot be effectively tested so are socially validated instead; because of this, it's harder to see the direct connection to the group's success. For these, how comfortable and anxiety-free members are when they abide by those beliefs is the only measure of success (religion, for instance). It's important to distinguish between the those beliefs that are aspirational versus actually being practiced (an organization may strive for teamwork but reward based on individual success, for instance)\n- **Basic underlying assumptions** - When a solution to a problem repeatedly works, a group gradually comes to believe that's how nature works. That belief is an underlying assumption. These are the implicit assumptions that actually guide behavior and tell members how to perceive, think about, and feel about things. Underlying assumptions are very difficult to change, as change to them temporarily destabilizes how members of the culture think about the world, leading to anxiety and members trying to rationalize away the change instead of embracing it.\n\nCultures aren't islands; they nest. **Macro cultures** are very stable top-level cultures; they've been around a long time and are the cultures in which other cultures live. For instance, the US has a culture, in that the California tech sector has a culture, in that, there's Google's culture, and in that, ChromeOS's culture. **Subcultures** are a sub-division of a macro culture, so a team on ChromeOS may have its own subculture, much like ChromeOS is a subculture of Google. Generally speaking, subcultures inherit the macro culture they reside in, tweaking as needed for the problems they wind up solving.\n\nIn organizations, subcultures tend to form when a subunit's needs necessitate it having its own leader. There are five main subunit structures that typically create their own subcultures: occupational units (engineering, finance, PM), geographic units, product/market/technology units, and operating divisions. Organizational hierarchies also wind up having their own subcultures, which can generally be broken down into operators, engineering and design, and executives:\n\n- **Operators** - The individuals who produce or sell the org's products. They view themselves as the ones who “run the place”. Operators evolve organically per organization, and therefore are highly sensitive to the degree to which all functions are independent. They often route around rules and hierarchy that “get in the way” in unpredictable conditions, and will often teach new operators the “on-the-ground reality” to get a job done (see: _blameless errors_).\n- **Engineering and Design** - The individuals who design new products, structures, and processes to make the organizations more effective. They bring with them their occupational subculture, with engineers especially looking to remove as much possibility of human error as possible in the systems they design. A software engineer may be both part of this group and the operators group at the same time.\n- **Executives** - Primarily the CEO and their executive team, but extends to middle management as well. Mainly concerned with the survival and financial health of the organization. Generally need to manage at a distance so think in terms of control systems and routines and become increasingly impersonal. Middle management tend to have similar needs, but without the power or autonomy to make sweeping change unilaterally, so live in an ambiguous authority environment.\n\nMany problems attributed to bureaucracy, environment factors, or personality conflicts among managers are actually lack of alignment between these subcultures as the individuals of these subcultures often wind up working across purposes with each other.\n\nExternal adaptation and internal integration\n: External adaptation and internal integration are the cornerstones of how culture is formed. They are the problems that groups find solutions to that become the underlying assumptions of a culture, which beliefs and values and, eventually, artifacts come from.\n\n**External adaptation** stems from a group's _mission_. It's their shared understanding of their primary tasks and manifest (consequences that people see, observe, or expect and is explicitly stated and understood) and latent (consequences neither recognized or intended; identified by observers because they don't expect those tasks to be performed) functions. Groups develop _goals_ derived from this mission, build a _consensus_ on how to obtain those goals (things like rewards structure and authority systems), how to _measure_ how well the group is fulfilling those goals, and how to _correct_ if goals are not being met. Being aligned on core mission and identity isn't enough to ensure success or common goals, though; **strategy** is a key part of external adaptation, and is needed to ensure subcultures are aligned to fulfill the mission.\n\n**Internal integration** stems from a group's need to comfortably work together. It encompasses _language_ and related conceptual categories, _identity and boundary_ criteria for how lateral (one task to another), vertical (one rank to another), and inclusion (outsider to insider) work is defined, _authority_ as distribution of power and status and how manage face (self-image of who we are and our self-esteem), _trust and openness_ of relationships, and especially the building and maintenance of psychological safety, _rewards and punishments_ for when expectations are or are not met, and how to explain the _unexplainable_, given that culture is based on decisions of the past and therefore can't account for everything coming.\n\n> Culture is multifaceted, fulfilling the function of providing stability, meaning, and predictability in the present, but is the result of functionally effective decisions in the group's past\n\nEmbedding and transmitting culture\n: Because every culture is nested in another culture, leaders need to consider how new beliefs and values will fit into the larger culture they sit in, or they won't be adopted. There are _primary_ ways that culture can be embedded and transmitted to new members, and _secondary_ ways, which can be used to reinforce the primary means.\n\nCulture is **primarily transmitted** by what leaders pay attention to, measure, and control regularly. It's how they react to critical incidents and crises, allocate resources, rewards, and status, and how they recruit, select, promote, and excommunicate members. It's also done through deliberate role modeling and coaching.\n\nThose methods can be supported by **secondary embedding mechanisms**, like organizational design, structure, systems, procedures, rites, and rituals, along with formal statements of an organization's philosophy, creeds, or even by creating charters. They can also take on less direct means, like the design of physical and digital spaces and by the stories that are told about important events or people. These mechanisms only work if they are consistent with the primary mechanisms, otherwise they'll be ignored or create an internal source of conflict.\n\nRelationship levels\n: From _Organizational and Cultural Leadership_. A group's relationship levels, or power distance, represent the psychological distance between members; it's how they to relate to each other to make the group feel safe, comfortable, and productive, and is a key aspect of face. While the specific rules for a given culture change to reflect its current state, there are four levels that a relationship can fall into:\n\n- **-1, Exploitation** - Usually only experienced by prisoners, POWs, slaves, or occasionally members of a different culture who are considered underdeveloped. This level is defined by a lack of trust and openness, and while one can choose to build relationships with members of this group, there is no expectation that anyone is owed anything.\n- **1, Acknowledgement and civility** - These relationships are transactional; people on the street, service members, professional helpers, etc…. Interactions are governed by defined roles and are usually task-based. The parties may not know each other personally, but they treat each other respectfully. There's trust to a certain degree to not harm each other, and there are polite levels of openness and conversation. In corporate settings, think of cross-functional team members who you ask for help on a task but do not work closely with. These are professional, formal transactions.\n- **2, Recognition as a unique person** - These are casual friends, members of working teams, clients and subordinates who have personal, but not intimate, relationships. These relations have a deeper level of trust; they make and honor commitments and promises to each other, agree not to harm or undermine each other, and agree not to lie or withhold information to each other relevant to their tasks. In corporate settings, think of “work friends”. These are friendly, personable transactions.\n- **3, Strong emotions** - These are close friends, loved ones, and those you're intimate with. You're generally more open with these individuals, and it's assumed that you'll actively support one another when possible or needed, going beyond level 2 relationships. In corporate settings, think of “real” friends, partners, or spouses. These are intimate relationships\n\nTuckman's Stages of Group Development\n: Referenced from _Organizational and Cultural Leadership_ ([Wiki](https://en.wikipedia.org/wiki/Tuckman%27s_stages_of_group_development)). Tuckman proposes that there are four stages all groups go through as they mature: forming, storming, norming, and performing. The stages describe how team members interact with each other, and are a reflection of the culture and leadership of the team.\n\n- **Forming** - Finding one's identity and role. Here, the team agrees on goals and begins to tackle tasks. Team members tend to behave quite independently here, and team members are usually on their best behavior. Discussions center on defining the scope of tasks, how to approach tasks, and the like.\n- **Storming** - Resolving who has authority and influence. At the start of this stage, there is usually a positive and polite atmosphere. Time and competition pressures will reveal some members become more active and others shut down, revealing a status system where some are seen as contributing more than others. Disagreements and personality clashes may be aired, but must be resolved before a team can move out of this stage, so some teams never leave, or some may re-enter when new challenges arise. This is the stage where psychological safety, dependability, and structure and clarity (see _Google re:Work_) are cemented.\n- **Norming** - Team resolves at what relationship level they want to operate at by making explicit that which was implicit. They may choose to stay task-focused (level 1) or get to know each other and become friendly (level 2). People least conflicted about the issue of closeness will see or name issues as they happen. The leader must point out that everyone is different with different needs, and the strength of the group is in its variety instead of its homogeneousness. The illusion of “we all like each other” is replaced with “we can all understand, accept, and appreciate each other”. There is a danger here that members become so focused on keeping the peace that they become reluctant to share controversial ideas.\n- **Performing** - Team can focus on task accomplishment and use its resources to work effectively. They are motivated and knowledgeable, with autonomous decision making and acceptance of dissent, as long as it is channeled through means acceptable to the team.\n\nMany teams get stuck in _forming_ as members try to vie for influence and power, or in _storming_ believing they're all great and they like each other. In both cases, members are thinking primarily about themselves and their role in the group and therefore aren't able to give full attention to the group's tasks. Teams may also revert to previous stages under changing circumstances; for instance, a change in leadership may cause a team to revert to _storming._\n\n## Organizational Change\n\nOk, now for my super theory of super everything. With those terms in your head and (maybe) the readings complete, let's bring in the [8 steps for leading change](https://www.kotterinc.com/methodology/8-steps/) from _Leading Change_. In my personal journey here, from all the readings I mentioned above, I read _The Field Guide to Understanding Human Error_ first, then _Leading Change_, so this framework for understanding how change happens has been in the back of my mind since the beginning. But, it wasn't until I read the other books did the pieces really start to make sense, kind of like Neo finally seeing the world as code at the end of The Matrix. Here, interspersed with Kotter's 8 steps is how I see how all the pieces fit together.\n\n### 1. Create a sense of urgency\n\nAt its core, the 8 steps of organizational change are about how to introduce a _paradigm shift_ in an organization. A paradigm shift will only work if there's a problem with the current paradigm, and you can convince others that it's a problem, too (next section). Change not deeply rooted in a real, tangible problem, is at best going to be superficial, at worst is going to create new problems without solving any.\n\nAt this stage you're starting to identify a _diagnosis_; a core problem that the change initiative will be designed to overcome. It is usually driven by either a culture issue (the current way of working isn't working for today's problems) or a crisis (declining sales, layoffs, etc…). Be wary of organizational change for the sake of change or vanity; this is likely going to cause anxiety and create culture issues that will linger.\n\nWhen you create a sense of urgency, you're naming the problem that your change initiative is going to solve, and declaring yourself responsible for inspiring others to change.\n\n### 2. Build a guiding coalition\n\nOnce you've identified your core problem, you need to bring in others to help steer the change process. The guiding coalition should be made up of members from all three levels of the organizational hierarchy: operators, engineers and designers, and executives. This will ensure that there's across the board representation for how the organization currently operates, including the on-the-ground deviations, and will ensure decisions aren't being made just for the benefit of one of the levels. It's important that, amongst the executive representatives, there's at least one leader who is bought-in that can have direct top-down control of the change initiative, if need be. It's much harder to get change to stick without some form of leadership approval initially.\n\nThe guiding coalition should not be too large; this is a group that needs to be able to reach consensus and act around, assess success of, and sell the change initiative. This group is likely to need Level 2 relationships to be successful.\n\n### 3. Form a strategic vision\n\nIt's now the guiding coalition's job to build a strategy for how to accomplish the change initiative. The _diagnosis_ should be settled by this point, it's now about determining the _guiding principles_ and _coherent actions_ to take. For larger change initiatives, you'll likely need a multi-staged strategy covering different timespans.\n\nTo build this out, _as-is scenarios_ and _empathy maps_ (_Design Thinking_) are good tools to get a deeper understanding of how the problem affects different people in the organization. _Ideation_, _prioritization grids_, and _to-be_ _scenarios_ can then be used to help come to a consensus on what the best goal end-state is and what actions need to be taken to get there.\n\nKeep in mind the rest of steps when building a strategy; you're going to need to get _innovators_ and _early adopters_ on board to get the change initiative to feel sticky across the organization, you're going to need to see success within a relatively short period of time, show that that success can be sustained, and figure out how to change aspects of the organization's culture to accommodate the new way of working.\n\n**You'll also need to seriously examine the existing culture.** When forming a strategic vision for a new future, you must examine how it's going to change the current culture, and therefore identity, of the organization. Because culture is an interconnected set of assumptions, not isolated elements of how groups work, your change initiative _will be changing the group's culture_ even if that's not your primary intention.\n\n### 4. Enlist a volunteer army\n\n_While Kotter has steps 4, 5, and 6 as separate items, I consider them the three steps of kickstarting your change initiative. Instead of being separate steps_ per se _, steps 4 and 5 are how to enable 6, with you going back to them as you generate wins and sustain acceleration (step 7) as you build towards self-sustaining adoption_.\n\nThis is the start of the _diffusion of innovations_ curve. Identify _innovator_ and _early adopter_ individuals or teams and work closely with them to get them to adopt the new way of working. You will not win everyone over to start with, so you should focus your efforts on those who are highly motivated to see the change actually stick. For change to be successful, these groups need to become evangelists for the rest of the organization, letting your message scale. They're also invaluable for the guiding coalition to gather feedback from to help shape the change initiative over time.\n\n### 5. Enable action by removing barriers\n\nThere are two main areas where barriers are likely to crop up: resource constraints and culture clashes.\n\nResource constraints are likely the most straightforward to deal with; it's the project management iron triangle of scope, budget, and time. If you want to get more done with fewer people, you need more time. Short time and fixed scope? Enlarge the budget. Fixed budget and fixed time? Reduce the scope. These are the forces at play to ensure a project remains successful. At this stage you're preparing to show some wins in your change initiative, so you want to do whatever you can to have an impact quickly.\n\nThe second, much harder area, is culture clashes. These usually fall into one of two categories: clashes with the _macro culture_, and _negative change agents_.\n\nClashes with the _macro culture_ are difficult to route around; a change initiative is ultimately a shift in culture. Because all cultures live within a _macro culture_ and need to adopt that culture's norms, shifting too radically away from it may make it hard or impossible to work. If you can't find creative ways of bridging the gap between the two cultures, you'll likely need to add something to your strategy's _guiding principles_ to prevent straying too far, and rethink your _coherent actions_ to reflect that change. This may also mean starting over.\n\nOn the other hand, what you could be running into is the friction being generated as the new culture and old culture clash, creating anxiety and causing your organization's current culture to fight back. That fighting back usually manifests itself in the form of “negative change agents”. It may be subtle, like a leader verbally agreeing to work one way and continuing to work another, or it may be obvious, like someone loudly pushing back against a new tool. Don't discount all negative change agents, there's a reason they don't come along. Think of it through _blameless_ eyes and try and see if you can tweak your strategy to cover their issues. They may also be a _laggard_; don't try and win them over to start with, bring them along as the process draws to a close.\n\n### 6. Generate short-term wins\n\nThe goal of focusing on _innovators_ and _early adopters_ and removing their barriers to adoption is to show that the new way of working can work, and can work quickly. You're goal should be to show that the new way of working works within the first 3-6 months of the start of a change initiative. These can can be small wins, but they're needed to build momentum and bring the next stage of adoption on. Share the success and learnings that you've had along the way widely. Hold _blameless retrospectives_, solicit feedback, and show how that feedback has led to improvements in the plan. Make the wins not just your coalition's wins, but the wins of everyone who's adopted the change initiative.\n\nThis is a good point to start to introduce new _primary and secondary culture embedding mechanisms_. Reward teams who adopt the new way of working with something small but meaningful; give them time during current rites and rituals to share their success, invite them to share feedback directly with the guiding coalition or leadership, provide them with a unique project codename and ensure it gets used when talking about it. The goal here is to provide incentives in the current cultural zeitgeist that bridges the gap to the new one you want to create.\n\n### 7. Sustain acceleration\n\nYou sustain acceleration by showing that the short-term wins weren't flukes; the new way of working consistently solves the _diagnosis_ and can do so for a variety of adopters. This builds a reputation that the _external adaptation_ or _internal integration_ problems the change initiative is meant to address are working, and that the culture's _basic underlying assumptions_ can evolve while still retaining a sense of safety for the group. At this stage, you should start to see some members having fully embraced the new way of working and are adopting the new assumptions outright, turning them into _espoused beliefs and values_. Keep the wins coming, keep the feedback loop coming, and keep sharing the success.\n\nThis step is a long one; it begins at the point where you're onboarding the _early majority_ and you're starting to see self-sustaining adoption, and will probably peak around the start of _late majority_ adoption.\n\n### 8. Institute change\n\nFinally, you need to solidify the change in the organization's culture. _Laggards_ aren't going to adopt the new way of working until it's embedded in the culture. If enough negative change agents still exist at this point, and they're visible enough to cause others to doubt their commitment to the new process, the initiative may wind up failing. Yes, even at this stage, a change initiative can fail.\n\nTo embed the change in the culture, you'll need to rely on _primary cultural embedding mechanisms_. Coach and mentor organization members on the new way of working, allocate (or take away) rewards (compensation, perks, etc…), status, and resources based on adherence to the new ways of working. Ensure leaders are cognizant in how they pay attention to the new way of working versus the old way of working. Recruit new leaders for adherence to the new way of working, and excommunicate those who refuse to change. _Secondary cultural embedding mechanisms_ may need changing too, like systems, procedures, or tools, common activities like recurring meetings or events, changing formal statements like vision statements and charters, or even changing the physical spaces people work in.\n\nIn the first few years of a change initiative, it's especially important that leaders are extra vigilant about ensuring _primary embedding mechanisms_ stick; cultures are inherently biased towards past success and can fall back at any time until the change is fully embedded and a new culture has taken root. That's not to say that everything needs to be kept still during this time, strategy can evolve within the bounds set by the initial direction, or you may find that the change uncovers deeper needs that then need to be addressed, and a larger change initiative is warranted. Culture and strategy are intertwined, living entities; make sure you continue nurturing both.\n\n---\n\nA huge thanks to everyone who's helped shape my thinking around this topic, but especially Bill Higgins for his friendship and mentorship, and Damon Deaner for taking a chance on the IBM front-end development community and me in particular with Hackademy, the first change initiative I had a heavy hand in running.","src/content/posts/strategy-team-culture-and-organizational-change.md","1467528666861619",{"html":1935,"metadata":1936},"\u003Cp>Throughout my career, at just about every place I’ve worked, I’ve been in the thick of some kind of change. At the New York State Senate, it was the modernization of IT infrastructure. At NBCUniversal, it was the introduction of Responsive Web Design, Content Strategy, and Agile. At IBM, it was \u003Ca href=\"/musings/it-all-started-our-motion-designer/\">design and dev collaboration\u003C/a>. And the \u003Ca href=\"https://medium.com/design-ibm/listen-to-the-wild-ducks-how-ibm-adopted-slack-2bcfd3732680\">adoption of Slack\u003C/a> and GitHub. And \u003Ca href=\"https://github.com/Snugug/building-fed/blob/master/notes.md\">building front-end development community\u003C/a> and teaching modern development through Hackademy. All within a larger culture shift focusing on design. At Google, it’s been the transition from ChromeOS Apps to Progressive Web Apps and Fugu APIs, and the introduction of \u003Ca href=\"https://chromeos.dev/en\">ChromeOS.dev\u003C/a> as a space for ChromeOS to come together to share our technical and partner work. While I may not have seen it at the time, they all have the same things in common: even if they were small or fairly self-contained, they all required a strategy to keep them focused and needed a cultural and organizational shift to actually pull off.\u003C/p>\n\u003Cp>As I’ve grown in my understanding of these topics and related topics, connections have emerged. How strategy underpins how you should approach organizational change, and how organizational change is inherently cultural change. Who to target when in the process, and how to understand if it’s likely to resonate, then stick, with the target audience. This isn’t a definitive guide, there are plenty referenced, but this should help you get started in your journey (and get this out of my head into a place others can benefit from it).\u003C/p>\n\u003Ch2 id=\"readings\">Readings\u003C/h2>\n\u003Cp>I often joke that \u003Ca href=\"/musings/book-recommendations/\">I only read while on vacation\u003C/a>, and then, only really business books; I’m slowly building my own MBA while on the beaches of Jamaica. From my years of doing this, I’ve picked out a few key readings that have shaped how I think about strategy, culture, and organizational change (SCOC) and divided them into two groups: core readings and supplemental readings. The core readings are the primary building blocks of knowledge, whereas the supplemental readings add additional insights that can strengthen how you think about the core readings and approach work in general.\u003C/p>\n\u003Ch3 id=\"core-readings\">Core readings\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.kotterinc.com/bookshelf/leading-change/\">Leading Change\u003C/a> - John Kotter. Describes the 8-step process that’s needed for change to start and stick inside organizations.\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.goodreads.com/en/book/show/11721966\">Good Strategy / Bad Strategy: The Difference and Why It Matters\u003C/a> - Richard Rumelt. Lays out a foundation for all strategies called the “Strategic Kernel”, describes the difference between good strategy and bad strategy, and how strategy relates to vision and mission.\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.wiley.com/en-us/Organizational+Culture+and+Leadership%2C+5th+Edition-p-9781119212041\">Organizational Culture and Leadership\u003C/a> - Edgar Schein, Peter Schein. Defines what culture is, how it arises, its parts (both visible and invisible), different concepts that come up when examining cultures, and how micro and macro cultures interact with each other.\u003C/li>\n\u003Cli>\u003Ca href=\"https://rework.withgoogle.com/guides/understanding-team-effectiveness/steps/identify-dynamics-of-effective-teams/\">Dynamics of Effective Teams\u003C/a> - Google re\u003Cdiv>\u003C/div>. Google research on effective teams, specifically focusing on the five pillars that they identified as the most important indicators of success.\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"supplemental-readings\">Supplemental readings\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Ca href=\"https://www.routledge.com/The-Field-Guide-to-Understanding-Human-Error/Dekker/p/book/9781472439055\">The Field Guide to Understanding Human Error\u003C/a> - Sidney Dekker. Proposes that there’s an old way to think about errors focused on individual blame, a new blameless way to think about them, and why the new way is better for understanding systems, actions, and working to fix problems. This new way is foundational to Resilience Engineering, blameless retrospectives, and even identifying problems that may form part of a strategic kernel\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.goodreads.com/book/show/61539.The_Structure_of_Scientific_Revolutions\">The Structure of Scientific Revolutions\u003C/a> - Thomas Kuhn. A scientist’s approach to the history of science, challenging the long-held belief that scientific progress happened linearly. Most importantly, it introduces the concept of “paradigm shift” as we know it today, which provides important insight into the first step of \u003Cem>Leading Change\u003C/em>: having a sense of urgency.\u003C/li>\n\u003Cli>\u003Ca href=\"https://www.simonandschuster.com/books/Diffusion-of-Innovations-5th-Edition/Everett-M-Rogers/9780743258234\">Diffusion of Innovations\u003C/a> - Everett Rogers. A set of research, followed by analysis, describing how new ideas, especially new technology, takes root. The concepts presented can be used to understand who to target and when during organizational change.\u003C/li>\n\u003Cli>Design Thinking (\u003Ca href=\"https://designthinking.ideo.com/\">Ideo\u003C/a>, \u003Ca href=\"https://www.ibm.com/design/thinking/page/toolkit\">IBM\u003C/a>). A human-centered approach to problem solving and innovation approachable by everyone, not just “designers”. Helpful for ideating on problems and potential solutions, especially useful when creating coherent actions in a strategic kernel, identifying patterns in cultures, and prioritizing work.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"important-terms-and-concepts\">Important terms and concepts\u003C/h2>\n\u003Cp>While both the core and supplemental readings, and the related works mentioned in them, are really worth reading, there’s a lot going on in them (I’ve got nearly 40 pages of personal notes between Good Strategy / Bad Strategy and Organizational Culture and Leadership alone). There are some terms and concepts, though, that really stick out for me, and form the basis of how I think and talk about SCOC. While many of the definitions are taken directly from their source, some are instead amalgamations from different sources based on my understanding of how things work together or how I’ve come to teach the concepts over time. While it may seem counter-intuitive, I generally start with the core concepts from the supplemental readings, as I feel they form a a set of building blocks to better understand the core readings.\u003C/p>\n\u003Cdl>\n\u003Cdt>Blameless errors\u003C/dt>\n\u003Cdd>From \u003Cem>The Field Guide to Understanding Human Error\u003C/em>. The “old” way of thinking about error is, roughly, that someone did something wrong; they didn’t follow the rules or they intentionally or unintentionally missed something or skipped a step. It’s therefore their fault that something went wrong and they’re to blame. The “new” way to think about error is through context. Assume the actor is trying to do their best, and if they didn’t follow the rules or missed or skipped something, it’s because they were trying to route around problems that would have prevented them from completing their task in good faith (for instance, lots of false positives in tests could condition them to skip testing, which may let a bug through). Examine when things go wrong through the eyes of the actor, the context they’re in, and the context they had at the time, not from an omnipotent point of view after. Work should then be done to reduce problems in the systems and contexts in which those decisions were made, instead of, for instance, blaming the actor for not following procedure correctly. In software engineering, this is the core concept for “blameless retrospectives”.\n\u003C/dd>\n\u003Cdt>Paradigm shift\u003C/dt>\n\u003Cdd>From \u003Cem>The Structure of Scientific Revolutions\u003C/em>. A paradigm is the current way something exists. In the book, it’s the set of scientific principles currently considered mainstream, but it could be the current team culture, current software engineering practices, current organizational structure, etc…. A paradigm shift happens when a new paradigm arises and wins enough followers over to break from the previous paradigm, leaving it behind. New paradigms arise when practitioners (often those new to the paradigm, like young scientists entering the field) feel that the current paradigm no longer meets their needs (for instance, doesn’t fully explain the results of their experiments) and seek out a new way of understanding their work to resolve those issues. In \u003Cem>Leading Change\u003C/em>, this would be described as a “sense of urgency” (defined below). An old paradigm shifts to a new paradigm when enough members of the old paradigm agree that the problems the new paradigm aims to solve are worth solving and that the new paradigm also solves their problems, too. New paradigms will not take hold if they aren’t able to satisfy the needs of the majority of the practitioners from the previous paradigm.\n\u003C/dd>\n\u003Cdt>Diffusion curve\u003C/dt>\n\u003Cdd>From \u003Cem>Diffusion of Innovations\u003C/em>. While there are a number of different rearticulations of this theory, I use the terms from the original book. The theory discusses how new ideas (innovations) spread. The \u003Ca href=\"https://en.wikipedia.org/wiki/Diffusion_of_innovations\">Wikipedia article\u003C/a> is an excellent summary of the theory, but the key items I take with me when thinking about how to apply this to SCOC are the elements that go into the diffusion of an innovation, and the adoption curve.\n\u003C/dd>\n\u003C/dl>\n\u003Cp>The key elements of diffusion are:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Innovation\u003C/strong> - The actual idea, practice, or object that is perceived as new and someone would like others to adopt. Can, for instance, be a new paradigm, a new piece of technology, or a new organization structure.\u003C/li>\n\u003Cli>\u003Cstrong>Adopters\u003C/strong> - The people (individuals or groups) that the innovation is meant for\u003C/li>\n\u003Cli>\u003Cstrong>Communication channels\u003C/strong> - How information is transferred between adopters and innovators.\u003C/li>\n\u003Cli>\u003Cstrong>Time\u003C/strong> - Adoption almost never happens instantaneously.\u003C/li>\n\u003Cli>\u003Cstrong>Social systems\u003C/strong> - Micro and macro cultural influences on adopters.\u003C/li>\n\u003C/ul>\n\u003Cp>Because of the social systems adopters find themselves in and the communication channels they have (especially with how “close” to the progenitor of an innovation), adoption can be broken down into 5 cohorts: innovators, early adopters, early majority, late majority, and laggards\u003C/p>\n\u003Cp>#\u003Ca href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Diffusion_of_ideas.svg/1920px-Diffusion_of_ideas.svg.png\">Diffusion of Innovations adoption curve, showing the breakdown of each adoption cohort. Image from Wikipedia.\u003C/a>\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Innovators\u003C/strong> - Individuals who are willing and able to take risks on adopting a new innovation, usually thanks to high social status, financial stability, and/or close contact with the source of an innovation and other innovators. They have a high tolerance for failure and can absorb the cost of failure with their existing resources. They usually make up the first roughly 2.5% of adopters. When looking to apply this to SCOC work, these are the individuals or groups who are eager to try something new, knowing that their work isn’t likely to be negatively affected if the change doesn’t succeed, are willing to work through learning pains, are happy to help shape the direction of the work, and can see a large positive future if it works out.\u003C/li>\n\u003Cli>\u003Cstrong>Early adopters\u003C/strong> - Looked to as thought leaders within all adopter categories. They have similar resources to innovators, but are more picky in what they choose to adopt, less willing to take risks if something ultimately fails. Because of this, they hold a key communication position across the adopter board. They usually make up the next roughly 13.5% of adopters. In SCOC work, find the individuals or groups that others look to for guidance, are far enough from the innovation progenitor that their opinions are viewed as genuine endorsements, and are willing to put in work to help spread the innovation.\u003C/li>\n\u003Cli>\u003Cstrong>Early majority\u003C/strong> - Usually individuals or groups with average resources who aren’t considered thought leaders. They’re one of the largest cohorts, at roughly 34% of all adopters, and usually only start adopting after some time has passed. The point at which the early majority starts adopting an innovation is the tipping point where an innovation moves from niche appeal to mass and self-sustaining adoption. This is sometimes called “the marketing chasm” or when an innovation reaches “critical mass”. In SCOC work, look for individuals or groups who are willing to adopt after having been convinced by innovators and early adopters that the innovation will be a net positive for them.\u003C/li>\n\u003Cli>\u003Cstrong>Late majority\u003C/strong> - The late majority starts after around 50% of an innovation’s potential audience has adopted. They approach innovation with a high degree of skepticism and will only adopt after they’ve seen it be successfully adopted elsewhere. They tend to have a smaller amount of resources than average and make up the next roughly 34% of adoption. In SCOC work, this is a group that’ll need to be convinced that the innovation won’t have a negative impact on them, as opposed to a net positive effect.\u003C/li>\n\u003Cli>\u003Cstrong>Laggards\u003C/strong> - The final group, making up the last roughly 16% of adoption, laggards typically will only adopt a new innovation when they have no other choice but to do so. They’re typically highly skeptical of change and have the lowest amount of resources to expend on change. In SCOC work, this cohort will only likely change at the end of a transition period and after new norms have been rooted in the culture or organization. Members of this cohort are also most likely to be \u003Cem>detractors\u003C/em> in a change process (negative change agents). While these individuals are typically characterized as having a low amount of resources to expend, don’t confuse this for not having high status in a culture or organization; laggards can be executives that are opposed to change and, while they may have lots of resources, have little to none to spend on change because of their opposition.\u003C/li>\n\u003C/ul>\n\u003Cdl>\n\u003Cdt>Strategy\u003C/dt>\n\u003Cdd>From \u003Cem>Good Strategy/Bad Strategy\u003C/em>. Strategy is the alignment of goals (overall values and desires) into actions and objectives (specific operational targets). A good strategy has one, or only a few, key objectives that will lead to favorable outcomes and create cascading benefits. It defines critical challenges and tie those challenges to actions. It is constrained and has a good chance of success. Bad strategy is a list of things to do, or a restatement of the desired state of affairs or the challenge ahead. It contains fluff, doesn’t face the challenge head-on, is a statement of desire rather than plans for overcoming obstacles, and either fails to address critical issues or is impractical. Ultimately, a good strategy is a coherent set of actions backed by an argument (the Strategic Kernel). Strategy is also distinct from vision, mission, or values statements:\n\u003C/dd>\n\u003C/dl>\n\u003Cul>\n\u003Cli>\u003Cstrong>Vision statement\u003C/strong> - An aspirational view of the future \u003Cbr>\n\u003Cem>Provide access to the world’s information in one click\u003C/em>\u003C/li>\n\u003Cli>\u003Cstrong>Mission statement\u003C/strong> - The purpose of your work \u003Cbr>\n\u003Cem>Organize the world’s information and make it universally accessible and useful.\u003C/em>\u003C/li>\n\u003Cli>\u003Cstrong>Values statement\u003C/strong> - Core cultural beliefs \u003Cbr>\n\u003Cem>Don’t be evil\u003C/em>\u003C/li>\n\u003C/ul>\n\u003Cp>Strategy is often formed within the bounds of these goals, but strategy’s purpose is overcoming a challenge; these items may set what challenges are to be faced and how you may prefer to think about them, but they themselves won’t help you solve problems. Strategy does.\u003C/p>\n\u003Cdl>\n\u003Cdt>Strategic Kernel\u003C/dt>\n\u003Cdd>From \u003Cem>Good Strategy/Bad Strategy\u003C/em>. While there are many things that may make up a strategy, all strategy shares at least three things in common: a diagnosis, a guiding policy, and coherent actions.\n\u003C/dd>\n\u003C/dl>\n\u003Cul>\n\u003Cli>\u003Cstrong>Diagnosis\u003C/strong> - Explains the challenge, simplifying and identifying critical things the strategy is meant to overcome. A diagnosis should define a domain of action and should favor leverage over outcomes (problems, not solutions). It doesn’t need to explain everything, but the problems being tackled need to be addressable and they need to be addressable in a given timespan.\u003C/li>\n\u003Cli>\u003Cstrong>Guiding policy\u003C/strong> - The overall approach chosen to overcome the problems identified in the diagnosis. I often refer to these as the strategy’s “guard rails” as they’re meant to channel actions in a certain direction without defining what should be done. Guiding policies should \u003Cem>not\u003C/em> be goals or visions of end states. Great guiding policies should draw upon sources of advantage, or create advantage by anticipating the actions and reactions of others.\u003C/li>\n\u003Cli>\u003Cstrong>Coherent actions\u003C/strong> - The coordinated steps designed to carry out the guiding policy. It doesn’t need to include all actions, but needs to include enough to bring high-level concepts down to earth. The actions should coordinate and build upon each other. They’re made coherent by being consistent, with coordinated deployment of resources, imposed by policy and design. Incoherent actions are in conflict with the guiding policy or in pursuit of unrelated challenges. Agile Epics, or IBM Design Thinking Hills, are good first sets of actions to be drawn up here.\u003C/li>\n\u003C/ul>\n\u003Cdl>\n\u003Cdt>Culture\u003C/dt>\n\u003Cdd>From \u003Cem>Organizational Culture and Leadership\u003C/em>. Culture is:\n\u003C/dd>\n\u003C/dl>\n\u003Cblockquote>\n\u003Cp>The accumulated shared learning of a group as it solves its problems of external adaptation [(the environment they exist in)] and internal integration [(the human problems that arise in collective life)]\u003C/p>\n\u003C/blockquote>\n\u003Cp>More succinctly, culture is how groups have learned to solve problems and organize in response to internal and external pressures; it is a learned phenomenon. Culture is pervasive, dealing with all aspects of how a group functions and how it is taught to new members. For a group to have a culture, it needs a level of stability. As such, not all groups have cultures, only ones that need to learn to do things together and have more or less constant membership will. Culture is made up of three items: artifacts, espoused beliefs and values, and basic underlying assumptions.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Artifacts\u003C/strong> - Physical manifestations of culture (language, processes, etc…). You cannot understand a culture by its artifacts alone, you need to talk to an individual to understand the importance of them (for instance, pyramids as temples versus graves).\u003C/li>\n\u003Cli>\u003Cstrong>Espoused beliefs and values\u003C/strong> - What the culture says is important to it. An individual’s beliefs become group values only after they’ve been tested and and have been proven to be able to consistently solve a problem. Some beliefs cannot be effectively tested so are socially validated instead; because of this, it’s harder to see the direct connection to the group’s success. For these, how comfortable and anxiety-free members are when they abide by those beliefs is the only measure of success (religion, for instance). It’s important to distinguish between the those beliefs that are aspirational versus actually being practiced (an organization may strive for teamwork but reward based on individual success, for instance)\u003C/li>\n\u003Cli>\u003Cstrong>Basic underlying assumptions\u003C/strong> - When a solution to a problem repeatedly works, a group gradually comes to believe that’s how nature works. That belief is an underlying assumption. These are the implicit assumptions that actually guide behavior and tell members how to perceive, think about, and feel about things. Underlying assumptions are very difficult to change, as change to them temporarily destabilizes how members of the culture think about the world, leading to anxiety and members trying to rationalize away the change instead of embracing it.\u003C/li>\n\u003C/ul>\n\u003Cp>Cultures aren’t islands; they nest. \u003Cstrong>Macro cultures\u003C/strong> are very stable top-level cultures; they’ve been around a long time and are the cultures in which other cultures live. For instance, the US has a culture, in that the California tech sector has a culture, in that, there’s Google’s culture, and in that, ChromeOS’s culture. \u003Cstrong>Subcultures\u003C/strong> are a sub-division of a macro culture, so a team on ChromeOS may have its own subculture, much like ChromeOS is a subculture of Google. Generally speaking, subcultures inherit the macro culture they reside in, tweaking as needed for the problems they wind up solving.\u003C/p>\n\u003Cp>In organizations, subcultures tend to form when a subunit’s needs necessitate it having its own leader. There are five main subunit structures that typically create their own subcultures: occupational units (engineering, finance, PM), geographic units, product/market/technology units, and operating divisions. Organizational hierarchies also wind up having their own subcultures, which can generally be broken down into operators, engineering and design, and executives:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Operators\u003C/strong> - The individuals who produce or sell the org’s products. They view themselves as the ones who “run the place”. Operators evolve organically per organization, and therefore are highly sensitive to the degree to which all functions are independent. They often route around rules and hierarchy that “get in the way” in unpredictable conditions, and will often teach new operators the “on-the-ground reality” to get a job done (see: \u003Cem>blameless errors\u003C/em>).\u003C/li>\n\u003Cli>\u003Cstrong>Engineering and Design\u003C/strong> - The individuals who design new products, structures, and processes to make the organizations more effective. They bring with them their occupational subculture, with engineers especially looking to remove as much possibility of human error as possible in the systems they design. A software engineer may be both part of this group and the operators group at the same time.\u003C/li>\n\u003Cli>\u003Cstrong>Executives\u003C/strong> - Primarily the CEO and their executive team, but extends to middle management as well. Mainly concerned with the survival and financial health of the organization. Generally need to manage at a distance so think in terms of control systems and routines and become increasingly impersonal. Middle management tend to have similar needs, but without the power or autonomy to make sweeping change unilaterally, so live in an ambiguous authority environment.\u003C/li>\n\u003C/ul>\n\u003Cp>Many problems attributed to bureaucracy, environment factors, or personality conflicts among managers are actually lack of alignment between these subcultures as the individuals of these subcultures often wind up working across purposes with each other.\u003C/p>\n\u003Cdl>\n\u003Cdt>External adaptation and internal integration\u003C/dt>\n\u003Cdd>External adaptation and internal integration are the cornerstones of how culture is formed. They are the problems that groups find solutions to that become the underlying assumptions of a culture, which beliefs and values and, eventually, artifacts come from.\n\u003C/dd>\n\u003C/dl>\n\u003Cp>\u003Cstrong>External adaptation\u003C/strong> stems from a group’s \u003Cem>mission\u003C/em>. It’s their shared understanding of their primary tasks and manifest (consequences that people see, observe, or expect and is explicitly stated and understood) and latent (consequences neither recognized or intended; identified by observers because they don’t expect those tasks to be performed) functions. Groups develop \u003Cem>goals\u003C/em> derived from this mission, build a \u003Cem>consensus\u003C/em> on how to obtain those goals (things like rewards structure and authority systems), how to \u003Cem>measure\u003C/em> how well the group is fulfilling those goals, and how to \u003Cem>correct\u003C/em> if goals are not being met. Being aligned on core mission and identity isn’t enough to ensure success or common goals, though; \u003Cstrong>strategy\u003C/strong> is a key part of external adaptation, and is needed to ensure subcultures are aligned to fulfill the mission.\u003C/p>\n\u003Cp>\u003Cstrong>Internal integration\u003C/strong> stems from a group’s need to comfortably work together. It encompasses \u003Cem>language\u003C/em> and related conceptual categories, \u003Cem>identity and boundary\u003C/em> criteria for how lateral (one task to another), vertical (one rank to another), and inclusion (outsider to insider) work is defined, \u003Cem>authority\u003C/em> as distribution of power and status and how manage face (self-image of who we are and our self-esteem), \u003Cem>trust and openness\u003C/em> of relationships, and especially the building and maintenance of psychological safety, \u003Cem>rewards and punishments\u003C/em> for when expectations are or are not met, and how to explain the \u003Cem>unexplainable\u003C/em>, given that culture is based on decisions of the past and therefore can’t account for everything coming.\u003C/p>\n\u003Cblockquote>\n\u003Cp>Culture is multifaceted, fulfilling the function of providing stability, meaning, and predictability in the present, but is the result of functionally effective decisions in the group’s past\u003C/p>\n\u003C/blockquote>\n\u003Cdl>\n\u003Cdt>Embedding and transmitting culture\u003C/dt>\n\u003Cdd>Because every culture is nested in another culture, leaders need to consider how new beliefs and values will fit into the larger culture they sit in, or they won’t be adopted. There are \u003Cem>primary\u003C/em> ways that culture can be embedded and transmitted to new members, and \u003Cem>secondary\u003C/em> ways, which can be used to reinforce the primary means.\n\u003C/dd>\n\u003C/dl>\n\u003Cp>Culture is \u003Cstrong>primarily transmitted\u003C/strong> by what leaders pay attention to, measure, and control regularly. It’s how they react to critical incidents and crises, allocate resources, rewards, and status, and how they recruit, select, promote, and excommunicate members. It’s also done through deliberate role modeling and coaching.\u003C/p>\n\u003Cp>Those methods can be supported by \u003Cstrong>secondary embedding mechanisms\u003C/strong>, like organizational design, structure, systems, procedures, rites, and rituals, along with formal statements of an organization’s philosophy, creeds, or even by creating charters. They can also take on less direct means, like the design of physical and digital spaces and by the stories that are told about important events or people. These mechanisms only work if they are consistent with the primary mechanisms, otherwise they’ll be ignored or create an internal source of conflict.\u003C/p>\n\u003Cdl>\n\u003Cdt>Relationship levels\u003C/dt>\n\u003Cdd>From \u003Cem>Organizational and Cultural Leadership\u003C/em>. A group’s relationship levels, or power distance, represent the psychological distance between members; it’s how they to relate to each other to make the group feel safe, comfortable, and productive, and is a key aspect of face. While the specific rules for a given culture change to reflect its current state, there are four levels that a relationship can fall into:\n\u003C/dd>\n\u003C/dl>\n\u003Cul>\n\u003Cli>\u003Cstrong>-1, Exploitation\u003C/strong> - Usually only experienced by prisoners, POWs, slaves, or occasionally members of a different culture who are considered underdeveloped. This level is defined by a lack of trust and openness, and while one can choose to build relationships with members of this group, there is no expectation that anyone is owed anything.\u003C/li>\n\u003Cli>\u003Cstrong>1, Acknowledgement and civility\u003C/strong> - These relationships are transactional; people on the street, service members, professional helpers, etc…. Interactions are governed by defined roles and are usually task-based. The parties may not know each other personally, but they treat each other respectfully. There’s trust to a certain degree to not harm each other, and there are polite levels of openness and conversation. In corporate settings, think of cross-functional team members who you ask for help on a task but do not work closely with. These are professional, formal transactions.\u003C/li>\n\u003Cli>\u003Cstrong>2, Recognition as a unique person\u003C/strong> - These are casual friends, members of working teams, clients and subordinates who have personal, but not intimate, relationships. These relations have a deeper level of trust; they make and honor commitments and promises to each other, agree not to harm or undermine each other, and agree not to lie or withhold information to each other relevant to their tasks. In corporate settings, think of “work friends”. These are friendly, personable transactions.\u003C/li>\n\u003Cli>\u003Cstrong>3, Strong emotions\u003C/strong> - These are close friends, loved ones, and those you’re intimate with. You’re generally more open with these individuals, and it’s assumed that you’ll actively support one another when possible or needed, going beyond level 2 relationships. In corporate settings, think of “real” friends, partners, or spouses. These are intimate relationships\u003C/li>\n\u003C/ul>\n\u003Cdl>\n\u003Cdt>Tuckman’s Stages of Group Development\u003C/dt>\n\u003Cdd>Referenced from \u003Cem>Organizational and Cultural Leadership\u003C/em> (\u003Ca href=\"https://en.wikipedia.org/wiki/Tuckman%27s_stages_of_group_development\">Wiki\u003C/a>). Tuckman proposes that there are four stages all groups go through as they mature: forming, storming, norming, and performing. The stages describe how team members interact with each other, and are a reflection of the culture and leadership of the team.\n\u003C/dd>\n\u003C/dl>\n\u003Cul>\n\u003Cli>\u003Cstrong>Forming\u003C/strong> - Finding one’s identity and role. Here, the team agrees on goals and begins to tackle tasks. Team members tend to behave quite independently here, and team members are usually on their best behavior. Discussions center on defining the scope of tasks, how to approach tasks, and the like.\u003C/li>\n\u003Cli>\u003Cstrong>Storming\u003C/strong> - Resolving who has authority and influence. At the start of this stage, there is usually a positive and polite atmosphere. Time and competition pressures will reveal some members become more active and others shut down, revealing a status system where some are seen as contributing more than others. Disagreements and personality clashes may be aired, but must be resolved before a team can move out of this stage, so some teams never leave, or some may re-enter when new challenges arise. This is the stage where psychological safety, dependability, and structure and clarity (see \u003Cem>Google re:Work\u003C/em>) are cemented.\u003C/li>\n\u003Cli>\u003Cstrong>Norming\u003C/strong> - Team resolves at what relationship level they want to operate at by making explicit that which was implicit. They may choose to stay task-focused (level 1) or get to know each other and become friendly (level 2). People least conflicted about the issue of closeness will see or name issues as they happen. The leader must point out that everyone is different with different needs, and the strength of the group is in its variety instead of its homogeneousness. The illusion of “we all like each other” is replaced with “we can all understand, accept, and appreciate each other”. There is a danger here that members become so focused on keeping the peace that they become reluctant to share controversial ideas.\u003C/li>\n\u003Cli>\u003Cstrong>Performing\u003C/strong> - Team can focus on task accomplishment and use its resources to work effectively. They are motivated and knowledgeable, with autonomous decision making and acceptance of dissent, as long as it is channeled through means acceptable to the team.\u003C/li>\n\u003C/ul>\n\u003Cp>Many teams get stuck in \u003Cem>forming\u003C/em> as members try to vie for influence and power, or in \u003Cem>storming\u003C/em> believing they’re all great and they like each other. In both cases, members are thinking primarily about themselves and their role in the group and therefore aren’t able to give full attention to the group’s tasks. Teams may also revert to previous stages under changing circumstances; for instance, a change in leadership may cause a team to revert to \u003Cem>storming.\u003C/em>\u003C/p>\n\u003Ch2 id=\"organizational-change\">Organizational Change\u003C/h2>\n\u003Cp>Ok, now for my super theory of super everything. With those terms in your head and (maybe) the readings complete, let’s bring in the \u003Ca href=\"https://www.kotterinc.com/methodology/8-steps/\">8 steps for leading change\u003C/a> from \u003Cem>Leading Change\u003C/em>. In my personal journey here, from all the readings I mentioned above, I read \u003Cem>The Field Guide to Understanding Human Error\u003C/em> first, then \u003Cem>Leading Change\u003C/em>, so this framework for understanding how change happens has been in the back of my mind since the beginning. But, it wasn’t until I read the other books did the pieces really start to make sense, kind of like Neo finally seeing the world as code at the end of The Matrix. Here, interspersed with Kotter’s 8 steps is how I see how all the pieces fit together.\u003C/p>\n\u003Ch3 id=\"1-create-a-sense-of-urgency\">1. Create a sense of urgency\u003C/h3>\n\u003Cp>At its core, the 8 steps of organizational change are about how to introduce a \u003Cem>paradigm shift\u003C/em> in an organization. A paradigm shift will only work if there’s a problem with the current paradigm, and you can convince others that it’s a problem, too (next section). Change not deeply rooted in a real, tangible problem, is at best going to be superficial, at worst is going to create new problems without solving any.\u003C/p>\n\u003Cp>At this stage you’re starting to identify a \u003Cem>diagnosis\u003C/em>; a core problem that the change initiative will be designed to overcome. It is usually driven by either a culture issue (the current way of working isn’t working for today’s problems) or a crisis (declining sales, layoffs, etc…). Be wary of organizational change for the sake of change or vanity; this is likely going to cause anxiety and create culture issues that will linger.\u003C/p>\n\u003Cp>When you create a sense of urgency, you’re naming the problem that your change initiative is going to solve, and declaring yourself responsible for inspiring others to change.\u003C/p>\n\u003Ch3 id=\"2-build-a-guiding-coalition\">2. Build a guiding coalition\u003C/h3>\n\u003Cp>Once you’ve identified your core problem, you need to bring in others to help steer the change process. The guiding coalition should be made up of members from all three levels of the organizational hierarchy: operators, engineers and designers, and executives. This will ensure that there’s across the board representation for how the organization currently operates, including the on-the-ground deviations, and will ensure decisions aren’t being made just for the benefit of one of the levels. It’s important that, amongst the executive representatives, there’s at least one leader who is bought-in that can have direct top-down control of the change initiative, if need be. It’s much harder to get change to stick without some form of leadership approval initially.\u003C/p>\n\u003Cp>The guiding coalition should not be too large; this is a group that needs to be able to reach consensus and act around, assess success of, and sell the change initiative. This group is likely to need Level 2 relationships to be successful.\u003C/p>\n\u003Ch3 id=\"3-form-a-strategic-vision\">3. Form a strategic vision\u003C/h3>\n\u003Cp>It’s now the guiding coalition’s job to build a strategy for how to accomplish the change initiative. The \u003Cem>diagnosis\u003C/em> should be settled by this point, it’s now about determining the \u003Cem>guiding principles\u003C/em> and \u003Cem>coherent actions\u003C/em> to take. For larger change initiatives, you’ll likely need a multi-staged strategy covering different timespans.\u003C/p>\n\u003Cp>To build this out, \u003Cem>as-is scenarios\u003C/em> and \u003Cem>empathy maps\u003C/em> (\u003Cem>Design Thinking\u003C/em>) are good tools to get a deeper understanding of how the problem affects different people in the organization. \u003Cem>Ideation\u003C/em>, \u003Cem>prioritization grids\u003C/em>, and \u003Cem>to-be\u003C/em> \u003Cem>scenarios\u003C/em> can then be used to help come to a consensus on what the best goal end-state is and what actions need to be taken to get there.\u003C/p>\n\u003Cp>Keep in mind the rest of steps when building a strategy; you’re going to need to get \u003Cem>innovators\u003C/em> and \u003Cem>early adopters\u003C/em> on board to get the change initiative to feel sticky across the organization, you’re going to need to see success within a relatively short period of time, show that that success can be sustained, and figure out how to change aspects of the organization’s culture to accommodate the new way of working.\u003C/p>\n\u003Cp>\u003Cstrong>You’ll also need to seriously examine the existing culture.\u003C/strong> When forming a strategic vision for a new future, you must examine how it’s going to change the current culture, and therefore identity, of the organization. Because culture is an interconnected set of assumptions, not isolated elements of how groups work, your change initiative \u003Cem>will be changing the group’s culture\u003C/em> even if that’s not your primary intention.\u003C/p>\n\u003Ch3 id=\"4-enlist-a-volunteer-army\">4. Enlist a volunteer army\u003C/h3>\n\u003Cp>\u003Cem>While Kotter has steps 4, 5, and 6 as separate items, I consider them the three steps of kickstarting your change initiative. Instead of being separate steps\u003C/em> per se \u003Cem>, steps 4 and 5 are how to enable 6, with you going back to them as you generate wins and sustain acceleration (step 7) as you build towards self-sustaining adoption\u003C/em>.\u003C/p>\n\u003Cp>This is the start of the \u003Cem>diffusion of innovations\u003C/em> curve. Identify \u003Cem>innovator\u003C/em> and \u003Cem>early adopter\u003C/em> individuals or teams and work closely with them to get them to adopt the new way of working. You will not win everyone over to start with, so you should focus your efforts on those who are highly motivated to see the change actually stick. For change to be successful, these groups need to become evangelists for the rest of the organization, letting your message scale. They’re also invaluable for the guiding coalition to gather feedback from to help shape the change initiative over time.\u003C/p>\n\u003Ch3 id=\"5-enable-action-by-removing-barriers\">5. Enable action by removing barriers\u003C/h3>\n\u003Cp>There are two main areas where barriers are likely to crop up: resource constraints and culture clashes.\u003C/p>\n\u003Cp>Resource constraints are likely the most straightforward to deal with; it’s the project management iron triangle of scope, budget, and time. If you want to get more done with fewer people, you need more time. Short time and fixed scope? Enlarge the budget. Fixed budget and fixed time? Reduce the scope. These are the forces at play to ensure a project remains successful. At this stage you’re preparing to show some wins in your change initiative, so you want to do whatever you can to have an impact quickly.\u003C/p>\n\u003Cp>The second, much harder area, is culture clashes. These usually fall into one of two categories: clashes with the \u003Cem>macro culture\u003C/em>, and \u003Cem>negative change agents\u003C/em>.\u003C/p>\n\u003Cp>Clashes with the \u003Cem>macro culture\u003C/em> are difficult to route around; a change initiative is ultimately a shift in culture. Because all cultures live within a \u003Cem>macro culture\u003C/em> and need to adopt that culture’s norms, shifting too radically away from it may make it hard or impossible to work. If you can’t find creative ways of bridging the gap between the two cultures, you’ll likely need to add something to your strategy’s \u003Cem>guiding principles\u003C/em> to prevent straying too far, and rethink your \u003Cem>coherent actions\u003C/em> to reflect that change. This may also mean starting over.\u003C/p>\n\u003Cp>On the other hand, what you could be running into is the friction being generated as the new culture and old culture clash, creating anxiety and causing your organization’s current culture to fight back. That fighting back usually manifests itself in the form of “negative change agents”. It may be subtle, like a leader verbally agreeing to work one way and continuing to work another, or it may be obvious, like someone loudly pushing back against a new tool. Don’t discount all negative change agents, there’s a reason they don’t come along. Think of it through \u003Cem>blameless\u003C/em> eyes and try and see if you can tweak your strategy to cover their issues. They may also be a \u003Cem>laggard\u003C/em>; don’t try and win them over to start with, bring them along as the process draws to a close.\u003C/p>\n\u003Ch3 id=\"6-generate-short-term-wins\">6. Generate short-term wins\u003C/h3>\n\u003Cp>The goal of focusing on \u003Cem>innovators\u003C/em> and \u003Cem>early adopters\u003C/em> and removing their barriers to adoption is to show that the new way of working can work, and can work quickly. You’re goal should be to show that the new way of working works within the first 3-6 months of the start of a change initiative. These can can be small wins, but they’re needed to build momentum and bring the next stage of adoption on. Share the success and learnings that you’ve had along the way widely. Hold \u003Cem>blameless retrospectives\u003C/em>, solicit feedback, and show how that feedback has led to improvements in the plan. Make the wins not just your coalition’s wins, but the wins of everyone who’s adopted the change initiative.\u003C/p>\n\u003Cp>This is a good point to start to introduce new \u003Cem>primary and secondary culture embedding mechanisms\u003C/em>. Reward teams who adopt the new way of working with something small but meaningful; give them time during current rites and rituals to share their success, invite them to share feedback directly with the guiding coalition or leadership, provide them with a unique project codename and ensure it gets used when talking about it. The goal here is to provide incentives in the current cultural zeitgeist that bridges the gap to the new one you want to create.\u003C/p>\n\u003Ch3 id=\"7-sustain-acceleration\">7. Sustain acceleration\u003C/h3>\n\u003Cp>You sustain acceleration by showing that the short-term wins weren’t flukes; the new way of working consistently solves the \u003Cem>diagnosis\u003C/em> and can do so for a variety of adopters. This builds a reputation that the \u003Cem>external adaptation\u003C/em> or \u003Cem>internal integration\u003C/em> problems the change initiative is meant to address are working, and that the culture’s \u003Cem>basic underlying assumptions\u003C/em> can evolve while still retaining a sense of safety for the group. At this stage, you should start to see some members having fully embraced the new way of working and are adopting the new assumptions outright, turning them into \u003Cem>espoused beliefs and values\u003C/em>. Keep the wins coming, keep the feedback loop coming, and keep sharing the success.\u003C/p>\n\u003Cp>This step is a long one; it begins at the point where you’re onboarding the \u003Cem>early majority\u003C/em> and you’re starting to see self-sustaining adoption, and will probably peak around the start of \u003Cem>late majority\u003C/em> adoption.\u003C/p>\n\u003Ch3 id=\"8-institute-change\">8. Institute change\u003C/h3>\n\u003Cp>Finally, you need to solidify the change in the organization’s culture. \u003Cem>Laggards\u003C/em> aren’t going to adopt the new way of working until it’s embedded in the culture. If enough negative change agents still exist at this point, and they’re visible enough to cause others to doubt their commitment to the new process, the initiative may wind up failing. Yes, even at this stage, a change initiative can fail.\u003C/p>\n\u003Cp>To embed the change in the culture, you’ll need to rely on \u003Cem>primary cultural embedding mechanisms\u003C/em>. Coach and mentor organization members on the new way of working, allocate (or take away) rewards (compensation, perks, etc…), status, and resources based on adherence to the new ways of working. Ensure leaders are cognizant in how they pay attention to the new way of working versus the old way of working. Recruit new leaders for adherence to the new way of working, and excommunicate those who refuse to change. \u003Cem>Secondary cultural embedding mechanisms\u003C/em> may need changing too, like systems, procedures, or tools, common activities like recurring meetings or events, changing formal statements like vision statements and charters, or even changing the physical spaces people work in.\u003C/p>\n\u003Cp>In the first few years of a change initiative, it’s especially important that leaders are extra vigilant about ensuring \u003Cem>primary embedding mechanisms\u003C/em> stick; cultures are inherently biased towards past success and can fall back at any time until the change is fully embedded and a new culture has taken root. That’s not to say that everything needs to be kept still during this time, strategy can evolve within the bounds set by the initial direction, or you may find that the change uncovers deeper needs that then need to be addressed, and a larger change initiative is warranted. Culture and strategy are intertwined, living entities; make sure you continue nurturing both.\u003C/p>\n\u003Chr>\n\u003Cp>A huge thanks to everyone who’s helped shape my thinking around this topic, but especially Bill Higgins for his friendship and mentorship, and Damon Deaner for taking a chance on the IBM front-end development community and me in particular with Hackademy, the first change initiative I had a heavy hand in running.\u003C/p>",{"headings":1937,"localImagePaths":1977,"remoteImagePaths":1978,"frontmatter":1979,"imagePaths":1981},[1938,1941,1944,1947,1950,1953,1956,1959,1962,1965,1968,1971,1974],{"depth":80,"slug":1939,"text":1940},"readings","Readings",{"depth":904,"slug":1942,"text":1943},"core-readings","Core readings",{"depth":904,"slug":1945,"text":1946},"supplemental-readings","Supplemental readings",{"depth":80,"slug":1948,"text":1949},"important-terms-and-concepts","Important terms and concepts",{"depth":80,"slug":1951,"text":1952},"organizational-change","Organizational Change",{"depth":904,"slug":1954,"text":1955},"1-create-a-sense-of-urgency","1. Create a sense of urgency",{"depth":904,"slug":1957,"text":1958},"2-build-a-guiding-coalition","2. Build a guiding coalition",{"depth":904,"slug":1960,"text":1961},"3-form-a-strategic-vision","3. Form a strategic vision",{"depth":904,"slug":1963,"text":1964},"4-enlist-a-volunteer-army","4. Enlist a volunteer army",{"depth":904,"slug":1966,"text":1967},"5-enable-action-by-removing-barriers","5. Enable action by removing barriers",{"depth":904,"slug":1969,"text":1970},"6-generate-short-term-wins","6. Generate short-term wins",{"depth":904,"slug":1972,"text":1973},"7-sustain-acceleration","7. Sustain acceleration",{"depth":904,"slug":1975,"text":1976},"8-institute-change","8. Institute change",[],[],{"title":1928,"published":1980,"summary":1930},"2023-11-17",[],"singularity-1-0",{"id":1982,"data":1984,"body":1987,"filePath":1988,"digest":1989,"rendered":1990},{"title":1841,"published":1985,"summary":1986},["Date","2013-04-03T00:00:00.000Z"],"I'm super excited to announce [Singularity 1.0](https://github.com/Team-Sass/Singularity)!","I'm super excited to announce [Singularity 1.0](https://github.com/Team-Sass/Singularity)! Singularity 1.0 comes from months of work refining the architecture, mental model, and documentation around the original Singularity alpha, and I'm very excited to see it get out the door! Singularity is the same awesome grid system you know and love, now with more shine. For those who are not familiar with Singularity, here are some of its highlights:\n\n- Semantic grid: apply your grid directly to your markup without adding grid classes. Everything's stored within your CSS!\n- Support for both Symmetric and Asymmetric grids\n- Designed to be both Responsive and Mobile First.\n- Use [Breakpoint](http://breakpoint-sass.com/) to handle your Media Queries like normal; Singularity will know what grid to use when you call it!\n- Core support for both traditional Float and new Isolation output methods.\n- Super flexible: swap your grid, gutter, and even output method on the fly!\n- Designed to be a Grid Framework, not a Grid System.\n  - Generic math engine that is container agnostic\n  - Future friendly; Full API in place to support any output you'd like\n  - Base mixin is generic and easy to build custom input mixins from\n\nIf you'd like to get started using Singularity right now, head on over to the [Singularity Documentation](https://github.com/Team-Sass/Singularity/wiki)\n\n## What about Susy Next?\n\nTwo months ago, we announced the first alpha of [Susy Next](/musings/introducing-susy-next). Since that time, not much has moved on Susy Next, and I became anxious to get the code we had written there to a stable place. I was also upset about having abandoned the Singularity users before formally releasing a stable 1.0 for everyone to use. Because of this, I have been working with Scott Kellum to get the codebase of Singularity up to snuff and ready for prime-time consumption, and that's what we've launched today. I am still very excited about the potential of Susy Next, and have not abandoned the project. Instead, I will be working on both systems. When development picks back up on Susy Next and there is more to report, expect some more from me. In the mean time, I will be supporting Singularity and working with the Susy Next team where I can.","src/content/posts/singularity-1-0.md","ffa3be7b915f48b6",{"html":1991,"metadata":1992},"\u003Cp>I’m super excited to announce \u003Ca href=\"https://github.com/Team-Sass/Singularity\">Singularity 1.0\u003C/a>! Singularity 1.0 comes from months of work refining the architecture, mental model, and documentation around the original Singularity alpha, and I’m very excited to see it get out the door! Singularity is the same awesome grid system you know and love, now with more shine. For those who are not familiar with Singularity, here are some of its highlights:\u003C/p>\n\u003Cul>\n\u003Cli>Semantic grid: apply your grid directly to your markup without adding grid classes. Everything’s stored within your CSS!\u003C/li>\n\u003Cli>Support for both Symmetric and Asymmetric grids\u003C/li>\n\u003Cli>Designed to be both Responsive and Mobile First.\u003C/li>\n\u003Cli>Use \u003Ca href=\"http://breakpoint-sass.com/\">Breakpoint\u003C/a> to handle your Media Queries like normal; Singularity will know what grid to use when you call it!\u003C/li>\n\u003Cli>Core support for both traditional Float and new Isolation output methods.\u003C/li>\n\u003Cli>Super flexible: swap your grid, gutter, and even output method on the fly!\u003C/li>\n\u003Cli>Designed to be a Grid Framework, not a Grid System.\n\u003Cul>\n\u003Cli>Generic math engine that is container agnostic\u003C/li>\n\u003Cli>Future friendly; Full API in place to support any output you’d like\u003C/li>\n\u003Cli>Base mixin is generic and easy to build custom input mixins from\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Cp>If you’d like to get started using Singularity right now, head on over to the \u003Ca href=\"https://github.com/Team-Sass/Singularity/wiki\">Singularity Documentation\u003C/a>\u003C/p>\n\u003Ch2 id=\"what-about-susy-next\">What about Susy Next?\u003C/h2>\n\u003Cp>Two months ago, we announced the first alpha of \u003Ca href=\"/musings/introducing-susy-next\">Susy Next\u003C/a>. Since that time, not much has moved on Susy Next, and I became anxious to get the code we had written there to a stable place. I was also upset about having abandoned the Singularity users before formally releasing a stable 1.0 for everyone to use. Because of this, I have been working with Scott Kellum to get the codebase of Singularity up to snuff and ready for prime-time consumption, and that’s what we’ve launched today. I am still very excited about the potential of Susy Next, and have not abandoned the project. Instead, I will be working on both systems. When development picks back up on Susy Next and there is more to report, expect some more from me. In the mean time, I will be supporting Singularity and working with the Susy Next team where I can.\u003C/p>",{"headings":1993,"localImagePaths":1997,"remoteImagePaths":1998,"frontmatter":1999,"imagePaths":2000},[1994],{"depth":80,"slug":1995,"text":1996},"what-about-susy-next","What about Susy Next?",[],[],{"title":1841,"published":1569,"summary":1986},[],"yom-kippur-2024",{"id":2001,"data":2003,"body":2008,"filePath":2009,"digest":2010,"rendered":2011},{"title":2004,"published":2005,"updated":2006,"summary":2007},"Yom Kippur 2024",["Date","2024-10-12T00:00:00.000Z"],["Date","2024-10-12T00:00:00.000Z"],"I was in Poland during Yom Kippur, and went to  Auschwitz and Birkenau. These are my reflections on that trip. Holocaust trigger warning.",":::message{.error}\n**Content warning: The Holocaust**.\n\nThis was originally a [thread](https://mas.to/@snugug/113294430431389512) I posted on Mastodon. I'm moving it here, in its entirety, to preserve it. I've set this post's date to the date of the original thread.\n\nYou can see the pictures I took in the [Auschwitz-Birkenau album](https://snugug.photography/auschwitz-birkenau) on my photography site.\n:::\n\nI haven't observed Yom Kippur in a number of years, but today I happen to be in Krakow and chose to observe it by going to Auschwitz-Birkenau.\n\nThe main Auschwitz museum is hauntingly well preserved, almost looking like a movie set. Many of the facts I knew growing up Jewish and learning about the Holocaust, but standing there, in the actual spot, it hit a little different.\n\nBut then there was Bunker 11.\n\nBunker 11 was where the Nazis first tested gassing prisoners. The museum up to that point was similar to other Holocaust museums I had been to, but that, that was different, and just the beginning.\n\nThe next stop was in the only surviving actual gas chamber and crematorium on site. We walked through it. I saw the vents they dropped the gas from. They described why it was so effective.\n\nI've ways had a picture of what these were like in my mind, but it was so much more brutal through it's... banality? than I imagined. A grey concrete bunker, connected to a room with furnaces, burning so hot they needed steel carts to load the bodies. A true nightmare.\n\nThen we went to Birkenau.\n\nIf you don't know the name, Birkenau is where the trains dropped everyone off. We stood next to the house, pictured in era pictures from the main museum, where new arrivals were sorted either to bunkers or directly to the gas chambers. We saw the remains of a crematorium the Nazis destroyed to attempt to cover up their crimes in the final days of the war. The number of those killed there, 90% Jewish, their ashes scattered on the grounds, make it all a giant cemetery.\n\nBut the biggest things I got from actually being at Birkenau were one, it's size. It was 2km by 1km of fairly tightly packed bunkers. Multiple gas chambers and crematoriums. And two, a glimpse of the living conditions for those kept there.\n\nThey have preserved bunkers that we went into. Close, cramped, dark, with not enough airflow to stay cool in the summer or heat for the winter. Clearly designed with the intention that those living there would not survive.\n\nIt's a true miracle that anyone survived this, and a true horror that humans are capable of this much evil.\n\nToday, as I was there, as I saw intake pictures and bunks and gas chambers and remains and literal tonnes of hair shaved from those killed, I remember not only my loved ones lost, but them, too.\n\nMay their memory be a blessing.\n\n---\n\nReflecting back on my day today, the most ominous sign I think they have at the museum may have been the no open flames sign in the former gas chamber and crematorium.\n\nEverything else in the museum filled me with sadness, maybe even dread, but that modern sign in that place actually made my skin crawl with fear.","src/content/posts/yom-kippur-2024.md","338233bac3cd16e6",{"html":2012,"metadata":2013},"\u003Cdiv class=\"error message\" data-type=\"error\">\u003Cp>\u003Cstrong>Content warning: The Holocaust\u003C/strong>.\u003C/p>\u003Cp>This was originally a \u003Ca href=\"https://mas.to/@snugug/113294430431389512\">thread\u003C/a> I posted on Mastodon. I’m moving it here, in its entirety, to preserve it. I’ve set this post’s date to the date of the original thread.\u003C/p>\u003Cp>You can see the pictures I took in the \u003Ca href=\"https://snugug.photography/auschwitz-birkenau\">Auschwitz-Birkenau album\u003C/a> on my photography site.\u003C/p>\u003C/div>\n\u003Cp>I haven’t observed Yom Kippur in a number of years, but today I happen to be in Krakow and chose to observe it by going to Auschwitz-Birkenau.\u003C/p>\n\u003Cp>The main Auschwitz museum is hauntingly well preserved, almost looking like a movie set. Many of the facts I knew growing up Jewish and learning about the Holocaust, but standing there, in the actual spot, it hit a little different.\u003C/p>\n\u003Cp>But then there was Bunker 11.\u003C/p>\n\u003Cp>Bunker 11 was where the Nazis first tested gassing prisoners. The museum up to that point was similar to other Holocaust museums I had been to, but that, that was different, and just the beginning.\u003C/p>\n\u003Cp>The next stop was in the only surviving actual gas chamber and crematorium on site. We walked through it. I saw the vents they dropped the gas from. They described why it was so effective.\u003C/p>\n\u003Cp>I’ve ways had a picture of what these were like in my mind, but it was so much more brutal through it’s… banality? than I imagined. A grey concrete bunker, connected to a room with furnaces, burning so hot they needed steel carts to load the bodies. A true nightmare.\u003C/p>\n\u003Cp>Then we went to Birkenau.\u003C/p>\n\u003Cp>If you don’t know the name, Birkenau is where the trains dropped everyone off. We stood next to the house, pictured in era pictures from the main museum, where new arrivals were sorted either to bunkers or directly to the gas chambers. We saw the remains of a crematorium the Nazis destroyed to attempt to cover up their crimes in the final days of the war. The number of those killed there, 90% Jewish, their ashes scattered on the grounds, make it all a giant cemetery.\u003C/p>\n\u003Cp>But the biggest things I got from actually being at Birkenau were one, it’s size. It was 2km by 1km of fairly tightly packed bunkers. Multiple gas chambers and crematoriums. And two, a glimpse of the living conditions for those kept there.\u003C/p>\n\u003Cp>They have preserved bunkers that we went into. Close, cramped, dark, with not enough airflow to stay cool in the summer or heat for the winter. Clearly designed with the intention that those living there would not survive.\u003C/p>\n\u003Cp>It’s a true miracle that anyone survived this, and a true horror that humans are capable of this much evil.\u003C/p>\n\u003Cp>Today, as I was there, as I saw intake pictures and bunks and gas chambers and remains and literal tonnes of hair shaved from those killed, I remember not only my loved ones lost, but them, too.\u003C/p>\n\u003Cp>May their memory be a blessing.\u003C/p>\n\u003Chr>\n\u003Cp>Reflecting back on my day today, the most ominous sign I think they have at the museum may have been the no open flames sign in the former gas chamber and crematorium.\u003C/p>\n\u003Cp>Everything else in the museum filled me with sadness, maybe even dread, but that modern sign in that place actually made my skin crawl with fear.\u003C/p>",{"headings":2014,"localImagePaths":2015,"remoteImagePaths":2016,"frontmatter":2017,"imagePaths":2019},[],[],[],{"title":2004,"published":2018,"summary":2007,"updated":2018},"2024-10-12",[],"the-last-spa-router-you-ll-need",{"id":2020,"data":2022,"body":2026,"filePath":2027,"digest":2028,"rendered":2029},{"title":2023,"published":2024,"summary":2025},"The Last SPA Router You'll Need",["Date","2024-12-23T00:00:00.000Z"],"The Navigation API provides a standards-based way to build a client-side router that can be used with anything you desire to build your front-end in. I'll show you how I used it to rebuild the CMS for my photography site, and why the new Runes feature of Svelte 5, when combined with this, make for a truly killer combo.","I went through a number of iterations on how to manage my images over on [snugug.photography](https://snugug.photography). I started with doing everything in Lightroom (my desktop library manager of choice) and extracting the EXIF data at build time to grab everything I needed from there. This had a few problems, the biggest being that while I _could_ write titles, descriptions, and alt text in Lightroom, that it was incredibly cumbersome to do so. So I pivoted, and built a tiny Firebase app to help me.\n\nThis Firebase app does a couple of neat things: I drop a folder of images into a storage bucket, it reads those images, extracts and normalizes the EXIF data, and puts them into a database so I have a cache of that data. With database entries for everything, I can now manipulate the data a little easier and add site-specific metadata as I see fit. It also opens the ability to integrate external tools into my workflow, like the only thing approaching a good use for generative LLMs I've personally seen so far: writing alt text for images. To manage all of this, I found I needed a little content management system, and because it's a highly interactive system with deep user sessions, it's one of the few circumstances where a single page app (SPA) makes sense.\n\nMy first run at it was pretty simple; a single `client:only` component I threw into my Astro site that had all the logic stuffed in. It worked, it was a little messy, but it did the job. I had actually tried dividing it into sub components and building it \"correctly\", but I've both truly never liked any of the compromises most SPA routers make (namely being required to use their components to make navigation work, or hash navigation, or or surprise links are `div`s) and integrating an SPA route with subroutes into Astro in dev is a surprisingly unsolved pattern that was causing me issues. But I found the need to expand what my CMS was capable of, so I embarked on a rewrite.\n\nBecause this was only for me, I decided to try playing around with the [Navigation API](https://developer.mozilla.org/en-US/docs/Web/API/Navigation_API), an standards-based API specifically for managing all the tricky edge cases of trying to do client-side routing. It's available in Chromium based browsers, but has positive signals, and implementation work, from Safari and Firefox, and after using it for a morning, honestly, it can't come soon enough to them. For a basic URL based routing system like I've got, the flow is basically as follows:\n\n1. Add a navigation event listener\n2. Check to see if the destination URL should be owned by your router\n3. If not, return, if so, set your view.\n\nIt's really only those three steps. Throw in \"set initial view\" and \"render your view\" for a total of 5 steps, and, with only a smidge of hyperbole, I can say that this is probably the simplest, easiest, client side router you'll ever use. And the exact same pattern, with almost the _exact same code_, can be used with _any_ framework (or without a framework!). It's really a game changer. Here's what it looks like:\n\n```js\n// Get the initial path that's being loaded\nlet url = new URL(document.URL).pathname;\n\nnavigation.addEventListener('navigate', (e) => {\n  // Get the path for the URL being navigated to\n  url = new URL(e.destination.url).pathname;\n  // If it's not covered by your SPA, return and it works as normal\n  // For me, this means if it's not part of my admin path\n  if (!url.startsWith('/admin')) return;\n\n  // If you do want deal with it, intercept the event and call a handler to change your view. It can take an async function, important for dynamically loading your routes. I'll get back to that in a second.\n  e.intercept({ handler: setView });\n});\n```\n\nThat's it! That's all the logic you need to set up your router! ~5 lines of vanilla, use anywhere with anything JavaScript. Write proper links with `a` tags, and this works, no special components necessary. You need to navigate programmatically? that's covered, too, with `navigation.navigate()`, passing in the URL or path you want to navigate to. It's so straight forward, so simple, so easy (and I really don't like using those words when describing tech) that writing a wrapping or helper library won't help ergonomics or understanding. It's an _excellent_ API, and hats off to the group that came up with it.\n\nNow, you'll be asking, how does this work to actually change the view? Well, from here on out is going to be implementation specific, but the code for Svelte 5 is, again, very straight forward and you should be able to translate it into whatever tool you're using:\n\n```ts\n// This is a little Svelte 5, a little TypeScript.\n// The first thing I'm doing is creating a variable called View that I'm telling Svelte is going to change (the $state Rune) and should be treated a Svelte component.\nlet View = $state() as Component;\n\nasync function setView() {\n  // Then, write your logic! For me, I'm starting by splitting the pathname into pieces and removing the first piece, because that'll just be the leading slash and adds noise.\n  const parts = url.split('/');\n  parts.shift();\n\n  // Then, I'm looking to see if the user is logged in\n  if (!user) {\n    // This is the secret sauce dynamic loading patterns, AKA a standard module import. Get the component, set it as the View.\n    // Svelte 5's new Rune based state management means I can set this directly and Svelte knows it needs to run its magic. Different state managers and different frameworks will do this slightly differently, but the logic is the same.\n    const { default: m } = await import('./admin/Login.svelte');\n    View = m;\n  } else if (parts.length === 1) {\n    // On my index page, in my case, load all of my albums\n    const { default: m } = await import('./admin/Albums.svelte');\n    View = m;\n  } else if (parts.length === 2) {\n    // The logic you use here is entirely up to you. It can be more fancy than this, but it can also be this simple. I know that if I've got two items, I'm looking for an album. I've got another state manager called store that's shared between components, so I'm going to store the album from the URL in there, and the Album component will pick that up to load the correct album. I could have also done this in the Album component directly! The world is your oyster.\n    const { default: m } = await import('./admin/Album.svelte');\n    store.album = parts[1];\n    View = m;\n  } else if (parts.length === 3) {\n    // Second verse, same as the first. If I've got three parts, I'm going to store the album and the image in my global store for future reference\n    const { default: m } = await import('./admin/Image.svelte');\n    store.album = parts[1];\n    store.image = parts[2];\n    View = m;\n  }\n}\n\n// The final thing you need to do is call serView when your app runs to get the right view in place. In Svelte 5, the way to do this is through the $effect Rune, but you could call it on DOMContentLoaded, onMount in previous versions of Svelte, or whatever similar lifecycle event your framework has\n$effect(() => {\n  setView();\n});\n```\n\nThat's it! That's the whole JS of the router! A few lines of vanilla JS and some blink-and-you'll-miss-it integrations with a state manager. And with a modern bundler, like Vite, these `import` routes will be code split (which is why I'm not using a single, dynamic import statement here), giving you the holy grail (from a performance perspective) of SPA routers–a code-split, asynchronous routing system with 0 external dependencies that only weighs bytes, even before the gzipped and minimized size laundering that we use to describe library impact nowadays. And, like I previously said, it's universal, bring it with you to any tool, any framework you're using, and never learn another router again, because here we #UseThePlatform.\n\nOh, there's one last bit you need to do: actually render your component. While this will vary from framework to framework, implementation to implementation, one of the other reason I'm particularly happy with Svelte 5 here is, because we've told Svelte that View is stat that will change, that gets boiled down to this:\n\n```html\n\u003CView />\n```","src/content/posts/the-last-spa-router-you-ll-need.md","65c795e59e1af8aa",{"html":2030,"metadata":2031},"\u003Cp>I went through a number of iterations on how to manage my images over on \u003Ca href=\"https://snugug.photography\">snugug.photography\u003C/a>. I started with doing everything in Lightroom (my desktop library manager of choice) and extracting the EXIF data at build time to grab everything I needed from there. This had a few problems, the biggest being that while I \u003Cem>could\u003C/em> write titles, descriptions, and alt text in Lightroom, that it was incredibly cumbersome to do so. So I pivoted, and built a tiny Firebase app to help me.\u003C/p>\n\u003Cp>This Firebase app does a couple of neat things: I drop a folder of images into a storage bucket, it reads those images, extracts and normalizes the EXIF data, and puts them into a database so I have a cache of that data. With database entries for everything, I can now manipulate the data a little easier and add site-specific metadata as I see fit. It also opens the ability to integrate external tools into my workflow, like the only thing approaching a good use for generative LLMs I’ve personally seen so far: writing alt text for images. To manage all of this, I found I needed a little content management system, and because it’s a highly interactive system with deep user sessions, it’s one of the few circumstances where a single page app (SPA) makes sense.\u003C/p>\n\u003Cp>My first run at it was pretty simple; a single \u003Ccode>client:only\u003C/code> component I threw into my Astro site that had all the logic stuffed in. It worked, it was a little messy, but it did the job. I had actually tried dividing it into sub components and building it “correctly”, but I’ve both truly never liked any of the compromises most SPA routers make (namely being required to use their components to make navigation work, or hash navigation, or or surprise links are \u003Ccode>div\u003C/code>s) and integrating an SPA route with subroutes into Astro in dev is a surprisingly unsolved pattern that was causing me issues. But I found the need to expand what my CMS was capable of, so I embarked on a rewrite.\u003C/p>\n\u003Cp>Because this was only for me, I decided to try playing around with the \u003Ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/Navigation_API\">Navigation API\u003C/a>, an standards-based API specifically for managing all the tricky edge cases of trying to do client-side routing. It’s available in Chromium based browsers, but has positive signals, and implementation work, from Safari and Firefox, and after using it for a morning, honestly, it can’t come soon enough to them. For a basic URL based routing system like I’ve got, the flow is basically as follows:\u003C/p>\n\u003Col>\n\u003Cli>Add a navigation event listener\u003C/li>\n\u003Cli>Check to see if the destination URL should be owned by your router\u003C/li>\n\u003Cli>If not, return, if so, set your view.\u003C/li>\n\u003C/ol>\n\u003Cp>It’s really only those three steps. Throw in “set initial view” and “render your view” for a total of 5 steps, and, with only a smidge of hyperbole, I can say that this is probably the simplest, easiest, client side router you’ll ever use. And the exact same pattern, with almost the \u003Cem>exact same code\u003C/em>, can be used with \u003Cem>any\u003C/em> framework (or without a framework!). It’s really a game changer. Here’s what it looks like:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"js\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// Get the initial path that's being loaded\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">let\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> url \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F92672\"> new\u003C/span>\u003Cspan style=\"color:#A6E22E\"> URL\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(document.URL).pathname;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">navigation.\u003C/span>\u003Cspan style=\"color:#A6E22E\">addEventListener\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'navigate'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">, (\u003C/span>\u003Cspan style=\"color:#FD971F;font-style:italic\">e\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) \u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">=>\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Get the path for the URL being navigated to\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  url \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F92672\"> new\u003C/span>\u003Cspan style=\"color:#A6E22E\"> URL\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(e.destination.url).pathname;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // If it's not covered by your SPA, return and it works as normal\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // For me, this means if it's not part of my admin path\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#F92672\">!\u003C/span>\u003Cspan style=\"color:#F8F8F2\">url.\u003C/span>\u003Cspan style=\"color:#A6E22E\">startsWith\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'/admin'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">)) \u003C/span>\u003Cspan style=\"color:#F92672\">return\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // If you do want deal with it, intercept the event and call a handler to change your view. It can take an async function, important for dynamically loading your routes. I'll get back to that in a second.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  e.\u003C/span>\u003Cspan style=\"color:#A6E22E\">intercept\u003C/span>\u003Cspan style=\"color:#F8F8F2\">({ handler: setView });\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">});\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>That’s it! That’s all the logic you need to set up your router! ~5 lines of vanilla, use anywhere with anything JavaScript. Write proper links with \u003Ccode>a\u003C/code> tags, and this works, no special components necessary. You need to navigate programmatically? that’s covered, too, with \u003Ccode>navigation.navigate()\u003C/code>, passing in the URL or path you want to navigate to. It’s so straight forward, so simple, so easy (and I really don’t like using those words when describing tech) that writing a wrapping or helper library won’t help ergonomics or understanding. It’s an \u003Cem>excellent\u003C/em> API, and hats off to the group that came up with it.\u003C/p>\n\u003Cp>Now, you’ll be asking, how does this work to actually change the view? Well, from here on out is going to be implementation specific, but the code for Svelte 5 is, again, very straight forward and you should be able to translate it into whatever tool you’re using:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"ts\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// This is a little Svelte 5, a little TypeScript.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// The first thing I'm doing is creating a variable called View that I'm telling Svelte is going to change (the $state Rune) and should be treated a Svelte component.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">let\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> View \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#A6E22E\"> $state\u003C/span>\u003Cspan style=\"color:#F8F8F2\">() \u003C/span>\u003Cspan style=\"color:#F92672\">as\u003C/span>\u003Cspan> \u003C/span>\u003Cspan style=\"color:#A6E22E;text-decoration:underline\">Component\u003C/span>\u003Cspan style=\"color:#F8F8F2\">;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">async\u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\"> function\u003C/span>\u003Cspan style=\"color:#A6E22E\"> setView\u003C/span>\u003Cspan style=\"color:#F8F8F2\">() {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Then, write your logic! For me, I'm starting by splitting the pathname into pieces and removing the first piece, because that'll just be the leading slash and adds noise.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">  const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> parts \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> url.\u003C/span>\u003Cspan style=\"color:#A6E22E\">split\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'/'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  parts.\u003C/span>\u003Cspan style=\"color:#A6E22E\">shift\u003C/span>\u003Cspan style=\"color:#F8F8F2\">();\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">  // Then, I'm looking to see if the user is logged in\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F92672\">  if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (\u003C/span>\u003Cspan style=\"color:#F92672\">!\u003C/span>\u003Cspan style=\"color:#F8F8F2\">user) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // This is the secret sauce dynamic loading patterns, AKA a standard module import. Get the component, set it as the View.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Svelte 5's new Rune based state management means I can set this directly and Svelte knows it needs to run its magic. Different state managers and different frameworks will do this slightly differently, but the logic is the same.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> { default: m } \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F92672\"> await\u003C/span>\u003Cspan style=\"color:#F92672\"> import\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'./admin/Login.svelte'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    View \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> m;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  } \u003C/span>\u003Cspan style=\"color:#F92672\">else\u003C/span>\u003Cspan style=\"color:#F92672\"> if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (parts.length \u003C/span>\u003Cspan style=\"color:#F92672\">===\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // On my index page, in my case, load all of my albums\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> { default: m } \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F92672\"> await\u003C/span>\u003Cspan style=\"color:#F92672\"> import\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'./admin/Albums.svelte'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    View \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> m;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  } \u003C/span>\u003Cspan style=\"color:#F92672\">else\u003C/span>\u003Cspan style=\"color:#F92672\"> if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (parts.length \u003C/span>\u003Cspan style=\"color:#F92672\">===\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // The logic you use here is entirely up to you. It can be more fancy than this, but it can also be this simple. I know that if I've got two items, I'm looking for an album. I've got another state manager called store that's shared between components, so I'm going to store the album from the URL in there, and the Album component will pick that up to load the correct album. I could have also done this in the Album component directly! The world is your oyster.\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> { default: m } \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F92672\"> await\u003C/span>\u003Cspan style=\"color:#F92672\"> import\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'./admin/Album.svelte'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    store.album \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> parts[\u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">];\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    View \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> m;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  } \u003C/span>\u003Cspan style=\"color:#F92672\">else\u003C/span>\u003Cspan style=\"color:#F92672\"> if\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> (parts.length \u003C/span>\u003Cspan style=\"color:#F92672\">===\u003C/span>\u003Cspan style=\"color:#AE81FF\"> 3\u003C/span>\u003Cspan style=\"color:#F8F8F2\">) {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">    // Second verse, same as the first. If I've got three parts, I'm going to store the album and the image in my global store for future reference\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#66D9EF;font-style:italic\">    const\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> { default: m } \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F92672\"> await\u003C/span>\u003Cspan style=\"color:#F92672\"> import\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(\u003C/span>\u003Cspan style=\"color:#E6DB74\">'./admin/Image.svelte'\u003C/span>\u003Cspan style=\"color:#F8F8F2\">);\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    store.album \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> parts[\u003C/span>\u003Cspan style=\"color:#AE81FF\">1\u003C/span>\u003Cspan style=\"color:#F8F8F2\">];\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    store.image \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> parts[\u003C/span>\u003Cspan style=\"color:#AE81FF\">2\u003C/span>\u003Cspan style=\"color:#F8F8F2\">];\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">    View \u003C/span>\u003Cspan style=\"color:#F92672\">=\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> m;\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">  }\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">}\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#88846F\">// The final thing you need to do is call serView when your app runs to get the right view in place. In Svelte 5, the way to do this is through the $effect Rune, but you could call it on DOMContentLoaded, onMount in previous versions of Svelte, or whatever similar lifecycle event your framework has\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">$effect\u003C/span>\u003Cspan style=\"color:#F8F8F2\">(() \u003C/span>\u003Cspan style=\"color:#66D9EF;font-style:italic\">=>\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> {\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#A6E22E\">  setView\u003C/span>\u003Cspan style=\"color:#F8F8F2\">();\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">});\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>That’s it! That’s the whole JS of the router! A few lines of vanilla JS and some blink-and-you’ll-miss-it integrations with a state manager. And with a modern bundler, like Vite, these \u003Ccode>import\u003C/code> routes will be code split (which is why I’m not using a single, dynamic import statement here), giving you the holy grail (from a performance perspective) of SPA routers–a code-split, asynchronous routing system with 0 external dependencies that only weighs bytes, even before the gzipped and minimized size laundering that we use to describe library impact nowadays. And, like I previously said, it’s universal, bring it with you to any tool, any framework you’re using, and never learn another router again, because here we #UseThePlatform.\u003C/p>\n\u003Cp>Oh, there’s one last bit you need to do: actually render your component. While this will vary from framework to framework, implementation to implementation, one of the other reason I’m particularly happy with Svelte 5 here is, because we’ve told Svelte that View is stat that will change, that gets boiled down to this:\u003C/p>\n\u003Cpre class=\"astro-code monokai\" style=\"background-color:#272822;color:#F8F8F2; overflow-x: auto;\" tabindex=\"0\" data-language=\"html\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#F8F8F2\">&#x3C;\u003C/span>\u003Cspan style=\"color:#F44747\">View\u003C/span>\u003Cspan style=\"color:#F8F8F2\"> />\u003C/span>\u003C/span>\u003C/code>\u003C/pre>",{"headings":2032,"localImagePaths":2033,"remoteImagePaths":2034,"frontmatter":2035,"imagePaths":2037},[],[],[],{"title":2023,"published":2036,"summary":2025},"2024-12-23",[]]